<html><head><style>table {border-collapse: collapse;}}</style></head><body><table border="1"><tbody><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1002/pra2.2015.145052010081" target="_blank"> News in an online world: The need for an “automatic crap detector”<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-84987711761</td><td>Year: <b>2015</b></td></tr><tr><td colspan="3">Authors: <b>Chen Y., Conroy N.J., Rubin V.L.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Western Ontario</b></td></tr><tr><td colspan="3">Widespread adoption of internet technologies has changed the way that news is created and consumed. The current online news environment is one that incentivizes speed and spectacle in reporting, at the cost of fact-checking and verification. The line between user generated content and traditional news has also become increasingly blurred. This poster reviews some of the professional and cultural issues surrounding online news and argues for a two-pronged approach inspired by Hemingway's “automatic crap detector” (Manning, 1965) in order to address these problems: a) proactive public engagement by educators, librarians, and information specialists to promote digital literacy practices; b) the development of automated tools and technologies to assist journalists in vetting, verifying, and fact-checking, and to assist news readers by filtering and flagging dubious information.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1002/pra2.2015.145052010082" target="_blank"> Automatic deception detection: Methods for finding fake news<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-84987722728</td><td>Year: <b>2015</b></td></tr><tr><td colspan="3">Authors: <b>Conroy N.J., Rubin V.L., Chen Y.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Western Ontario</b></td></tr><tr><td colspan="3">This research surveys the current state-of-the-art technologies that are instrumental in the adoption and development of fake news detection. “Fake news detection” is defined as the task of categorizing news along a continuum of veracity, with an associated measure of certainty. Veracity is compromised by the occurrence of intentional deceptions. The nature of online news publication has changed, such that traditional fact checking and vetting from potential deception is impossible against the flood arising from content generators, as well as various formats and genres. The paper provides a typology of several varieties of veracity assessment methods emerging from two major categories – linguistic cue approaches (with machine learning), and network analysis approaches. We see promise in an innovative hybrid approach that combines linguistic cue and machine learning, with network-based behavioral data. Although designing a fake news detector is not a straightforward problem, we propose operational guidelines for a feasible fake news detecting system.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1002/pra2.2015.145052010083" target="_blank"> Deception detection for news: Three types of fakes<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-84987753820</td><td>Year: <b>2015</b></td></tr><tr><td colspan="3">Authors: <b>Rubin V.L., Chen Y., Conroy N.J.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Western Ontario</b></td></tr><tr><td colspan="3">A fake news detection system aims to assist users in detecting and filtering out varieties of potentially deceptive news. The prediction of the chances that a particular news item is intentionally deceptive is based on the analysis of previously seen truthful and deceptive news. A scarcity of deceptive news, available as corpora for predictive modeling, is a major stumbling block in this field of natural language processing (NLP) and deception detection. This paper discusses three types of fake news, each in contrast to genuine serious reporting, and weighs their pros and cons as a corpus for text analytics and predictive modeling. Filtering, vetting, and verifying online information continues to be essential in library and information science (LIS), as the lines between traditional news and online information are blurring.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/TMM.2016.2617078" target="_blank"> Novel Visual and Statistical Image Features for Microblogs News Verification<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85013439258</td><td>Year: <b>2017</b></td></tr><tr><td colspan="3">Authors: <b>Jin Z., Cao J., Zhang Y., Zhou J., Tian Q.</b></td></tr><tr><td colspan="3">Organisations: <b>Chinese Academy of Sciences, Capital Normal University, University of Texas at San Antonio</b></td></tr><tr><td colspan="3">Microblog has been a popular media platform for reporting and propagating news. However, fake news spreading on microblogs would severely jeopardize its public credibility. To identify the truthfulness of news on microblogs, images are very crucial content. In this paper, we explore the key role of image content in the task of automatic news verification on microblogs. Existing approaches to news verification depend on features extracted mainly from the text content of news tweets, while image features for news verification are often ignored. According to our study, however, images are very popular and have a great influence on microblogs news propagation. In addition, fake and real news events have different image distribution patterns. Therefore, we propose several visual and statistical features to characterize these patterns visually and statistically for detecting fake news. Experiments on a real-world multimedia dataset collected from Sina Weibo validate the effectiveness of our proposed image features. The news verification performance of our method outperforms baseline methods. To the best of our knowledge, this is the first attempt that systematically explores image features on news verification task.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Rhetorical structure theory as a feature for deception detection in news reports in the Russian language<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85021806697</td><td>Year: <b>2017</b></td></tr><tr><td colspan="3">Authors: <b>Pisarevskaya D.</b></td></tr><tr><td colspan="3">Organisations: <b>Institute for System Programming</b></td></tr><tr><td colspan="3">The framework of the Rhetorical Structure Theory (RST) can be used to reveal the differences between structures of truthful and deceptive (fake) news. This approach was already used for English. In this paper it is applied to Russian. Corpus consists of 134 truthful and deceptive news stories in Russian. Texts annotations contain 33 relation categories. Three data sets of experimental data were created: with only rhetorical relation categories (frequencies), with rhetorical relation categories and bigrams of categories, with rhetorical relation categories and trigrams of categories. Support Vector Machines and Random Forest Classifier were used for text classification. The best results we got by using Support Vector Machines with linear kernel for the first data set (0.65). The model could be used as a preliminary filter for fake news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Online fake news detection algorithm<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85029696193</td><td>Year: <b>2017</b></td></tr><tr><td colspan="3">Authors: <b>Sirajudeen S.M., Azmi N.F.A., Abubakar A.I.</b></td></tr><tr><td colspan="3">Organisations: <b>International Islamic University Malaysia</b></td></tr><tr><td colspan="3">The widespread of online hoax news is increasing rapidly, especially with the vast number of Microblogging sites allowing disseminating distasteful content. This has become vigorous and nearly unstoppable now. Spreading online fake news has been identified as one of the major top concern of online abuse. Due to the difficulty in preventing and evaluating what does fake news contain prior to publishing it online, if an algorithm is known for detecting fake news, then spreading online fake news wouldn’t exist in the first place, lead this paper to presents an evaluation of the effectiveness of algorithm(s), able to detect and filter to reasonable degree of accuracy what constitute an online fake news. The proposed approach is a multi-layered evaluations technique to be built as an app, where all information read online is associated with a tag, given a description of the facts about the contain. A proof of concept is provided for better understanding of the proposed techniques. This has contributed in providing possible steps to be taken by some popular Microblogging sites to stop the widespread of fake news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/SNPD.2017.8022715" target="_blank"> Implementation of emotional features on satire detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85030848543</td><td>Year: <b>2017</b></td></tr><tr><td colspan="3">Authors: <b>Thu P.P., New N.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Computer Studies Mandalay</b></td></tr><tr><td colspan="3">Recognition of satirical language in social multimedia outlets turn out to be a trending research area in computational linguistics. Many researchers have analyzed satirical language from various point of views: lexically, syntactically, and semantically. However, due to the ironic dimension of emotion embedded in satirical language, emotional study of satirical language has ever left behind. In this study, we propose the new emotion-based satire detection model using supervised and unsupervised weighting approaches (TFRF and TFIDF). We implement the model with Ensemble Bagging classifier compared with benchmark classifier: SVM. The model not only outperform the word-based baseline: BoW but also handle both short text and long text configurations. Our work in recognition of satirical language can aid in lessening the impact of implicit language in public opinion mining, sentiment analysis, fake news detection and cyberbullying.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-319-69155-8_9" target="_blank"> Detection of Online Fake News Using N-Gram Analysis and Machine Learning Techniques<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85032711154</td><td>Year: <b>2017</b></td></tr><tr><td colspan="3">Authors: <b>Ahmed H., Traore I., Saad S.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Victoria, University of Windsor</b></td></tr><tr><td colspan="3">Fake news is a phenomenon which is having a significant impact on our social life, in particular in the political world. Fake news detection is an emerging research area which is gaining interest but involved some challenges due to the limited amount of resources (i.e., datasets, published literature) available. We propose in this paper, a fake news detection model that use n-gram analysis and machine learning techniques. We investigate and compare two different features extraction techniques and six different machine classification techniques. Experimental evaluation yields the best performance using Term Frequency-Inverted Document Frequency (TF-IDF) as feature extraction technique, and Linear Support Vector Machine (LSVM) as a classifier, with an accuracy of 92%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Some like it Hoax: Automated fake news detection in social networks<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85033802855</td><td>Year: <b>2017</b></td></tr><tr><td colspan="3">Authors: <b>Tacchini E., Della Vedova M.L., Moret S., de Alfaro L., Ballarin G.</b></td></tr><tr><td colspan="3">Organisations: <b>Università Cattolica, Università Cattolica, École Polytechnique Fédérale de Lausanne, UC</b></td></tr><tr><td colspan="3">In the recent years, the reliability of information on the Internet has emerged as a crucial issue of modern society. Social network sites (SNSs) have revolutionized the way in which information is spread by allowing users to freely share content. As a consequence, SNSs are also increasingly used as vectors for the diffusion of misinformation and hoaxes. The amount of disseminated information and the rapidity of its diffusion make it practically impossible to assess reliability in a timely manner, highlighting the need for automatic online hoax detection systems. As a contribution towards this objective, we show that Facebook posts can be classified with high accuracy as hoaxes or non-hoaxes on the basis of the users who “liked” them. We present two classification techniques, one based on logistic regression, the other on a novel adaptation of boolean crowdsourcing algorithms. On a dataset consisting of 15,500 Facebook posts and 909,236 users, we obtain classification accuracies exceeding 99% even when the training set contains less than 1% of the posts. We further show that our techniques are robust: they work even when we restrict our attention to the users who like both hoax and non-hoax posts. These results suggest that mapping the diffusion pattern of information can be a useful component of automatic hoax detection systems.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-319-70096-0_59" target="_blank"> 3HAN: A Deep Neural Network for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85035092969</td><td>Year: <b>2017</b></td></tr><tr><td colspan="3">Authors: <b>Singhania S., Fernandez N., Rao S.</b></td></tr><tr><td colspan="3">Organisations: <b>International Institute of Information Technology - Bangalore</b></td></tr><tr><td colspan="3">The rapid spread of fake news is a serious problem calling for AI solutions. We employ a deep learning based automated detector through a three level hierarchical attention network (3HAN) for fast, accurate detection of fake news. 3HAN has three levels, one each for words, sentences, and the headline, and constructs a news vector: an effective representation of an input news article, by processing an article in an hierarchical bottom-up manner. The headline is known to be a distinguishing feature of fake news, and furthermore, relatively few words and sentences in an article are more important than the rest. 3HAN gives a differential importance to parts of an article, on account of its three layers of attention. By experiments on a large real-world data set, we observe the effectiveness of 3HAN with an accuracy of 96.77%. Unlike some other deep learning models, 3HAN provides an understandable output through the attention weights given to different parts of an article, which can be visualized through a heatmap to enable further manual fact checking.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3132847.3132877" target="_blank"> CSI: A hybrid deep model for fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85037361396</td><td>Year: <b>2017</b></td></tr><tr><td colspan="3">Authors: <b>Ruchansky N., Seo S., Liu Y.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Southern California</b></td></tr><tr><td colspan="3">The topic of fake news has drawn attention both from the public and the academic communities. Such misinformation has the potential of affecting public opinion, providing an opportunity for malicious parties to manipulate the outcomes of public events such as elections. Because such high stakes are at play, automatically detecting fake news is an important, yet challenging problem that is not yet well understood. Nevertheless, there are three generally agreed upon characteristics of fake news: the text of an article, the user response it receives, and the source users promoting it. Existing work has largely focused on tailoring solutions to one particular characteristic which has limited their success and generality. In this work, we propose a model that combines all three characteristics for a more accurate and automated prediction. Specifically, we incorporate the behavior of both parties, users and articles, and the group behavior of users who propagate fake news. Motivated by the three characteristics, we propose a model called CSI which is composed of three modules: Capture, Score, and Integrate. The first module is based on the response and text; it uses a Recurrent Neural Network to capture the temporal pattern of user activity on a given article. The second module learns the source characteristic based on the behavior of users, and the two are integrated with the third module to classify an article as fake or not. Experimental analysis on real-world data demonstrates that CSI achieves higher accuracy than existing models, and extracts meaningful latent representations of both users and articles.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/UKRCON.2017.8100379" target="_blank"> Fake news detection using naive Bayes classifier<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85039900097</td><td>Year: <b>2017</b></td></tr><tr><td colspan="3">Authors: <b>Granik M., Mesyura V.</b></td></tr><tr><td colspan="3">Organisations: <b>Vinnytsia National Technical University</b></td></tr><tr><td colspan="3">This paper shows a simple approach for fake news detection using naive Bayes classifier. This approach was implemented as a software system and tested against a data set of Facebook news posts. We achieved classification accuracy of approximately 74% on the test set which is a decent result considering the relative simplicity of the model. This results may be improved in several ways, that are described in the article as well. Received results suggest, that fake news detection problem can be addressed with artificial intelligence methods.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.procs.2017.11.106" target="_blank"> The current state of fake news: Challenges and opportunities<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85040242886</td><td>Year: <b>2017</b></td></tr><tr><td colspan="3">Authors: <b>Figueira A., Oliveira L.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Porto, CEOS.PP Polytechnic of Porto</b></td></tr><tr><td colspan="3">The authenticity of Information has become a longstanding issue affecting businesses and society, both for printed and digital media. On social networks, the reach and effects of information spread occur at such a fast pace and so amplified that distorted, inaccurate or false information acquires a tremendous potential to cause real world impacts, within minutes, for millions of users. Recently, several public concerns about this problem and some approaches to mitigate the problem were expressed. In this paper, we discuss the problem by presenting the proposals into categories: content based, source based and diffusion based. We describe two opposite approaches and propose an algorithmic solution that synthesizes the main concerns. We conclude the paper by raising awareness about concerns and opportunities for businesses that are currently on the quest to help automatically detecting fake news by providing web services, but who will most certainly, on the long term, profit from their massive usage.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.18653/v1/P17-2067" target="_blank"> “Liar, liar pants on fire”: A new benchmark dataset for fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85040544441</td><td>Year: <b>2017</b></td></tr><tr><td colspan="3">Authors: <b>Wang W.Y.</b></td></tr><tr><td colspan="3">Organisations: <b>University of California</b></td></tr><tr><td colspan="3">Automatic fake news detection is a challenging problem in deception detection, and it has tremendous real-world political and social impacts. However, statistical approaches to combating fake news has been dramatically limited by the lack of labeled benchmark datasets. In this paper, we present LIAR: a new, publicly available dataset for fake news detection. We collected a decade-long, 12.8K manually labeled short statements in various contexts from POLITIFACT.COM, which provides detailed analysis report and links to source documents for each case. This dataset can be used for fact-checking research as well. Notably, this new dataset is an order of magnitude larger than previously largest public fake news datasets of similar type. Empirically, we investigate automatic fake news detection based on surface-level linguistic patterns. We have designed a novel, hybrid convolutional neural network to integrate metadata with text. We show that this hybrid approach can improve a text-only deep learning model.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/SmartCloud.2017.40" target="_blank"> Automatically Identifying Fake News in Popular Twitter Threads<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85041669389</td><td>Year: <b>2017</b></td></tr><tr><td colspan="3">Authors: <b>Buntain C., Golbeck J.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Maryland</b></td></tr><tr><td colspan="3">Information quality in social media is an increasingly important issue, but web-scale data hinders experts' ability to assess and correct much of the inaccurate content, or 'fake news,' present in these platforms. This paper develops a method for automating fake news detection on Twitter by learning to predict accuracy assessments in two credibility-focused Twitter datasets: CREDBANK, a crowdsourced dataset of accuracy assessments for events in Twitter, and PHEME, a dataset of potential rumors in Twitter and journalistic assessments of their accuracies. We apply this method to Twitter content sourced from BuzzFeed's fake news dataset and show models trained against crowdsourced workers outperform models based on journalists' assessment and models trained on a pooled dataset of both crowdsourced workers and journalists. All three datasets, aligned into a uniform format, are also publicly available. A feature analysis then identifies features that are most predictive for crowdsourced and journalistic accuracy assessments, results of which are consistent with prior work. We close with a discussion contrasting accuracy and credibility and why models of non-experts outperform models of journalists for fake news detection in Twitter.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Fake news detection: Network data from social media used to predict fakes<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85041696530</td><td>Year: <b>2017</b></td></tr><tr><td colspan="3">Authors: <b>Granskogen T., Gulla J.A.</b></td></tr><tr><td colspan="3">Organisations: <b>Norwegian University of Science and Technology</b></td></tr><tr><td colspan="3">Fake news has swept through the media world in the last few years, and with that comes a wish to be able to accurately and automatically detect these fakes such that action can be taken against them. Social network sites are among one of the places where this kind of data are most shared. Using the structure of these sites, we can predict to a high degree if a post is fake or not. We are doing this not by analyzing the contents of the posts, but using the social structure of the site. These social network data mimics the real world where people with similar interests will come together around topics and positions. Using logistic regression and crowd sourcing algorithms, we consolidate previous findings, with prediction accuracy as high as 93 % on datasets consisting from 4200 posts to 15,500. The algorithms show best performance on full datasets.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-658-19567-0_19" target="_blank"> A model of positive and negative learning: Learning demands and resources, learning engagement, critical thinking, and fake news detection<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85043489967</td><td>Year: <b>2017</b></td></tr><tr><td colspan="3">Authors: <b>Dormann C., Demerouti E., Bakker A.</b></td></tr><tr><td colspan="3">Organisations: <b>Johannes Gutenberg University Mainz, University of Technology Eindhoven, Erasmus University Rotterdam</b></td></tr><tr><td colspan="3">This chapter proposes a model of positive and negative learning (PNL model). We use the term negative learning when stress among students occurs, and when knowledge and abilities are not properly developed. We use the term positive learning if motivation is high and active learning occurs. The PNL model proposes that (a) learning-related demands and resources contribute to learning engagement and burnout, (b) that learning engagement improves critical thinking, which (c) should enhance students' abilities to detect fake news. Two studies demonstrate the validity of the learning engagement and burnout constructs, and learning-related demands and resources as possible antecedents. Also, critical thinking mediates the effect of learning engagement on fake news detection. Still, 30.30% of the students believed more in fake news than in real news. We discuss implications of the PNL model for the design of learning conditions.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.26615/978-954-452-049-6_045" target="_blank"> We built a fake news & click-bait filter: What happened next will blow your mind!<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85045767767</td><td>Year: <b>2017</b></td></tr><tr><td colspan="3">Authors: <b>Karadzhov G., Gencheva P., Koychev I., Nakov P.</b></td></tr><tr><td colspan="3">Organisations: <b>Sofia University St. Kliment Ohridski, Qatar Computing Research Institute</b></td></tr><tr><td colspan="3">It is completely amazing! Fake news and click-baits have totally invaded the cyber space. Let us face it: everybody hates them for three simple reasons. Reason #2 will absolutely amaze you. What these can achieve at the time of election will completely blow your mind! Now, we all agree, this cannot go on, you know, somebody has to stop it. So, we did this research on fake news/click-bait detection and trust us, it is totally great research, it really is! Make no mistake. This is the best research ever! Seriously, come have a look, we have it all: neural networks, attention mechanism, sentiment lexicons, author profiling, you name it. Lexical features, semantic features, we absolutely have it all. And we have totally tested it, trust us! We have results, and numbers, really big numbers. The best numbers ever! Oh, and analysis, absolutely top notch analysis. Interested? Come read the shocking truth about fake news and click-bait in the Bulgarian cyber space. You won't believe what we have found!.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3159652.3159677" target="_blank"> Tracing fake-news footprints: Characterizing social media messages by how they propagate<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85046902878</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Wu L., Liu H.</b></td></tr><tr><td colspan="3">Organisations: <b>Arizona State University</b></td></tr><tr><td colspan="3">When a message, such as a piece of news, spreads in social networks, howcanwe classify it into categories of interests, such as genuine or fake news? Classification of social media content is a fundamental task for social media mining, and most existing methods regard it as a text categorization problem and mainly focus on using content features, such as words and hashtags. However, for many emerging applications like fake news and rumor detection, it is very challenging, if not impossible, to identify useful features from content. For example, intentional spreaders of fake news may manipulate the content to make it look like real news. To address this problem, this paper concentrates on modeling the propagation of messages in a social network. Specifically, we propose a novel approach, TraceMiner, to (1) infer embeddings of social media users with social network structures; and (2) utilize an LSTM-RNN to represent and classify propagation pathways of a message. Since content information is sparse and noisy on social media, adopting TraceMiner allows to provide a high degree of classification accuracy even in the absence of content information. Experimental results on real-world datasets show the superiority over state-of-the-art approaches on the task of fake news detection and news categorization.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/BigData.2017.8257971" target="_blank"> Active learning based news veracity detection with feature weighting and deep-shallow fusion<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85047809284</td><td>Year: <b>2017</b></td></tr><tr><td colspan="3">Authors: <b>Das Bhattacharjee S., Talukder A., Balantrapu B.V.</b></td></tr><tr><td colspan="3">Organisations: <b>University of North Carolina</b></td></tr><tr><td colspan="3">The objective of a news veracity detection system is to identify various types of potentially misleading or false information, typically in a digital platform. A critical challenge in this scenario is that there are large volumes of data available online. However, obtaining samples with annotations (i.e. ground-truth labels) is difficult and a known limiting factor for many data analytic tasks including the current problem of news veracity detection. In this paper, we propose a human-machine collaborative learning system to evaluate the veracity of a news content, with a limited amount of annotated data samples. In a semi-supervised scenario, an initial classifier is learnt on a small, limited amount of the annotated data followed by an interactive approach to gradually update the model by shortlisting only relevant samples from the large pool of unlabeled data that are most likely to improve the classifier performance. Our prioritized active learning solution achieves faster convergence in terms of the classification performance, while requiring about 1-2 orders of magnitude fewer annotated samples compared to fully supervised solutions to attain a reasonably acceptable accuracy of nearly 80%. Unlike traditional deep learning architecture, the proposed active learning based deep model designed with a smaller number of more localized filters per layer can efficiently learn from small relevant sample batches that can effectively improve performance in the weakly-supervised learning environment and thus is more suitable for several practical applications. An effective dynamic domain adaptive feature weighting scheme can adjust the relative importance of feature dimensions iteratively. Insightful initial feedback gathered from two independent learning modules (a NLP shallow feature based classifier and a deep classifier), modeled to capture complementary information about data characteristics are finally fused together to achieve an impressive 25% average gain in the detection performance.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.procs.2018.05.132" target="_blank"> Stance-In-Depth Deep Neural Approach to Stance Classification<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85049085373</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Rajendran G., Chitturi B., Poornachandran P.</b></td></tr><tr><td colspan="3">Organisations: <b>Amrita School of Engineering, Amrita Center for Cyber Security and Networks</b></td></tr><tr><td colspan="3">Understanding the user intention from text is a problem of growing interest. The social media like Twitter, Facebook etc. extract user intention to analyze the behaviour of a user which in turn is employed for bot recognition, satire detection, fake news detection etc. The process of identifying stance of a user from the text is called stance detection. This article compares the headline and body pair of a news article and classifies the pair as related or unrelated. The related pair is further classified into agree, disagree, discuss. We call related as detailed classification and unrelated as broad classification. We employ deep neural nets for feature extraction and stance classification. RNN models and its extensions showed significant variations in the classification of detailed class. Bidirectional LSTM model achieved the best accuracy for broad as well as detailed classification.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.12928/TELKOMNIKA.v16i4.9062" target="_blank"> News reliability evaluation using Latent Semantic Analysis<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85049864912</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Xiaoning G., De Zhern T., Fei T.Y., Shuan L.H., King S.W.</b></td></tr><tr><td colspan="3">Organisations: <b>Multimedia University</b></td></tr><tr><td colspan="3">The rapid rise and widespread of 'Fake News' has severe implications in the society today. Much efforts have been directed towards the development of methods to verify news reliability on the Internet in recent years. In this paper, an automated news reliability evaluation system was proposed. The system utilizes term several Natural Language Processing (NLP) techniques such as Term Frequency-Inverse Document Frequency (TF-IDF), Phrase Detection and Cosine Similarity in tandem with Latent Semantic Analysis (LSA). A collection of 9203 labelled articles from both reliable and unreliable sources were collected. This dataset was then applied random test-train split to create the training dataset and testing dataset. The final results obtained shows 81.87% for precision and 86.95% for recall with the accuracy being 73.33%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.2991/ijndc.2018.6.2.3" target="_blank"> Implementation of emotional features on satire detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85050006509</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Thu P.P., Aung T.N.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Computer Studies</b></td></tr><tr><td colspan="3">Recognition of satirical language in social multimedia outlets turns out to be a trending research area in computational linguistics. Many researchers have analyzed satirical language from the various point of views: lexically, syntactically, and semantically. However, due to the ironic dimension of emotion embedded in the language, emotional study of satirical language has ever left behind. This paper proposes the emotion-based detection system for satirical figurative language processing. These emotional features are extracted using emotion lexicon: EmoLex and sentiment lexicon: VADER. Ensemble bagging technique is used to tackle the problem of ambiguous nature of emotion. Experiments are carried out on both short text and long text configurations namely news articles, Amazon product reviews, and tweets. Recognition of satirical language can aid in lessening the impact of implicit language in public opinion mining, sentiment analysis, fake news detection and cyberbullying.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/MIPR.2018.00092" target="_blank"> Understanding User Profiles on Social Media for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85050097165</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Shu K., Wang S., Liu H.</b></td></tr><tr><td colspan="3">Organisations: <b>Arizona State University</b></td></tr><tr><td colspan="3">Consuming news from social media is becoming increasingly popular nowadays. Social media brings benefits to users due to the inherent nature of fast dissemination, cheap cost, and easy access. However, the quality of news is considered lower than traditional news outlets, resulting in large amounts of fake news. Detecting fake news becomes very important and is attracting increasing attention due to the detrimental effects on individuals and the society. The performance of detecting fake news only from content is generally not satisfactory, and it is suggested to incorporate user social engagements as auxiliary information to improve fake news detection. Thus it necessitates an in-depth understanding of the correlation between user profiles on social media and fake news. In this paper, we construct real-world datasets measuring users trust level on fake news and select representative groups of both "experienced" users who are able to recognize fake news items as false and "naïve" users who are more likely to believe fake news. We perform a comparative analysis over explicit and implicit profile features between these user groups, which reveals their potential to differentiate fake news. The findings of this paper lay the foundation for future automatic fake news detection research.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/MIPR.2018.00093" target="_blank"> Media-Rich Fake News Detection: A Survey<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85050149601</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Parikh S.B., Atrey P.K.</b></td></tr><tr><td colspan="3">Organisations: <b>State University of New York</b></td></tr><tr><td colspan="3">Fake News has been around for decades and with the advent of social media and modern day journalism at its peak, detection of media-rich fake news has been a popular topic in the research community. Given the challenges associated with detecting fake news research problem, researchers around the globe are trying to understand the basic characteristics of the problem statement. This paper aims to present an insight on characterization of news story in the modern diaspora combined with the differential content types of news story and its impact on readers. Subsequently, we dive into existing fake news detection approaches that are heavily based on text-based analysis, and also describe popular fake news data-sets. We conclude the paper by identifying 4 key open research challenges that can guide future research.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-319-91521-0_35" target="_blank"> Is It Really Fake? – Towards an Understanding of Fake News in Social Media Communication<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85050567356</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Meinert J., Mirbabaie M., Dungs S., Aker A.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Duisburg-Essen</b></td></tr><tr><td colspan="3">This paper outlines the development of Fake News and seeks to clarify different perspectives regarding the term within Social Media communication. Current information systems, such as Social Media platforms, allow real-time communication, enabling people to produce and spread false information and rumors within a few seconds, potentially reaching a wide audience. This, in turn, could have negative impacts on politics, society, and business. To demystify Fake News and create a common understanding, we analyzed the literature on Fake News and summarized existing articles as well as strategies tested to detect Fake News. We conclude that detection methods mostly perform binary classifications based on linguistic features without providing explanations or further information to the user.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3209978.3210197" target="_blank"> Computational surprise in information retrieval<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85051541709</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Niu X., Zadrozny W., Grace K., Ke W.</b></td></tr><tr><td colspan="3">Organisations: <b>University of North Carolina at Charlotte, University of Sydney, Drexel University</b></td></tr><tr><td colspan="3">The concept of surprise is central to human learning and development. However, compared to accuracy, surprise has received little attention in the IR community, yet it is an essential component of the information seeking process. This workshop brings together researchers and practitioners of IR to discuss the topic of computational surprise, to set a research agenda, and to examine how to build datasets for research into this fascinating topic. The themes in this workshop include discussion of what can be learned from some well-known surprise models in other fields, such as Bayesian surprise; how to evaluate surprise based on user experience; and how computational surprise is related to the newly emerging areas, such as fake news detection, computational contradiction, clickbait detection, etc.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3219819.3219903" target="_blank"> EANN: Event adversarial neural networks for multi-modal fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85051552480</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Wang Y., Ma F., Xun G., Jha K., Su L., Gao J., Jin Z., Yuan Y.</b></td></tr><tr><td colspan="3">Organisations: <b>State University of New York at Buffalo, University of Chinese Academy of Sciences, Beijing University of Technology</b></td></tr><tr><td colspan="3">As news reading on social media becomes more and more popular, fake news becomes a major issue concerning the public and government. The fake news can take advantage of multimedia content to mislead readers and get dissemination, which can cause negative effects or even manipulate the public events. One of the unique challenges for fake news detection on social media is how to identify fake news on newly emerged events. Unfortunately, most of the existing approaches can hardly handle this challenge, since they tend to learn event-specific features that can not be transferred to unseen events. In order to address this issue, we propose an end-to-end framework named Event Adversarial Neural Network (EANN), which can derive event-invariant features and thus benefit the detection of fake news on newly arrived events. It consists of three main components: the multi-modal feature extractor, the fake news detector, and the event discriminator. The multi-modal feature extractor is responsible for extracting the textual and visual features from posts. It cooperates with the fake news detector to learn the discriminable representation for the detection of fake news. The role of event discriminator is to remove the event-specific features and keep shared features among events. Extensive experiments are conducted on multimedia datasets collected from Weibo and Twitter. The experimental results show our proposed EANN model can outperform the state-of-the-art methods, and learn transferable feature representations.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> NewsVallum: Semantics-Aware Text and Image Processing for Fake News Detection system<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85051853672</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Armano G., Carta S.M., Recupero D.R., Battiato S., Bennato D., Ortis A., Boratto L., Noia T.D., Sciascio E.D.</b></td></tr><tr><td colspan="3">Organisations: <b>Università degli studi di Cagliari, Università degli studi di Catania, Centre Tecnológic de Catalunya, Politecnico di Bari</b></td></tr><tr><td colspan="3">As a consequence of the social revolution we faced on the Web, news and information we daily enjoy may come from different and diverse sources which are not necessarily the traditional ones such as newspapers, either in their paper or online version, television, radio, etc. Everyone on the Web is allowed to produce and share news which can soon become viral if they follow the new media channels represented by social networks. This freedom in producing and sharing news comes with a counter-effect: the proliferation of fake news. Unfortunately, they can be very effective and may influence people and, more generally, the public opinion. We propose a combined approach of natural language and image processing that takes into account the semantics encoded within both text and images coming with news together with contextual information that may help in the classification of a news as fake or not.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-319-99954-8_12" target="_blank"> Pattern recognition solutions for fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85054324123</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Choras M., Gielczyk A., Kozik R., Demestichas K., Puchalski D.</b></td></tr><tr><td colspan="3">Organisations: <b>UTP University of Science and Technology, Institute of Communication and Computer Systems - ICCS National Technical University of Athens, ITTI Sp. z o.o.</b></td></tr><tr><td colspan="3">Information is a crucial value nowadays in network digital societies. Therefore, the phenomenon of “fake news” is a serious problem in modern media and communication, e.g. with respect to information spreading within the society about current events and incidents. Fake news are currently a problem for media and broadcasting sector, for citizens, but also for homeland security. In this paper we present and overview the problem of fake news, we show the ideas and solutions for fake news detection, and we present our initial results for one of such approaches based on forged images detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-00671-6_39" target="_blank"> Content based fake news detection using knowledge graphs<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85054793795</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Pan J.Z., Pavlova S., Li C., Li N., Li Y., Liu J.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Aberdeen, Wuhan University</b></td></tr><tr><td colspan="3">This paper addresses the problem of fake news detection. There are many works already in this space; however, most of them are for social media and not using news content for the decision making. In this paper, we propose some novel approaches, including the B-TransE model, to detecting fake news based on news content using knowledge graphs. In our solutions, we need to address a few technical challenges. Firstly, computational-oriented fact checking is not comprehensive enough to cover all the relations needed for fake news detection. Secondly, it is challenging to validate the correctness of the extracted triples from news articles. Our approaches are evaluated with the Kaggle’s ‘Getting Real about Fake News’ dataset and some true articles from main stream media. The evaluations show that some of our approaches have over 0.80 F1-scores.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-01252-6_7" target="_blank"> Fighting Fake News: Image Splice Detection via Learned Self-Consistency<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85055105278</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Huh M., Liu A., Owens A., Efros A.A.</b></td></tr><tr><td colspan="3">Organisations: <b>UC Berkeley, Carnegie Mellon University</b></td></tr><tr><td colspan="3">Advances in photo editing and manipulation tools have made it significantly easier to create fake imagery. Learning to detect such manipulations, however, remains a challenging problem due to the lack of sufficient amounts of manipulated training data. In this paper, we propose a learning algorithm for detecting visual image manipulations that is trained only using a large dataset of real photographs. The algorithm uses the automatically recorded photo EXIF metadata as supervisory signal for training a model to determine whether an image is self-consistent — that is, whether its content could have been produced by a single imaging pipeline. We apply this self-consistency model to the task of detecting and localizing image splices. The proposed method obtains state-of-the-art performance on several image forensics benchmarks, despite never seeing any manipulated images at training. That said, it is merely a step in the long quest for a truly general purpose visual forensics tool.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.23919/FRUCT.2018.8468301" target="_blank"> Automatic online fake news detection combining content and social signals<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85055534632</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Della Vedova M.L., Tacchini E., Moret S., Ballarin G., Dipierro M., De Alfaro L.</b></td></tr><tr><td colspan="3">Organisations: <b>Università Cattolica, École Poly Technique Fédérale, Independent Researcher, DePaul University, UC Santa</b></td></tr><tr><td colspan="3">The proliferation and rapid diffusion of fake news on the Internet highlight the need of automatic hoax detection systems. In the context of social networks, machine learning (ML) methods can be used for this purpose. Fake news detection strategies are traditionally either based on content analysis (i.e. analyzing the content of the news) or-more recently-on social context models, such as mapping the news' diffusion pattern. In this paper, we first propose a novel ML fake news detection method which, by combining news content and social context features, outperforms existing methods in the literature, increasing their already high accuracy by up to 4.8%. Second, we implement our method within a Facebook Messenger chatbot and validate it with a real-world application, obtaining a fake news detection accuracy of 81.7%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Deception detection in news reports in the russian language: Lexics and discourse<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85055580286</td><td>Year: <b>2017</b></td></tr><tr><td colspan="3">Authors: <b>Pisarevskaya D.</b></td></tr><tr><td colspan="3">Organisations: <b>-</b></td></tr><tr><td colspan="3">Different language markers can be used to reveal the differences between structures of truthful and deceptive (fake) news. Two experiments are held: The first one is based on lexics level markers, the second one on discourse level is based on rhetorical relations categories (frequencies). Corpus consists of 174 truthful and deceptive news stories in Russian. Support Vector Machines and Random Forest Classifier were used for text classification. The best results for lexical markers we got by using Support Vector Ma-chines with rbf kernel (f-measure 0.65). The model could be developed and be used as a preliminary filter for fake news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3230348.3230354" target="_blank"> Polarity analysis of editorial articles towards fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85055585408</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Samonte M.J.C.</b></td></tr><tr><td colspan="3">Organisations: <b>Mapua University</b></td></tr><tr><td colspan="3">The need in verifying online information is essential to identify the lines between fake news and factual information. Social media has become the platform for the digital production of news articles. It can be found from various sources - blogs to social networking sites, or even online forums. This indicates how potentially fake news can influence the overall opinion of the masses. This study aims to create a model that categorizes online editorial articles and use different classifier to determine its polarity through sentiment analysis. This is a step first taken in order to detect fake against real news online through data mining. In this study, online news articles from various known websites were extracted in order to develop a model. The researcher demonstrate that news articles can be analyzed and showed effective results through the performance of the classifiers used in this study.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.24963/ijcai.2018/533" target="_blank"> Neural user response generator: Fake news detection with collective user intelligence<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85055684127</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Qian F., Gong C., Sharma K., Liu Y.</b></td></tr><tr><td colspan="3">Organisations: <b>Peking University, University of Southern California</b></td></tr><tr><td colspan="3">Fake news on social media is a major challenge and studies have shown that fake news can propagate exponentially quickly in early stages. Therefore, we focus on early detection of fake news, and consider that only news article text is available at the time of detection, since additional information such as user responses and propagation patterns can be obtained only after the news spreads. However, we find historical user responses to previous articles are available and can be treated as soft semantic labels, that enrich the binary label of an article, by providing insights into why the article must be labeled as fake. We propose a novel Two-Level Convolutional Neural Network with User Response Generator (TCNN-URG) where TCNN captures semantic information from article text by representing it at the sentence and word level, and URG learns a generative model of user response to article text from historical user responses which it can use to generate responses to new articles in order to assist fake news detection. We conduct experiments on one available dataset and a larger dataset collected by ourselves. Experimental results show that TCNN-URG outperforms the baselines based on prior approaches that detect fake news from article text alone.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-02922-7_11" target="_blank"> Social Context-Aware Trust Prediction: Methods for Identifying Fake News<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85055783469</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Ghafari S.M., Yakhchi S., Beheshti A., Orgun M.</b></td></tr><tr><td colspan="3">Organisations: <b>Macquarie University</b></td></tr><tr><td colspan="3">Fake news, a type of yellow journalism or propaganda, consist of false or incorrect information and have the potential to spread very fast on online social networks. This false information is mainly distributed by social actors who has influence in a specific context (e.g., politics or industry) with the intent to mislead in order to damage an entity (e.g., a politician or a product). Identifying fake news is a challenging task and requires analyzing the reliability, truth, or ability (i.e., trust) of social actors in a certain context and to a certain extent. To address this challenge, in this paper, we present a context-aware trust prediction approach which considers the notion of a context (which conceptually refers to any knowledge to specify the condition of an entity) as well as the social actor’s behavior (supported by theories from social psychology) as first class citizens. We present novel algorithms that employ social context factors inspired by social phycology theories and mathematically model our approach based on Tensor Decomposition. We perform an extensive empirical study and present evaluation results on the effectiveness and the quality of the results using real-world datasets.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-02131-3_52" target="_blank"> Raising a model for fake news detection using machine learning in Python<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85055820291</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Agudelo G.E.R., Parra O.J.S., Velandia J.B.</b></td></tr><tr><td colspan="3">Organisations: <b>Universidad Distrital “Francisco José de Caldas”, National University of Colombia</b></td></tr><tr><td colspan="3">Fake news has been spreading in greater numbers and has generated more and more misinformation, one of the clearest examples being the United States presidential elections of 2016, for which a lot of false information was circulated before the votes that improved the image of Donald Trump overs Hilary’s Clinton (Singh et al. n.d.). Because fake news is too much, it becomes necessary to use computational tools to detect them; this is why the use of algorithms of Machine Learning like “CountVectorizer”, “TfidfVectorizer”, a Naive Bayes Model and natural language processing for the identification of false news in public data sets is proposed.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-02922-7_14" target="_blank"> DUAL: A Deep Unified Attention Model with Latent Relation Representations for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85055854713</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Dong M., Yao L., Wang X., Benatallah B., Huang H., Sheng Q.Z.</b></td></tr><tr><td colspan="3">Organisations: <b>University of New South Wales, Macquarie University</b></td></tr><tr><td colspan="3">The prevalence of online social media has enabled news to spread wider and faster than traditional publication channels. The easiness of creating and spreading the news, however, has also facilitated the massive generation and dissemination of fake news. It, therefore, becomes especially important to detect fake news so as to minimize its adverse impact such as misleading people. Despite active efforts to address this issue, most existing works focus on mining news’ content or context information from individuals but neglect the use of clues from multiple resources. In this paper, we consider clues from both news’ content and side information and propose a hybrid attention model to leverage these clues. In particular, we use an attention-based bi-directional Gated Recurrent Units (GRU) to extract features from news content and a deep model to extract hidden representations of the side information. We combine the two hidden vectors resulted from the above extractions into an attention matrix and learn an attention distribution over the vectors. Finally, the distribution is used to facilitate better fake news detection. Our experimental results on two real-world benchmark datasets show our approach outperforms multiple baselines in the accuracy of detecting fake news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/DASC/PiCom/DataCom/CyberSciTec.2018.00042" target="_blank"> Fake news detection enhancement with data imputation<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85056867563</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Kotteti C.M.M., Dong X., Qian L., Li N.</b></td></tr><tr><td colspan="3">Organisations: <b>Texas AandM University System</b></td></tr><tr><td colspan="3">Raw datasets collected for fake news detection usually contain some noise such as missing values. In order to improve the performance of machine learning based fake news detection, a novel data preprocessing method is proposed in this paper to process the missing values. Specifically, we have successfully handled the missing values problem by using data imputation for both categorical and numerical features. For categorical features, we imputed missing values with the most frequent value in the columns. For numerical features, the mean value of the column is used to impute numerical missing values. In addition, TF-IDF vectorization is applied in feature extraction to filter out irrelevant features. Experimental results show that Multi-Layer Perceptron (MLP) classifier with the proposed data preprocessing method outperforms baselines and improves the prediction accuracy by more than 15%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-03928-8_17" target="_blank"> Evaluating deep neural networks for automatic fake news detection in political domain<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85057111412</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Fernandez-Reyes F.C., Shinde S.</b></td></tr><tr><td colspan="3">Organisations: <b>Everis AI digital lab</b></td></tr><tr><td colspan="3">Fake news has become a hot trending topic after the latest U.S. presidential elections when Donald Trump took office. The political speech during the presidential campaign was plagued with half-truths, falsehoods, and click-baits, creating confusion for the voters. Several algorithms have been designed to tackle the automatic fake news detection problem, but some issues still remain uncovered. Some approaches address the problem from a perspective where the website reputation is used as part of their analysis. Typical algorithms take into account text patterns and statistics for automatic fake news detection. Commonly, the fake news detection problem is treated as a multi-class text classifier. This paper proposes several deep neural architectures to classify fake news in the political domain. Furthermore, we demonstrate that combining statements and credibility patterns of politicians are very important for detecting fake news in a deep neural network classifier. We have found that the information about the politician is very useful for any of the tested architectures.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ASONAM.2018.8508520" target="_blank"> Weakly supervised learning for fake news detection on Twitter<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85057305268</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Helmstetter S., Paulheim H.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Mannheim</b></td></tr><tr><td colspan="3">The problem of automatic detection of fake news in social media, e.g., on Twitter, has recently drawn some attention. Although, from a technical perspective, it can be regarded as a straight-forward, binary classification problem, the major challenge is the collection of large enough training corpora, since manual annotation of tweets as fake or non-fake news is an expensive and tedious endeavor. In this paper, we discuss a weakly supervised approach, which automatically collects a large-scale, but very noisy training dataset comprising hundreds of thousands of tweets. During collection, we automatically label tweets by their source, i.e., trustworthy or untrustworthy source, and train a classifier on this dataset. We then use that classifier for a different classification target, i.e., the classification of fake and non-fake tweets. Although the labels are not accurate according to the new classification target (not all tweets by an untrustworthy source need to be fake news, and vice versa), we show that despite this unclean inaccurate dataset, it is possible to detect fake news with an F1 score of up to 0.9.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ASONAM.2018.8508647" target="_blank"> Meta-terrorism: Identifying linguistic patterns in public discourse after an attack<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85057329520</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Kostakos P., Nykanen M., Martinviita M., Pandya A., Oussalah M.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Oulu</b></td></tr><tr><td colspan="3">When a terror-related event occurs, there is a surge of traffic on social media comprising of informative messages, emotional outbursts, helpful safety tips, and rumors. It is important to understand the behavior manifested on social media sites to gain a better understanding of how to govern and manage in a time of crisis. We undertook a detailed study of Twitter during two recent terror-related events: The Manchester attacks and the Las Vegas shooting. We analyze the tweets during these periods using (a) sentiment analysis, (b) topic analysis, and (c) fake news detection. Our analysis demonstrates the spectrum of emotions evinced in reaction and the way those reactions spread over the event timeline. Also, with respect to topic analysis, we find 'echo chambers', groups of people interested in similar aspects of the event. Encouraged by our results on these two event datasets, the paper seeks to enable a holistic analysis of social media messages in a time of crisis.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ASONAM.2018.8508408" target="_blank"> CIMT Detect: A community infused matrix-tensor coupled factorization based method for fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85057343719</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Gupta S., Thirukovalluru R., Mannarswamy S., Sinha M.</b></td></tr><tr><td colspan="3">Organisations: <b>IIIT-Hyderabad, Conduent Labs, Accenture CORE - AI Labs</b></td></tr><tr><td colspan="3">In this paper, we tackle the problem of fake news detection from social media by exploiting the presence of echo chamber communities (communities sharing same beliefs) that exist within the social network of the users. By modeling the echo-chambers as closely-connected communities within the social network, we represent a news article as a 3-mode tensor of the structure - <News, User, Community> and propose a tensor factorization based method to encode the news article in a latent embedding space preserving the community structure. We also propose an extension of the above method, which jointly models the community and content information of the news article through a coupled matrix-tensor factorization framework. We empirically demonstrate the efficacy of our method for the task of Fake News Detection over two real-world datasets.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3274856.3274882" target="_blank"> Overview and categorization of recent approaches to microblog classification<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85058645207</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Mikhailava V., Khaustov V., Klyuev V.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Aizu</b></td></tr><tr><td colspan="3">A growing popularity of microblogs requires scientists to develop methods for effective and efficient analysis of short texts in order to understand opinions of microblog users and the trustworthiness of their messages. In this review, we examine most common approaches to sentiment analysis in microblogs and explain their advantages and weaknesses. We also review approaches to assessing credibility in news headlines and political statements and discuss their applicability in microblogs. Distinct characteristics of microblog posts, such as slang, emoticons, poor grammar and spelling are in the focus of the evaluation. Such properties of microblog messages deteriorate the performance of conventional classifiers and limit their use in practical applications.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.5220/0006898801280135" target="_blank"> The fake news challenge: Stance detection using traditional machine learning approaches<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85059089463</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Masood R., Aker A.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Duisburg-Essen</b></td></tr><tr><td colspan="3">Fake news has caused sensation lately, and this term is the Collins Dictionary Word of the Year 2017. As the news are disseminated very fast in the era of social networks, an automated fact checking tool becomes a requirement. However, a fully automated tool that judges a claim to be true or false is always limited in functionality, accuracy and understandability. Thus, an alternative suggestion is to collaborate a number of analysis tools in one platform which help human fact checkers and normal users produce better judging based on many aspects. A stance detection tool is a first stage of an online challenge that aims to detect fake news. The goal is to determine the relative perspective of a news article towards its title. In this paper, we tackle the challenge of stance detection by utilizing traditional machine learning algorithms along with problem specific feature engineering. Our results show that these models outperform the best outcomes of the participating solutions which mainly use deep learning models.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/CIC.2018.00048" target="_blank"> Hybrid machine-crowd approach for fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85059756495</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Shabani S., Sokhn M.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Basel, University of Applied Sciences Western Switzerland</b></td></tr><tr><td colspan="3">The rapid growth of fake news, especially in social media has become a challenging problem that has negative social impacts on a global scale. In contrast to fake news which intend to deceive and manipulate the reader, satirical stories are designed to entertain the reader by ridiculing or criticizing a social figure. Due to its serious threats of misleading information, researchers, governments, journalists and fact-checking volunteers are working together to address the fake news issue and increase the accountability of digital media. The automatic fake news detection systems enable identification of deceptive news. Low accuracy remains the main drawback of these systems. The automatic detection using only news' content is a technically challenging task as the language used in these articles is made to bypass the fake news detectors. This becomes even more complicated when the task is to differentiate the satirical stories from fake news. On the other side, human cognitive skills have shown to overperform machine-based systems when it comes to such tasks. In this paper, we address the fake news and satire detection by proposing a method that uses a hybrid machine-crowd approach for detection of potentially deceptive news. This system combines the human factor with the machine learning approach and a decision-making model that estimates the classification confidence of algorithms and decides whether the task needs human input or not. Our approach achieves reasonably higher accuracy compared to the reported baseline results, in exchange of cost and latency of using the crowdsourcing service.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/SCEECS.2018.8546944" target="_blank"> Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85059933759</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Jain A., Kasbe A.</b></td></tr><tr><td colspan="3">Organisations: <b>Maulana Azad National Institute of Technology</b></td></tr><tr><td colspan="3">Information preciseness on Internet, especially on social media, is an increasingly important concern, but web-scale data hampers, ability to identify, evaluate and correct such data, or so called "fake news," present in these platforms. In this paper, we propose a method for "fake news" detection and ways to apply it on Facebook, one of the most popular online social media platforms. This method uses Naive Bayes classification model to predict whether a post on Facebook will be labeled as REAL or FAKE. The results may be improved by applying several techniques that are discussed in the paper. Received results suggest, that fake news detection problem can be addressed with machine learning methods.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.cogsys.2018.12.018" target="_blank"> Human-machine interaction: A case study on fake news detection using a backtracking based on a cognitive system<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85060255837</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Ko H., Hong J.Y., Kim S., Mesicek L., Na I.S.</b></td></tr><tr><td colspan="3">Organisations: <b>Chosun University, Hankuk University of Foreign Studies, Sangmyung University, Jan Evangelista Purkyne University</b></td></tr><tr><td colspan="3">Although the Internet provides a variety of news, it also can give confusion caused by personal subjective thoughts such as personal TV, blogs, and unproven news. The unproven news is written in a subjective direction with added personal opinions rather than objective content, so readers may acquire knowledge with the wrong outlook. In addition, fake news is being produced and the problem of social polarization is becoming serious. In the end, it is necessary to detect the fake news, but it is not easy to distinguish the truth of published news because of the lack of fake news distinction time compared to the speed of information sharing on the Internet and the diversity and strong subjectivity of news. Therefore, in this paper, the possibility of fake news is defined by using the reverse-tracking method of the articles which are posted on the Cognitive System. Finally, as the result, the detection rate is average 85%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3297001.3297047" target="_blank"> Can siamese networks help in stance detection?<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85061129532</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Santosh T.Y.S.S., Bansal S., Saha A.</b></td></tr><tr><td colspan="3">Organisations: <b>IIT Kharagpur</b></td></tr><tr><td colspan="3">An important component of fake news detection is to evaluate the stance, different news sources take towards the assertion. Automatic stance detection, would facilitate the process of fact checking. In this paper, we present our stance detection system which comprises of siamese adaptation of Long Short Term Memory (LSTM) networks augmented with an attention mechanism, as siamese adaptation forces the LSTM to entirely capture the semantic differences during training, rather than supplementing the network with a more complex learner that can help resolve shortcomings in the learned representations. Our experiments on a public benchmark dataset, FakeNewsChallenge (FNC), demonstrate the effectiveness of our approach. It focuses on classifying the stance of a news article body relative to a headline as agree, disagree, discuss, or unrelated.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICBK.2018.00017" target="_blank"> Sentiment and semantic deep hierarchical attention neural network for fine grained news classification<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85061357468</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Allaparthi S.T., Yaparla G., Pudi V.</b></td></tr><tr><td colspan="3">Organisations: <b>International Institute of Information Technology-Hyderabad</b></td></tr><tr><td colspan="3">The purpose of this study is to examine the differences between different types of news stories. Given the huge impact of social networks, online content plays an important role in forming or changing the opinions of people. Unlike traditional journalism where only certain news organizations can publish content, online journalism has given chance even for individuals to publish. This has its own advantages like individual empowerment but has given a chance to a lot of malicious entities to spread misinformation for their own benefit. As reported by many organizations in recent history, this even has influence on major events like the outcome of elections. Therefore, it is of great importance now, to have some sort of automated classification of news stories. In this work, we propose a deep hierarchical attention neural architecture combining sentiment and semantic embeddings for more accurate fine grained classification of news stories. Experimental results show that the sentiment embedding along with semantic information outperform several state-of-the-art methods in this task.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3289600.3291382" target="_blank"> Fake News: Fundamental theories, detection strategies and challenges<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85061693900</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Zhou X., Zafarani R., Shu K., Liu H.</b></td></tr><tr><td colspan="3">Organisations: <b>Syracuse University, Arizona State University</b></td></tr><tr><td colspan="3">The explosive growth of fake news and its erosion to democracy, justice, and public trust increased the demand for fake news detection. As an interdisciplinary topic, the study of fake news encourages a concerted effort of experts in computer and information science, political science, journalism, social science, psychology, and economics. A comprehensive framework to systematically understand and detect fake news is necessary to attract and unite researchers in related areas to conduct research on fake news. This tutorial aims to clearly present (1) fake news research, its challenges, and research directions; (2) a comparison between fake news and other related concepts (e.g., rumours); (3) the fundamental theories developed across various disciplines that facilitate interdisciplinary research; (4) various detection strategies unified under a comprehensive framework for fake news detection; and (5) the state-of-the-art datasets, patterns, and models. We present fake news detection from various perspectives, which involve news content and information in social networks, and broadly adopt techniques in data mining, machine learning, natural language processing, information retrieval and social search. Facing the upcoming 2020 U.S. presidential election, challenges for automatic, effective and efficient fake news detection are also clarified in this tutorial.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3289600.3290994" target="_blank"> Beyond news contents: The role of social context for fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85061758760</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Shu K., Liu H., Wang S.</b></td></tr><tr><td colspan="3">Organisations: <b>Arizona State University, Penn State University</b></td></tr><tr><td colspan="3">Social media is becoming popular for news consumption due to its fast dissemination, easy access, and low cost. However, it also enables the wide propagation of fake news, i.e., news with intentionally false information. Detecting fake news is an important task, which not only ensures users receive authentic information but also helps maintain a trustworthy news ecosystem. The majority of existing detection algorithms focus on finding clues from news contents, which are generally not effective because fake news is often intentionally written to mislead users by mimicking true news. Therefore, we need to explore auxiliary information to improve detection. The social context during news dissemination process on social media forms the inherent tri-relationship, the relationship among publishers, news pieces, and users, which has potential to improve fake news detection. For example, partisan-biased publishers are more likely to publish fake news, and low-credible users are more likely to share fake news. In this paper, we study the novel problem of exploiting social context for fake news detection. We propose a tri-relationship embedding framework TriFN, which models publisher-news relations and user-news interactions simultaneously for fake news classification. We conduct experiments on two real-world datasets, which demonstrate that the proposed approach significantly outperforms other baseline methods for fake news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Review spam criteria for enhancing a review spam detector<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85062504240</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Wijnhoven F., Pieper A.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Twente</b></td></tr><tr><td colspan="3">When making purchasing decisions, customers increasingly rely on opinions posted on the Internet. Businesses, therefore, have an incentive to promote their own products or demote competitors' products by creating positive or negative spam reviews on platforms like Amazon.com. Several researchers propose methods and tools to detect review spam automatically. This research proposes a framework for detecting review spam by extending Reviewskeptic (which is a text-based hotel review spam detector) with reviewer behavior-related and time-related criteria. The new spam detector is called ReviewAlarm. A ground of truth dataset has been created by the means of a manual assessment and has been used to compare the performance of Reviewskeptic and ReviewAlarm on this dataset. With ReviewAlarm we are able to improve the performance of the tool on our dataset. However, this research also reveals several weaknesses about the criteria that are being used in review spam detection. Therefore, we argue that additional reviewer behavior research is needed for finding better tools and more generalizable criteria. We believe that these insights give important directions for fake news detection methods.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/DSAA.2018.00082" target="_blank"> SeCredISData 2018: Special session on sentiment, emotion, and credibility of information in social data<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85062843641</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Benamara F., Bosco C., Patti V., Fersini E., Pasi G., Viviani M.</b></td></tr><tr><td colspan="3">Organisations: <b>Paul Sabatier University, University of Turin, University of Milano-Bicocca</b></td></tr><tr><td colspan="3">The Social Web represents nowadays the principal means to support and foster social interactions among people through Web 2.0 technologies. Individuals interact in virtual communities to pursue mutual interests or goals, by exchanging multiple kinds of contents (i.e., textual, acoustic, visual), the so-called User-Generated Content (UGC). In this context, the SeCredISData Special Session is especially devoted at discussing the implications that the analysis of big social data has in tackling open issues related to society from different perspectives. On one side, there is the need to push forward the research on emotion and sentiment, and the investigation of affective cognitive models and their possible integration into intelligent systems. On the other side, it is urgent to address the issue of on-line information credibility assessment, in an era where trusted intermediaries have disappeared and people must rely only on their cognitive capacities to judge information. The Special Session is therefore aimed at promoting the development of models and applications able to tackle these issues.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/DSAA.2018.00036" target="_blank"> Forecasting retweet count during elections using graph convolution neural networks<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85062857530</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Vijayan R., Mohler G.</b></td></tr><tr><td colspan="3">Organisations: <b>Purdue University Indianapolis</b></td></tr><tr><td colspan="3">A retweet refers to sharing a tweet posted by another user on Twitter and is primary way information spreads on the Twitter network. Political parties use Twitter extensively as a part of their campaign to promote their presence, announce their propaganda, and at times debating with opponents. In this work we consider the problem of early prediction of the final retweet count using information from the network during the first several minutes after a post is made. Such predictions are useful for ranking and promoting posts and also can be used in combination with fake news detection. From a machine learning perspective, the task can be viewed as a regression problem. We introduce a novel graph convolution neural network for forecasting retweet count that combines network level features through graph convolution layers as well as tweet level features at a higher dense layer in the network. We first will provide an overview of the graph convolution network architecture and then perform several experiments on Twitter data collected during presidential elections in South Africa (2014) and Kenya (2013). We show that the model outperforms baseline models including a feed forward neural network and the popular point process based model SEISMIC.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.ipm.2019.03.004" target="_blank"> An overview of online fake news: Characterization, detection, and discussion<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85063107606</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Zhang X., Ghorbani A.A.</b></td></tr><tr><td colspan="3">Organisations: <b>University of New Brunswick (UNB)</b></td></tr><tr><td colspan="3">Over the recent years, the growth of online social media has greatly facilitated the way people communicate with each other. Users of online social media share information, connect with other people and stay informed about trending events. However, much recent information appearing on social media is dubious and, in some cases, intended to mislead. Such content is often called fake news. Large amounts of online fake news has the potential to cause serious problems in society. Many point to the 2016 U.S. presidential election campaign as having been influenced by fake news. Subsequent to this election, the term has entered the mainstream vernacular. Moreover it has drawn the attention of industry and academia, seeking to understand its origins, distribution and effects. Of critical interest is the ability to detect when online content is untrue and intended to mislead. This is technically challenging for several reasons. Using social media tools, content is easily generated and quickly spread, leading to a large volume of content to analyse. Online information is very diverse, covering a large number of subjects, which contributes complexity to this task. The truth and intent of any statement often cannot be assessed by computers alone, so efforts must depend on collaboration between humans and technology. For instance, some content that is deemed by experts of being false and intended to mislead are available. While these sources are in limited supply, they can form a basis for such a shared effort. In this survey, we present a comprehensive overview of the finding to date relating to fake news. We characterize the negative impact of online fake news, and the state-of-the-art in detection methods. Many of these rely on identifying features of the users, content, and context that indicate misinformation. We also study existing datasets that have been used for classifying fake news. Finally, we propose promising research directions for online fake news analysis.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.18653/v1/p18-1022" target="_blank"> A stylometric inquiry into hyperpartisan and fake news<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85063109511</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Potthast M., Kiesel J., Reinartz K., Bevendorff J., Stein B.</b></td></tr><tr><td colspan="3">Organisations: <b>Leipzig University, Bauhaus-Universität Weimar</b></td></tr><tr><td colspan="3">We report on a comparative style analysis of hyperpartisan (extremely one-sided) news and fake news. A corpus of 1,627 articles from 9 political publishers, three each from the mainstream, the hyperpartisan left, and the hyperpartisan right, have been fact-checked by professional journalists at BuzzFeed: 97% of the 299 fake news articles identified are also hyperpartisan. We show how a style analysis can distinguish hyperpartisan news from the mainstream (F1 = 0.78), and satire from both (F1 = 0.81). But stylometry is no silver bullet as style-based fake news detection does not work (F1 = 0.46). We further reveal that left-wing and right-wing news share significantly more stylistic similarities than either does with the mainstream. This result is robust: it has been confirmed by three different modeling approaches, one of which employs Unmasking in a novel way. Applications of our results include partisanship detection and pre-screening for semi-automatic fake news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICCES.2018.8639198" target="_blank"> Deep Learning Algorithms for Detecting Fake News in Online Text<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85063161783</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Girgis S., Gadallah M., Amer E.</b></td></tr><tr><td colspan="3">Organisations: <b>Modern Academy for Computer Science and Management Technology, Misr International University</b></td></tr><tr><td colspan="3">Spreading of fake news is a social phenomenon that is pervasive at the social level between individuals, and also through social media such as Facebook and Twitter. Fake news that we are interested in is one of many kinds of deception in social media, but it's more important one as it is created with dishonest intention to mislead people. We are concerned about this issue because we have noticed that this phenomenon has recently caused through the means of social communication to change the course of society and peoples and also their views, for example, during revolutions in some Arab countries have emerged some false news that led to the absence of truth and stirs up public opinion and also fake of news is one of the factors Trump successes in the presidential election. So we decided to face and reduce this phenomenon, which is still the main factor to choose most of our decisions. Techniques of fake news detection varied, ingenious, and often exciting. In this paper our objective is to build a classifier that can predict whether a piece of news is fake or not based only its content, thereby approaching the problem from a purely deep learning perspective by RNN technique models (vanilla, GRU) and LSTMs. We will show the difference and analysis of results by applying them to the dataset that we used called LAIR. We found that the results are close, but the GRU is the best of our results that reached (0.217) followed by LSTM (0.2166) and finally comes vanilla (0.215). Due to these results, we will seek to increase accuracy by applying a hybrid model between the GRU and CNN techniques on the same data set.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/TENCON.2018.8650350" target="_blank"> FaNDeR: Fake News Detection Model Using Media Reliability<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85063205582</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Seo Y., Jeong C.-S., Seo D.</b></td></tr><tr><td colspan="3">Organisations: <b>Korea University, Nuua</b></td></tr><tr><td colspan="3">With the development of media including newspaper written by robots and many unreliable sources, it's getting hard to distinguish whether the news is true or not. In this paper, we shall present a novel fake news detection model, FaNDeR(Fake News Detection model using media Reliability) which can efficiently classify the level of truth for the news in the question answering system based on modified CNN deep learning model. Our model reflects the reliability of various medias by training with the input dataset which contains the truthfulness of each media as well as that of the proposition. Our model is designed for higher accuracy with media dataset in terms of data augmentation, batch size control and model modification. We shall show that our model has higher accuracy over statistical approach by reflecting the tendency of truth level for each media through the training of the dataset collected so far.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICIEV.2018.8641018" target="_blank"> Fake news pattern recognition using linguistic analysis<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85063222633</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Dey A., Rafi R.Z., Hasan Parash S., Arko S.K., Chakrabarty A.</b></td></tr><tr><td colspan="3">Organisations: <b>BRAC University</b></td></tr><tr><td colspan="3">In the wake of the 2016 US Presidential Election, the upsurge of fake news has been a subject of increased discussion and debate. In this paper, we propose a general framework that can been adopted in future elections worldwide to augment humans in making better decisions when it comes to recognizing news deception and identifying hidden bias of the author. For our study, we constructed a dataset comprising 200 tweets on »Hilary Clinton», while performing veracity assessment. We initially perform »text normalization» on tweets, explore techniques for feature extraction to classify news into categories, perform a comprehensive linguistic analysis on tweets, extract bag-of-words to find noticeable pattern, and finally apply k-nearest neighbor algorithm for classifying polarized news from credible. We later turn to some popular evaluation metrics to quantify the success rate of our framework, discuss the results of implementing knn algorithm and discuss interconnected research domains and future research directions for constructing an ideal model for fake news detection system around social media.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s10588-018-09280-3" target="_blank"> FakeNewsTracker: a tool for fake news collection, detection, and visualization<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85063376271</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Shu K., Mahudeswaran D., Liu H.</b></td></tr><tr><td colspan="3">Organisations: <b>Arizona State University</b></td></tr><tr><td colspan="3">Nowadays social media is widely used as the source of information because of its low cost, easy to access nature. However, consuming news from social media is a double-edged sword because of the wide propagation of fake news, i.e., news with intentionally false information. Fake news is a serious problem because it has negative impacts on individuals as well as society large. In the social media the information is spread fast and hence detection mechanism should be able to predict news fast enough to stop the dissemination of fake news. Therefore, detecting fake news on social media is an extremely important and also a technically challenging problem. In this paper, we present FakeNewsTracker, a system for fake news understanding and detection. As we will show, FakeNewsTracker can automatically collect data for news pieces and social context, which benefits further research of understanding and predicting fake news with effective visualization techniques.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1117/12.2522679" target="_blank"> NLP based sentiment analysis for Twitter's opinion mining and visualization<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85063444733</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Al-Ghalibi M., Lawonn K., Al-Azzawi A.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Koblenz-Landau, University of Missouri</b></td></tr><tr><td colspan="3">In many of today's big data analytics applications, it might need to analyze social media feeds as well as to visualize users' opinions. This will provide a viable alternative source to establish new metrics in our digital life. Social interaction with people in Twitter is open-ended, making media analysis in Twitter easier in comparison with other social media. That is because the interaction in those media is often different since most of them are private. This work is therefore devoted to focus merely on Twitter and deemed to be within the confines of Data Mining. It is concerned with Natural Language Processing (NLP)-based sentiment analysis for Twitter's opinion mining. As such, the objective of this work is to use a data mining approach of text-feature extraction, classification, and dimensionality reduction, using sentiment analysis to analyze and visualize Twitter users' opinion. The utilized methodology is based on applying sentiment analysis NLP on a large number of tweets in order to get word scoring of the tweet and thus to exploit public tweeting for knowledge discovery. This will moreover serve for fake news detection. The pertinent mechanism involves several consecutive steps, namely: dataset collection stage, the pre-processing stage, NLP stage, sentiment analysis stage, and prediction and classification stage using BNN. The U.S. Airlines Sentiment Analysis Twitter dataset has been utilized which is already provided with Data for Everyone. The presented system is monitoring Twitter streams from both the media and the public. It is capable to extract meaningful data from tweets in real-time and store them into a relational model for analysis. And then use our dimension reduction method. This will help people discover the correlation of the leading role between them, which also reflects news media's focuses and people's interests. This system has proved better results with respect to accuracy and efficiency in comparison with some other similar works. It is convenient for a wide application spectrum involving: big data analytics solutions, predicting e-commerce customer's behavior, improving marketing strategy, getting market competitive advantages, besides visualization in various data mining applications.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.eswa.2019.03.036" target="_blank"> Behind the cues: A benchmarking study for fake news detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85063508692</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Gravanis G., Vakali A., Diamantaras K., Karadais P.</b></td></tr><tr><td colspan="3">Organisations: <b>Aristotle University of Thessaloniki, A.T.E.I. of Thessaloniki</b></td></tr><tr><td colspan="3">Fake news has become a problem of great impact in our information driven society because of the continuous and intense fakesters content distribution. Information quality in news feeds is under questionable veracity calling for automated tools to detect fake news articles. Due to many faces of fakesters, creating such tool is a challenging problem. In this work, we propose a model for fake news detection using content based features and Machine Learning (ML) algorithms. To conclude in most accurate model we evaluate several feature sets proposed for deception detection and word embeddings as well. Moreover, we test the most popular ML classifiers and investigate the possible improvement reached under ensemble ML methods such as AdaBoost and Bagging. An extensive set of earlier data sources has been used for experimentation and evaluation of both feature sets and ML classifiers. Moreover, we introduce a new text corpus, the “UNBiased” (UNB) dataset, which integrates various news sources and fulfills several standards and rules to avoid biased results in classification task. Our experimental results show that the use of an enhanced linguistic feature set with word embeddings along with ensemble algorithms and Support Vector Machines (SVMs) is capable to classify fake news with high accuracy.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICSESS.2018.8663864" target="_blank"> FAMOUS: Fake News Detection Model Based on Unified Key Sentence Information<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85063605998</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Kim N., Jeong C.-S., Seo D.</b></td></tr><tr><td colspan="3">Organisations: <b>Korea University, _</b></td></tr><tr><td colspan="3">Fake news detection causes a challenging problem due to the great influence of communication media over the public. In this paper, we shall present a new fake news detection model using unified key sentence information which can efficiently perform sentence matching between question and article by using key sentence retrieval based on bilateral multi perspective matching model. Our model makes use of one unified word vector for the key sentences of article by extracting them to the question from article and then merging the word vector for each key sentence. It can efficiently perform the sentence matching by executing matching operations between the contextual information obtained from the word vectors of question and key sentences through bidirectional long short term memory. Our model shows the competitive performance for fake news detection on the Korean article dataset over the previous result.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1002/pra2.2018.14505501100" target="_blank"> Comparing features of fabricated and legitimate political news in digital environments (2016-2017)<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85064484129</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Asubiaro T.V., Rubin V.L.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Western Ontario</b></td></tr><tr><td colspan="3">With the problem of ‘fake news’ in the digital media, there are efforts at creation of awareness, automation of ‘fake news’ detection and news literacy. This research is descriptive as it pulls evidence from the content of online fabricated news for the features that distinguish fabrications from the legitimate political news around the time of the U.S. Presidential Elections (276 articles in total, from November 2016 - June 2017). Certain stylistic and psycho-linguistic features of fabrications may be apparent to the news readers: fewer words and paragraphs but longer paragraphs, more slangs, swear words and affective words in the stories. Such features could be used for educational information literacy campaigns for spotting so-called ‘fake news’. Other informative features may require specialized analytical tools (or further training) to notice the presence of more words, punctuation marks, demonstratives and emotiveness in fabrications but fewer verifiable facts (or named entities) in their headlines.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1002/pra2.2018.14505501125" target="_blank"> Towards automatic fake news classification<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85064496126</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Ghosh S., Shah C.</b></td></tr><tr><td colspan="3">Organisations: <b>Rutgers University</b></td></tr><tr><td colspan="3">The interaction of technology with humans has many adverse effects. The rapid growth and outreach of the social media and the Web have led to the dissemination of questionable and untrusted content among a wider audience, which has negatively influenced their lives and judgment. Many research studies have been conducted to tackle the detection and spreading of fake news, which is misinformation that looks genuine. While the first step of such tasks would be to classify claims associated based on their credibility, the next steps would involve identifying hidden patterns in style, syntax, and content of such news claims. We propose a generalized method based on Deep Neural Networks to detect if a given claim is fake or genuine. We have used a modular approach by combining techniques from information retrieval, natural language processing, and deep learning. Our classifier comprises two main submodules. The first submodule uses the claim to retrieve relevant articles from the knowledge base which can then be used to verify the truth of the claim. It also uses word-level features for prediction. The second submodule uses a deep neural network to learn the underlying style of fake content. Our experiments conducted on benchmark datasets show that for the given classification task we can obtain up to 82.4% accuracy by using a combination of two models; the first model was up to 72% accurate while the second model was around 81% accurate. Our detection model has the potential to automatically detect and prevent the spread of fake news, thus, limiting the caustic influence of technology in the human lives.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1002/pra2.2018.14505501116" target="_blank"> Educators' perceptions of information literacy and skills required to spot ‘fake news’<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85064506416</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Delellis N.S., Rubin V.L.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Western Ontario</b></td></tr><tr><td colspan="3">This research examines the concept of ‘fake news’ in the context of information literacy (IL) in a post-secondary educational setting. Educators' perceptions shape both IL curricula and classroom discussions with students. We conducted 18 interviews with members of 3 integral groups implementing IL education (8 professors, 6 librarians, 4 department chairs). Interviews explored participants' perceptions of: IL education, perceived skills associated with IL, skills required to spot ‘fake news’, and gauged our participants' willingness to incorporate segments dedicated to detecting ‘fake news’ in IL curriculum. Our qualitative findings identify a substantial overlap that exists between skills associated with IL and ‘fake news’ detection (e.g., close-reading, critical disposition, bias awareness). Professors and academic administrators also appeared to underappreciate the role of librarians as IL educators. We advocate improving communication among integral facilitators of IL education. More research is needed to assess effectiveness of IL education as an ‘inoculation’ against ‘fake news.‘.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3305260" target="_blank"> Combating fake news: A survey on identification and mitigation techniques<a></b></td></tr><tr><td>Type: Review</td><td>ID: S_2-s2.0-85064656517</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Sharma K., Qian F., Jiang H., Ruchansky N., Liu Y., Zhang M.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Southern California, Peking University</b></td></tr><tr><td colspan="3">The proliferation of fake news on social media has opened up new directions of research for timely identification and containment of fake news and mitigation of its widespread impact on public opinion. While much of the earlier research was focused on identification of fake news based on its contents or by exploiting users' engagements with the news on social media, there has been a rising interest in proactive intervention strategies to counter the spread of misinformation and its impact on society. In this survey, we describe the modern-day problem of fake news and, in particular, highlight the technical challenges associated with it. We discuss existing methods and techniques applicable to both identification and mitigation, with a focus on the significant advances in each method and their advantages and limitations. In addition, research has often been limited by the quality of existing datasets and their specific application contexts. To alleviate this problem, we comprehensively compile and summarize characteristic features of available datasets. Furthermore, we outline new directions of research to facilitate future development of effective and interdisciplinary solutions.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3313991.3314008" target="_blank"> Multi-label fake news detection using multi-layered supervised learning<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85064666138</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Rasool T., Butt W.H., Shaukat A., Akram M.U.</b></td></tr><tr><td colspan="3">Organisations: <b>National University of Sciences and Technology</b></td></tr><tr><td colspan="3">Rapid spreading of misinformation is a growing worldwide concern as it has the capacity to greatly influence individual reputation and societal behavior. The consequences of unchecked spreading of misinformation can not only vary from political to financial but also effect global opinion for a long time. Thus, detecting fake news is important but challenging as the ability to accurately categorize certain information as true or fake is limited even in human. Moreover, fake news are a blend of correct news and false information making accurate classification even more confusing. In this paper, we propose a novel method of multilevel multiclass fake news detection based on relabeling of the dataset and learning iteratively. The proposed method outperforms the benchmark and our experiments indicate that profile of the source of information contributes the most in fake news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.5220/0007566307940800" target="_blank"> Fake news detection via NLP is vulnerable to adversarial attacks<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85064814138</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Zhou Z., Guan H., Bhat M.M., Hsu J.</b></td></tr><tr><td colspan="3">Organisations: <b>Wuhan University, University of Wisconsin-Madison</b></td></tr><tr><td colspan="3">News plays a significant role in shaping people's beliefs and opinions. Fake news has always been a problem, which wasn't exposed to the mass public until the past election cycle for the 45th President of the United States. While quite a few detection methods have been proposed to combat fake news since 2015, they focus mainly on linguistic aspects of an article without any fact checking. In this paper, we argue that these models have the potential to misclassify fact-tampering fake news as well as under-written real news. Through experiments on Fakebox, a state-of-the-art fake news detector, we show that fact tampering attacks can be effective. To address these weaknesses, we argue that fact checking should be adopted in conjunction with linguistic characteristics analysis, so as to truly separate fake news from real news. A crowdsourced knowledge graph is proposed as a straw man solution to collecting timely facts about news events.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Combining machine learning with knowledge engineering to detect fake news in social networks - A survey<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85064994520</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Ahmed S., Corradini F., Hinkelmann K.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Camerino, FHNW University of Applied Sciences and Arts Northwestern Switzerland</b></td></tr><tr><td colspan="3">Due to extensive spread of fake news on social and news media it became an emerging research topic now a days that gained attention. In the news media and social media the information is spread high-speed but without accuracy and hence detection mechanism should be able to predict news fast enough to tackle the dissemination of fake news. It has the potential for negative impacts on individuals and society. Therefore, detecting fake news on social media is important and also a technically challenging problem these days. We knew that Machine learning is helpful for building Artificial intelligence systems based on tacit knowledge because it can help us to solve complex problems due to real word data. On the other side we knew that Knowledge engineering is helpful for representing expert‟s knowledge which people aware of that knowledge. Due to this we proposed that integration of Machine learning and knowledge engineering can be helpful in detection of fake news. In this paper we present what is fake news, importance of fake news, overall impact of fake news on different areas, different ways to detect fake news on social media, existing detections algorithms that can help us to overcome the issue, similar application areas and at the end we proposed combination of data driven and engineered knowledge to combat fake news. We studied and compared three different modules text classifiers, stance detection applications & fact checking existing techniques that can help to detect fake news. Furthermore, we investigated the impact of fake news on society. Experimental evaluation of publically available datasets and our proposed fake news detection combination can serve better in detection of fake news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/MIS.2019.2899143" target="_blank"> Supervised Learning for Fake News Detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85065563581</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Reis J.C.S., Correia A., Murai F., Veloso A., Benevenuto F., Cambria E.</b></td></tr><tr><td colspan="3">Organisations: <b>Universidade Federal de Minas Gerais, Nanyang Technological University</b></td></tr><tr><td colspan="3">A large body of recent works has focused on understanding and detecting fake news stories that are disseminated on social media. To accomplish this goal, these works explore several types of features extracted from news stories, including source and posts from social media. In addition to exploring the main features proposed in the literature for fake news detection, we present a new set of features and measure the prediction performance of current approaches and features for automatic detection of fake news. Our results reveal interesting findings on the usefulness and importance of features for detecting false news. Finally, we discuss how fake news detection approaches can be used in the practice, highlighting challenges and opportunities.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/MIPR.2019.00088" target="_blank"> High Dimensional Latent Space Variational AutoEncoders for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85065603771</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Sadiq S., Wagner N., Shyu M.-L., Feaster D.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Miami, University of Miami</b></td></tr><tr><td colspan="3">With the advent of social media and cell phones, news is now far more reaching and impactful than ever before. This comes with the exponential increase in fake news that blurs the lines of reality and holds the power to sway public opinion. To counter the impact of fake news, several research groups have developed novel algorithms that could fact check news as a human would do. Unfortunately, natural language processing (NLP) is a complicated task because of the underlying hidden meanings in human communication. In this paper, we propose a novel method that builds a latent representation of natural language to capture its underlying hidden meanings accurately and classify fake news. Our approach connects the high-level semantic concepts in the news content with their low-level deep representations so that the complex news text consisting of satire, sarcasm, and purposeful misleading content can be translated into quantifiable latent spaces. This allows us to achieve very high accuracy, surpassing the scores of all winners of the fake news challenge.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/MIPR.2019.00031" target="_blank"> On the Origin, Proliferation and Tone of Fake News<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85065625545</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Parikh S.B., Patil V., Atrey P.K.</b></td></tr><tr><td colspan="3">Organisations: <b>State University of New York</b></td></tr><tr><td colspan="3">Since the advent of social media, we have turned towards consuming news from stand-alone websites to popular social media sites (i.e. Facebook, Twitter, Reddit, etc.); we have noticed a growing number of fake news articles spread across the internet. Existing methods for fake news detection mainly focus on natural language processing and machine learning models to analyze the legitimacy of the news content in order to detect whether it is legit or fake. Currently, there are not many approaches aimed at testing, validating, and ideally refining the findings from traditional fake news detection literature as obtained via surveys and understanding how fake news originate and spread in first place. This paper presents three crucial hypotheses studies that are derived from analyses like, 1) media outlets that publish fake news (origin), 2) social media users who post or share fake news (proliferation), and 3) linguistic (tone) in which fake news are written. The hypotheses are tested on two real-world datasets and results are provided. We envision that this study paves the way to design and develop new multifarious fusion models to detect fake news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.ins.2019.05.035" target="_blank"> A survey on fake news and rumour detection techniques<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85065786362</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Bondielli A., Marcelloni F.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Pisa, University of Florence</b></td></tr><tr><td colspan="3">False or unverified information spreads just like accurate information on the web, thus possibly going viral and influencing the public opinion and its decisions. Fake news and rumours represent the most popular forms of false and unverified information, respectively, and should be detected as soon as possible for avoiding their dramatic effects. The interest in effective detection techniques has been therefore growing very fast in the last years. In this paper we survey the different approaches to automatic detection of fake news and rumours proposed in the recent literature. In particular, we focus on five main aspects. First, we report and discuss the various definitions of fake news and rumours that have been considered in the literature. Second, we highlight how the collection of relevant data for performing fake news and rumours detection is problematic and we present the various approaches, which have been adopted to gather these data, as well as the publicly available datasets. Third, we describe the features that have been considered in fake news and rumour detection approaches. Fourth, we provide a comprehensive analysis on the various techniques used to perform rumour and fake news detection. Finally, we identify and discuss future directions.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.3233/JIFS-179034" target="_blank"> Detection of fake news in a new corpus for the Spanish language<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85066450814</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Posadas-Duran J.-P., Escobar J.J.M., Gomez-Adorno H., Sidorov G.</b></td></tr><tr><td colspan="3">Organisations: <b>Escuela Superior de Ingeniería Mecánica y Electrica Unidad Zacatenco (ESIME Zacatenco), Universidad Nacional Autónoma de México</b></td></tr><tr><td colspan="3">We present a new resource to analyze and detect deceptive information that is present in a huge amount of news websites. Specifically, we compiled a corpus of news in the Spanish language extracted from several websites. The corpus is annotated with two labels (real and fake) for automatic fake news detection. Furthermore, the corpus also provides the category of the news, presenting a detailed analysis on vocabulary overlap among categories. Finally, we present a style-based fake news detection method. The obtained results showthat the introduced corpus is an interesting resource for future research in this area.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3308560.3316739" target="_blank"> A topic-agnostic approach for identifying fake news pages<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85066884280</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Castelo S., Santos A., Pham K., Freire J., Elghafari A., Almeida T., Nakamura E.</b></td></tr><tr><td colspan="3">Organisations: <b>New York University, Federal University of Amazonas</b></td></tr><tr><td colspan="3">Fake news and misinformation have been increasingly used to manipulate popular opinion and influence political processes. To better understand fake news, how they are propagated, and how to counter their effect, it is necessary to first identify them. Recently, approaches have been proposed to automatically classify articles as fake based on their content. An important challenge for these approaches comes from the dynamic nature of news: as new political events are covered, topics and discourse constantly change and thus, a classifier trained using content from articles published at a given time is likely to become ineffective in the future. To address this challenge, we propose a topic-agnostic (TAG) classification strategy that uses linguistic and web-markup features to identify fake news pages. We report experimental results using multiple data sets which show that our approach attains high accuracy in the identification of fake news, even as topics evolve over time.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3308560.3316476" target="_blank"> Fake news detection: An interdisciplinary research<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85066888553</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Zhou X., Zafarani R.</b></td></tr><tr><td colspan="3">Organisations: <b>Syracuse University</b></td></tr><tr><td colspan="3">The explosive growth of fake news and its erosion to democracy, journalism and economy has increased the demand for fake news detection. To achieve efficient and explainable fake news detection, an interdisciplinary approach is required, relying on scientific contributions from various disciplines, e.g., social sciences, engineering, among others. Here, we illustrate how such multidisciplinary contributions can help detect fake news by improving feature engineering, or by providing well-justified machine learning models. We demonstrate how news content, news propagation patterns, and users' engagements with news can help detect fake news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3308558.3313552" target="_blank"> MvaE: Multimodal variational autoencoder for fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85066898250</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Khattar D., Gupta M., Goud J.S., Varma V.</b></td></tr><tr><td colspan="3">Organisations: <b>International Institute of Information Technology</b></td></tr><tr><td colspan="3">In recent times, fake news and misinformation have had a disruptive and adverse impact on our lives. Given the prominence of microblogging networks as a source of news for most individuals, fake news now spreads at a faster pace and has a more profound impact than ever before. This makes detection of fake news an extremely important challenge. Fake news articles, just like genuine news articles, leverage multimedia content to manipulate user opinions but spread misinformation. A shortcoming of the current approaches for the detection of fake news is their inability to learn a shared representation of multimodal (textual + visual) information. We propose an end-to-end network, Multimodal Variational Autoencoder (MVAE), which uses a bimodal variational autoencoder coupled with a binary classifier for the task of fake news detection. The model consists of three main components, an encoder, a decoder and a fake news detector module. The variational autoencoder is capable of learning probabilistic latent variable models by optimizing a bound on the marginal likelihood of the observed data. The fake news detector then utilizes the multimodal representations obtained from the bimodal variational autoencoder to classify posts as fake or not. We conduct extensive experiments on two standard fake news datasets collected from popular microblogging websites: Weibo and Twitter. The experimental results show that across the two datasets, on average our model outperforms state-of-the-art methods by margins as large as ∼6% in accuracy and ∼5% in F1 scores.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3308558.3313724" target="_blank"> From stances' imbalance to their hierarchical representation and detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85066904669</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Zhang Q., Lipani A., Yilmaz E., Liang S., Ren Z.</b></td></tr><tr><td colspan="3">Organisations: <b>University College London, Sun Yat-sen University, Shandong University</b></td></tr><tr><td colspan="3">Stance detection has gained increasing interest from the research community due to its importance for fake news detection. The goal of stance detection is to categorize an overall position of a subject towards an object into one of the four classes: agree, disagree, discuss, and unrelated. One of the major problems faced by current machine learning models used for stance detection is caused by a severe class imbalance among these classes. Hence, most models fail to correctly classify instances that fall into minority classes. In this paper, we address this problem by proposing a hierarchical representation of these classes, which combines the agree, disagree, and discuss classes under a new related class. Further, we propose a two-layer neural network that learns from this hierarchical representation and controls the error propagation between the two layers using the Maximum Mean Discrepancy regularizer. Compared with conventional four-way classifiers, this model has two advantages: (1) the hierarchical architecture mitigates the class imbalance problem; (2) the regularization makes the model to better discern between the related and unrelated stances. An extensive experimentation demonstrates state-of-the-art accuracy performance of the proposed model for stance detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3308558.3314119" target="_blank"> XFake: Explainable fake news detector with visualizations<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85066910246</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Yang F., Du M., Pentyala S.K., Ji S., Mohseni S., Linder R., Hu X., Ragan E.D., Yuan H.</b></td></tr><tr><td colspan="3">Organisations: <b>Texas A and M University, University of Florida, Washington State University</b></td></tr><tr><td colspan="3">In this demo paper, we present the XFake system, an explainable fake news detector that assists end-users to identify news credibility. To effectively detect and interpret the fakeness of news items, we jointly consider both attributes (e.g., speaker) and statements. Specifically, MIMIC, ATTN and PERT frameworks are designed, where MIMIC is built for attribute analysis, ATTN is for statement semantic analysis and PERT is for statement linguistic analysis. Beyond the explanations extracted from the designed frameworks, relevant supporting examples as well as visualization are further provided to facilitate the interpretation. Our implemented system is demonstrated on a real-world dataset crawled from PolitiFact1, where thousands of verified political news have been collected.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Fake news detection using machine learning and natural language processing<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85066981407</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Agarwalla K., Nandan S., Nair V.A., Deva Hema D.</b></td></tr><tr><td colspan="3">Organisations: <b>SRM Institute of Science and Technology</b></td></tr><tr><td colspan="3">The web and internet-based life have led the entrance to news data, a lot less demanding and agreeable. Mass-media affects the life of the general public and as it frequently occurs. There are few individuals that exploit these privileges. This prompts the creation of the news articles that are not totally evident or indeed, even totally false. People intentionally spread these counterfeit articles with the help of web-based social networking sites. The fundamental objective of fake news sites is to influence the popular belief on specific issues. The main goal of fake news websites is to affect public opinion on certain matters. Our aim is to find a reliable and accurate model that classifies a given news article as either fake or true.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/JEEIT.2019.8717386" target="_blank"> Classifying Arabic tweets based on credibility using content and user features<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85067125772</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Jardaneh G., Abdelhaq H., Buzz M., Johnson D.</b></td></tr><tr><td colspan="3">Organisations: <b>An-Najah National University, University of Colorado</b></td></tr><tr><td colspan="3">Social Media services, such as Facebook and Twitter, have recently become a huge and continuous source of daily news. People all around the world rely heavily on news published via social media to know more about current events and activities. As a result, many users have started to exploit social media by broadcasting misleading news for financial and political purposes, which has an adverse impact on society. In this paper, we utilize machine learning to identify fake news from Arabic tweets based on a supervised classification model. Twitter content published in Arabic is very noisy with a high level of uncertainty, where little work has been accomplished to process and extract important features for classification purposes. In this paper, we utilize content-and user-related features, and employ sentiment analysis to generate new features for the detection of fake Arabic news. Sentiment analysis led to improving the accuracy of the prediction process. Among a number of machine learning algorithms used to train the classification models, four algorithms are chosen, namely Random Forest, Decision Tree, AdaBoost, and Logistic Regression. The experimental evaluation shows that our system can filter out fake news with an accuracy of 76%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-20521-8_54" target="_blank"> Semantic Fake News Detection: A Machine Learning Perspective<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85067488804</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Brasoveanu A.M.P., Andonie R.</b></td></tr><tr><td colspan="3">Organisations: <b>Transilvania University of Braşov, MODUL Technology GmbH, Central Washington University</b></td></tr><tr><td colspan="3">Fake news detection is a difficult problem due to the nuances of language. Understanding the reasoning behind certain fake items implies inferring a lot of details about the various actors involved. We believe that the solution to this problem should be a hybrid one, combining machine learning, semantics and natural language processing. We introduce a new semantic fake news detection method built around relational features like sentiment, entities or facts extracted directly from text. Our experiments show that by adding semantic features the accuracy of fake news classification improves significantly.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-23407-2_11" target="_blank"> Learning contextual features with multi-head self-attention for fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85068229157</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Wang Y., Han H., Wang X., Liao Q., Ding Y.</b></td></tr><tr><td colspan="3">Organisations: <b>Harbin Institute of Technology (Shenzhen), Dongguan University of Technology, Peng Cheng Laboratory</b></td></tr><tr><td colspan="3">Automatic fake news detection has attracted great concern in recent years due to it’s tremendous negative impacts on public. Since fake news is usually written to mislead readers, lexical features based methods have great limitations. Previous work has proven the effectiveness of contextual information for fake news detection. However, they ignore the influence of sequence order when extract features from contextual information. Inspired by transformer technique, we propose Contextual Features with Multi-head Self-attention model(CMS) to extract features from contextual information for fake news detection. CMS can automatic capture the dependencies between contextual information and learning a global representation from contextual information for fake news detection. Experimental results on the real-world data demonstrate the effectiveness of the proposed model.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-23281-8_30" target="_blank"> A Novel Approach Towards Fake News Detection: Deep Learning Augmented with Textual Entailment Features<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85068324597</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Saikh T., Ekbal A., Bhattacharyya P., Anand A.</b></td></tr><tr><td colspan="3">Organisations: <b>Indian Institute of Technology Patna, Indian Institute of Information Technology Kalyani</b></td></tr><tr><td colspan="3">The phenomenal growth in web information has nourished research endeavours for automatic fact checking, or fake news and/or misinformation detection. This is one of the very emerging and challenging problems in Natural Language Processing (NLP), Machine Learning (ML) and Data Science. One such problem relates to estimating the veracity of a news story, which is a complex and deep problem. The very recently released Fake News Challenge Stage 1 (FNC-1) dataset introduced the benchmark FNC stage-1: stance detection task. This task could be an effective first step towards building a robust fact checking system. In this paper, we correlate this stance detection problem with Textual Entailment (TE). We present the systems which are based on statistical machine learning (ML), Deep Learning (DL), and a combination of both. Empirical evaluation shows encouraging performance, outperforming the state-of-the-art system.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.ejor.2019.06.022" target="_blank"> Detecting fake news for reducing misinformation risks using analytics approaches<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85068382820</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Zhang C., Gupta A., Kauten C., Qin X., Deokar A.V.</b></td></tr><tr><td colspan="3">Organisations: <b>Auburn University, University of Massachusetts Lowell</b></td></tr><tr><td colspan="3">Fake news is playing an increasingly dominant role in spreading misinformation by influencing people's perceptions or knowledge to distort their awareness and decision-making. The growth of social media and online forums has spurred the spread of fake news causing it to easily blend with truthful information. This study provides a novel text analytics–driven approach to fake news detection for reducing the risks posed by fake news consumption. We first describe the framework for the proposed approach and the underlying analytical model including the implementation details and validation based on a corpus of news data. We collect legitimate and fake news, which is transformed from a document based corpus into a topic and event–based representation. Fake news detection is performed using a two-layered approach, which is comprised of detecting fake topics and fake events. The efficacy of the proposed approach is demonstrated through the implementation and validation of a novel FakE News Detection (FEND) system. The proposed approach achieves 92.49% classification accuracy and 94.16% recall based on the specified threshold value of 0.6.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-26773-5_6" target="_blank"> Fake News Detection in Microblogging Through Quantifier-Guided Aggregation<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85068733894</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>De Grandis M., Pasi G., Viviani M.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Milano-Bicocca</b></td></tr><tr><td colspan="3">Nowadays, big volumes of User-Generated Content (UGC) spread across various kinds of social media. In microblogging, UCG can be generated in the form of ‘newsworthy’ posts, i.e., related to information that has a public utility for the people. In this context, being the UGC diffused without almost any traditional form of trusted external control, the possibility of incurring in possible fake news is far from remote. For this reason, several approaches for fake news detection in microblogging have been proposed up to now, mostly based on machine learning techniques. In this paper, an ongoing work based on the use of the Multi-Criteria Decision Making (MCDM) paradigm to detect fake news is proposed. The aim is to reduce data dependency in building the model, and to have flexible control over the choices behind the fake news detection process.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICASSP.2019.8683170" target="_blank"> Sentiment Aware Fake News Detection on Online Social Networks<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85068968519</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Ajao O., Zargari S., Bhowmik D.</b></td></tr><tr><td colspan="3">Organisations: <b>Sheffield Hallam University, University of Stirling</b></td></tr><tr><td colspan="3">Messages posted to online social networks (OSN) causes a recent stir due to the intended spread of fake news or rumor. This work aims to understand and analyse the characteristics of fake news especially in relation to sentiments, for the automatic detection of fake news and rumors. Based on empirical observations, we propose a hypothesis that there exists a relation between fake messages or rumours and sentiments of the texts posted online. We verify our hypothesis by comparing with the state-of-the-art baseline text-only fake news detection methods that do not consider sentiments. We performed experiments on standard Twitter fake news dataset and show good improvements in detecting fake news or rumor posts.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Hybrid text classification method for fake news detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85069445671</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Kaur P., Boparai R.S., Singh D.</b></td></tr><tr><td colspan="3">Organisations: <b>Computer Science and Applications in Big Data specialization from Chandigarh University, Thapar Institute of Engineering and Technology</b></td></tr><tr><td colspan="3">Fake news will be news, stories or scams made to purposely misguide or delude perusers. As a rule, these accounts are made to impact individuals' perspectives, push a political motivation or cause disarray and can regularly be a gainful business for online distributers. Fake news stories can swindle individuals by looking like believed sites or utilizing comparative names and web delivers to trustworthy news associations. The fake news detection has the three phases which are pre-processing, feature extraction and classification. In the previous time Support Vector Machine (SVM) classification is applied for the fake news detection. To improve accuracy of the fake news hybrid classification model is designed in this research work. The proposed model is implemented in Python and results are analyzed in terms of accuracy, precision and recall. Experimental analysis shows that the proposed method outperforms competitive techniques.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3292522.3326012" target="_blank"> Trust it or not: Effects of machine-learningwarnings in helping individuals mitigate misinformation<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85069450320</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Seo H., Xiong A., Lee D.</b></td></tr><tr><td colspan="3">Organisations: <b>Pennsylvania State University</b></td></tr><tr><td colspan="3">Despite increased interests in the study of fake news, how to aid users' decision in handling suspicious or false information has not been well understood. To obtain a better understanding on the impact of warnings on individuals' fake news decisions, we conducted two online experiments, evaluating the effect of three warnings (i.e., one Fact-Checking and two Machine-Learning based) against a control condition, respectively. Each experiment consisted of three phases examining participants' recognition, detection, and sharing of fake news, respectively. In Experiment 1, relative to the control condition, participants' detection of both fake and real news was better when the Fact-Checking warning but not the two Machine-Learning warnings were presented with fake news. Postsession questionnaire results revealed that participants showed more trust for the Fact-Checking warning. In Experiment 2, we proposed a Machine-Learning-Graph warning that contains the detailed results of machine-learning based detection and removed the source within each news headline to test its impact on individuals' fake news detection with warnings. We did not replicate the effect of the Fact-Checking warning obtained in Experiment 1, but the Machine-Learning-Graph warning increased participants' sensitivity in differentiating fake news from real ones. Although the best performance was obtained with the Machine-Learning-Graph warning, participants trusted it less than the Fact-Checking warning. Therefore, our study results indicate that a transparent machine learning warning is critical to improving individuals' fake news detection but not necessarily increase their trust on the model.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3292522.3326027" target="_blank"> Explainable machine learning for fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85069461071</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Reis J.C.S., Correia A., Murai F., Veloso A., Benevenuto F.</b></td></tr><tr><td colspan="3">Organisations: <b>Universidade Federal de Minas Gerais</b></td></tr><tr><td colspan="3">Recently, there have been many research efforts aiming to understand fake news phenomena and to identify typical patterns and features of fake news. Yet, the real discriminating power of these features is still unknown: some are more general, but others perform well only with specific data. In this work, we conduct a highly exploratory investigation that produced hundreds of thousands of models from a large and diverse set of features. These models are unbiased in the sense that their features are randomly chosen from the pool of available features. While the vast majority of models are ineffective, we were able to produce a number of models that yield highly accurate decisions, thus effectively separating fake news from actual stories. Specifically, we focused our analysis on models that rank a randomly chosen fake news story higher than a randomly chosen fact with more than 0.85 probability. For these models we found a strong link between features and model predictions, showing that some features are clearly tailored for detecting certain types of fake news, thus evidencing that different combinations of features cover a specific region of the fake news space. Finally, we present an explanation of factors contributing to model decisions, thus promoting civic reasoning by complementing our ability to evaluate digital content and reach warranted conclusions.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/SYNASC.2018.00064" target="_blank"> A tool for fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85069472984</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Al Asaad B., Erascu M.</b></td></tr><tr><td colspan="3">Organisations: <b>West University of Timisoara</b></td></tr><tr><td colspan="3">The word post-truth was considered by Oxford Dictionaries Word of the Year 2016. The word is an adjective relating to or denoting circumstances in which objective facts are less influential in shaping public opinion than appeals to emotion and personal belief. This leads to misinformation and problems in society. Hence, it is important to make effort to detect these facts and prevent them from spreading. In this paper we propose machine learning techniques, in particular supervised learning, for fake news detection. More precisely, we used a dataset of fake and real news to train a machine learning model using Scikit-learn library in Python. We extracted features from the dataset using text representation models like Bag-of-Words, Term Frequency-Inverse Document Frequency (TF-IDF) and Bi-gram frequency. We tested two classification approaches, namely probabilistic classification and linear classification on the title and the content, checking if it is clickbait/nonclickbait, respectively fake/real. The outcome of our experiments was that the linear classification works the best with the TF-IDF model in the process of content classification. The Bi-gram frequency model gave the lowest accuracy for title classification in comparison with Bag-of-Words and TF-IDF.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> A study on fake news detection using naïve bayes, SVM, neural networks and LSTM<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85069504390</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Reddy P.S., Elizabeth Roy D., Manoj P., Keerthana M., Tijare P.V.</b></td></tr><tr><td colspan="3">Organisations: <b>CMR Institute of Technology</b></td></tr><tr><td colspan="3">Accounting to the expeditious digitization across all channels and mediums, the menace of fake news has been burgeoning at a colossal scale. Majority of the countries all across the world are trying to combat this challenge. This paper explores the application of Natural Language Processing and Machine Learning techniques to identify fake news accurately. Pre-processing tools are used to clean the data and apply feature extraction on them. Then a fake news detection model is built using four different techniques. Finally, the paper investigates and compares the accuracy of techniques which are Naive Bayes, Support Vector Machine (SVM), neural network and long short-term memory (LSTM) to find the best fit for the model.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.26599/TST.2018.9010139" target="_blank"> Detecting fake news over online social media via domain reputations and content understanding<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85069524460</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Xu K., Wang F., Wang H., Yang B.</b></td></tr><tr><td colspan="3">Organisations: <b>Arizona State University, Jiangxi University of Finance and Economics</b></td></tr><tr><td colspan="3">Fake news has recently leveraged the power and scale of online social media to effectively spread misinformation which not only erodes the trust of people on traditional presses and journalisms, but also manipulates the opinions and sentiments of the public. Detecting fake news is a daunting challenge due to subtle difference between real and fake news. As a first step of fighting with fake news, this paper characterizes hundreds of popular fake and real news measured by shares, reactions, and comments on Facebookfrom two perspectives: domain reputations and content understanding. Our domain reputation analysis reveals that the Web sites of the fake and real news publishers exhibit diverse registration behaviors, registration timing, domain rankings, and domain popularity. In addition, fake news tends to disappear from the Web after a certain amount of time. The content characterizations on the fake and real news corpus suggest that simply applying term frequency-inverse document frequency (tf-idf) and Latent Dirichlet Allocation (LDA) topic modeling is inefficient in detecting fake news, while exploring document similarity with the term and word vectors is a very promising direction for predicting fake and real news. To the best of our knowledge, this is the first effort to systematically study domain reputations and content characteristics of fake and real news, which will provide key insights for effectively detecting fake news on social media.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Fake news detection using ensemble machine learning<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85070017117</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Mohale P., Leung W.S.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Johannesburg</b></td></tr><tr><td colspan="3">Consuming news from social networks has become the new normal. In theory, the rapid rise of social media can be seen to have a positive impact in promoting active citizenship. Unfortunately, social networks can also prove to be a considerable threat. Just as their platforms promote easy access to rapid and low-cost dissemination of information, social media is also fertile ground for the spreading of misinformation. As a result, governments now face the reality of having to bolt the proverbial barn door while the fake news horse is already free, running amok. Given fake news’ ability to deceive, cause instability, and spread propaganda, governments must ensure that there are measures in place that will allow them to effectively deal with what qualifies as a form of cyber warfare. It is therefore quite critical to be able to detect fake news on social media to mitigate the potential negative effects. Detecting fake news on social networks can be quite a challenge as they are often written to masquerade as real news. To effectively detect fake news on social networks, one may need to exhaust all the auxiliary information. Furthermore, the sheer amount at which fake news is seen to propagate means that the process of identifying and shutting down the fake news articles cannot be left to human means alone. Ensemble machine learning makes use of a set of classifiers whose individual decisions are aggregated by weighted voting to improve predictions, decrease variance and bias. In this paper, we present an ensemble machine learning model which determines the truth probability of given statements from social networks by considering all the relating metadata. The proposed system makes use of five different classifiers to improve the detection of fake news on social networks. We trained and tested the model using a fake news dataset with the results of our experiment yielding fake news detection accuracies averaging 80%. Results are shown to improve significantly when the feature selection stage of the training process includes more attributes of the dataset.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1117/12.2521854" target="_blank"> Evaluation of algorithms for fake news identification<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85070064294</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Kalvoda B., Stoick B., Snell N., Straub J.</b></td></tr><tr><td colspan="3">Organisations: <b>North Dakota State University</b></td></tr><tr><td colspan="3">Today, information is spread quickly throughout communities by means of simple messaging, group chats, and social media platforms. Because of the ease of use that these services provide, misinformation has become a common trend. The term 'fake news' has emerged as being a way to refer to all information shared in a manner that is meant to mislead a reader into thinking something is a true statement when it is not. Combating fake news has become a major topic, and many are attempting to find a way of detecting when something is real or made up. In this paper, we look at a database of news articles that have been classified as either real or fake and apply machine learning to automatically determine if something is deliberately misleading. Algorithms have been developed to make judgements, classify articles in a database and judge new articles based on learned knowledge. This model combines multiple factors that may raise or lower confidence in the article being legitimate or illegitimate and provides a single confidence metric. This paper presents the development of these algorithms for assessing articles. It discusses the efficacy of using this approach and compares it to other classification approaches. It then presents the results of using the system to classify numerous presented articles and discusses the sufficiency of system accuracy for multiple applications. Finally, it discusses next steps in the fake news detection project and how these algorithms fit within them.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1117/12.2520131" target="_blank"> Development of a 'fake news' machine learning classifier and a dataset for its testing<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85070105750</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Fleck W., Snell N., Traylor T., Straub J.</b></td></tr><tr><td colspan="3">Organisations: <b>North Dakota State University</b></td></tr><tr><td colspan="3">Fabricated news stories that contain false information but are presented as factually accurate (commonly known as â€ fake news') have generated substantial interest and media attention following the 2016 U.S. presidential election. While the full details of what transpired during the election are still not known, it appears that multiple groups used social media to spread false information packaged in fabricated news articles that were presented as truthful. Some have argued that this campaign had a material impact on the election. Moreover, the 2016 U.S. presidential election is far from the only campaign where fake news had an apparent role. In this paper, work on a counter-fake-news research effort is presented. In the long term, this project is focused on building an indications and warnings systems for potentially deceptive false content. As part of this project, a dataset of manually classified legitimate and deceptive news articles was curated. The key criteria for classifying legitimate and deceptive articles, identified by the manual classification project, are identified and discussed. The identified criteria can be embodied in a natural language processing system to perform illegitimate content detection. The criteria include the document's source and origin, title, political perspective, and several key content characteristics. This paper presents and evaluates the efficacy of each of these characteristics and their suitability for legitimate versus illegitimate classification. The paper concludes by discussing the use of these characteristics as input to a customized naïve Bayesian probability classifier, the results of the use of this classifier and future work on its development.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-13-9942-8_40" target="_blank"> Comparative Performance of Machine Learning Algorithms for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85070209435</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Bali A.P.S., Fernandes M., Choubey S., Goel M.</b></td></tr><tr><td colspan="3">Organisations: <b>Asia Pacific Institute of Information Technology SD India</b></td></tr><tr><td colspan="3">Automatic detection of fake news, which could negatively affect individuals and the society, is an emerging research area attracting global attention. The problem has been approached in this paper from Natural Language Processing and Machine Learning perspectives. The evaluation is carried out for three standard datasets with a novel set of features extracted from the headlines and the contents. Performances of seven machine learning algorithms in terms of accuracies and F1 scores are compared. Gradient Boosting outperformed other classifiers with mean accuracy of 88% and F1-Score of 0.91.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s00779-019-01289-y" target="_blank"> Multi-level word features based on CNN for fake news detection in cultural communication<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85070291278</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Li Q., Hu Q., Lu Y., Yang Y., Cheng J.</b></td></tr><tr><td colspan="3">Organisations: <b>Xi’an Jiaotong University</b></td></tr><tr><td colspan="3">In recent years, due to the booming development of online social networks, fake news has been appearing in large numbers and widespread in the online world. With deceptive words, online social network users can get infected by these online fake news easily, which has brought about tremendous effects on the offline society already. An important goal in improving the trustworthiness of information in online social networks is to identify the fake news timely. However, fake news detection remains to be a challenge, primarily because the content is crafted to resemble the truth in order to deceive readers, and without fact-checking or additional information, it is often hard to determine veracity by text analysis alone. In this paper, we first proposed multi-level convolutional neural network (MCNN), which introduced the local convolutional features as well as the global semantics features, to effectively capture semantic information from article texts which can be used to classify the news as fake or not. We then employed a method of calculating the weight of sensitive words (TFW), which has shown their stronger importance with their fake or true labels. Finally, we develop MCNN-TFW, a multiple-level convolutional neural network-based fake news detection system, which is combined to perform fake news detection in that MCNN extracts article representation and WS calculates the weight of sensitive words for each news. Extensive experiments have been done on fake news detection in cultural communication to compare MCNN-TFW with several state-of-the-art models, and the experimental results have demonstrated the effectiveness of the proposed model.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/CCAA.2018.8777343" target="_blank"> Fake news detection using a deep neural network<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85070373491</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Kaliyar R.K.</b></td></tr><tr><td colspan="3">Organisations: <b>Bennett University</b></td></tr><tr><td colspan="3">The process of obtaining news from social media is like double edged weapon. On one hand, it is easy to access, less time consuming, user friendly, easily conveyable socially relevant news, possibility for obtaining various perspective of a single news and is being updated in every minute. On other hand, news is being manipulated by various networking sites based on private opinions or interest. Fake news is misinformation or manipulated news that is spread across the social media with an intention to damage a person, agency and organization. Due to the dissemination of fake news, there is need for computational methods to detect them. Fake news detection aims to help users to expose varieties of fabricated news. We can decide whether the news is solid or forged based on formerly witnessed fake or real news. We can use various models to access deceptive news in social media. Our contribution is bifold. First, we must introduce the datasets which contain both fake and real news and conduct various experiments to organize fake news detector. We use Natural Language Processing, Machine learning and deep learning techniques to classify the datasets. We yield a comprehensive audit of detecting fake news by including fake news categorization, existing algorithms from machine learning techniques.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Overview of the CLEF-2019 Checkthat! LAB: Automatic identification and verification of claims. Task 2: Evidence and factuality<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85070501566</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Hasanain M., Suwaileh R., Elsayed T., Barron-Cedeno A., Nakov P.</b></td></tr><tr><td colspan="3">Organisations: <b>Qatar University, Università di Bologna, Qatar Computing Research Institute</b></td></tr><tr><td colspan="3">We present an overview of Task 2 of the second edition of the CheckThat! Lab at CLEF 2019. Task 2 asked (A) to rank a given set of Web pages with respect to a check-worthy claim based on their usefulness for fact-checking that claim, (B) to classify these same Web pages according to their degree of usefulness for fact-checking the target claim, (C) to identify useful passages from these pages, and (D) to use the useful pages to predict the claim's factuality. Task 2 at CheckThat! provided a full evaluation framework, consisting of data in Arabic (gathered and annotated from scratch) and evaluation based on normalized discounted cumulative gain (nDCG) for ranking, and F1 for classification. Four teams submitted runs. The most successful approach to subtask A used learning-to-rank, while different classifiers were used in the other subtasks. We release to the research community all datasets from the lab as well as the evaluation scripts, which should enable further research in the important task of evidence-based automatic claim verification.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3331184.3331285" target="_blank"> Leveraging emotional signals for credibility detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85070514202</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Giachanou A., Rosso P., Crestani F.</b></td></tr><tr><td colspan="3">Organisations: <b>Universitat Politècnica de València, Università della Svizzera italiana</b></td></tr><tr><td colspan="3">The spread of false information on the Web is one of the main problems of our society. Automatic detection of fake news posts is a hard task since they are intentionally written to mislead the readers and to trigger intense emotions to them in an attempt to be disseminated in the social networks. Even though recent studies have explored different linguistic patterns of false claims, the role of emotional signals has not yet been explored. In this paper, we study the role of emotional signals in fake news detection. In particular, we propose an LSTM model that incorporates emotional signals extracted from the text of the claims to differentiate between credible and non-credible ones. Experiments on real world datasets show the importance of emotional signals for credibility assessment.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICACCAF.2018.8776822" target="_blank"> Trust Network, Blockchain and Evolution in Social Media to Build Trust and Prevent Fake News<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85070536858</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Tee W.J., Murugesan R.K.</b></td></tr><tr><td colspan="3">Organisations: <b>Taylor's University</b></td></tr><tr><td colspan="3">Fake news on major social media platforms has real-world consequences on the sentiments of citizens. For instance, it has the power to influence the election results of a country. The problem statement is fake news detection and prevention on social media presents unique challenges that require novel algorithms. The research methodology is to implement current blockchain technology with advanced Artificial Intelligence in social media platform to prevent fake news. This study aims to provide a substantial review on implementing blockchain on social media in order to build public trust on credible news and prevent spread of fake news via social media. In particular, this paper provides the research problem and discusses state-of-the-art blockchain solutions and technical constraints as well as points out the future research direction in tackling the challenges.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICACCAF.2018.8776689" target="_blank"> Fake News on Social Media: Brief Review on Detection Techniques<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85070555852</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Mahid Z.I., Manickam S., Karuppayah S.</b></td></tr><tr><td colspan="3">Organisations: <b>Universiti Sains Malaysia</b></td></tr><tr><td colspan="3">The widespread of fake news on social media has resulted with serious real-world impacts, mounting concerns among the global net users in the last few years. This has also drawn interest from researchers around the globe to work on deception detection mechanisms to mitigate the problem. The goal is to realize a mechanism that is automatic, robust, reliable and efficient, despite various challenges that might hamper the efforts. In this paper, we present the review on the state-of-the-art of fake news detection mechanisms on social media. We first discuss the background of the problems that are surrounding fake news and the impacts it has on the users. We further describe the definition of fake news and discuss on different deception detection approaches presented in categories such as the content-based, social context-based and hybrid-based methods. We conclude the paper with four keys of open research challenges that may guide the future research.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.12928/TELKOMNIKA.V17I2.11779" target="_blank"> The architecture social media and online newspaper credibility measurement for fake news detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85070855850</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Arianto R., Warnars H.L.H.S., Abdurachman E., Heryadi Y., Gaol F.L.</b></td></tr><tr><td colspan="3">Organisations: <b>Menara PLN, Bina Nusantara University Kebon</b></td></tr><tr><td colspan="3">Social media is one of the communication media favored by people in the world, especially in Indonesia. This is evidenced by the results of the APJII survey which shows that the majority of Indonesians use social media in their daily activities. One of the advantages of social media is the dissemination of information faster than conventional media so that the quality of information disseminated is lower than conventional media due to the process of disseminating information not through the filter process. By measuring the level of credibility of the online newspaper based on the time credibility, website credibility, and message credibility factors and measuring the level of credibility on social media based on the time credibility, Social Media Credibility, and Message Credibility factors with different levels of weight, it will produce a news likelihood level it's fake news or facts.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3292500.3330935" target="_blank"> Defend: Explainable fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85071180295</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Shu K., Liu H., Cui L., Wang S., Lee D.</b></td></tr><tr><td colspan="3">Organisations: <b>Arizona State University, Penn State University University</b></td></tr><tr><td colspan="3">In recent years, to mitigate the problem of fake news, computational detection of fake news has been studied, producing some promising early results. While important, however, we argue that a critical missing piece of the study be the explainability of such detection, i.e., why a particular piece of news is detected as fake. In this paper, therefore, we study the explainable detection of fake news. We develop a sentence-comment co-attention sub-network to exploit both news contents and user comments to jointly capture explainable top-k check-worthy sentences and user comments for fake news detection. We conduct extensive experiments on real-world datasets and demonstrate that the proposed method not only significantly outperforms 7 state-of-the-art fake news detection methods by at least 5.33% in F1-score, but also (concurrently) identifies top-k user comments that explain why a news piece is fake, better than baselines by 28.2% in NDCG and 30.7% in Precision.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3292500.3332287" target="_blank"> Fake news research: Theories, detection strategies, and open problems<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85071198824</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Zafarani R., Zhou X., Shu K., Liu H.</b></td></tr><tr><td colspan="3">Organisations: <b>Syracuse University, Arizona State University</b></td></tr><tr><td colspan="3">Fake news has become a global phenomenon due its explosive growth, particularly on social media. The goal of this tutorial is to (1) clearly introduce the concept and characteristics of fake news and how it can be formally differentiated from other similar concepts such as mis-/dis-information, satire news, rumors, among others, which helps deepen the understanding of fake news; (2) provide a comprehensive review of fundamental theories across disciplines and illustrate how they can be used to conduct interdisciplinary fake news research, facilitating a concerted effort of experts in computer and information science, political science, journalism, social science, psychology and economics. Such concerted efforts can result in highly efficient and explainable fake news detection; (3) systematically present fake news detection strategies from four perspectives (i.e., knowledge, style, propagation, and credibility) and the ways that each perspective utilizes techniques developed in data/graph mining, machine learning, natural language processing, and information retrieval; and (4) detail open issues within current fake news studies to reveal great potential research opportunities, hoping to attract researchers within a broader area to work on fake news detection and further facilitate its development. The tutorial aims to promote a fair, healthy and safe online information and news dissemination ecosystem, hoping to attract more researchers, engineers and students with various interests to fake news research. Few prerequisite are required for KDD participants to attend.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.35940/ijitee.J9453.0881019" target="_blank"> An effecient fake news detection system using machine learning<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85071249692</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Lakshmanarao A., Swathi Y., Srinivasa Ravi Kiran T.</b></td></tr><tr><td colspan="3">Organisations: <b>Raghu Engineering College, BABA Institute of Technology&Sciences, P.B.Siddhartha College of Arts & Science</b></td></tr><tr><td colspan="3">Social media plays a major role in several things in our life. Social media helps all of us to find some important news with low price. It also provides easy access in less time. But sometimes social media gives a chance for the fast-spreading of fake news. So there is a possibility that less quality news with false information is spread through the social media. This shows a negative impact on the number of people. Sometimes it may impact society also. So, detection of fake news has vast importance. Machine learning algorithms play a vital role in fake news detection; Especially NLP (Natural Language Processing) algorithms are very useful for detecting the fake news. In this paper, we employed machine learning classifiers SVM, K-Nearest Neighbors, Decision tree, Random forest. By using these classifiers we successfully build a model to detect fake news from the given dataset. Python language was used for experiments.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-29035-1_22" target="_blank"> A machine learning approach to fake news detection using knowledge verification and natural language processing<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85071464955</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Ibrishimova M.D., Li K.F.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Victoria</b></td></tr><tr><td colspan="3">The term “fake news” gained international popularity as a result of the 2016 US presidential election campaign. It is related to the practice of spreading false and/or misleading information in order to influence popular opinion. This practice is known as disinformation. It is one of the main weapons used in information warfare, which is listed as an emerging cybersecurity threat. In this paper, we explore “fake news” as a disinformation tool. We survey previous efforts in defining and automating the detection process of “fake news”. We establish a new fluid definition of “fake news” in terms of relative bias and factual accuracy. We devise a novel framework for fake news detection, based on our proposed definition and using a machine learning model.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/UEMCON.2018.8796519" target="_blank"> Exploiting Behavioral Differences to Detect Fake Ne<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85071518953</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Chen W., Yang C., Cheng G., Zhang Y., Yeo C.K., Lau C.T., Lee B.S.</b></td></tr><tr><td colspan="3">Organisations: <b>Nanyang Technological University</b></td></tr><tr><td colspan="3">Online social platforms have become the most influential media and their impact will be far greater in the highly connected and super-efficient smart cities. The speed, reach and sheer volume of digital media pose a global challenge to combat fake news. There is an urgent need to build resilience in a post-truth era. Misinformation gnaws social cohesion and erodes the trust of the citizens. This study seeks to identify the key differences in the traits between fake news and normal information in tweets and present two case studies to showcase two such features, namely, user sentiments and spread pattern. We then we propose an AI-based system using Autoencoder and Recurrent Neural Networks to detect fake news in Sina Weibo. This Proof-of-Concept (POC) can achieve a reasonable accuracy and F1 score and also proves its applicability to other online social platforms. The proposed POC is especially useful for governments, companies and other organizations to identify such misinformation as early as possible so that immediate actions can be taken to minimize the potential negative effect. It can also be deployed for use by social media platform users.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3339252.3341487" target="_blank"> Fake news detection by image montage recognition<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85071725345</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Steinebach M., Gotkowski K., Liu H.</b></td></tr><tr><td colspan="3">Organisations: <b>Fraunhofer SIT</b></td></tr><tr><td colspan="3">Fake news have been a problem for multiple years now and in addition to this “fake images” that accompany them are becoming increasingly a problem too. The aim of such fake images is to back up the fake message itself and make it appear authentic. For this purpose, more and more images such as photo-montages are used, which have been spliced from several images. This can be used to defame people by putting them in unfavorable situations or the other way around as propaganda by making them appear more important. In addition, montages may have been altered with noise and other manipulations to make an automatic recognition more difficult. In order to take action against such montages and still detect them automated, a concept based on feature detection is developed. Furthermore, an indexing of the features is carried out by means of a nearest neighbor algorithm in order to be able to quickly compare a high number of images. Afterwards, images suspected to be a montage are reviewed by a verifier. This concept is implemented and evaluated with two feature detectors. Even montages that have been manipulated with different methods are identified as such in an average of 100 milliseconds with a probability of mostly over 90%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3339252.3341497" target="_blank"> SocialTruth project approach to online disinformation (fake news) detection and mitigation<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85071732535</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Choras M., Pawlicki M., Kozik R., Demestichas K., Kosmides P., Gupta M.</b></td></tr><tr><td colspan="3">Organisations: <b>UTP University of Science and Technology, National Technical University of Athens, London South Bank University</b></td></tr><tr><td colspan="3">The extreme growth and adoption of Social Media, in combination with their poor governance and the lack of quality control over the digital content being published and shared, has led information veracity to a continuous deterioration. Current approaches entrust content verification to a single centralised authority, lack resilience towards attempts to successfully "game" verification checks, and make content verification difficult to access and use. In response, our ambition is to create an open, democratic, pluralistic and distributed ecosystem that allows easy access to various verification services (both internal and third-party), ensuring scalability and establishing trust in a completely decentralized environment. In fact, this is the ambition of the EU H2020 SocialTruth project. In this paper, we present the innovative project approach and the vision of effective online disinformation detection for various practical use-cases.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.eswa.2019.112943" target="_blank"> Fighting post-truth using natural language processing: A review and open challenges<a></b></td></tr><tr><td>Type: Review</td><td>ID: S_2-s2.0-85072269918</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Saquete E., Tomas D., Moreda P., Martinez-Barco P., Palomar M.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Alicante</b></td></tr><tr><td colspan="3">Post-truth is a term that describes a distorting phenomenon that aims to manipulate public opinion and behavior. One of its key engines is the spread of Fake News. Nowadays most news is rapidly disseminated in written language via digital media and social networks. Therefore, to detect fake news it is becoming increasingly necessary to apply Artificial Intelligence (AI) and, more specifically Natural Language Processing (NLP). This paper presents a review of the application of AI to the complex task of automatically detecting fake news. The review begins with a definition and classification of fake news. Considering the complexity of the fake news detection task, a divide-and-conquer methodology was applied to identify a series of subtasks to tackle the problem from a computational perspective. As a result, the following subtasks were identified: deception detection; stance detection; controversy and polarization; automated fact checking; clickbait detection; and, credibility scores. From each subtask, a PRISMA compliant systematic review of the main studies was undertaken, searching Google Scholar. The various approaches and technologies are surveyed, as well as the resources and competitions that have been involved in resolving the different subtasks. The review concludes with a roadmap for addressing the future challenges that have emerged from the analysis of the state of the art, providing a rich source of potential work for the research community going forward.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.5755/j01.eie.25.4.23972" target="_blank"> A novel approach for detection of fake news on social media using metaheuristic optimization algorithms<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85072525972</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Ozbay F.A., Alatas B.</b></td></tr><tr><td colspan="3">Organisations: <b>Firat University</b></td></tr><tr><td colspan="3">Deceptive content is becoming increasingly dangerous, such as fake news created by social media users. Individuals and society have been affected negatively by the spread of low-quality news on social media. The fake and real news needs to be detected to eliminate the disadvantages of social media. This paper proposes a novel approach for fake news detection (FND) problem on social media. Applying this approach, FND problem has been considered as an optimization problem for the first time and two metaheuristic algorithms, the Grey Wolf Optimization (GWO) and Salp Swarm Optimization (SSO) have been adapted to the FND problem for the first time as well. The proposed FND approach consists of three stages. The first stage is data preprocessing. The second stage is adapting GWO and SSO for construction of a novel FND model. The last stage consists of using proposed FND model for testing. The proposed approach has been evaluated using three different real-world datasets. The results have been compared with seven supervised artificial intelligence algorithms. The results show GWO algorithm has the best performance in comparison with SSO algorithm and the other artificial intelligence algorithms. GWO seems to be efficiently used for solving different types of social media problems.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1371/journal.pone.0222713" target="_blank"> Self Multi-Head Attention-based Convolutional Neural Networks for fake news detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85072669112</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Fang Y., Gao J., Huang C., Peng H., Wu R.</b></td></tr><tr><td colspan="3">Organisations: <b>College of Cybersecurity Sichuan University, China Information Technology Security Evaluation Center</b></td></tr><tr><td colspan="3">With the rapid development of the internet, social media has become an essential tool for getting information, and attracted a large number of people join the social media platforms because of its low cost, accessibility and amazing content. It greatly enriches our life. However, its rapid development and widespread also have provided an excellent convenience for the range of fake news, people are constantly exposed to fake news and suffer from it all the time. Fake news usually uses hyperbole to catch people’s eyes with dishonest intention. More importantly, it often misleads the reader and causes people to have wrong perceptions of society. It has the potential for negative impacts on society and individuals. Therefore, it is significative research on detecting fake news. In the paper, we built a model named SMHA-CNN (Self Multi-Head Attention-based Convolutional Neural Networks) that can judge the authenticity of news with high accuracy based only on content by using convolutional neural networks and self multi-head attention mechanism. In order to prove its validity, we conducted experiments on a public dataset and achieved a precision rate of 95.5% with a recall rate of 95.6% under the 5-fold cross-validation. Our experimental result indicates that the model is more effective at detecting fake news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-28577-7_25" target="_blank"> Overview of the CLEF-2019 CheckThat! Lab: Automatic Identification and Verification of Claims<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85072834528</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Elsayed T., Hasanain M., Suwaileh R., Nakov P., Da San Martino G., Barron-Cedeno A., Atanasova P.</b></td></tr><tr><td colspan="3">Organisations: <b>Qatar University, Qatar Computing Research Institute, Università di Bologna, University of Copenhagen</b></td></tr><tr><td colspan="3">We present an overview of the second edition of the CheckThat! Lab at CLEF 2019. The lab featured two tasks in two different languages: English and Arabic. Task 1 (English) challenged the participating systems to predict which claims in a political debate or speech should be prioritized for fact-checking. Task 2 (Arabic) asked to (A) rank a given set of Web pages with respect to a check-worthy claim based on their usefulness for fact-checking that claim, (B) classify these same Web pages according to their degree of usefulness for fact-checking the target claim, (C) identify useful passages from these pages, and (D) use the useful pages to predict the claim’s factuality. CheckThat! provided a full evaluation framework, consisting of data in English (derived from fact-checking sources) and Arabic (gathered and annotated from scratch) and evaluation based on mean average precision (MAP) and normalized discounted cumulative gain (nDCG) for ranking, and F &#x0024;&#x0024;:1&#x0024;&#x0024; for classification. A total of 47 teams registered to participate in this lab, and fourteen of them actually submitted runs (compared to nine last year). The evaluation results show that the most successful approaches to Task 1 used various neural networks and logistic regression. As for Task 2, learning-to-rank was used by the highest scoring runs for subtask A, while different classifiers were used in the other subtasks. We release to the research community all datasets from the lab as well as the evaluation scripts, which should enable further research in the important tasks of check-worthiness estimation and automatic claim verification.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-29238-6_8" target="_blank"> FakeChain: A Blockchain Architecture to Ensure Trust in Social Media Networks<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85072840426</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Ochoa I.S., de Mello G., Silva L.A., Fernandes A.M.R., Leithardt V.R.Q., Gomes A.J.P.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Vale do Itajai, Universidade da Beira Interior, Instituto de Telecomunicações</b></td></tr><tr><td colspan="3">The electoral period has great importance in any democracy, but nowadays, different groups try to get an advantage in the democratic process by posting fake news on social media networks. The use of data mining technique to identify fake news is on development stage, and there is no holistic solution to this problem yet. In our work, we proposed an architecture that uses a centralized blockchain on fake news detection process. The primary characteristic of our architecture is the use of data mining as a consensus algorithm to authenticate the information published on social networks. Using our architecture is possible to identify fake news, alert readers, punish who dissolves this type of information and reward who publish true information on the network.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-30760-8_25" target="_blank"> Fake News Detection with the New German Dataset “GermanFakeNC”<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85072852584</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Vogel I., Jiang P.</b></td></tr><tr><td colspan="3">Organisations: <b>Fraunhofer Institute for Secure Information Technology SIT</b></td></tr><tr><td colspan="3">The spread of misleading information and “alternative facts” on the internet gained in the last decade considerable importance worldwide. In recent years, several attempts have been made to counteract fake news based on automatic classification via machine learning models. These, however, require labeled data. The scarcity of available corpora for predictive modeling is a major stumbling block in this field, especially in other languages than English. Our contribution is twofold. First, we introduce a new publicly available German dataset “German Fake News Corpus” (GermanFakeNC) for the task of fake news detection which consists of 490 manually fact-checked articles. Every false statement in the text is verified claim-by-claim by authoritative sources. Our ground truth for trustworthy news consists of 4,500 news articles from well-known mainstream news publishers. With regard to the second contribution, we choose a Convolutional Neural Network (CNN) (κ = 0.89) and the widely used SVM (κ = 0.72) technique to detect fake news. Thus we hope that our approach will stimulate the progress in fake news detection and claim verification across languages.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-28957-7_13" target="_blank"> Evaluation of the existing tools for fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85072954254</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Gielczyk A., Wawrzyniak R., Choras M.</b></td></tr><tr><td colspan="3">Organisations: <b>UTP University of Science and Technology Bydgoszcz</b></td></tr><tr><td colspan="3">The extreme growth and adoption of Social Media and User Generated Content (UGC) websites, in combination with their poor governance and the lack of quality control over the digital content being published and shared, has led information veracity to a continuous deterioration. Therefore, there is a growing need for reliable information assurance, called by both private and public users and authorities. Due to the popularity of the social media and Internet availability all over the world, anyone can provide a piece of information on the web. This may create a ready channel for spreading false, not verified or confusing information, which may be called ‘fake news’. In order to protect the user from online disinformation, some tools have already been proposed. In this article we have described the available online tools and evaluated them using the same dataset, which was created for this study. We have provided the results proving that fake news detection is an increasingly more pressing, yet a difficult research problem.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Creating task-generic features for fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85073147836</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Olivieri A.C., Shabani S., Sokhn M., Cudre-Mauroux P.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Fribourg, University of Basel, HES-SO Valais-Wallis</b></td></tr><tr><td colspan="3">Information spreads at a pace never seen before on online platforms, even when this information is fake. Fake news can have substantial impact, for instance when it concern politics and influences the results of legislations or elections. Finding a methodology to verify if some piece of news is true or false is hence essential. In this work, we propose a methodology to create task-generic features that are paired with textual features in order to detect fake news. Task-generic features are created by elaborating on metadata attached to answers from Google's search engine, and by using crowdsourcing for missing values. We experimentally validate our method on a dataset for fake news detection based on the PolitiFact website. Our results show an improvement in F1-Score of 3% over the state of the art, which is significant for a 6-class task.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.18653/v1/d17-1317" target="_blank"> Truth of varying shades: Analyzing language in fake news and political fact-checking<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85073170072</td><td>Year: <b>2017</b></td></tr><tr><td colspan="3">Authors: <b>Rashkin H., Choi E., Choi Y., Jang J.Y., Volkova S.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Washington, Pacific Northwest National Laboratory</b></td></tr><tr><td colspan="3">We present an analytic study on the language of news media in the context of political fact-checking and fake news detection. We compare the language of real news with that of satire, hoaxes, and propaganda to find linguistic characteristics of untrustworthy text. To probe the feasibility of automatic political fact-checking, we also present a case study based on PolitiFact.com using their factuality judgments on a 6-point scale. Experiments show that while media fact-checking remains to be an open research question, stylistic cues can help determine the truthfulness of text.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/IC3.2019.8844892" target="_blank"> FIND: Fake Information and News Detections using Deep Learning<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85073193200</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Verma A., Mittal V., Dawn S.</b></td></tr><tr><td colspan="3">Organisations: <b>Jaypee Institute of Information Technology</b></td></tr><tr><td colspan="3">Fake news detection is very difficult while its spread is simple and has vast repercussions. To tackle this problem we propose a model which detects fake information and news with the help of Deep Learning and Natural Language Processing. A Deep Neural Network on self scraped data set is trained and by using Natural Language Processing the correlation of words in respective documents is found and these correlations serve as initial weights for the deep neural network which predicts a binary label to detect whether the news is fake or not. In this work we have successfully used Recurrent Neural Network and Long Short-Term Memories and Grated Recurrent Units to test for classification. Tensorboard is used for implementation of the proposed framework and provide visualizations for the neural network. Confusion matrix and classification reports show that accuracy score of upto 94 percent can be achieved using LSTM model. The tradeoff is the increased time requirement. Since the fake news can be established based on the learning model, a good training set is mandatory. The results show that the proposed framework is able to adequately present accurate result.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/IC3.2019.8844880" target="_blank"> Fake News Detection Using Sentiment Analysis<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85073196185</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Bhutani B., Rastogi N., Sehgal P., Purwar A.</b></td></tr><tr><td colspan="3">Organisations: <b>Jaypee Institute of Information Technology</b></td></tr><tr><td colspan="3">Social media is one of the most revolutionary inventions of the present times. With its own set of advantages and disadvantages it is extremely essential for each one of us. Today Fake News has become a major problem wreaking havoc all over the world. Therefore building an algorithm with the best possible accuracy will be a revelation and it will have a massive impact on the social issues which are prevalent as well as on the current political scenario. Social Media and online news articles serve as a major source of news and for data for people since it can be approached easily, has a subsidized costing and is readily available-just a click away. However, it does have several negative impacts too such as no check on the source or authenticity and validity of the views being endorsed. Hence, we have proposed a new solution for fake news detection which incorporates sentiment as an important feature to improve the accuracy. It also investigates the performance of proposed method using three different data sets. Results show that proposed solution performs well. Moreover, the comparison is also made with other methods under this study.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/IRI.2019.00066" target="_blank"> Fake news detection using bayesian inference<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85073215677</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Najar F., Zamzami N., Bouguila N.</b></td></tr><tr><td colspan="3">Organisations: <b>Concordia University, King Abdulaziz University</b></td></tr><tr><td colspan="3">Given the huge volume of information available on social media, making a distinction between false information and a real one is a challenging task. In fact, several statistical models dealing with this problem are based on multinomial distributions. However, a new family of distributions that is an exponential family approximation to the Dirichlet Compound Multinomial (EDCM) has been introduced to be more adjustable to high-dimensional data and to overcome the drawbacks of the multinomial assumption. Thus, in this paper, we tackle the problem of fake news detection using finite mixture models of EDCM distributions. In particular, we develop a Bayesian approach based on Markov Chain Monte Carlo and Metropolis-Hastings algorithm for the learning of these mixture models. The proposed method is validated via extensive simulations and a comparison with multinomial-based mixture models is provided.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICSCC.2019.8843597" target="_blank"> Fake News Detection in Social Media using Blockchain<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85073222458</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Paul S., Joy J.I., Sarker S., Shakib A.-A.-H., Ahmed S., Das A.K.</b></td></tr><tr><td colspan="3">Organisations: <b>East West University</b></td></tr><tr><td colspan="3">Blockchain technology has opened the gate of creating decentralized applications, where security is a big concern. Here, any transaction ever held is recorded permanently. Over the years, some non-reputable sources have been publishing fake and attractive news stories. Due to the lack of any regulatory systems, this news cannot be verified. Hence, these unreliable sources can publish whatever they want, and even in some cases, it makes chaos in society. In recent times due to the ease in internet availability and social media, inappropriate news can spread more quickly than ever before. In some cases, fake news is more attractive than the real one. Thus, people become misguided. Using the advantages of Blockchain's peer-to-peer network concepts, we will discuss a way to detect fake news in social media.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.3390/app9194062" target="_blank"> exBAKE: Automatic fake news detection model based on Bidirectional Encoder Representations from Transformers (BERT)<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85073295962</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Jwa H., Lim H., Oh D., Park K., Kang J.M.</b></td></tr><tr><td colspan="3">Organisations: <b>Korea University, Global Cyber University</b></td></tr><tr><td colspan="3">News currently spreads rapidly through the internet. Because fake news stories are designed to attract readers, they tend to spread faster. For most readers, detecting fake news can be challenging and such readers usually end up believing that the fake news story is fact. Because fake news can be socially problematic, a model that automatically detects such fake news is required. In this paper, we focus on data-driven automatic fake news detection methods. We first apply the Bidirectional Encoder Representations from Transformers model (BERT) model to detect fake news by analyzing the relationship between the headline and the body text of news. To further improve performance, additional news data are gathered and used to pre-train this model. We determine that the deep-contextualizing nature of BERT is best suited for this task and improves the 0.14 F-score over older state-of-the-art models.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3298689.3346972" target="_blank"> The 7th international workshop on news recommendation and analytics (INRA 2019)<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85073324403</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Ozgobek O., Gulla J.A., Kille B., Lommatzsch A.</b></td></tr><tr><td colspan="3">Organisations: <b>Norwegian University of Science and Technology, Berlin Institute of Technology</b></td></tr><tr><td colspan="3">Publishing news represents a vital function for societal health. News recommender systems, which support readers fnding relevant content, face challenges beyond those encountered by other types of recommender systems. They have to deal with a dynamic fow of unstructured, fragmentary, and potentially unreliable news stories. The International Workshop on News Recommendation and Analytics (INRA) focuses on the challenges of news recommender systems and aims to connect researchers, practitioners and journalists. The seventh edition of INRA takes place as a half-day workshop in conjunction with thirteenth ACM Conference on Recommender Systems (RecSys'19) on September 16-20, 2019 in Copenhagen, Denmark. INRA 2019 focuses on the news recommender systems under three main categories: News recommendation, news analytics, and ethical aspects of news recommendation.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.35940/ijitee.K1829.0981119" target="_blank"> Fake news detection of Indian and United States election data using machine learning algorithm<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85073325556</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Kumar A., Singh S., Kaur G.</b></td></tr><tr><td colspan="3">Organisations: <b>Central University of Punjab, Bathinda College of Law</b></td></tr><tr><td colspan="3">The world of digital media is thriving by the day and hence, there is an urge of businesses to magnify it more gaining them maximum financial benefits. This particular urge calls for more and more expansions concerning creating and developing new content whether it's in the form of websites that aims at branding businesses or could be in the form of online newspapers and magazines. Since from last few decades’ medium of communication had changed. Now a day people are using social networks very extensively for news updates. These networks aim to make social lives better. Today, everyone knows and uses social media which contains unverified article, post, message and news. Nowadays' fake news is making various issues from mocking articles to a created news and plan government publicity in certain outlets. Fake news and the absence of trust in the media are developing issues with immense consequences in our general public. It is needed to look into how the techniques in the fields of computer science using machine learning, natural language processing helps us to detect fake news. Fake news is now observed as one of the major threats to freedom of expression, journalism, and democracy of a country. In this research, a comprehensive way of detecting fake news using machine learning model has been presented that is trained by Fake News data based on US election and trained on recent Indian political Fake news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.4230/LIPIcs.TIME.2019.2" target="_blank"> From unstructured data to narrative abstractive summaries<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85073535785</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Boro E.S.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Alicante</b></td></tr><tr><td colspan="3">To provide with easy and optimal access to digital information, narrative summaries must have a coherent and natural structure. Depending on how a summary is produced, a distinction can be made between extractive and abstractive summaries. Using an abstractive summarization approach, the relevant information (e.g., who? what?, when?, where?,...) could be fused together, leading to the generation of one or more new sentences. However, in order to do this it is necessary to obtain and process the temporal information in a text. A very effective way is the generation of timelines starting from multiple documents so that the generation of summaries is supported by the generated timeline, without losing the relevant temporal information of the texts. In this proposal, a enriched timeline is generated automatically, and the process of generating abstractive summaries is presented using this timeline as a basis [1]. Finally, potential applications of the automatic timeline generation would be presented, as for example its application to Fake News detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/HPCC/SmartCity/DSS.2019.00383" target="_blank"> Stacking-based ensemble learning on low dimensional features for fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85073552954</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Li S., Niu X., Wang Y., Ji K., Yu Z., Chen Z., Ma K.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Jinan</b></td></tr><tr><td colspan="3">With the age of incoming of self-media, everyone can be the author of the content in the media age of big data. This has caused a mass of fake news appearing in the network. Authors of these fake news will mislead the public by spreading and it will bring economic and social benefits. Existing work focuses on using the various types of features of the article in the hope that a way to accurately identify fake news can be found, but this undermines their universality. In this paper, we propose a pipeline that combines preprocessing, feature extraction and model fusion for a more accurate and automated prediction. Specially we fusion of latent semantic analysis (LSA) and ensemble learning model results using stacking. Experimental analysis of real-world data demonstrates that our pipeline achieves higher accuracy than existing approaches.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.35940/ijitee.K1236.09811S19" target="_blank"> Fake news and rumour detection on social media<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85073726663</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Devi M.U., Tyagi H., Jindal A.</b></td></tr><tr><td colspan="3">Organisations: <b>SRMIST</b></td></tr><tr><td colspan="3">PC Mediated Communication (CMC) advances like, for example, online journals, Twitter, Reddit, Facebook and other web based life presently have such a large number of dynamic clients that they have turned into an ideal stage for news conveyance on a mass scale. Such a mass scale news conveyance framework accompanies a proviso of faulty veracity. Building up the unwavering quality of data online is a strenuous and an overwhelming test yet it is basically essential particularly amid the time-touchy circumstances, for example, genuine crises which can have destructive impact on people and society. 2016 US Presidential race is an encapsulation of the previously mentioned crisis. In a study, it was concluded that the public's engagement with phoney news through Facebook was higher than through standard sources. So as to battle the spread of malevolent and unplanned falsehood in online networking we built up a model to recognise counterfeit news. Counterfeit news recognition is a procedure of classifying news and estimating it on the continuum of veracity. Detection is done by classifying and clustering assertions made about the event followed by veracity assessment methods emerging from linguistic cue, characteristics of the people involved and network propagation dynamics.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3331184.3331288" target="_blank"> Information cascades modeling via deep multi-task learning<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85073788082</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Chen X., Zhou F., Zhong T., Zhang F., Zhang K., Trajcevski G.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Electronic Science and Technology of China, University of Maryland, Iowa State University</b></td></tr><tr><td colspan="3">Effectively modeling and predicting the information cascades is at the core of understanding the information diffusion, which is essential for many related downstream applications, such as fake news detection and viral marketing identification. Conventional methods for cascade prediction heavily depend on the hypothesis of diffusion models and hand-crafted features. Owing to the significant recent successes of deep learning in multiple domains, attempts have been made to predict cascades by developing neural networks based approaches. However, the existing models are not capable of capturing both the underlying structure of a cascade graph and the node sequence in the diffusion process which, in turn, results in unsatisfactory prediction performance. In this paper, we propose a deep multi-task learning framework with a novel design of shared-representation layer to aid in explicitly understanding and predicting the cascades. As it turns out, the learned latent representation from the shared-representation layer can encode the structure and the node sequence of the cascade very well. Our experiments conducted on real-world datasets demonstrate that our method can significantly improve the prediction accuracy and reduce the computational cost compared to state-of-the-art baselines.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.35940/ijitee.L2510.1081219" target="_blank"> Recognition of position group relationship in dynamic social networks<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85073808495</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Thabitha D., Jhansi Vazram B., Ezra Sastry G.</b></td></tr><tr><td colspan="3">Organisations: <b>Narasaraopet Engineering College</b></td></tr><tr><td colspan="3">Mental stress is turning into a threat to people's health currently days. With the last step of life, a lot of and a lot of folks are feeling stressed. A novel hybrid model combined with Convolution Neural Network (CNN) to control tweet content and social interaction information for stress detection effectively. Network anomaly detection is an important and dynamic research area. Many network intrusion detection methods and systems (NIDS) have been proposed in the literature. Fake news detection on social media presents unique characteristics and challenges that make existing detection algorithms from traditional news media ineffective or not applicable. Based on the information that is provided by the online social network, the conditions are limited. This method can opinion investigation of Facebook post after Formation of point utilizing Support Vector Method (SVM). After grouping client is in pressure or not k-closest neighbor calculation (KNN) is utilized for proposal emergency clinic on a guide just as Admin can send letters of precautionary measure list for the client for end up solid and upbeat throughout everyday life.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICOEI.2019.8862748" target="_blank"> ALIKAH- A clickbait and fake news detection system using natural language processing<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85074079868</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Kuriakose A., Sebastian D., Mathew E.M., Mathew H., Gokulnath G.Er.</b></td></tr><tr><td colspan="3">Organisations: <b>APJ Abdul Kalam Technological University</b></td></tr><tr><td colspan="3">Nowadays, social media is a very important thing in our daily lives. People can't even think about a second without social media. Because of their busy life, people depend more on social media for information, thus increasing its popularity. Social media can be considered as a two-sided coin having its own advantage and disadvantage. These media help people to connect with their family or friends around the world. But the other side of the social media has many disadvantages. It can be considered as the cause of many problems in our society. One such major issue is the fake news. People were unable to distinguish the true and fake news and also about the credibility of the news and the news provider. They blindly believe the news without knowing the truth and they share the news with others. As a result, the fake news spread faster than the true news. By this, many people and organizations get affected. So, in a world of increasing fake news, a fake news detection system is an essential thing. This project deals with fake news. The system is a Webapp named ALIKAH- a clickbait and fake news detection system. It is just like social media network where the news providers can provide the news. This system distinguishes the fake and true news among the news provided in the Alikah system. There are three modules in this system-the admin, news providers and the users. Admin manages and monitors the system and its functionalities. News providers can provide the news to this system after getting permission from the admin and the user can view, like, comment, report and subscribe to the news and the news provider. Neural network is used as the classifier. This system detects the fake news by checking the credibility of the news provider, monitoring the comments and also by checking the relation of the heading and content of the news provided. It also helps to detect the fake news spreading on other social media like Facebook, by using its heading and content. This system definitely will be a beneficiary to the people and organizations which get affected by the news and also help to find the providers of these news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICOEI.2019.8862770" target="_blank"> Fake news detection using machine learning approaches: A systematic review<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85074097965</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Manzoor S.I., Singla J., Nikita</b></td></tr><tr><td colspan="3">Organisations: <b>Lovely Professional University</b></td></tr><tr><td colspan="3">The easy access and exponential growth of the information available on social media networks has made it intricate to distinguish between false and true information. The easy dissemination of information by way of sharing has added to exponential growth of its falsification. The credibility of social media networks is also at stake where the spreading of fake information is prevalent. Thus, it has become a research challenge to automatically check the information viz a viz its source, content and publisher for categorizing it as false or true. Machine learning has played a vital role in classification of the information although with some limitations. This paper reviews various Machine learning approaches in detection of fake and fabricated news. The limitation of such and approaches and improvisation by way of implementing deep learning is also reviewed.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1177/2053951719843310" target="_blank"> Big Data and quality data for fake news and misinformation detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85074170366</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Torabi Asr F., Taboada M.</b></td></tr><tr><td colspan="3">Organisations: <b>Simon Fraser University</b></td></tr><tr><td colspan="3">Fake news has become an important topic of research in a variety of disciplines including linguistics and computer science. In this paper, we explain how the problem is approached from the perspective of natural language processing, with the goal of building a system to automatically detect misinformation in news. The main challenge in this line of research is collecting quality data, i.e., instances of fake and real news articles on a balanced distribution of topics. We review available datasets and introduce the MisInfoText repository as a contribution of our lab to the community. We make available the full text of the news articles, together with veracity labels previously assigned based on manual assessment of the articles’ truth content. We also perform a topic modelling experiment to elaborate on the gaps and sources of imbalance in currently available datasets to guide future efforts. We appeal to the community to collect more data and to make it available for research purposes.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3331184.3331248" target="_blank"> Learning from fact-checkers: Analysis and generation of fact-checking language<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85074216453</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Vo N., Lee K.</b></td></tr><tr><td colspan="3">Organisations: <b>Worcester Polytechnic Institute</b></td></tr><tr><td colspan="3">In fighting against fake news, many fact-checking systems comprised of human-based fact-checking sites (e.g., snopes.com and politifact.com) and automatic detection systems have been developed in recent years. However, online users still keep sharing fake news even when it has been debunked. It means that early fake news detection may be insufficient and we need another complementary approach to mitigate the spread of misinformation. In this paper, we introduce a novel application of text generation for combating fake news. In particular, we (1) leverage online users named fact-checkers, who cite fact-checking sites as credible evidences to fact-check information in public discourse; (2) analyze linguistic characteristics of fact-checking tweets; and (3) propose and build a deep learning framework to generate responses with fact-checking intention to increase the fact-checkers' engagement in fact-checking activities. Our analysis reveals that the fact-checkers tend to refute misinformation and use formal language (e.g. few swear words and Internet slangs). Our framework successfully generates relevant responses, and outperforms competing models by achieving up to 30% improvements. Our qualitative study also confirms that the superiority of our generated responses compared with responses generated from the existing models.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3341981.3344229" target="_blank"> SADHAN: Hierarchical attention networks to learn latent aspect embeddings for fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85074222907</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Mishra R., Setty V.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Stavanger</b></td></tr><tr><td colspan="3">Recently false claims and misinformation have become rampant in the web, affecting election outcomes, societies and economies. Consequently, fact checking websites such as snopes.com and politifact. com are becoming popular. However, these websites require expert analysis which is slow and not scalable. Many recent works try to solve these challenges using machine learning models trained on a variety of features and a rich lexicon or more recently, deep neural networks to avoid feature engineering. In this paper, we propose hierarchical deep attention networks to learn embeddings for various latent aspects of news. Contrary to existing solutions which only apply word-level self-attention, our model jointly learns the latent aspect embeddings for classifying false claims by applying hierarchical attention. Using several manually annotated high quality datasets such as Politifact, Snopes and Fever we show that these learned aspect embeddings are strong predictors of false claims. We show that latent aspect embeddings learned from attention mechanisms improve the accuracy of false claim detection by up to 13.5% in terms of Macro F1 compared to a state-of-the-art attention mechanism guided by claim-text (DeClarE). We also extract and visualize the evidence from the external articles which supports or disproves the claims.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/JCSSE.2019.8864171" target="_blank"> Natural Language Contents Evaluation System for Detecting Fake News using Deep Learning<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85074227967</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Ahn Y.-C., Jeong C.-S.</b></td></tr><tr><td colspan="3">Organisations: <b>Korea University</b></td></tr><tr><td colspan="3">This Recently, a lot of information is spreading rapidly on SNS. Inaccurate communication of news media includes fears about unreliable sources and fake news that lacks confirmation of facts. Fake news is spread through SNS, causing social confusion and further economic loss. The purpose of the news is accurate information transmission. In this regard, it is very important to judge the discrepancies in the contents of the text and the distorted reports. We try to solve the problem of judging whether the sentence to be verified is correct after collecting the facts. This paper defines the problem of extracting the related sentences from the input sentence in Fact Data Corpus which is assumed to be fact and judging whether the extracted sentence and the input sentence are true or false. In the various NLP tasks, we create a Korean-specific pre-Training model using state-of-The-Art BERT. Using this model, fine-Tuning is performed to match the data set detected by Korean fake news. The AUROC score of 83.8% is derived from the test set generated using the fine-Tuned model.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/JCSSE.2019.8864154" target="_blank"> Fake News Detection System using Article Abstraction<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85074241092</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Kim K.-H., Jeong C.-S.</b></td></tr><tr><td colspan="3">Organisations: <b>Korea University</b></td></tr><tr><td colspan="3">Recently, fake news has been incurring many problems to our society. As a result, many researchers have been working on identifying fake news. Most of the fake news detection systems utilize the linguistic feature of the news. However, they have difficulty in sensing highly ambiguous fake news which can be detected only after identifying meaning and latest related information. In this paper, to resolve this problem, we shall present a new Korean fake news detection system using fact DB which is built and updated by human's direct judgement after collecting obvious facts. Our system receives a proposition, and search the semantically related articles from Fact DB in order to verify whether the given proposition is true or not by comparing the proposition with the related articles in fact DB. To achieve this, we utilize a deep learning model, Bidirectional Multi-Perspective Matching for Natural Language Sentence(BiMPM), which has demonstrated a good performance for the sentence matching task. However, BiMPM has some limitations in that the longer the length of the input sentence is, the lower its performance is, and it has difficulty in making an accurate judgement when an unlearned word or relation between words appear. In order to overcome the limitations, we shall propose a new matching technique which exploits article abstraction as well as entity matching set in addition to BiMPM. In our experiment, we shall show that our system improves the whole performance for fake news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.physa.2019.123174" target="_blank"> Fake news detection within online social media using supervised artificial intelligence algorithms<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85074460484</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Ozbay F.A., Alatas B.</b></td></tr><tr><td colspan="3">Organisations: <b>Firat University</b></td></tr><tr><td colspan="3">Along with the development of the Internet, the emergence and widespread adoption of the social media concept have changed the way news is formed and published. News has become faster, less costly and easily accessible with social media. This change has come along with some disadvantages as well. In particular, beguiling content, such as fake news made by social media users, is becoming increasingly dangerous. The fake news problem, despite being introduced for the first time very recently, has become an important research topic due to the high content of social media. Writing fake comments and news on social media is easy for users. The main challenge is to determine the difference between real and fake news. In this paper, a two-step method for identifying fake news on social media has been proposed, focusing on fake news. In the first step of the method, a number of pre-processing is applied to the data set to convert un-structured data sets into the structured data set. The texts in the data set containing the news are represented by vectors using the obtained TF weighting method and Document-Term Matrix. In the second step, twenty-three supervised artificial intelligence algorithms have been implemented in the data set transformed into the structured format with the text mining methods. In this work, an experimental evaluation of the twenty-three intelligent classification methods has been performed within existing public data sets and these classification models have been compared depending on four evaluation metrics.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3184558.3188722" target="_blank"> Fake News Detection in Social Networks via Crowd Signals<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85074482071</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Tschiatschek S., Singla A., Gomez Rodriguez M., Merchant A., Krause A.</b></td></tr><tr><td colspan="3">Organisations: <b>Microsoft Research, MPI-SWS, IIIT-H, ETH Zurich</b></td></tr><tr><td colspan="3">Our work considers leveraging crowd signals for detecting fake news and is motivated by tools recently introduced by Facebook that enable users to flag fake news. By aggregating users' flags, our goal is to select a small subset of news every day, send them to an expert (e.g., via a third-party fact-checking organization), and stop the spread of news identified as fake by an expert. The main objective of our work is to minimize the spread of misinformation by stopping the propagation of fake news in the network. It is especially challenging to achieve this objective as it requires detecting fake news with high-confidence as quickly as possible. We show that in order to leverage users' flags efficiently, it is crucial to learn about users' flagging accuracy. We develop a novel algorithm, DETECTIVE, that performs Bayesian inference for detecting fake news and jointly learns about users' flagging accuracy over time. Our algorithm employs posterior sampling to actively trade off exploitation (selecting news that maximize the objective value at a given epoch) and exploration (selecting news that maximize the value of information towards learning about users' flagging accuracy). We demonstrate the effectiveness of our approach via extensive experiments and show the power of leveraging community signals for fake news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.35940/ijeat.A2633.109119" target="_blank"> Fakebuster: Fake news detection system using logistic regression technique in machine learning<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85074582614</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Mokhtar M.S., Jusoh Y.Y., Admodisastro N., Pa N., Amruddin A.Y.</b></td></tr><tr><td colspan="3">Organisations: <b>Universiti Putra Malaysia, Technology Park Malaysia</b></td></tr><tr><td colspan="3">The uncontrollable spread of fake news through the net is irresistible in this globalization era. Fake news dissemination cannot be tolerated as the bad impacts of it to the society is really worrying. Furthermore, this will lead to more significant problems and potential threat such as confusion, misconceptions, slandering and luring users to share provocative lies made from fabricated news through their social media to occur. Within Malaysia context, there is lack in platform for fake news detection in Malay language articles and most of Malaysians received news through their social messaging applications. Fake news can be certainly solved by the aid of artificial intelligence which includes machine learning algorithms. The objective of this project is to propose a fake news detection model using Logistic Regression, to evaluate the performance of Logistic Regression as fake news detection model and to develop a web application that allows entry of a news content or news URL. In this study, Logistic Regression was applied in detecting fake news. Model development methodology is referenced and followed in this project. Based on existing studies, Logistic Regression showed a good performance in classification task. In addition, stancedetection approach is added to improve the accuracy of the model performance. Based on analysis made, this model within stance detection approach yields an excellent accuracy using TF-IDF feature in constructing this fake news model. This model is then integrated with web service that accepts input either news URL or news content in text which is then checked for its truth level through “FAKEBUSTER” application.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-33509-0_86" target="_blank"> A Novel Approach for Selecting Hybrid Features from Online News Textual Metadata for Fake News Detection<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85074681726</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Elhadad M.K., Li K.F., Gebali F.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Victoria</b></td></tr><tr><td colspan="3">Nowadays, online news platforms have become the main sources of news for many users. Hence, an urgent need arises to find a way to classify this news automatically and measure its validity to avoid spreading fake news. In this paper, we tried to simulate how humans, in real life, are dealing with news documents. We introduced a new way in which we can deal with the whole textual content of the news documents by extracting a number of characteristics of those texts and extracting a complex set of other metadata related features without segmenting the news documents into parts (title, content, date, source, etc.). Performances of nine machine learning algorithms in terms of Accuracies, Precision, Recall and F1-score are compared when using three different datasets obtaining much better result than the results in [1] and [2].</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/PACRIM47961.2019.8985062" target="_blank"> Fake News Detection on Social Media: A Systematic Survey<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85074709499</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Elhadad M.K., Fun Li K., Gebali F.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Victoria</b></td></tr><tr><td colspan="3">These days there are instabilities in many societies in the world, either because of political, economic, and other societal issues. The advance in mobile technology has enabled social media to play a vital role in organizing activities in favour or against certain parties or countries. Many researchers see the need to develop automated systems that are capable of detecting and tracking fake news on social media. In this paper, we introduce a systematic survey on the process of fake news detection on social media. The types of data and the categories of features used in the detection model, as well as benchmark datasets are discussed.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3350546.3352534" target="_blank"> Check-it: A plugin for detecting and reducing the spread of fake news and misinformation on the web<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85074774412</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Paschalides D., Christodoulou C., Andreou R., Pallis G., Dikaiakos M.D., Kornilakis A., Markatos E.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Cyprus, University of Crete Heraklion</b></td></tr><tr><td colspan="3">Over the past few years, we have been witnessing the rise of misinformation on the Internet. People fall victims of fake news continuously, and contribute to their propagation knowingly or inadvertently. Many recent efforts seek to reduce the damage caused by fake news by identifying them automatically with artificial intelligence techniques, using signals from domain flag-lists, online social networks, etc. In this work, we present Check-It, a system that combines a variety of signals into a pipeline for fake news identification. Check-It is developed as a web browser plugin with the objective of efficient and timely fake news detection, while respecting user privacy. In this paper, we present the design, implementation and performance evaluation of Check-It. Experimental results show that it outperforms state-of-the-art methods on commonly-used datasets.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1002/ett.3767" target="_blank"> Fake news detection using deep learning models: A novel approach<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85074776534</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Kumar S., Asthana R., Upreti N., Akbar M., Upadhyay S.</b></td></tr><tr><td colspan="3">Organisations: <b>Ajay Kumar Garg Engineering College</b></td></tr><tr><td colspan="3">With the ever increase in social media usage, it has become necessary to combat the spread of false information and decrease the reliance of information retrieval from such sources. Social platforms are under constant pressure to come up with efficient methods to solve this problem because users' interaction with fake and unreliable news leads to its spread at an individual level. This spreading of misinformation adversely affects the perception about an important activity, and as such, it needs to be dealt with using a modern approach. In this paper, we collect 1356 news instances from various users via Twitter and media sources such as PolitiFact and create several datasets for the real and the fake news stories. Our study compares multiple state-of-the-art approaches such as convolutional neural networks (CNNs), long short-term memories (LSTMs), ensemble methods, and attention mechanisms. We conclude that CNN + bidirectional LSTM ensembled network with attention mechanism achieved the highest accuracy of 88.78%, whereas Ko et al tackled the fake news identification problem and achieved a detection rate of 85%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3350546.3352552" target="_blank"> Which machine learning paradigm for fake news detection?<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85074785254</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Katsaros D., Stavropoulos G., Papakostas D.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Cyprus, University of Thessaly</b></td></tr><tr><td colspan="3">Fake news detection/classification is gradually becoming of paramount importance to out society in order to avoid the so-called reality vertigo, and protect in particular the less educated persons. Various machine learning techniques have been proposed to address this issue. This article presents a comprehensive performance evaluation of eight machine learning algorithms for fake news detection/classification.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s00500-019-04436-y" target="_blank"> Automating fake news detection system using multi-level voting model<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85074815206</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Kaur S., Kumar P., Kumaraguru P.</b></td></tr><tr><td colspan="3">Organisations: <b>TIET, IIIT</b></td></tr><tr><td colspan="3">The issues of online fake news have attained an increasing eminence in the diffusion of shaping news stories online. Misleading or unreliable information in the form of videos, posts, articles, URLs is extensively disseminated through popular social media platforms such as Facebook and Twitter. As a result, editors and journalists are in need of new tools that can help them to pace up the verification process for the content that has been originated from social media. Motivated by the need for automated detection of fake news, the goal is to find out which classification model identifies phony features accurately using three feature extraction techniques, Term Frequency–Inverse Document Frequency (TF–IDF), Count-Vectorizer (CV) and Hashing-Vectorizer (HV). Also, in this paper, a novel multi-level voting ensemble model is proposed. The proposed system has been tested on three datasets using twelve classifiers. These ML classifiers are combined based on their false prediction ratio. It has been observed that the Passive Aggressive, Logistic Regression and Linear Support Vector Classifier (LinearSVC) individually perform best using TF-IDF, CV and HV feature extraction approaches, respectively, based on their performance metrics, whereas the proposed model outperforms the Passive Aggressive model by 0.8%, Logistic Regression model by 1.3%, LinearSVC model by 0.4% using TF-IDF, CV and HV, respectively. The proposed system can also be used to predict the fake content (textual form) from online social media websites.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3358528.3358567" target="_blank"> Early detection of fake news “before it flies high<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85074841428</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Gereme F.B., Zhu W.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Electronic Science and Technology of China</b></td></tr><tr><td colspan="3">Currently, social media for news consumption is preferred over the conventional media and attracted many people due to its low cost, easy access, simplistic way of commenting & sharing, more timely nature, and rapid information sharing capabilities. On the other hand, it aggravates the prompt and wide spreading of fake news. Fake news may be fabricated for the purpose of, commercial gain, political propaganda, seeking attention, and intent of defamation. Interest of individuals, and various groups to influence events and policies around the globe is the other reason for fake news generation and dissemination. The extensive spread of fake news is progressively becoming a threat to individuals and society as a whole. It disrupts the authenticity balance of the news ecosystem; induces biased or false beliefs into consumers; creates real-life fears in the society and threatens freedom of speech, freedom of the press and democracy. The craving to mitigate the undesirable effects of fake news, recently makes fake news detection on social media an emerging research area attracting tremendous attention. Following this warm concern, various researches have been conducted and showed promising results. In this work, we propose a model for early detection of fake news using deep learning, and news content. Deep learning and heterogeneous dataset has been used to create a more generic model that could perform better in the real world. We conducted experiments on two real world datasets and a third dataset which is obtained by combining the two datasets and randomly shuffled them. Our experiment results have shown that early detection of fake news using news content and deep learning models, without waiting for news propagation, is achievable and should be given better attention to combat fake news effectively before it proliferates and misleads many people. The experimental results obtained are interesting.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.3745/JIPS.04.0142" target="_blank"> Fake news detection using deep learning<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85074926857</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Lee D.-H., Kim Y.-R., Kim H.-J., Park S.-M., Yang Y.-J.</b></td></tr><tr><td colspan="3">Organisations: <b>Sungkyunkwan University, Hansung University, Yonsei University, Hanyang University, Gachon University</b></td></tr><tr><td colspan="3">With the wide spread of Social Network Services (SNS), fake news-which is a way of disguising false information as legitimate media-has become a big social issue. This paper proposes a deep learning architecture for detecting fake news that is written in Korean. Previous works proposed appropriate fake news detection models for English, but Korean has two issues that cannot apply existing models: Korean can be expressed in shorter sentences than English even with the same meaning; therefore, it is difficult to operate a deep neural network because of the feature scarcity for deep learning. Difficulty in semantic analysis due to morpheme ambiguity. We worked to resolve these issues by implementing a system using various convolutional neural network-based deep learning architectures and "Fasttext" which is a word-embedding model learned by syllable unit. After training and testing its implementation, we could achieve meaningful accuracy for classification of the body and context discrepancies, but the accuracy was low for classification of the headline and body discrepancies.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> An experimental technique on fake news detection in online social media<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85075283229</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Boukhari M.A., Gayakwad M.D.</b></td></tr><tr><td colspan="3">Organisations: <b>Bharati Vidyapeeth (Deemed to be University)</b></td></tr><tr><td colspan="3">Social media is a double-edged sword for news consumption. On the one side, its low price, simple access and fast data dissemination lead individuals to search and consume social media news. On the otherT side,T thisT isT allowsT theT wideT disseminationT ofT \fakeT news,T.T lowT qualityT newsT withT intentionallyT falseT information.T TheT widespreadT disseminationT ofT falseT newsT hasT theT abilityT toT impactT peopleT and society highly negatively… Therefore, the detection of false news in recently, social media has become a studyT thatT attractsT tremendousT attention.T FalseT newsT ofT DetectionT UniqueT inT theT socialT mediaT featuresT andT difficultiesT thatT makeT algorithmsT availableT forT detectionT ofT traditionalT IneffectiveT orT non-applicableT media.T First,T theT falseT newsT isT deliberatelyT writtenT toT deceiveT readersT intoT believingT falseT dataT andT information,T makingT itT tT dissectsT andT notT trivialT inT orderT toT detectT newsT content,T weT needT toT includeT informationT Auxiliary,T asT theT socialT commitmentsT ofT usersT inT helpingT toT createT aT determinationT forT socialT media.T Second,T thisT extraT dataT andT informationT isT challengingT inT andT ofT itselfT socialT commitmentsT ofT theT usersT withT falseT newsT produceT dataT whichT areT large,T incomplete,T unstructuredT andT that’sT loud.T BecauseT theT issueT ofT identifyingT fakeT newsT inT socialT mediaT isT bothT difficultT andT meaningful,T weT performedT thisT studyT toT promoteT furtherT researchT intoT theT issue..T ThisT studyT providesT aT thoroughT overviewT ofT theT detectionT ofT fakeT socialT mediaT news,T includingT fakeT psychologicalT andT socialT theoryT newsT characteristics,T currentT informationT miningT algorithms,T assessmentT metricsT andT representativeT datasetsT weT alsoT addressT associatedT fieldsT ofT studies,T openT issuesT andT futureT directionsT forT theT detectionT ofT fakeT newsT onT socialT media.T We also discuss related research areas, open problems, and future research directions for fake news detection on social media.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3357384.3357862" target="_blank"> dEFEND: A system for explainable fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85075429232</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Cui L., Wang S., Lee D., Shu K., Liu H.</b></td></tr><tr><td colspan="3">Organisations: <b>Penn State University, Arizona State University</b></td></tr><tr><td colspan="3">Despite recent advancements in computationally detecting fake news, we argue that a critical missing piece be the explainability of such detection-i.e., why a particular piece of news is detected as fake-and propose to exploit rich information in users' comments on social media to infer the authenticity of news. In this demo paper, we present our system for an explainable fake news detection called dEFEND, which can detect the authenticity of a piece of news while identifying user comments that can explain why the news is fake or real. Our solution develops a sentence-comment co-attention sub-network to exploit both news contents and user comments to jointly capture explainable top-k check-worthy sentences and user comments for fake news detection. The system is publicly accessible.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-32233-5_54" target="_blank"> Multi-depth Graph Convolutional Networks for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85075565606</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Hu G., Qi S., Wang X., Liao Q., Ding Y.</b></td></tr><tr><td colspan="3">Organisations: <b>Harbin Institute of Technology (Shenzhen), Dongguan University of Technology, Peng Cheng Laboratory</b></td></tr><tr><td colspan="3">Fake news arouses great concern owing to its political and social impacts in recent years. One of the significant challenges of fake news detection is to automatically identify fake news based on limited information. Existing works show that only considering news content and its linguistic features cannot achieve satisfactory performance when the news is short. To improve detection performance with limited information, we focus on incorporating the similarity of news to discriminate different degrees of fakeness. Specifically, we propose a multi-depth graph convolutional networks framework (M-GCN) to (1) acquire the representation of each news node via graph embedding; and (2) use multi-depth GCN blocks to capture multi-scale information of neighbours and combine them by attention mechanism. Experiment results on one of the largest real-world public fake news dataset LIAR demonstrate that the proposed M-GCN outperforms the latest five methods.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-32233-5_49" target="_blank"> User-Characteristic Enhanced Model for Fake News Detection in Social Media<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85075583350</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Jiang S., Chen X., Zhang L., Chen S., Liu H.</b></td></tr><tr><td colspan="3">Organisations: <b>Guangdong University of Foreign Studies, Eastern Language Processing Center</b></td></tr><tr><td colspan="3">In recent years, social media has become an ideal channel for news consumption while it also contributes to the rapid dissemination of fake news out of easy access and low cost. Fake news has detrimental effects both on the society and individuals. Nowadays, fake news detection in social media has been widely explored. While most previous works focus on different network analysis, user profiles of individuals in the news-user network are proven to be useful yet ignored when analyzing the network structure. Therefore, in this paper, we aim to utilize user attributes to discover potential user connections in the friendship network with attributed network representation learning and reconstruct the news-user network to enhance the embeddings of news and users in the news propagation network, which effectively identify those users who tend to spread fake news. Finally, we propose a unified framework to learn news content and news-user network features respectively. Experimental results on two real-world datasets demonstrate the effectiveness of our proposed approach, which achieves the state-of-the-art performance.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3323503.3360626" target="_blank"> Fake news detection on social media via implicit crowd signals<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85075594980</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Freire P.M.S., Goldschmidt R.R.</b></td></tr><tr><td colspan="3">Organisations: <b>Military Institute of Engineering (IME)</b></td></tr><tr><td colspan="3">The proliferation of Fake News on social media has been a source of widespread concern. One of the main approaches to automatically detect this type of news is based on crowd signals, i.e., opinions manifested by social media users concerning whether the news are fake or not. Although promising, this approach depends on information that is not always available: the explicit opinion of the users about the news to be checked. To overcome this drawback, this article proposes a crowd signal-based method that does not demand the users’ explicit opinion to detect Fake News. The proposed method infers the users’ opinions from their news spreading (publication/propagation) behavior. Preliminary experiments with two real-world datasets provided evidence that the proposed method can detect Fake News without demanding the explicit opinion of the users about the news and without compromising the classification results obtained by the state-of-the-art crowd signal-based method.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-33904-3_5" target="_blank"> Applying Self-attention for Stance Classification<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85075655497</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Bugueno M., Mendoza M.</b></td></tr><tr><td colspan="3">Organisations: <b>Universidad Técnica Federico Santa María</b></td></tr><tr><td colspan="3">Stance classification is the task of automatically identify the user’s positions about a specific topic. The classification of stance may help to understand how people react to a piece of target information, a task that is interesting in different areas as advertising campaigns, brand analytics, and fake news detection, among others. The rise of social media has put into the focus of this task the classification of stance in online social networks. A number of methods have been designed for this purpose showing that this problem is hard and challenging. In this work, we explore how to use self-attention models for stance classification. Instead of using attention mechanisms to learn directly from the text we use self-attention to combine different baselines’ outputs. For a given post, we use the transformer architecture to encode each baseline output exploiting relationships between baselines and posts. Then, the transformer learns how to combine the outputs of these methods reaching a consistently better classification than the ones provided by the baselines. We conclude that self-attention models are helpful to learn from baselines’ outputs in a stance classification task.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-33904-3_7" target="_blank"> Brazilian Presidential Elections in the Era of Misinformation: A Machine Learning Approach to Analyse Fake News<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85075667973</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Alves J.L., Weitzel L., Cardoso C.E., Cunha L., Quaresma P.</b></td></tr><tr><td colspan="3">Organisations: <b>Fluminense Federal University, Universidade de Évora</b></td></tr><tr><td colspan="3">As Brazil faced one of its most important elections in recent times, the fact-checking agencies handled the same kind of misinformation that has attacked voting in the US. However, stopping fake content before it goes viral remains an intense challenge. This paper examines a sample database of the 2018 Brazilian election articles shared by Brazilians over social media platforms. We evaluated three different configuration of Long Short-Term Memory. Experiment results indicate that the 3-layer Deep BiLSTMs with trainable word embeddings configuration was the best structure for fake news detection. We noticed that the developments in deep learning could potentially benefit fake news research.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ViTECoN.2019.8899556" target="_blank"> Detection of Online Fake News : A Survey<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85075826617</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Gaonkar S., Itagi S., Chalippatt R., Gaonkar A., Aswale S., Shetgaonkar P.</b></td></tr><tr><td colspan="3">Organisations: <b>Goa University</b></td></tr><tr><td colspan="3">There has been a large surge of fake news in recent times due to the immense use of social media and online news media. It has become much easier to spread fake news then how it used to be earlier. This kind of fake news when spread may have a severe effect. Hence it is extremely essential that certain measures should be taken in order to reduce or distinguish between real and fake news. This paper presents a survey on fake news detection. In addition, this paper proposes a model that classifies unreliable news into real and fake news after computing a score and will be able to distinguish between real and fake news based on various parameters obtained from a Uniform Resource Locator (URL). The model proposed will use various MachineLearning and Natural Language Processing (NLP) techniques to achieve maximum accuracy.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.3837/tiis.2019.10.008" target="_blank"> Fagon: Fake news detection model using grammatical transformation on deep neural network<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85076016496</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Seo Y., Jeong C.-S., Han S.-S., Jeon Y.-B.</b></td></tr><tr><td colspan="3">Organisations: <b>Korea University, Soonchunhyang University</b></td></tr><tr><td colspan="3">As technology advances, the amount of fake news is increasing more and more by various reasons such as political issues and advertisement exaggeration. However, there have been very few research works on fake news detection, especially which uses grammatical transformation on deep neural network. In this paper, we shall present a new Fake News Detection Model, called FAGON(Fake news detection model using Grammatical transformation On deep Neural network) which determines efficiently if the proposition is true or not for the given article by learning grammatical transformation on neural network. Especially, our model focuses the Korean language. It consists of two modules: sentence generator and classification. The former generates multiple sentences which have the same meaning as the proposition, but with different grammar by training the grammatical transformation. The latter classifies the proposition as true or false by training with vectors generated from each sentence of the article and the multiple sentences obtained from the former model respectively. We shall show that our model is designed to detect fake news effectively by exploiting various grammatical transformation and proper classification structure.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> A comparison of machine learning algorithms in fake news detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85076203546</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Ahmad F., Lokeshkumar R.</b></td></tr><tr><td colspan="3">Organisations: <b>School of Computer Science and Engineering</b></td></tr><tr><td colspan="3">Fake news has turned out to be a menace. Distinguishing Fake news is a critical advance towards safeguarding the uprightness and prosperity of the society. With the increasing popularity of social media, there’s an upsurge in the propagation of counterfeiting news. There is a lack of proper frameworks for dealing with fake news. The proposed work aims at exploring the various machine learning techniques for detection and analysis of fake news. In this way, the accompanying task goes for proposing a worldview for ordering counterfeit news and utilizing learning systems such as Naïve Bayes, Support Vector Machines, Stochastic Gradient Descent and Neural Networks and draws an act comparison between the same. The analysis is based on a dataset of 20000 news samples collected from various sources including social media, news websites, online gossips etc. pre-processed using TF-IDF and count vectorizer. Similar ideas are utilized for incorporating an assessment investigation application for a sample 2014 American Presidential Election social media dataset which depicts user behavior with relevant subjects dependent on pertinence, freshness and criticalness. The model results in an underlying accuracy of 93% with further improvements to be expected based on cross-referencing, dynamism and tracking history of reputation of news sources. The research in the area of fake news detection has been vastly inhibited by lack of quantity and quality of existing datasets along with algorithms to model the given problems. To counter this issue, we thoroughly assemble and outline trademark machine learning algorithms and a context-independent dataset for analysis.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.26615/978-954-452-056-4_113" target="_blank"> Machine learning approach to fact-checking in west slavic languages<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85076458736</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Priban P., Steinberger J., Hercig T.</b></td></tr><tr><td colspan="3">Organisations: <b>University of West Bohemia</b></td></tr><tr><td colspan="3">Fake news detection and closely-related fact-checking have recently attracted a lot of attention. Automatization of these tasks has been already studied for English. For other languages, only a few studies can be found (e.g. (Baly et al., 2018)), and to the best of our knowledge, no research has been conducted for West Slavic languages. In this paper, we present datasets for Czech, Polish, and Slovak. We also ran initial experiments which set a baseline for further research into this area.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.13053/CyS-23-3-3281" target="_blank"> Cross-domain failures of fake news detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85076634553</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Janicka M., Pszona M., Wawer A.</b></td></tr><tr><td colspan="3">Organisations: <b>Samsung R and D Institute Poland</b></td></tr><tr><td colspan="3">Fake news recognition has become a prominent research topic in natural language processing. Researchers reported significant successes when applying methods based on various stylometric and lexical features and machine learning, with accuracy reaching 90%. This article is focused on answering the question: are the fake news detection models universally applicable or limited to the domain they have been trained on? We used four different, freely available English language Fake News corpora and trained models in both in-domain and cross-domain setting. We also explored and compared features important in each domain. We found that the performance in cross-domain setting degrades by 20% and sets of features important to detect fake texts differ between domains. Our conclusions support the hypothesis that high accuracy of machine learning models applied to fake news detection may be related to over-fitting, and models need to be trained and evaluated on mixed types of texts.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-33607-3_46" target="_blank"> Automatic ground truth dataset creation for fake news detection in social media<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85076642805</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Pla Karidi D., Nakos H., Stavrakas Y.</b></td></tr><tr><td colspan="3">Organisations: <b>IMSI Athena RC</b></td></tr><tr><td colspan="3">Fake news has become over the last years one of the most crucial issues for social media platforms, users and news organizations. Therefore, research has focused on developing algorithmic methods to detect misleading content on social media. These approaches are data-driven, meaning that the efficiency of the produced models depends on the quality of the training dataset. Although several ground truth datasets have been created, they suffer from serious limitations and rely heavily on human annotators. In this work, we propose a method for automating as far as possible the process of dataset creation. Such datasets can be subsequently used as training and test data in machine learning classification techniques regarding fake news detection in microblogging platforms, such as Twitter.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-33617-2_34" target="_blank"> Machine Learning Methods for Fake News Classification<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85077014654</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Ksieniewicz P., Wozniak M., Choras M., Kozik R.</b></td></tr><tr><td colspan="3">Organisations: <b>Wrocław University of Science and Technology, UTP University of Science and Technology</b></td></tr><tr><td colspan="3">The problem of the fake news publication is not new and it already has been reported in ancient ages, but it has started having a huge impact especially on social media users. Such false information should be detected as soon as possible to avoid its negative influence on the readers and in some cases on their decisions, e.g., during the election. Therefore, the methods which can effectively detect fake news are the focus of intense research. This work focuses on fake news detection in articles published online and on the basis of extensive research we confirmed that chosen machine learning algorithms can distinguish them from reliable information.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/BigMM.2019.00-44" target="_blank"> SpotFake: A multi-modal framework for fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85077018511</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Singhal S., Shah R.R., Chakraborty T., Kumaraguru P., Satoh S.</b></td></tr><tr><td colspan="3">Organisations: <b>IIIT-Delhi, NII</b></td></tr><tr><td colspan="3">A rapid growth in the amount of fake news on social media is a very serious concern in our society. It is usually created by manipulating images, text, audio, and videos. This indicates that there is a need of multimodal system for fake news detection. Though, there are multimodal fake news detection systems but they tend to solve the problem of fake news by considering an additional sub-task like event discriminator and finding correlations across the modalities. The results of fake news detection are heavily dependent on the subtask and in absence of subtask training, the performance of fake news detection degrade by 10% on an average. To solve this issue, we introduce SpotFake-a multi-modal framework for fake news detection. Our proposed solution detects fake news without taking into account any other subtasks. It exploits both the textual and visual features of an article. Specifically, we made use of language models (like BERT) to learn text features, and image features are learned from VGG-19 pre-trained on ImageNet dataset. All the experiments are performed on two publicly available datasets, i.e., Twitter and Weibo. The proposed model performs better than the current state-of-the-art on Twitter and Weibo datasets by 3.27% and 6.83%, respectively.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/BRACIS.2019.00109" target="_blank"> Fake news detection using one-class classification<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85077084653</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Faustini P., Ferreira Covoes T.</b></td></tr><tr><td colspan="3">Organisations: <b>Universidade Federal Do ABC (UFABC)</b></td></tr><tr><td colspan="3">Fake news have attracted attention of general public because of the influence they can exert on important activities of society, such as elections. Efforts have been made to detect them, but usually they rely on human labour fact-checking, what can be costly and time consuming. Computational approaches have typically relied on supervised learning models, in which a model is trained based on fake and true news samples. Such approach allows a large amount of news to be classified in a short time, but it demands datasets labelled with positive and negative instances. Our work proposes to detect fake news by training a model with only fake samples in the training dataset, through One-Class Classification (OCC). We compare a novel algorithm, called DCDistanceOCC, to others published in literature, and got similar, or even better, results. The case study is the Brazilian politics scenario starting at the 2018 general elections on Twitter and WhatsApp. These two platforms were a fertile ground to fake news proliferation. We also evaluated the models over another available dataset from literature. To the best of our knowledge, this is the first paper to identify fake news using an OCC approach and also the first one to provide Portuguese-based WhatsApp and Twitter datasets with fake news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-29563-9_17" target="_blank"> A Two-Stage Model Based on BERT for Short Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85077134099</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Liu C., Wu X., Yu M., Jiang J., Huang W., Lu X., Li G.</b></td></tr><tr><td colspan="3">Organisations: <b>Chinese Academy of Sciences, University of Chinese Academy of Sciences, Deakin University</b></td></tr><tr><td colspan="3">Online social media promotes the development of the news industry and make it easy for everyone to obtain the latest news. Meanwhile, the circumstances get worse because of fake news. Fake news is flooding and become a serious threat which may cause high societal and economic losses, making fake news detection important. Unlike traditional one, news on social media tends to be short and misleading, which is more confusing to identify. On the other hand, fake news may contain parts of the facts and parts of the incorrect contents in one statement, which is not so clear and simple to classify. Hence, we propose a two-stage model to deal with the difficulties. Our model is built on BERT, a pre-trained model with a more powerful feature extractor Transformer instead of CNN or RNN. Besides, some accessible information is used to extend features and calculate attention weights. At last, inspired by fine-grained sentiment analysis, we treat fake news detection as fine-grained multiple-classification task and use two similar sub-models to identify different granularity labels separately. We evaluate our model on a real-world benchmark dataset. The experimental results demonstrate its effectiveness in fine-grained fake news detection and its superior performance to the baselines and other competitive approaches.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3360901.3364438" target="_blank"> Searching for evidence of scientific news in scholarly big data<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85077289978</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Hoque M.R.U., Li J., Bradley D., Wu J., Kwan C., Chiatti A.</b></td></tr><tr><td colspan="3">Organisations: <b>Old Dominion University, Old Dominion University, Applied Research LLC, Open University</b></td></tr><tr><td colspan="3">Public digital media can often mix factual information with fake scientific news, which is typically difficult to pinpoint, especially for non-professionals. These scientific news articles create illusions and misconceptions, thus ultimately influence the public opinion, with serious consequences at a broader social scale. Yet, existing solutions aiming at automatically verifying the credibility of news articles are still unsatisfactory. We propose to verify scientific news by retrieving and analyzing its most relevant source papers from an academic digital library (DL), e.g., arXiv. Instead of querying keywords or regular named entities extracted from news articles, we query domain knowledge entities (DKEs) extracted from the text. By querying each DKE, we retrieve a list of candidate scholarly papers. We then design a function to rank them and select the most relevant scholarly paper. After exploring various representations, experiments indicate that the term frequency-inverse document frequency (TF-IDF) representation with cosine similarity outperforms baseline models based on word embedding. This result demonstrates the efficacy of using DKEs to retrieve scientific papers which are relevant to a specific news article. It also indicates that word embedding may not be the best document representation for domain specific document retrieval tasks. Our method is fully automated and can be effectively applied to facilitating fake and misinformed news detection across many scientific domains.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3363818" target="_blank"> Robust fake news detection over time and attack<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85077367010</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Horne B.D., Adali S., NOrregaard J.</b></td></tr><tr><td colspan="3">Organisations: <b>Rensselaer Polytechnic Institute, Technical University of Denmark</b></td></tr><tr><td colspan="3">In this study, we examine the impact of time on state-of-the-art news veracity classifiers. We show that, as time progresses, classification performance for both unreliable and hyper-partisan news classification slowly degrade. While this degradation does happen, it happens slower than expected, illustrating that hand-crafted, content-based features, such as style of writing, are fairly robust to changes in the news cycle.We show that this small degradation can bemitigated using online learning. Last, we examine the impact of adversarial content manipulation by malicious news producers. Specifically, we test three types of attack based on changes in the input space and data availability. We show that static models are susceptible to content manipulation attacks, but online models can recover from such attacks.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Different absorption from the same sharing: Sifted Multi-task Learning for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85077457160</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Wu L., Rao Y., Jin H., Nazir A., Sun L.</b></td></tr><tr><td colspan="3">Organisations: <b>Xi'an Jiaotong University</b></td></tr><tr><td colspan="3">Recently, neural networks based on multitask learning have achieved promising performance on fake news detection, which focus on learning shared features among tasks as complementary features to serve different tasks. However, in most of the existing approaches, the shared features are completely assigned to different tasks without selection, which may lead to some useless and even adverse features integrated into specific tasks. In this paper, we design a sifted multi-task learning method with a selected sharing layer for fake news detection. The selected sharing layer adopts gate mechanism and attention mechanism to filter and select shared feature flows between tasks. Experiments on two public and widely used competition datasets, i.e. RumourEval and PHEME, demonstrate that our proposed method achieves the state-of-the-art performance and boosts the F1-score by more than 0.87%, 1.31%, respectively.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.ins.2019.12.040" target="_blank"> Discovering differential features: Adversarial learning for information credibility evaluation<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85077458112</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Wu L., Rao Y., Nazir A., Jin H.</b></td></tr><tr><td colspan="3">Organisations: <b>Xi'an Jiaotong University</b></td></tr><tr><td colspan="3">A series of deep learning approaches extract a large number of credibility features to detect fake news on the Internet. However, these extracted features still suffer from many irrelevant and noisy features that restrict severely the performance of the approaches. In this paper, we propose a novel model based on Adversarial Networks and inspirited by the Shared-Private model (ANSP), which aims at reducing common, irrelevant features from the extracted features for information credibility evaluation. Specifically, ANSP involves two tasks: one is to prevent the binary classification of true and false information for capturing common features relying on adversarial networks guided by reinforcement learning. Another extracts credibility features (henceforth, private features) from multiple types of credibility information and compares with the common features through two strategies, i.e., orthogonality constraints and KL-divergence for making the private features more differential. Experiments first on two six-label LIAR and Weibo datasets demonstrate that ANSP achieves state-of-the-art performance, boosting the accuracy by 2.1%, 3.1%, respectively and then on four-label Twitter16 validate the robustness of the model with 1.8% performance improvements.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.30534/ijatcse/2019/20862019" target="_blank"> Content-social based features for fake news detection model from twitter<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85077536849</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Hussein A., Ahmad F.K., Kamaruddin S.S.</b></td></tr><tr><td colspan="3">Organisations: <b>Universiti Utara Malaysia</b></td></tr><tr><td colspan="3">The advancement of social networks has facilitated the sharing and spread of news among people over the world. With the growth of these networks and growth of the volume of the news shared daily, the phenomena of fake news become more stronger and widely spread. In this paper, content-social based features for fake news detection model from Twitter data has been proposed. This work aims to analyze content-based features of news content including of linguistic features, writing style features, semantic features and sentiment features along with social-context based features of news diffusion over the social network including user-based features and network-based features to detect fake news from Twitter news posts. With using of unsupervised graph-based clustering approach, no labelled data is required and this make the proposed model more practical to detect online fake news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Distributed learning automata-based intelligence for propagation-based fake news detection on social media during crisis<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85077749689</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Abouzeid A., Granmo O.-C., Goodwin M., Webersik C.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Agder</b></td></tr><tr><td colspan="3">-</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/SNAMS.2019.8931873" target="_blank"> Automatic Identification of Fake News Using Deep Learning<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85077816026</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Qawasmeh E., Tawalbeh M., Abdullah M.</b></td></tr><tr><td colspan="3">Organisations: <b>Jordan University of Science and Technology</b></td></tr><tr><td colspan="3">The rapid development of computing trends, wireless communications, and the smart devices industry has contributed to the widespread of the internet. People can access internet services and applications from anywhere in the world at any time. There is no doubt that these technological advances have made our lives easier and saved our time and efforts. On the other side, we should admit that there is a misuse of internet and its applications including online platforms. As an example, online platforms have been involved in spreading fake news all over the world to serve certain purposes (political, economic, or social media). Detecting fake news is considered one of the hard challenges in term of the existing content-based analysis of traditional methods. Recently, the performance of neural network models have outperformed traditional machine learning methods due to the outstanding ability of feature extraction. Still, there is a lack of research work on detecting fake news in news and time critical events. Therefore, in this paper, we have investigated the automatic identification of fake news over online communication platforms. Moreover, We propose an automatic identification of fake news using modern machine learning techniques. The proposed model is a bidirectional LSTM concatenated model that is applied on the FNC-1 dataset with 85.3 % accuracy performance.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICCCNT45670.2019.8944460" target="_blank"> Bidirectional LSTM Based on POS tags and CNN Architecture for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85078168968</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Balwant M.K.</b></td></tr><tr><td colspan="3">Organisations: <b>Uttar Pradesh Rajarshi Tandon Open University</b></td></tr><tr><td colspan="3">Fake news generally on social media spreads very quickly and this brings many serious consequences. Traditional lexico-syntactic based features have limited success to detect fake news. Majority of fake news detection techniques are tested on small dataset containing limited training examples. In this work, we evaluate our architecture on Liar-Liar dataset which contain 12836 short news from different sources including social media. The proposed architecture incorporates POS (part of speech) tags information of news article through Bidirectional LSTM and speaker profile information through Convolutional Neural Network. The results show that the resulting hybrid architecture significantly improves detection performance of Fake news on Liar Dataset.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.eswa.2020.113199" target="_blank"> Towards automatically filtering fake news in Portuguese<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85078194025</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Silva R.M., Almeida T.A., Santos R.L.S., Pardo T.A.S.</b></td></tr><tr><td colspan="3">Organisations: <b>Federal University of São Carlos, University of São Paulo</b></td></tr><tr><td colspan="3">In the last years, the popularity of smartphones and social networks has been contributing to the spread of fake news. Through these electronic media, this type of news can deceive thousands of people in a short time and cause great harm to individuals, companies, or society. Fake news has the potential to change a political scenario, to contribute to the spread of diseases, and even to cause deaths. Despite the efforts of several studies on fake news detection, most of them only cover English language news. There is a lack of labeled datasets of fake news in other languages and, moreover, important questions still remain open. For example, there is no consensus on what are the best classification strategies and sets of features to be used for automatic fake news detection. To answer this and other important open questions, we present a new public and real dataset of labeled true and fake news in Portuguese, and we perform a comprehensive analysis of machine learning methods for fake news detection. The experiments were performed using different sets of features and employing different types of classification methods. A careful analysis of the results provided sufficient evidence to respond appropriately to the open questions. The various evaluated scenarios and the drawn conclusions from the results shed light on the potentiality of the methods and on the challenges that fake news detection presents.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.5373/JARDCS/V11SP11/20193112" target="_blank"> Ambient: A blockchain social media to build trust and discredit fake news<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85078361258</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Foong K.Y., Ang S.Y., Chia D.Z., Tee W.J., Murugesan R.K., Hamzah M.D.</b></td></tr><tr><td colspan="3">Organisations: <b>Taylor’s University, Hilti Asia IT Services Sdn. Bhd</b></td></tr><tr><td colspan="3">Fake news on social media platforms are rising at an alarming rate and have real world consequences. For instance, it has the power to influence the election results of a country. Social media is a “double-edged sword” that has both positive and negative impact to society. In our modern society today, transparent, trustable and reliable technology that focuses on ensuring credibility of everyday news is very important to protect the foundation of democracy and liberty of a country. The problem is automatic fake news detection and prevention on current social media platform is a unique challenge. The existing algorithms used in current social media are not effective. Thus, novel solution to detect and prevent fake news is much needed. In this research, a novel blockchain social media system, i.e. Ambient, is proposed that implement crowd intelligence in detecting fake news and moderating the contents. The proposed system not only strives to reduce spread of fake news, but also to reward users for their quality content.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3371158.3371187" target="_blank"> Computational fact validation from knowledge graph using structured and unstructured information<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85078415141</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Khandelwal S., Kumar D.</b></td></tr><tr><td colspan="3">Organisations: <b>Indian Institute of Technology</b></td></tr><tr><td colspan="3">In today's world, data or information is increasing at an exponential rate, and so is the fake news. Traditional fact-checking methods like fake news detection by experts, analysts, or some organizations do not match with the volume of information available. This is where the problem of computational fact-checking or validation becomes relevant. Given a Knowledge Graph, a knowledge corpus, and a fact (triple statement), the goal of fact-checking is to decide whether the fact or knowledge is correct or not. Existing approaches extensively used several structural features of the input Knowledge Graph to address the mentioned problem. In this work, our primary focus would be to leverage the unstructured information along with the structured ones. Our approach considers finding evidence from Wikipedia and structured information from Wikidata, which helps in determining the validity of the input facts. As features from the structured domain, we have used TransE embedding considering components of the input fact. The similarity of input fact with elements of relevant Wikipedia pages has been used as unstructured features. The experiments with a dataset consisting of nine relations of Wikidata has established the advantage of combining unstructured features with structured features for the given task.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3371158.3371402" target="_blank"> The Kauwa-Kaate fake news detection system: DemO<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85078437341</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Bagade A., Pale A., Sheth S., Agarwal M., Chakrabarti S., Chebrolu K., Sudarshan S.</b></td></tr><tr><td colspan="3">Organisations: <b>IIT Bombay, CMU</b></td></tr><tr><td colspan="3">Fake news spread via social media is a major problem today. It is not easy with current-generation tools to check if a particular article is genuine or contains fake news. While there are many Web sites today that debunk viral fake news, checking if a particular article has been debunked or is true is not easy for an end-user. Search engines like Google do not make it easy to check a complete article since they limit the number of query keywords. In this paper, we outline the architecture of the Kauwa-Kaate system for fact-checking articles. Queried articles are searched against articles crawled from fact-checking sites, as well as against articles crawled from trusted news sites. Our system supports querying based on text as well as on images and video; the latter features are very important since many fake news articles are based on images and videos. We also describe the user interfaces which we will use to demonstrate the Kauwa-Kaate system.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-36987-3_17" target="_blank"> A Hybrid Approach for Fake News Detection in Twitter Based on User Features and Graph Embedding<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85078446406</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Hamdi T., Slimi H., Bounhas I., Slimani Y.</b></td></tr><tr><td colspan="3">Organisations: <b>National School for Computer Science, University of Carthage</b></td></tr><tr><td colspan="3">The quest for trustworthy, reliable and efficient sources of information has been a struggle long before the era of internet. However, social media unleashed an abundance of information and neglected the establishment of competent gatekeepers that would ensure information credibility. That’s why, great research efforts sought to remedy this shortcoming and propose approaches that would enable the detection of non-credible information as well as the identification of sources of fake news. In this paper, we propose an approach which permits to evaluate information sources in term of credibility in Twitter. Our approach relies on node2vec to extract features from twitter followers/followees graph. We also incorporate user features provided by Twitter. This hybrid approach considers both the characteristics of the user and his social graph. The results show that our approach consistently and significantly outperforms existent approaches limited to user features.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.14569/ijacsa.2019.0101243" target="_blank"> Proof of credibility: A blockchain approach for detecting and blocking fake news in social networks<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85078482536</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Torky M., Nabil E., Said W.</b></td></tr><tr><td colspan="3">Organisations: <b>Islamic University of Madinah Madinah, Islamic University of Madinah, Cairo University, Zagazig University</b></td></tr><tr><td colspan="3">Rumors and misleading information detection and prevention still represent a big challenge against social network developers and researchers. Since newsworthy information propagation is a traditional behavior of most of the users in social media, then verifying information credibility and reliability is indeed a vital security requirement for social network platforms. Due to its immutability, security, tamper-proof and P2P design, Blockchain as a powerful technology can provide a magical solution to overcome this challenge. This Paper introduces a novel blockchain approach called Proof of Credibility (PoC) for detecting fake news and blocking its propagation in social networks. The functionality of the PoC protocol has been simulated on two datasets of newsworthy tweets collected from different news sources on Twitter. The results clarified a satisfying performance and efficiency of the proposed approach in detecting rumors and blocking its propagation.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.cogsys.2019.12.005" target="_blank"> FNDNet – A deep convolutional neural network for fake news detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85078707421</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Kaliyar R.K., Goswami A., Narang P., Sinha S.</b></td></tr><tr><td colspan="3">Organisations: <b>Bennett University, BITS Pilani, CSIR - Central Electronics Engineering Research Institute</b></td></tr><tr><td colspan="3">With the increasing popularity of social media and web-based forums, the distribution of fake news has become a major threat to various sectors and agencies. This has abated trust in the media, leaving readers in a state of perplexity. There exists an enormous assemblage of research on the theme of Artificial Intelligence (AI) strategies for fake news detection. In the past, much of the focus has been given on classifying online reviews and freely accessible online social networking-based posts. In this work, we propose a deep convolutional neural network (FNDNet) for fake news detection. Instead of relying on hand-crafted features, our model (FNDNet) is designed to automatically learn the discriminatory features for fake news classification through multiple hidden layers built in the deep neural network. We create a deep Convolutional Neural Network (CNN) to extract several features at each layer. We compare the performance of the proposed approach with several baseline models. Benchmarked datasets were used to train and test the model, and the proposed model achieved state-of-the-art results with an accuracy of 98.36% on the test data. Various performance evaluation parameters such as Wilcoxon, false positive, true negative, precision, recall, F1, and accuracy, etc. were used to validate the results. These results demonstrate significant improvements in the area of fake news detection as compared to existing state-of-the-art results and affirm the potential of our approach for classifying fake news on social media. This research will assist researchers in broadening the understanding of the applicability of CNN-based deep models for fake news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3341161.3342894" target="_blank"> Same: Sentiment-aware multi-modal embedding for detecting fake news<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85078852922</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Cui L., Wang S., Lee D.</b></td></tr><tr><td colspan="3">Organisations: <b>Pennsylvania State University</b></td></tr><tr><td colspan="3">How to effectively detect fake news and prevent its diffusion on social media has gained much attention in recent years. However, relatively little focus has been given on exploiting user comments left for posts and latent sentiments therein in detecting fake news. Inspired by the rich information available in user comments on social media, therefore, we investigate whether the latent sentiments hidden in user comments can potentially help distinguish fake news from reliable content. We incorporate users’ latent sentiments into an end-to-end deep embedding framework for detecting fake news, named as SAME. First, we use multi-modal networks to deal with heterogeneous data modalities. Second, to learn semantically meaningful spaces per data source, we adopt an adversarial mechanism. Third, we define a novel regularization loss to bring embeddings of relevant pairs closer. Our comprehensive validation using two real-world datasets, PolitiFact and GossipCop, demonstrates the effectiveness of SAME in detecting fake news, significantly outperforming state-of-the-art methods.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3341161.3342958" target="_blank"> Semi-supervised learning and graph neural networks for fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85078859862</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Benamira A., Devillers B., Lesot E., Ray A.K., Saadi M., Malliaros F.D.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Paris-Saclay, Inria Saclay</b></td></tr><tr><td colspan="3">Social networks have become the main platforms for information dissemination. Nevertheless, due to the increasing number of users, social media platforms tend to be highly vulnerable to the propagation of disinformation – making the detection of fake news a challenging task. In this work, we focus on content-based methods for detecting fake news – casting the problem to a binary text classification one (an article corresponds to either fake news or not). In particular, our work proposes a graph-based semi-supervised fake news detection method based on graph neural networks. The experimental results indicate that the proposed methodology achieves better performance compared to traditional classification techniques, especially when trained on limited number of labeled articles.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3341161.3342927" target="_blank"> The role of user profiles for fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85078868477</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Shu K., Liu H., Zhou X., Zafarani R., Wang S.</b></td></tr><tr><td colspan="3">Organisations: <b>Arizona State University, Penn State University, Syracuse University</b></td></tr><tr><td colspan="3">Consuming news from social media is becoming increasingly popular. Social media appeals to users due to its fast dissemination of information, low cost, and easy access. However, social media also enables the widespread of fake news. Due to the detrimental societal effects of fake news, detecting fake news has attracted increasing attention. However, the detection performance only using news contents is generally not satisfactory as fake news is written to mimic true news. Thus, there is a need for an in-depth understanding on the relationship between user profiles on social media and fake news. In this paper, we study the problem of understanding and exploiting user profiles on social media for fake news detection. In an attempt to understand connections between user profiles and fake news, first, we measure users’ sharing behaviors and group representative users who are more likely to share fake and real news; then, we perform a comparative analysis of explicit and implicit profile features between these user groups, which reveals their potential to help differentiate fake news from real news. To exploit user profile features, we demonstrate the usefulness of these user profile features in a fake news classification task. We further validate the effectiveness of these features through feature importance analysis. The findings of this work lay the foundation for deeper exploration of user profile features of social media and enhance the capabilities for fake news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/KICSS45055.2018.8950518" target="_blank"> FaGoN: Fake news detection model using grammatic transformation on neural network<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85078907026</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Seo Y., Jeong C.-S.</b></td></tr><tr><td colspan="3">Organisations: <b>Korea University</b></td></tr><tr><td colspan="3">These days, most of fake news are detected and verified by people, which requires a great amount of time and effort. It is difficult to Figure out the truthfulness of the news by machine algorithm because the sentences have various forms. In this paper, we shall present a fast and efficient fake news detection model which can Figure out whether the given proposition is true or not from article by exploiting grammatical transformation based on deep learning. Our model consists of four layers: word embedding layer, context generation layer, matching layer and inference layer. In word embedding layer, the words in proposition are embedded into word vector. In context generation layer, the word vectors enter into LSTM layer and generate context vector. In matching layer, attention vector is generated from the contextual embedding vector in the previous layer computing the weighted sum. Then, the hidden state vector from LSTM layers and attention vector are compared through matching operation generating the sentences which has the same meaning but different forms. In inference layer, our model calculates the similarity between the generated sentences and the sentences in articles, and classifies the answer, true or false. We shall evaluate our model calculating the perplexity to Figure out whether the generated sentences are grammatically correct. Also, the model is tested by changing the sentence group's size to find the optimal size of the group. By showing the Our model figured out the fake news very well with the test of CNN news dataset getting the right answer.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICDM.2019.00062" target="_blank"> Exploiting multi-domain visual information for fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85078909531</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Qi P., Cao J., Yang T., Guo J., Li J.</b></td></tr><tr><td colspan="3">Organisations: <b>Institute of Computing Technology, University of Chinese Academy of Sciences</b></td></tr><tr><td colspan="3">The increasing popularity of social media promotes the proliferation of fake news. With the development of multimedia technology, fake news attempts to utilize multimedia content with images or videos to attract and mislead readers for rapid dissemination, which makes visual content an important part of fake news. Fake-news images, images attached to fake news posts, include not only fake images that are maliciously tampered but also real images that are wrongly used to represent irrelevant events. Hence, how to fully exploit the inherent characteristics of fake-news images is an important but challenging problem for fake news detection. In the real world, fake-news images may have significantly different characteristics from real-news images at both physical and semantic levels, which can be clearly reflected in the frequency and pixel domain, respectively. Therefore, we propose a novel framework Multi-domain Visual Neural Network (MVNN) to fuse the visual information of frequency and pixel domains for detecting fake news. Specifically, we design a CNN-based network to automatically capture the complex patterns of fake-news images in the frequency domain; and utilize a multi-branch CNN-RNN model to extract visual features from different semantic levels in the pixel domain. An attention mechanism is utilized to fuse the feature representations of frequency and pixel domains dynamically. Extensive experiments conducted on a real world dataset demonstrate that MVNN outperforms existing methods with at least 9.2% in accuracy, and can help improve the performance of multi-modal fake news detection by over 5.2%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/i-PACT44901.2019.8960044" target="_blank"> Comparison of Various Machine Learning Models for Accurate Detection of Fake News<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85078965129</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Poddar K., Amali G.B.D., Umadevi K.S.</b></td></tr><tr><td colspan="3">Organisations: <b>School of Computer Science and Eng.</b></td></tr><tr><td colspan="3">Fake news consists of news that is not well researched or deliberate steps have been taken to spread misinformation or hoaxes via different forms of news distribution networks. This paper aims to tackle this issue using a computational model of probabilistic and geometric machine learning models. Moreover, the scores of two different vectorizers namely count and Term Frequency Inverse Document Format(TF-IDF) will be compared to find the appropriate vectorizer for fake news detection. English stop words have been used to improve the scores. Various classifiers like Naive Bayes, Support Vector Machine(SVM), Logistic regression and decision tree classifier were used to predict the fake news. Simulation results indicate Support Vector Machine (SVM) with the TF-IDF gave the most accurate prediction.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3369114.3369149" target="_blank"> A closer look at fake news detection: A deep learning perspective<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85079099611</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Abedalla A., Al-Sadi A., Abdullah M.</b></td></tr><tr><td colspan="3">Organisations: <b>Jordan University of Science and Technology</b></td></tr><tr><td colspan="3">The increasingly rapid pace of spreading fake news is considered a problem in conjunction with the increasing number of people who are relying upon social media to get news. That earns widespread attention from research communities due to the negative impact and inuence of fake news on public decisions. Consequently, the current research strives to illuminate on fake news problem and the process of detecting fake news using deep learning approaches. Using the Fake News Challenge (FNC-1) dataset, we have developed different models to detect fake news based on the relation between article headline and article body. Our models are assembled mainly from Convolutional Neural Network (CNN), Long Short-Term Memory network (LSTM) and Bidirectional LSTM (Bi-LSTM). In the contrary of other studies on the same dataset where they reported accuracy for a test data derived from the same training dataset, our experiments achieved 71.2% accuracy for the official testing dataset.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.3390/ijerph17031066" target="_blank"> Information management in healthcare and environment: Towards an automatic system for fake news detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85079239094</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Lara-Navarra P., Falciani H., Sanchez-Perez E.A., Ferrer-Sapena A.</b></td></tr><tr><td colspan="3">Organisations: <b>Universitat Oberta de Catalunya, Tactical Whistleblower Association, Universitat Politècnica de València</b></td></tr><tr><td colspan="3">Comments and information appearing on the internet and on different social media sway opinion concerning potential remedies for diagnosing and curing diseases. In many cases, this has an impact on citizens’ health and affects medical professionals, who find themselves having to defend their diagnoses as well as the treatments they propose against ill-informed patients. The propagation of these opinions follows the same pattern as the dissemination of fake news about other important topics, such as the environment, via social media networks, which we use as a testing ground for checking our procedure. In this article, we present an algorithm to analyse the behaviour of users of Twitter, the most important social network with respect to this issue, as well as a dynamic knowledge graph construction method based on information gathered from Twitter and other open data sources such as web pages. To show our methodology, we present a concrete example of how the associated graph structure of the tweets related to World Environment Day 2019 is used to develop a heuristic analysis of the validity of the information. The proposed analytical scheme is based on the interaction between the computer tool—a database implemented with Neo4j—and the analyst, who must ask the right questions to the tool, allowing to follow the line of any doubtful data. We also show how this method can be used. We also present some methodological guidelines on how our system could allow, in the future, an automation of the procedures for the construction of an autonomous algorithm for the detection of false news on the internet related to health.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/IACC48062.2019.8971579" target="_blank"> Multiclass Fake News Detection using Ensemble Machine Learning<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85079318599</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Kaliyar R.K., Goswami A., Narang P.</b></td></tr><tr><td colspan="3">Organisations: <b>Bennett University, BITS Pilani</b></td></tr><tr><td colspan="3">Over the past few years, fake news and its influence have become a growing cause of concern in terms of debate and public discussions. Due to the availability of the Internet, a lot of user-generated content is produced across the globe in a single day using various social media platforms. Nowadays, it has become very easy to create fake news and propagate it worldwide within a short period of time. Despite receiving significant attention in the research community, fake news detection did not improve significantly due to insufficient context-specific news data. Most of the researchers have analyzed the fake news problem as a binary classification problem, but many more prediction classes exist. In this research work, experiments have been conducted using a tree-based Ensemble Machine Learning framework (Gradient Boosting) with optimized parameters combining content and context level features for fake news detection. Recently, adaptive boosting methods for classification problems have been derived as gradient descent algorithms. This formulation justifies key elements and parameters in the methods, which are chosen to optimize a single common objective function. Experiments are conducted using a multi-class dataset (FNC) and various machine learning models are used for classification. Experimental results demonstrate the effectiveness of the ensemble framework compared to existing benchmark results. Using the Gradient Boosting algorithm (an ensemble machine learning framework), we achieved an accuracy of 86% for multi-class classification of fake news having four classes.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Learning hierarchical discourse-level structure for fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85079557221</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Karimi H., Tang J.</b></td></tr><tr><td colspan="3">Organisations: <b>Michigan State University</b></td></tr><tr><td colspan="3">On the one hand, nowadays, fake news articles are easily propagated through various online media platforms and have become a grand threat to the trustworthiness of information. On the other hand, our understanding of the language of fake news is still minimal. Incorporating hierarchical discourse-level structure of fake and real news articles is one crucial step toward a better understanding of how these articles are structured. Nevertheless, this has rarely been investigated in the fake news detection domain and faces tremendous challenges. First, existing methods for capturing discourse-level structure rely on annotated corpora which are not available for fake news datasets. Second, how to extract out useful information from such discovered structures is another challenge. To address these challenges, we propose Hierarchical Discourse-level Structure for Fake news detection. HDSF learns and constructs a discourse-level structure for fake/real news articles in an automated and data-driven manner. Moreover, we identify insightful structure-related properties, which can explain the discovered structures and boost our understating of fake news. Conducted experiments show the effectiveness of the proposed approach. Further structural analysis suggests that real and fake news present substantial differences in the hierarchical discourse-level structures.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3369026" target="_blank"> Stance detection: A survey<a></b></td></tr><tr><td>Type: Review</td><td>ID: S_2-s2.0-85079571958</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Kucuk D., Fazli C.A.N.</b></td></tr><tr><td colspan="3">Organisations: <b>TÜBİTAK Energy Institute, Bilkent University</b></td></tr><tr><td colspan="3">Automatic elicitation of semantic information from natural language texts is an important research problem with many practical application areas. Especially after the recent proliferation of online content through channels such as social media sites, news portals, and forums; solutions to problems such as sentiment analysis, sarcasm/controversy/veracity/rumour/fake news detection, and argument mining gained increasing impact and significance, revealed with large volumes of related scientific publications. In this article, we tackle an important problem from the same family and present a survey of stance detection in social media posts and (online) regular texts. Although stance detection is defined in different ways in different application settings, the most common definition is “automatic classification of the stance of the producer of a piece of text, towards a target, into one of these three classes: {Favor, Against, Neither}.” Our survey includes definitions of related problems and concepts, classifications of the proposed approaches so far, descriptions of the relevant datasets and tools, and related outstanding issues. Stance detection is a recent natural language processing topic with diverse application areas, and our survey article on this newly emerging topic will act as a significant resource for interested researchers and practitioners.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s11633-019-1216-5" target="_blank"> Text-mining-based Fake News Detection Using Ensemble Methods<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85079826490</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Reddy H., Raj N., Gala M., Basava A.</b></td></tr><tr><td colspan="3">Organisations: <b>National Institute of Technology Karnataka</b></td></tr><tr><td colspan="3">Social media is a platform to express one’s views and opinions freely and has made communication easier than it was before. This also opens up an opportunity for people to spread fake news intentionally. The ease of access to a variety of news sources on the web also brings the problem of people being exposed to fake news and possibly believing such news. This makes it important for us to detect and flag such content on social media. With the current rate of news generated on social media, it is difficult to differentiate between genuine news and hoaxes without knowing the source of the news. This paper discusses approaches to detection of fake news using only the features of the text of the news, without using any other related metadata. We observe that a combination of stylometric features and text-based word vector representations through ensemble methods can predict fake news with an accuracy of up to 95.49%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1166/jctn.2020.8639" target="_blank"> An innovative and implementable approach for online fake news detection through machine learning<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85080062347</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Prabha T.A., Aisuwariya T., Kiran M.V.K., Vasudevan S.K.</b></td></tr><tr><td colspan="3">Organisations: <b>Amrita School of Engineering</b></td></tr><tr><td colspan="3">One should recollect the USA 2015 and 2016 U.S. presidential election cycle dealt with numerous scandals which were triggered by the forged news articles that blowout through the social media like Twitter and Facebook. When it was found that these articles were purposefully uploaded for financial and political gain, it's become evident that bogus news has to be identified and removed to prevent public from being deceived for someone's personal gain. This study builds a supervised machine language model to detect the fake news articles published during 2015 and 2016 U.S. election cycle. The data set contains identical number of bogusand factual news. The standard set of machine learning algorithms like K-Nearest Neighbors, Support Vector Machine, Naive Bayes and Passive Aggressive Classifier are trained using either the title or the content of the article. There results show that the PAC classifier produces the highest accuracy of 94.63% over the other three classifiers using diagram term frequency.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Fake news detection using deep markov random fields<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85080465121</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Nguyen D.M., Do T.H., Deligiannis N., Calderbank R.</b></td></tr><tr><td colspan="3">Organisations: <b>Vrije Universiteit Brussel, imec, Duke University</b></td></tr><tr><td colspan="3">Deep-learning-based models have been successfully applied to the problem of detecting fake news on social media. While the correlations among news articles have been shown to be effective cues for online news analysis, existing deep-learning-based methods often ignore this information and only consider each news article individually. To overcome this limitation, we develop a graph-theoretic method that inherits the power of deep learning while at the same time utilizing the correlations among the articles. We formulate fake news detection as an inference problem in a Markov random field (MRF) which can be solved by the iterative mean-field algorithm. We then unfold the mean-field algorithm into hidden layers that are composed of common neural network operations. By integrating these hidden layers on top of a deep network, which produces the MRF potentials, we obtain our deep MRF model for fake news detection. Experimental results on well-known datasets show that the proposed model improves upon various state-of-the-art models.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ISCISC48546.2019.8985152" target="_blank"> SANUB: A new method for sharing and analyzing news using blockchain<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85081047127</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Balouchestani A., Mahdavi M., Hallaj Y., Javdani D.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Isfahan, Iran University of Science and Technology</b></td></tr><tr><td colspan="3">Millions of news are being exchanged daily among people. With the appearance of the Internet, the way of broadcasting news has changed and become faster, however it caused many problems. For instance, the increase in the speed of broadcasting news leads to an increase in the speed of fake news creation. Fake news can have a huge impression on societies. Additionally, the existence of a central entity, such as news agencies, could lead to fraud in the news broadcasting process, e.g. generating fake news and publishing them for their benefits. Since Blockchain technology provides a reliable decentralized network, it can be used to publish news. In addition, Blockchain with the help of decentralized applications and smart contracts can provide a platform in which fake news can be detected through public participation. In this paper, we proposed a new method for sharing and analyzing news to detect fake news using Blockchain, called SANUB. SANUB provides features such as publishing news anonymously, news evaluation, reporter validation, fake news detection and proof of news ownership. The results of our analysis show that SANUB outperformed the existing methods.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICAIT47043.2019.8987258" target="_blank"> Fake News Detection Using Deep Learning Techniques<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85081101424</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Hiramath C.K., Deshpande G.C.</b></td></tr><tr><td colspan="3">Organisations: <b>KLS Gogte Institute of Technology</b></td></tr><tr><td colspan="3">News is crucial part of our life. In day to day life current news are helpful to enhance knowledge what happen around the world. So most of peoples prefer watching news most of the peoples generally prefer reading newspaper early in the morning enjoying with cup of tea. If news is fake that will mislead peoples sometimes fake news utilized to spread rumors about things or it will affect some political leader positions just because of fake news. So it's crucial to find the fake news. So we proposed system to detect fake news but now a day's data on web or social media is increasing vastly and it is so hectic to detect news is fake or not by looking all data and it is time consuming so we utilize classification techniques to classify huge data. Here we proposed fake news detection system based on classification such as Logistic regression (LR), Naïve bayes (NB), Support vector machine (SVM), Random forest (RF) and deep neural network (DNN). We compare all machine learning techniques for detecting fake news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/IMCOM48794.2020.9001800" target="_blank"> Multi-Modal Component Embedding for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85081126664</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Kang S., Hwang J., Yu H.</b></td></tr><tr><td colspan="3">Organisations: <b>POSTECH</b></td></tr><tr><td colspan="3">As numerous fake news bloom and spread wildly on social media, fake news detection has recently been drawing a growing amount of attention. Single news consists of various multi-modal components (e.g., text, image, and event). Thus, a desirable model for fake news detection must satisfy two requirements: 1) it must correctly learn the reliability of each component 2) it must be capable of capturing the relationship among the components. In this paper, we propose a Multi-modal Component Embedding framework (MCE) for fake news detection, which is designed to satisfy all the requirements. It first defines a latent vector for each news article as the sum of its component latent vectors. For each component, we regard its magnitude as its reliability, and regard its directional relationship as its consistency. In this context, the magnitude of each news latent vector represents how reliable the news is. Thus, MCE learns the latent space so that the magnitude of the real news vectors becomes larger than that of the fake news vectors. During the training, a news vector becomes larger when its component vectors are reliable (i.e., large magnitude) and when its component vectors are well aligned (i.e., high consistency). By doing so, MCE can capture the complex relationship among the components as well as the reliability of each component. Our extensive experiments on two real-world datasets show that MCE outperforms all the baselines. We also provide a qualitative analysis on the embedding space to verify its capability of satisfying the requirements.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/BigData47090.2019.9005980" target="_blank"> Detecting Fake News Articles<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85081339064</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Lin J., Tremblay-Taylor G., Mou G., You D., Lee K.</b></td></tr><tr><td colspan="3">Organisations: <b>Louisiana State University, Keene State College, Worcester Polytechnic Institute</b></td></tr><tr><td colspan="3">Fake news has been generated and widely spread although journalists and researchers created fact-checking websites (e.g., Snopes and PolitiFact) and analyzed characteristics of fake news. To fill this gap, in this paper we focus on developing machine learning models based on only text information in news articles toward automatically detecting fake news. In particular, we proposed a framework which extracts 134 features and builds traditional known machine learning models like Random Forest and XGBoost. We also propose a deep learning based model (LSTM with self-attention mechanism) to see which one performs better in the fake news article detection in both political news and celebrity news domains. In the experiments, we compare our models against 7 baselines. The results show that our XGBoost model improved 16.4% and 13.1% over the best baseline in terms of accuracy in both political news articles and celebrity news articles, respectively.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/BigData47090.2019.9005962" target="_blank"> A Location Independent Machine Learning Approach for Early Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85081345898</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Liu H.</b></td></tr><tr><td colspan="3">Organisations: <b>Raffles Institution</b></td></tr><tr><td colspan="3">The spread of fake news on the internet is presenting increasing threats to national security, with the potential to incite public unrest and violence. However, detecting fake news is challenging as they are intentionally written to mislead. Some current methods cannot detect fake news early and require external information like the source to assess articles. To tackle these challenges and improve the generalizability of the models, we adopted a text-based location-independent machine learning approach. It employed two types of machine learning models. The first is the bag-of-words model, made more robust by stacking two levels of models. The second is neural networks that utilize pre-trained GloVe word embeddings, including (a) one-dimensional convolutional neural network (CNN) and (b) bidirectional long short-term memory network (BiLSTM). All models were assessed on various metrics (accuracy, recall, precision and F1), and achieved over 90% on the test set, making this an effective location-independent approach to detect fake news at an early stage without reliance on external information.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/BigData47090.2019.9005556" target="_blank"> Deep Diffusive Neural Network based Fake News Detection from Heterogeneous Social Networks<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85081378853</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Zhang J., Dong B., Yu P.S.</b></td></tr><tr><td colspan="3">Organisations: <b>Florida State University, University of Illinois at Chicago</b></td></tr><tr><td colspan="3">In recent years, due to the booming development of online social networks, fake news for various commercial and political purposes has been appearing in large numbers and widespread in the online world. With deceptive words, online social network users can get infected by these online fake news easily, which has brought about tremendous effects on the offline society already. An important goal in improving the trustworthiness of information in online social networks is to identify the fake news timely. This paper aims at investigating the principles, methodologies and algorithms for detecting fake news articles, creators and subjects from online social networks and evaluating the corresponding performance. This paper addresses the challenges introduced by the unknown characteristics of fake news and diverse connections among news articles, creators and subjects. This paper introduces a novel automatic fake news credibility inference model, namely FakeDetector. Based on a set of explicit and latent features extracted from the textual information, FakeDetector builds a deep diffusive network model to learn the representations of news articles, creators and subjects simultaneously. Extensive experiments have been done on a real-world fake news dataset to compare FakeDetector with several state-of-the-art models, and the experimental results have demonstrated the effectiveness of the proposed model.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-41505-1_14" target="_blank"> Fake news detection on fake.br using hierarchical attention networks<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85081579423</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Okano E.Y., Ruiz E.E.S., Liu Z., Ji D.</b></td></tr><tr><td colspan="3">Organisations: <b>Universidade de São Paulo, Wuhan University</b></td></tr><tr><td colspan="3">Automatic fake news detection is a challenging problem in natural language processing, and contributions in this field may induce immense social impacts. This article examines the use of Hierarchical Attention Network (HAN) as a method for automatic fake news detection. We evaluate the proposed models in the Brazilian Portuguese fake news parallel corpus Fake.Br using its original full text, and also in the truncated version. We run the HAN varying the size of word embedding from 100 to 600, and by maintaining and removing the stop words. This method achieved an accuracy of 97% for full texts using the word embedding size of 600 from GloVe. However, when comparing running this method for truncated texts, this method presents similar results (90% accuracy) to the baseline established by the simple machine learning methods presented in the original presentation work of the Fake.Br (89% accuracy). Overall, keeping or removing stop words and varying the size of the word embeddings also shows a negligible advantage.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> NewsBag: A multimodal benchmark dataset for fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85081593242</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Jindal S., Sood R., Chakraborty T., Singh R., Vatsa M.</b></td></tr><tr><td colspan="3">Organisations: <b>IIIT-Delhi, IIT Jodhpur</b></td></tr><tr><td colspan="3">The spread of fake news poses a critical problem in today's world, where most individuals consume information from online platforms. Fake news detection is an arduous task, marred by the lack of a robust ground truth database for training classification models. Fake news articles manipulate multimedia content (text and images) to disseminate false information. Existing fake news datasets are either small in size or predominantly contain unimodal data. We propose two novel benchmark multimodal datasets, consisting of text and images, to enhance the quality of fake news detection. The first dataset includes manually collected real and fake news data from multiple online sources. In the second dataset, we study the effect of data augmentation by using a Bag of Words approach to increase the quantity of fake news data. These datasets are significantly larger in size in comparison to the existing datasets. We conducted extensive experiments by training state of the art unimodal and multimodal fake news detection algorithms on our dataset and comparing it with the results on existing datasets, showing the effectiveness of our proposed datasets. The experimental results show that data augmentation to increase the quantity of fake news does not hamper the accuracy of fake news detection. The results also conclude that the utilization of multimodal data for fake news detection substantially outperforms the unimodal algorithms.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1177/0267323120903686" target="_blank"> ‘They can’t fool me, but they can fool the others!’ Third person effect and fake news detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85081698585</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Corbu N., Oprea D.-A., Negrea-Busuioc E., Radu L.</b></td></tr><tr><td colspan="3">Organisations: <b>National University of Political Studies and Public Administration</b></td></tr><tr><td colspan="3">The aftermath of the 2016 US Presidential Elections and the Brexit campaign in Europe have opened the floor to heated debates about fake news and the dangers that these phenomena pose to elections and to democracy, in general. Despite a growing body of scholarly literature on fake news and its close relatives misinformation, disinformation or, more encompassing, communication and information disorders, few studies have so far attempted to empirically account for the effects that fake news might have, especially with respect to what communication scholars call the third person effect. This study aims to provide empirical evidence for the third person effect in the case of people’s self-perceived ability to detect fake news and of their perception of others’ ability to detect it. Based on a survey run in August 2018 and comprising a national, diverse sample of Romanian adults (N = 813), this research reveals that there is a significant third person effect regarding people’s self-reported ability to spot fake news and that this effect is stronger when people compare their fake news detection literacy to that of distant others than to that close others. Furthermore, this study shows that the most important predictors of third person effect related to fake news detection are education, income, interest in politics, Facebook dependency and confirmation bias, with age being a non-significant predictor.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.procs.2020.01.072" target="_blank"> Fake News Detection using Bi-directional LSTM-Recurrent Neural Network<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85082000410</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Bahad P., Saxena P., Kamal R.</b></td></tr><tr><td colspan="3">Organisations: <b>Devi Ahilya University, Prestige Institute of Engineering</b></td></tr><tr><td colspan="3">Media plays a vital role in the public dissemination of information about events. The rapid development of the Internet allows a quick spread of information through social networks or websites. Without the concern about the credibility of the information, the unverified or fake news is spread in social networks and reach thousands of users. Fake news is typically generated for commercial and political interests to mislead and attract readers. The spread of fake news has raised a big challenge to society. Automatic credibility analysis of news articles is a current research interest. Deep learning models are widely used for linguistic modeling. Typical deep learning models such as Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN) can detect complex patterns in textual data. Long Short-Term Memory (LSTM) is a tree-structured recurrent neural network used to analyze variable-length sequential data. Bi-directional LSTM allows looking at particular sequence both from front-to-back as well as from back-to-front. The paper presents a fake news detection model based on Bi-directional LSTM-recurrent neural network. Two publicly available unstructured news articles datasets are used to assess the performance of the model. The result shows the superiority in terms of accuracy of Bi-directional LSTM model over other methods namely CNN, vanilla RNN and unidirectional LSTM for fake news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.procs.2020.01.035" target="_blank"> Analysis of Classifiers for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85082004950</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Agarwal V., Sultana H.P., Malhotra S., Sarkar A.</b></td></tr><tr><td colspan="3">Organisations: <b>Vellore Institute of Technology, Ara Institute of Canterbury</b></td></tr><tr><td colspan="3">As time flows, the amount of data, especially text data increases exponentially. Along with the data, our understanding of AI also increases and the computing power enables us to train very complex and large models faster. Fake news has been gathering a lot of attention worldwide recently. The effects can be political, economic, organizational, or even personal. This paper discusses the approach of natural language processing and machine learning in order to solve this problem. Use of bag-of-words, n-grams, count vectorizer has been made, TF-IDF, and trained the data on five classifiers to investigate which of them works well for this specific dataset of labelled news statements. The precision, recall and f1 scores help us determine which model works best.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-15-3380-8_49" target="_blank"> Fake News Types and Detection Models on Social Media A State-of-the-Art Survey<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85082108600</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Collins B., Hoang D.T., Hwang D., Nguyen N.T.</b></td></tr><tr><td colspan="3">Organisations: <b>Yeungnam University, Wroclaw University of Science and Technology, Quang Binh University</b></td></tr><tr><td colspan="3">Fake news has gained prominence since the 2016 US presidential election as well as the Brexit referendum. Fake news has abused not only the press but also the democratic rules. Therefore, the need to restrict and eliminate it becomes inevitable. The popularity of fake news on social media has made people unwilling to engage in sharing positive news for fear that the information is false. The main problem with fake news is how quickly it spreads to social media. In this paper, we introduced an overview of the various models in detecting fake news such as Machine learning, Natural Language Processing, Crowd-sourced techniques, Expert fact-checker, as well as Hybrid Expert-Machine. We also do reviews of different types of fake news, which is an essential criterion for detecting fake news. Our findings show that detecting fake news is a challenging but workable task. The techniques that combine people and machines bring very satisfactory results. We also study about open issues of fake news, then propose some potential research tasks for future works.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICAEE47123.2019.9015097" target="_blank"> Merging deep learning model for fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85082175352</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Amine B.M., Drif A., Giordano S.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Setif 1, University of Applied Sciences of Southern Switzerland SUPSI</b></td></tr><tr><td colspan="3">Fake news attracted attention both from the public and the academic communities and represents a phenomenon that has a significant impact on our social life, especially on the political world. Further more, fake news phenomenon provide an opportunity for malicious parties to manipulate public opinion and events such as elections. In this work, we propose a merged deep learning model that detect fake articles regarding different characteristics. Therefore, we use word embedding technique and convolutional neural network to extract text based features and compare different architecture of deep learning while merging two CNNs with different metadata (Text, title, and author). We show on real dataset that the proposed approach is very efficient and allows to achieve high performances.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICCA49400.2020.9022837" target="_blank"> Defining News Authenticity on Social Media Using Machine Learning Approach<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85082398399</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Hlaing M.M.M., Kham N.S.M.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Computer Studies</b></td></tr><tr><td colspan="3">Social network and online news media are becoming popular in today's era. Due to low cost, easy access and rapid diffusion, social media platform becomes a source to distribute false information. Fake news propagation on social media can cause serious negative effects on human society especially in politic, reputation and finance. So, automatic fake news detection plays a vital role to robust news media platform on social network. Defining news authenticity is insufficient based on news content only. It also needs to analyze social features of news. In this paper, we propose an approach to detect fake news on social media that covers both news content and social context. We use synonym-based feature extraction method and three different classifiers based on multidimensional dataset. Experimental result shows the effective as an accuracy way to define news authenticity on online news media.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> A survey on fake news detection in social media using deep neural networks<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85082610851</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Alekya L., Susmitha G., Hemanth S., Lakshmi L.</b></td></tr><tr><td colspan="3">Organisations: <b>MLR Institute of Technology, BVRIT Hyderabad College of Engineering for Women</b></td></tr><tr><td colspan="3">Due to the emerging technologies and population growth, the rate of using social media has increased rapidly. As of now the social media has become the daily news to the world rather than the news channels and newspapers. The spread of fake news may lead to havocs. And more likely we are spreading the fake news to our surroundings by trust worthy on the social media finally that too much trust is being mis leaded. In upcoming days, we can’t distinguish real news and fake news. The rate of fake news has become disguise. In this process, we have made survey to detect fake news using Deep Learning techniques and algorithms. We have tested on some of the data sets such as LIAR, Buzzfeed, PolitiFact, Kaggle and McIntire. In this paper to detect the fake news, we have compared machine learning algorithms like Naïve-Bayes’, SVM, Decision Tree, AdaBoost, etc. Comparing the accuracy obtained using vanilla and LSTM are less accurate than GRU and CNN. We quest to increase accuracy by applying a hybrid model between the GRU and CNN techniques on the same data set.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ISCON47742.2019.9036221" target="_blank"> Fake News Detection: A long way to go<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85082982573</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Sharma S., Sharma D.K.</b></td></tr><tr><td colspan="3">Organisations: <b>GLA University</b></td></tr><tr><td colspan="3">One can easily say in today's world, information aka news to few is more precious than money itself. This news needs to be in authentic form which is usually found in adulterated version. Leading us to have a dire need for an identification of real news from any possible fake news. News, being a form of information can be subjective to the proofs and source for its authenticity. As a human, one can easily identify real news from fake news with the help of one's innate capability to deduce logic and outlandish source of the information piece. Just that one needs few trusted sources to check for the facts and myths. But on a real time basis, there is a dire need for some software which can nip such 'false news' in its bud. Leading it to be one of the most researched area nowadays. Primarily being a part of Information Retrieval, this area is taking up a lot of attention from researchers worldwide to come up with a real-time solution for such an issue. In this article we have checked and analysed many research articles along with many survey articles and summed up this paper so as to provide the readers with a short idea of what fake news is, it's different flavours in the news spectrum, its characteristics and identification basic. We also included the different methods used by prior researchers in the same field. Using few researches as examples we learned about the basics of those methods used in fake news identification. The future aspects are also included in this article along with the challenges one faces while doing research in this very field.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Vernon-fenwick at SemEval-2019 task 4: Hyperpartisan news detection using lexical and semantic features<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85083026422</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Srivastava V., Sahoo S.K., Gupta A., Rohit R.R., Prakash D., Kim Y.H.</b></td></tr><tr><td colspan="3">Organisations: <b>Samsung R&D Institute India</b></td></tr><tr><td colspan="3">In this paper, we present our submission for SemEval-2019 Task 4: Hyperpartisan News Detection. Hyperpartisan news articles are sharply polarized and extremely biased (one-sided). It shows blind beliefs, opinions and unreasonable adherence to a party, idea, faction or a person. Through this task, we aim to develop an automated system that can be used to detect hyperpartisan news and serve as a prescreening technique for fake news detection. The proposed system jointly uses a rich set of handcrafted textual and semantic features. Our system achieved 2nd rank on the primary metric (82.0% accuracy) and 1st rank on the secondary metric (82.1% F1-score), among all participating teams. Comparison with the best performing system on the leaderboard1 shows that our system is behind by only 0.2% absolute difference in accuracy.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/IConDA47345.2019.9034917" target="_blank"> Hyperpartisan news and articles detection using BERT and ELMo<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85083028514</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Huang G.K.W., Lee J.C.</b></td></tr><tr><td colspan="3">Organisations: <b>Universiti Malaysia Sarawak</b></td></tr><tr><td colspan="3">Fake news and articles are misleading the readers. This leads to the increasing studies of fake news article detection over the decades. Hyperpartisan news is news riddled with twisted and untruth and extremely one-sided. This news can spread more successfully than others. Besides that, hyperpartisan news can mimic the form of regular news articles. This study aims to identify and classify the hyperpartisan news with BERT and ELMo. Two distinct models, BERT and ELMo, were created to classify hyperpartisan news from two datasets, namely by-article and by-publisher. Few other models with different settings and training designed to test and optimise the performance of both models. The results of the optimised BERT and ELMo models can achieve 68.4% and 60.8%, respectively.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.34190/ICCWS.20.116" target="_blank"> Intelligent based framework for detection of fake news in the social network platforms<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85083387881</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Fasola O., Ojeniyi J., Oyeniyi S.</b></td></tr><tr><td colspan="3">Organisations: <b>Dominican University, Federal University of Technology</b></td></tr><tr><td colspan="3">Developing a framework for the detection of fake news that is based on a conceptual and intelligent framework will improve the detection of fake news in the social network platforms. It has been hypothesized that if not checked, the increasing spread of fake news may either be the immediate or remote cause of third world war. The existing frameworks suffer in two fundamentals of social concepts and artificial intelligence based revolutionary trends. The focus of this research work is to propose a fake news detection framework that combines the structurally modeled fake news concepts and artificial neural network model. The study used a cross-sectional model testing correlational design which formed the basis of developing the intelligent framework. A simple random sampling technique was used to determine the sample size. The research instrument used was questionnaire administered through Google form survey. The instrument was validated using content, construct and criterion validity. During the pilot test, the reliability of the instrument was established with the standard value of = 0.7 as the benchmark. The method of data analysis used was Pearson Product Moment Correlation Statistics within a significant level of 0.05. Analysis of moment structure tool was used to answer the research hypothesis using structural equation modeling technique. The data obtained from the questionnaires and the test were analyzed using the exploratory factor analysis process (a first generation statistical method of analysis), and the expected designed model, based on Structural Equation Modelling was evaluated using standard goodness of fit indices (GOF) of confirmatory factor analysis (a second generation statistical method of analysis). The dataset generated, measured, analyzed and modeled formed the basis for the development of intelligent based framework. The proposed artificial neural network framework comparatively achieved better detection rates over the conventional and structurally modeled datasets. The framework addresses the social disposition and artificial intelligence based fake news detection gaps.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-34080-3_22" target="_blank"> A Supervised Machine Learning Approach to Fake News Identification<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85083436617</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Datta A., Si S.</b></td></tr><tr><td colspan="3">Organisations: <b>Jalpaiguri Government Engineering College</b></td></tr><tr><td colspan="3">In the era of digitization, we no longer need to struggle to connect to the outer world. There are so many sources that provide us with news reports of our surroundings, national and international activities. But the problem is there are many sources which are fooling people by spreading fake news about everything. This can be fatal sometimes as it encourages human rage. So to prevent this, the data scientists are eager to detect this kind of sources automatically. We have proposed a new model for this supervised data to predict if the provided news is fake or not. We have used some machine learning algorithms like- Gradient Boosting, Random Forest, Extra tree, XGBoost etc. and among these, GBM gives best result as accuracy of 95%. Then a majority voting classifier is made with these algorithm which gives accuracy of 94.15%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Can machines learn to detect fake news? A survey focused on social media<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85083954801</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>da Silva F.C.D., da Costa Alves R.V., Garcia A.C.B.</b></td></tr><tr><td colspan="3">Organisations: <b>UNIRIO</b></td></tr><tr><td colspan="3">Through a systematic literature review method, in this work we searched classical electronic libraries in order to find the most recent papers related to fake news detection on social medias. Our target is mapping the state of art of fake news detection, defining fake news and finding the most useful machine learning technique for doing so. We concluded that the most used method for automatic fake news detection is not just one classical machine learning technique, but instead a amalgamation of classic techniques coordinated by a neural network. We also identified a need for a domain ontology that would unify the different terminology and definitions of the fake news domain. This lack of consensual information may mislead opinions and conclusions.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/Confluence47617.2020.9058106" target="_blank"> Fake news detection using discourse segment structure analysis<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85083982448</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Uppal A., Sachdeva V., Sharma S.</b></td></tr><tr><td colspan="3">Organisations: <b>Amity University</b></td></tr><tr><td colspan="3">Online news platforms greatly influence our society and culture in both positive and negative ways. As online media becomes more dependent for source of information, a lot of fake news is posted online, that widespread with people following it without any prior or complete information of event authenticity. Such misinformation has the potential to manipulate public opinions. The exponential growth of fake news propagation have become a great threat to public for news trustworthiness. It has become a compelling issue for which discovering, examining and dealing with fake news has increased in demand. However, with the limited availability of literature on the issue of uncovering fake news, a number of potential methodologies and techniques remains unexplored. The primary aim of this paper is to review existing methodologies, to propose and implement a method for automated deception detection. The proposed methodology uses deep learning in discourse-level structure analysis to formulate the structure that differentiates fake and real news. The baseline model achieved 74% accuracy.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> BREAKING! Presenting fake news corpus for automated fact checking<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85084004901</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Pathak A., Srihari R.K.</b></td></tr><tr><td colspan="3">Organisations: <b>University at Buffalo (SUNY)</b></td></tr><tr><td colspan="3">Popular fake news articles spread faster than mainstream articles on the same topic which renders manual fact checking inefficient. At the same time, creating tools for automatic detection is as challenging due to lack of dataset containing articles which present fake or manipulated stories as compelling facts. In this paper, we introduce manually verified corpus of compelling fake and questionable news articles on the USA politics, containing around 700 articles from Aug-Nov, 2016. We present various analyses on this corpus and finally implement classification model based on linguistic features. This work is still in progress as we plan to extend the dataset in the future and use it for our approach towards automated fake news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> FakeNewsTracker: A tool for fake news collection, detection, and visualization<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85084094497</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Shu K., Mahudeswaran D., Liu H.</b></td></tr><tr><td colspan="3">Organisations: <b>Arizona State University</b></td></tr><tr><td colspan="3">Nowadays social media is widely used as the source of information because of itslow cost, easy to access nature. However, consuming news from social media is a double-edgedsword because of the wide propagation of fake news, i.e., news with intentionally falseinformation. Fake news is a serious problem because it has negative impacts on individuals aswell as society large. In the social media the information is spread fast and hence detectionmechanism should be able to predict news fast enough to stop the dissemination of fake news.Therefore, detecting fake news on social media is an extremely important and also a technicallychallenging problem. In this paper, we present FakeNewsTracker, a system for fake newsunderstanding and detection. As we will show, FakeNewsTracker can automatically collect datafor news pieces and social context, which benefits further research of understanding andpredicting fake news with effective visualization techniques.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.13052/JCSM2245-1439.921" target="_blank"> Fake news detection by image montage recognition<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85084144389</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Steinebach M., Gotkowski K., Liu H.</b></td></tr><tr><td colspan="3">Organisations: <b>Fraunhofer SIT</b></td></tr><tr><td colspan="3">Fake news have been a problem for multiple years now and in addition to this "fake images" that accompany them are becoming increasingly a problem too. The aim of such fake images is to back up the fake message itself and make it appear authentic. For this purpose, more and more images such as photo-montages are used, which have been spliced from several images. This can be used to defame people by putting them in unfavorable situations or the other way around as propaganda by making them appear more important. In addition, montages may have been altered with noise and other manipulations to make an automatic recognition more difficult. In order to take action against such montages and still detect them automated, a concept based on feature detection is developed. Furthermore, an indexing of the features is carried out by means of a nearest neighbor algorithm in order to be able to quickly compare a high number of images. Afterwards, images suspected to be a montage are reviewed by a verifier. This concept is implemented and evaluated with two feature detectors. Even montages that have been manipulated with different methods are identified as such in an average of 100 milliseconds with a probability of mostly over 90%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-45442-5_82" target="_blank"> Time-critical geolocation for social good<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85084172789</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Suwaileh R.</b></td></tr><tr><td colspan="3">Organisations: <b>Qatar University</b></td></tr><tr><td colspan="3">Twitter has become an instrumental source of news in emergencies where efficient access, dissemination of information, and immediate reactions are critical. Nevertheless, due to several challenges, the current fully-automated processing methods are not yet mature enough for deployment in real scenarios. In this dissertation, I focus on tackling the lack of context problem by studying automatic geo-location techniques. I specifically aim to study the Location Mention Prediction problem in which the system has to extract location mentions in tweets and pin them on the map. To address this problem, I aim to exploit different techniques such as training neural models, enriching the tweet representation, and studying methods to mitigate the lack of labeled data. I anticipate many downstream applications for the Location Mention Prediction problem such as incident detection, real-time action management during emergencies, and fake news and rumor detection among others.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICCCEEE46830.2019.9070857" target="_blank"> A survey on automatic fake news identification techniques for online and socially produced data<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85084278076</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Hassan E.A., Meziane F.</b></td></tr><tr><td colspan="3">Organisations: <b>Sudan University of Science and Technology, University of Salford</b></td></tr><tr><td colspan="3">Fake news are spread on online sites and social media at an alarming speed and in large quantities. Fake news aim to mislead and deceive readers with verifiable false information and they are published on untrusted websites and social media accounts. As they have a very big impact on readers, it is critical to develop efficient models for detecting fake news. This paper reviews the literature on fake news detection and categorizes detection approaches into Knowledge Based approaches and Machine Learning based approaches. Machine Learning based approaches that have been covered in this paper are divided into Conventional approaches and Neural Network approaches. It provides Support Vector Machines (SVMs) and Naïve Bayes for Conventional approaches. In addition to Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) for Neural Network approaches. Also, the paper discusses the provided approaches.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICITIIT49094.2020.9071524" target="_blank"> Role of Contextual Features in Fake News Detection: A Review<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85084297534</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>George J., Skariah S.M., Aleena Xavier T.</b></td></tr><tr><td colspan="3">Organisations: <b>Amal Jyothi College of Engineering</b></td></tr><tr><td colspan="3">Deceptive news has an intention to defame a person, an institution or an organization. It often has a catastrophic effect on the views of the readers. With the advancement of technology, social media and online sites are made so accessible that, it acts as a catalyst for spreading fake news. Identification of such misinformation is a challenging task even for humans. But with Deep learning and Machine learning techniques, there have been efforts to solve this problem. In this paper the influence of linguistic characteristics and contextual features in fake news detection are analyzed and certain techniques like Naive Bayes, KNN, SVM, Decision tree, Hybrid CNN, CMS etc. are compared.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/IBSSC47189.2019.8973059" target="_blank"> F-NAD: An Application for Fake News Article Detection using Machine Learning Techniques<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85084419749</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Barua R., Maity R., Minj D., Barua T., Layek A.K.</b></td></tr><tr><td colspan="3">Organisations: <b>Indian Institute of Engineering Science Technology</b></td></tr><tr><td colspan="3">Nowadays the Internet and Social Media are flooded with fake accounts, fake posts and misleading news articles. The intention of these are often to mislead the common people and/or manipulate them into believing something that is not real. Misinformation or fake news can leave negative impact on a person or society as a whole that can last forever even if they get corrected afterwards. This work proposed here is to tackle this issue and it aims to identify a news articles whether it is real or misleading. This is achieved using an ensemble technique of state of the art recurrent neural networks (LSTM and GRU). An android application has also been developed for determining the sanctity of a news article. The proposed model is tested on a large dataset which is prepared in this work by collecting news from various fake and real news sources. It has also been tested using different standard datasets available in the literature and it is found that the proposed model performs better.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.procs.2020.03.276" target="_blank"> Deep neural approach to Fake-News identification<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85084494674</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Deepak S., Chitturi B.</b></td></tr><tr><td colspan="3">Organisations: <b>Amrita Vishwa Vidyapeetham</b></td></tr><tr><td colspan="3">The complexities of fake news detection cannot be overcome solely with Natural Language Processing. Even a human being finds it difficult to decide the authenticity of an article without further fact checking. Hence a Deep Learning model entirely based on NLP is bound to have huge limitations. In order to address this shortcoming, the proposed system additionally includes a live data stage mining which provides secondary features. These features include source domains of the article, author names etc. Since these features mimic the process of fact-checking to an extent, the model is expected to outperform existing models that are solely based on NLP. We seek to compare the results from models with and without secondary mined features. LSTM and FF Neural Networks are explored. Additionally, effectiveness of different word vector representations in relation to this problem are also investigated.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/iCoMET48670.2020.9074071" target="_blank"> Detection of Fake News Using Transformer Model<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85084672204</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Qazi M., Khan M.U.S., Ali M.</b></td></tr><tr><td colspan="3">Organisations: <b>Comsats University Islamabad</b></td></tr><tr><td colspan="3">Social media is one of the major platforms to get news and information. However, it also provides convenience for widespread of fake news. The reason at the back of fake news is to create hype in order to get the audience's attention and build negative impact on society. The fake news detection is necessary to purify the Internet environment. Various machine learning based detection algorithms are designed to detect fake news. We use attention-based transformer model on publically available dataset for detection of fake and real news. This research aims to test and compare state-of-the-art algorithm and our proposed technique in detection of fake and real news. Our result shows that 15% of the accuracy in fake news detection is improved by transformer model as compare to Hybrid CNN.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Unsupervised fake news detection on social media: A generative approach<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85084719009</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Yang S., Gu R., Wu F., Shu K., Liu H., Wang S.</b></td></tr><tr><td colspan="3">Organisations: <b>Shanghai Jiao Tong University, Arizona State University, Pennsylvania State University</b></td></tr><tr><td colspan="3">Social media has become one of the main channels for people to access and consume news, due to the rapidness and low cost of news dissemination on it. However, such properties of social media also make it a hotbed of fake news dissemination, bringing negative impacts on both individuals and society. Therefore, detecting fake news has become a crucial problem attracting tremendous research effort. Most existing methods of fake news detection are supervised, which require an extensive amount of time and labor to build a reliably annotated dataset. In search of an alternative, in this paper, we investigate if we could detect fake news in an unsupervised manner. We treat truths of news and users' credibility as latent random variables, and exploit users' engagements on social media to identify their opinions towards the authenticity of news. We leverage a Bayesian network model to capture the conditional dependencies among the truths of news, the users' opinions, and the users' credibility. To solve the inference problem, we propose an efficient collapsed Gibbs sampling approach to infer the truths of news and the users' credibility without any labelled data. Experiment results on two datasets show that the proposed method significantly outperforms the compared unsupervised methods.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/CSCI49370.2019.00255" target="_blank"> Enhancing the fake news detection by applying effective feature selection based on semantic sources<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85084761682</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Sabeeh V., Bashaireh R.A., Zohdy M.</b></td></tr><tr><td colspan="3">Organisations: <b>Oakland University</b></td></tr><tr><td colspan="3">Capturing reliable information from social networks is a challenge due to fake news risks. Existing works face shortages in exploiting short text processing, and in utilizing semantic-based resources to select optimal features. This paper proposed a CNIRI-FS (Contextual Negation Handling and Inherent Relation Identification for Enhanced Feature Selection) model to detect fake information; utilizing Wikipedia to add semantic features and an external enrichment from trusted web pages. A Genetic Algorithm (GA) was used to filter out unreliable features. The optimal feature set along with the negation handled features is validated using machine learning classifiers. The CNIRI-FS model results showed higher precision and accuracy than a model without optimal feature selection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-43722-0_22" target="_blank"> Fake News Detection Using Time Series and User Features Classification<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85084766803</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Previti M., Malgeri M., Rodriguez-Fernandez V., Camacho D., Carchiolo V.</b></td></tr><tr><td colspan="3">Organisations: <b>Università degli Studi di Catania, Universidad Autónoma de Madrid, Technical University of Madrid</b></td></tr><tr><td colspan="3">In a scenario where more and more individuals use online social network platforms as an instrument to propagate news without any control, it is necessary to design and implement new methods and techniques that guarantee the veracity of the disseminated news. In this paper, we propose a method to classify true and false news, commonly known as fake news, which exploits time series-based features extracted from the evolution of news, and features from the users involved in the news spreading. Applying our methodology over a real Twitter dataset of precategorized true and false news, we have obtained an accuracy of 84.61% in 10-fold cross-validation, and proved experimentally that all the selected features are relevant for this classification task.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1287/mnsc.2019.3295" target="_blank"> Fake news propagation and detection: A sequential model<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85084926438</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Papanastasiou Y.</b></td></tr><tr><td colspan="3">Organisations: <b>University of California</b></td></tr><tr><td colspan="3">In the wake of the 2016 U.S. presidential election, social-media platforms are facing increasing pressure to combat the propagation of “fake news” (i.e., articles whose content is fabricated). Motivated by recent attempts in this direction, we consider the problem faced by a social-media platform that is observing the sharing actions of a sequence of rational agents and is dynamically choosing whether to conduct an inspection (i.e., a “fact-check”) of an article whose validity is ex ante unknown. We first characterize the agents' inspection and sharing actions and establish that, in the absence of any platform intervention, the agents' news-sharing process is prone to the proliferation of fabricated content, even when the agents are intent on sharing only truthful news. We then study the platform's inspection problem. We find that because the optimal policy is adapted to crowdsource inspection from the agents, it exhibits features that may appear a priori nonobvious; most notably, we show that the optimal inspection policy is nonmonotone in the ex ante probability that the article being shared is fake. We also investigate the effectiveness of the platform's policy in mitigating the detrimental impact of fake news on the agents' learning environment. We demonstrate that in environments characterized by a low (high) prevalence of fake news, the platform's policy is more effective when the rewards it collects from content sharing are low relative to the penalties it incurs from the sharing of fake news (when the rewards it collects from content sharing are high in absolute terms).</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.eswa.2020.113503" target="_blank"> Fake news detection in multiple platforms and languages<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85084943711</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Faustini P.H.A., Covoes T.F.</b></td></tr><tr><td colspan="3">Organisations: <b>Federal University of ABC (UFABC)</b></td></tr><tr><td colspan="3">The debate around fake news has grown recently because of the potential harm they can have on different fields, being politics one of the most affected. Due to the amount of news being published every day, several studies in computer science have proposed models using machine learning to detect fake news. However, most of these studies focus on news from one language (mostly English) or rely on characteristics of social media-specific platforms (like Twitter or Sina Weibo). Our work proposes to detect fake news using only text features that can be generated regardless of the source platform and are the most independent of the language as possible. We carried out experiments from five datasets, comprising both texts and social media posts, in three language groups: Germanic, Latin, and Slavic, and got competitive results when compared to benchmarks. We compared the results obtained through a custom set of features and with other popular techniques when dealing with natural language processing, such as bag-of-words and Word2Vec.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICICT46931.2019.8977659" target="_blank"> A smart System for Fake News Detection Using Machine Learning<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85084950821</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Jain A., Gupta A.K., Shakya A., Khatter H.</b></td></tr><tr><td colspan="3">Organisations: <b>KIET Group of Institutions, ABES Engineering College</b></td></tr><tr><td colspan="3">Most of the smart phone users prefer to read the news via social media over internet. The news websites are publishing the news and provide the source of authentication. The question is how to authenticate the news and articles which are circulated among social media like WhatsApp groups, Facebook Pages, Twitter and other micro blogs & social networking sites. It is harmful for the society to believe on the rumors and pretend to be a news. The need of an hour is to stop the rumors especially in the developing countries like India, and focus on the correct, authenticated news articles. This paper demonstrates a model and the methodology for fake news detection. With the help of Machine learning and natural language processing, author tried to aggregate the news and later determine whether the news is real or fake using Support Vector Machine. The results of the proposed model is compared with existing models. The proposed model is working well and defining the correctness of results upto 93.6% of accuracy.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1080/19361610.2020.1761224" target="_blank"> Intelligent Fake News Detection: A Systematic Mapping<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85085047943</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Meneses Silva C.V., Silva Fontes R., Colaco Junior M.</b></td></tr><tr><td colspan="3">Organisations: <b>Federal University of Sergipe</b></td></tr><tr><td colspan="3">Context: The speed with which the Fake News spread today has encouraged work in various areas to minimize the damage and the public insecurity caused by their proliferation. Objective: To characterize and analyze Fake News threat detection. Method: Systematic Mapping, since the area youthfulness still prevents a complete meta-analysis. Results: The most used algorithms were LSTM (17.14%), Naive-Bayes and Similarity Algorithm (11.43%). Conclusions: There is still the absence of more controlled experiments in the Big Data context. Fake News is a national security problem, requiring effective solutions to combat it. Situations like the Covid-19 virus (coronavirus) reinforce this fact.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s11227-020-03294-y" target="_blank"> DeepFakE: improving fake news detection using tensor decomposition-based deep neural network<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85085129998</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Kaliyar R.K., Goswami A., Narang P.</b></td></tr><tr><td colspan="3">Organisations: <b>Bennett University, BITS Pilani</b></td></tr><tr><td colspan="3">Social media platforms have simplified the sharing of information, which includes news as well, as compared to traditional ways. The ease of access and sharing the data with the revolution in mobile technology has led to the proliferation of fake news. Fake news has the potential to manipulate public opinions and hence, may harm society. Thus, it is necessary to examine the credibility and authenticity of the news articles being shared on social media. Nowadays, the problem of fake news has gained massive attention from research communities and needed an optimal solution with high efficiency and low efficacy. Existing detection methods are based on either news-content or social-context using user-based features as an individual. In this paper, the content of the news article and the existence of echo chambers (community of social media-based users sharing the same opinions) in the social network are taken into account for fake news detection. A tensor representing social context (correlation between user profiles on social media and news articles) is formed by combining the news, user and community information. The news content is fused with the tensor, and coupled matrix-tensor factorization is employed to get a representation of both news content and social context. The proposed method has been tested on a real-world dataset: BuzzFeed. The factors obtained after decomposition have been used as features for news classification. An ensemble machine learning classifier (XGBoost) and a deep neural network model (DeepFakE) are employed for the task of classification. Our proposed model (DeepFakE) outperforms with the existing fake news detection methods by applying deep learning on combined news content and social context-based features as an echo-chamber.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1002/asi.24359" target="_blank"> Detecting fake news stories via multimodal analysis<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85085138578</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Singh V.K., Ghosh I., Sonagara D.</b></td></tr><tr><td colspan="3">Organisations: <b>Rutgers University</b></td></tr><tr><td colspan="3">Filtering, vetting, and verifying digital information is an area of core interest in information science. Online fake news is a specific type of digital misinformation that poses serious threats to democratic institutions, misguides the public, and can lead to radicalization and violence. Hence, fake news detection is an important problem for information science research. While there have been multiple attempts to identify fake news, most of such efforts have focused on a single modality (e.g., only text-based or only visual features). However, news articles are increasingly framed as multimodal news stories, and hence, in this work, we propose a multimodal approach combining text and visual analysis of online news stories to automatically detect fake news. Drawing on key theories of information processing and presentation, we identify multiple text and visual features that are associated with fake or credible news articles. We then perform a predictive analysis to detect features most strongly associated with fake news. Next, we combine these features in predictive models using multiple machine-learning techniques. The experimental results indicate that a multimodal approach outperforms single-modality approaches, allowing for better fake news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICIoT48696.2020.9089487" target="_blank"> State of the Art Models for Fake News Detection Tasks<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85085470668</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Antoun W., Baly F., Hussein A., Hajj H., Achour R.</b></td></tr><tr><td colspan="3">Organisations: <b>American University of Beirut</b></td></tr><tr><td colspan="3">This paper presents state of the art methods for addressing three important challenges in automated fake news detection: fake news detection, domain identification, and bot identification in tweets. The proposed solutions achieved first place in a recent international competition on fake news. For fake news detection, we present two models. The winning model in the competition combines similarity between the embedding of each article's title and the embedding of the top five corresponding google search results. The new model relies on advances in Natural Language Understanding (NLU) end to end deep learning models to identify stylistic differences between legitimate and fake news articles. This second model was developed after the competition and outperforms the winning approach. For news domain detection, the winning model is a hybrid approach composed of named entity features concatenated with semantic embeddings derived from end to end models. For twitter bot detection, we propose to use the following features: duration between account creation and tweet date, presence of a tweet's link, presence of user's location, other tweet's features, and the tweets' metadata. Experiments include insights into the importance of the different features and the results indicate the superior performances of all proposed models.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICETCE48199.2020.9091751" target="_blank"> Reliability of News<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85085561341</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Harjule P., Sharma A., Chouhan S., Joshi S.</b></td></tr><tr><td colspan="3">Organisations: <b>Indian Institute of Information Technology</b></td></tr><tr><td colspan="3">In modern times, because of the the advancement of social media platforms, fake news relating to different purposes has been increasing day by day. Fake News on the internet is defined as a fabricated article with the intention to mislead, usually for profiting. Fake news and hoaxes have been there since before the advent of the Internet. Hoaxes have existed for a long time, since the "Great moon hoax" published in 1835. Along with the increase in the use of social media platforms like Facebook, Twitter etc. news spreads rapidly among millions of users within a very short span of time. This paper's purpose is to investigate the concepts, approaches and algorithms for identifying fake news articles and their creators from online social media platforms and assessing their performance. This paper introduces two models for detection of fake news. First by text classification where different classifier models were applied and it was found that RNN(LSTM) gave the best accuracy of 93 %. Second by crowd analysis where Parameter tuning method gave the best accuracy of 80 %.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICCCBDA49378.2020.9095586" target="_blank"> Detecting Fake News on Social Media: A Multi-Source Scoring Framework<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85085727085</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Liu H., Wang L., Han X., Zhang W., He X.</b></td></tr><tr><td colspan="3">Organisations: <b>Qilu University of Technology (Shandong Academy of Sciences)</b></td></tr><tr><td colspan="3">Social media has dramatically promoted the efficiency of news diffusion. However, as information is no longer verified by journalists or experts, it has also become a fruitful environment for fake news. Since fake news has long been a critical threat to our society, it has always been an important work for both social media sites and government agencies to combat fake news. Although a large body of research work and efforts have been focused on fake news detection in social media, most of the existing methods are single-source based, which can easily lead to subjective detection results. In this paper, we propose FNDMS, a framework that integrates the credibility scores of multiple news sources to detect fake news. FNDMS uses two sets of features, i.e., author-based features and content-based features, to measure the credibility of a single news source. Then a DST model is employed to integrate credibilities of multiple sources and produce a judgment on the truth of an event. To collect event-related reports, we also propose a three-step method to retrieve and filter news articles from social media sites. Experimental results on real social media data demonstrate the feasibility and advance of FNDMS.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-47436-2_27" target="_blank"> SAFE: Similarity-Aware Multi-modal Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85085729056</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Zhou X., Wu J., Zafarani R.</b></td></tr><tr><td colspan="3">Organisations: <b>Syracuse University</b></td></tr><tr><td colspan="3">Effective detection of fake news has recently attracted significant attention. Current studies have made significant contributions to predicting fake news with less focus on exploiting the relationship (similarity) between the textual and visual information in news articles. Attaching importance to such similarity helps identify fake news stories that, for example, attempt to use irrelevant images to attract readers’ attention. In this work, we propose a Similarity-Aware FakE news detection method (SAFE) which investigates multi-modal (textual and visual) information of news articles. First, neural networks are adopted to separately extract textual and visual features for news representation. We further investigate the relationship between the extracted features across modalities. Such representations of news textual and visual information along with their relationship are jointly learned and used to predict fake news. The proposed method facilitates recognizing the falsity of news articles based on their text, images, or their “mismatches.” We conduct extensive experiments on large-scale real-world data, which demonstrate the effectiveness of the proposed method.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.eswa.2020.113584" target="_blank"> Fake news detection using an ensemble learning model based on Self-Adaptive Harmony Search algorithms<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85085729802</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Huang Y.-F., Chen P.-H.</b></td></tr><tr><td colspan="3">Organisations: <b>National Yunlin University of Science and Technology</b></td></tr><tr><td colspan="3">In general, the features of fake news are almost the same as those of real news, so it is not easy to identify them. In this paper, we propose a fake news detection system using a deep learning model. First, news articles are preprocessed and analyzed based on different training models. Then, an ensemble learning model combining four different models called embedding LSTM, depth LSTM, LIWC CNN, and N-gram CNN is proposed for fake news detection. Besides, to achieve higher accuracy in fake news detection, the optimized weights of the ensemble learning model are determined using the Self-Adaptive Harmony Search (SAHS) algorithm. In the experiments, we verify that the proposed model is superior to the state-of-the-art methods, with the highest accuracy of 99.4%. Furthermore, we also investigate the cross-domain intractability issue and achieve the highest accuracy of 72.3%. Finally, we believe there is still room for improving the ensemble learning model in addressing the cross-domain intractability issue.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICDE48307.2020.00180" target="_blank"> FakeDetector: Effective fake news detection with deep diffusive neural network<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85085865382</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Zhang J., Dong B., Yu P.S.</b></td></tr><tr><td colspan="3">Organisations: <b>Florida State University, University of Illinois at Chicago</b></td></tr><tr><td colspan="3">In recent years, due to the booming development of online social networks, fake news for various commercial and political purposes has been appearing in large numbers and widespread in the online world. With deceptive words, online social network users can get infected by these online fake news easily, which has brought about tremendous effects on the offline society already. An important goal in improving the trustworthiness of information in online social networks is to identify the fake news timely. This paper aims at investigating the principles, methodologies and algorithms for detecting fake news articles, creators and subjects from online social networks and evaluating the corresponding performance. This paper addresses the challenges introduced by the unknown characteristics of fake news and diverse connections among news articles, creators and subjects. This paper introduces a novel gated graph neural network, namely FAKEDETECTOR. Based on a set of explicit and latent features extracted from the textual information, FAKEDETECTOR builds a deep diffusive network model to learn the representations of news articles, creators and subjects simultaneously. Extensive experiments have been done on a real-world fake news dataset to compare FAKEDETECTOR with several state-of-the-art models, and the experimental results are provided in the full-version of this paper at [13].</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICII.2019.00070" target="_blank"> Fake news detection in social networks using machine learning and deep learning: Performance evaluation<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85085944268</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Han W., Mehta V.</b></td></tr><tr><td colspan="3">Organisations: <b>California State University</b></td></tr><tr><td colspan="3">The problems related to fake news are growing rapidly which results in misleading views on some information. Social media networks are one of the fastest medium to spread information by creating a huge impact on manipulating information by influencing readers in positive and negative aspects. This paper aims at evaluating and comparing different approaches that are used to mitigate this issue including some traditional machine learning approaches, such as Naive Bayes, and the popular deep learning approaches, such as hybrid CNN and RNN. The comparison is not only within traditional methods or within deep learning methods, but also across traditional and non-traditional methods. This paper lays a foundation for selecting a machine learning or deep learning method for problem solving regarding the balance between accuracy and lightweightness.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1089/big.2020.0062" target="_blank"> FakeNewsNet: A Data Repository with News Content, Social Context, and Spatiotemporal Information for Studying Fake News on Social Media<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85085965145</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Shu K., Mahudeswaran D., Liu H., Wang S., Lee D.</b></td></tr><tr><td colspan="3">Organisations: <b>Arizona State University, Penn State University</b></td></tr><tr><td colspan="3">Social media has become a popular means for people to consume and share the news. At the same time, however, it has also enabled the wide dissemination of fake news, that is, news with intentionally false information, causing significant negative effects on society. To mitigate this problem, the research of fake news detection has recently received a lot of attention. Despite several existing computational solutions on the detection of fake news, the lack of comprehensive and community-driven fake news data sets has become one of major roadblocks. Not only existing data sets are scarce, they do not contain a myriad of features often required in the study such as news content, social context, and spatiotemporal information. Therefore, in this article, to facilitate fake news-related research, we present a fake news data repository FakeNewsNet, which contains two comprehensive data sets with diverse features in news content, social context, and spatiotemporal information. We present a comprehensive description of the FakeNewsNet, demonstrate an exploratory analysis of two data sets from different perspectives, and discuss the benefits of the FakeNewsNet for potential applications on fake news study on social media.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/MIS.2020.2997781" target="_blank"> Detecting fake news with weak social supervision<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85085987264</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Shu K., Liu H., Dumais S., Awadallah A.H.</b></td></tr><tr><td colspan="3">Organisations: <b>Arizona State University, Microsoft Research</b></td></tr><tr><td colspan="3">Limited labeled data are becoming one of the largest bottlenecks for supervised learning systems. This is especially the case for many real-world tasks, where large-scale labeled examples are either too expensive to acquire or unavailable due to privacy or data access constraints. Weak supervision has shown to be effective in mitigating the scarcity of labeled data by leveraging weak labels or injecting constraints from heuristic rules and/or extrinsic knowledge sources. Social media has little labeled data but possesses unique characteristics that make it suitable for generating weak supervision, resulting in a new type of weak supervision, i.e., weak social supervision. In this article, we illustrate how various aspects of social media can be used as weak social supervision. Specifically, we use the recent research on fake news detection as the use case, where social engagements are abundant but annotated examples are scarce, to show that weak social supervision is effective when facing the labeled data scarcity problem. This article opens the door to learning with weak social supervision for similar emerging tasks when labeled data are limited.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.3390/FI12050087" target="_blank"> Language-independent fake news detection: English, Portuguese, and Spanish mutual features<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85085998434</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Abonizio H.Q., de Morais J.I., Junior S.B., Tavares G.M.</b></td></tr><tr><td colspan="3">Organisations: <b>State University of Londrina (UEL), Università degli Studi di Milano (UNIMI)</b></td></tr><tr><td colspan="3">Online Social Media (OSM) have been substantially transforming the process of spreading news, improving its speed, and reducing barriers toward reaching out to a broad audience. However, OSM are very limited in providing mechanisms to check the credibility of news propagated through their structure. The majority of studies on automatic fake news detection are restricted to English documents, with few works evaluating other languages, and none comparing language-independent characteristics. Moreover, the spreading of deceptive news tends to be a worldwide problem; therefore, this work evaluates textual features that are not tied to a specific language when describing textual data for detecting news. Corpora of news written in American English, Brazilian Portuguese, and Spanish were explored to study complexity, stylometric, and psychological text features. The extracted features support the detection of fake, legitimate, and satirical news. We compared four machine learning algorithms (k-Nearest Neighbors (k-NN), Support Vector Machine (SVM), Random Forest (RF), and Extreme Gradient Boosting (XGB)) to induce the detection model. Results show our proposed language-independent features are successful in describing fake, satirical, and legitimate news across three different languages, with an average detection accuracy of 85.3% with RF.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-49186-4_34" target="_blank"> Hong Kong Protests: Using Natural Language Processing for Fake News Detection on Twitter<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85086180411</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Zervopoulos A., Alvanou A.G., Bezas K., Papamichail A., Kermanidis K., Maragoudakis M.</b></td></tr><tr><td colspan="3">Organisations: <b>Ionian University, University of the Aegean</b></td></tr><tr><td colspan="3">The automation of fake news detection is the focus of a great deal of scientific research. With the rise of social media over the years, there has been a strong preference for users to be informed using their social media account, leading to a proliferation of fake news through them. This paper evaluates the veracity of politically-oriented news and in particular the tweets about the recent event of Hong Kong protests, with the aid of a dataset recently published by Twitter. From this dataset, Chinese tweets are translated into English, which are kept along with originally English tweets. By utilizing a language-independent filtering process, relevant tweets are identified. To complete the dataset, tweets originating from valid sources are used as the real portion, with journalists rather than news agencies being considered, which constitutes a novel aspect of the methodology. Well-known Machine Learning algorithms are used to classify tweets, which are represented by a feature value vector that is extracted, selected and preprocessed from the datasets and mainly revolves around language use, with word entropy being a novel feature. The results derived from these algorithms highlight morphological, lexical and vocabulary differences between tweets spreading fake and real news, which are for the most part in accordance with past related work.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3374135.3385324" target="_blank"> Disinformation detection using passive aggressive algorithms<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85086181437</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Yu S., Lo D.</b></td></tr><tr><td colspan="3">Organisations: <b>Kennesaw State University</b></td></tr><tr><td colspan="3">Disinformation, also as known as fake news, is overwhelming. Intentionally false information is widespread. However, the detection of fake news is remaining to be a challenge due to the nature of the complexity of languages. Linear regression algorithms are proven to be effective in many practices. In this paper, the Passive-Aggressive and the Multinomial Naive Bayes are studied for fake news detection that involves term frequency and inverse document frequency to vectorize news content. Our results show that the Passive-Aggressive is more efficient than Multinomial Naive Bayes by combing with term frequency and inverse document frequency and could be applied as a primary screen for complex disinformation detection practically.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-49190-1_16" target="_blank"> Fake News Detection Regarding the Hong Kong Events from Tweets<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85086241756</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Nikiforos M.N., Vergis S., Stylidou A., Augoustis N., Kermanidis K.L., Maragoudakis M.</b></td></tr><tr><td colspan="3">Organisations: <b>Ionian University, University of the Aegean</b></td></tr><tr><td colspan="3">The rapid development of network services has led to the exponential growth of online information and the increasing number of social media users. These services are exploited by malicious accounts that spread fake news and propaganda in vast user networks. Consequently, an automated solution for fake news and deception detection is required. This paper introduces a new data set consisting of 2,366 tweets written in English, regarding the Hong Kong events (August, 2019), and a well-defined method for fake news detection that uses both linguistic and network features. Our approach is tested with experiments using 2 machine learning models, achieving high performance compared to previous research.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-50143-3_51" target="_blank"> Mining text patterns over fake and real tweets<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85086256842</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Diaz-Garcia J.A., Fernandez-Basso C., Martin-Bautista M.J., Ruiz M.D.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Granada</b></td></tr><tr><td colspan="3">With the exponential growth of users and user-generated content present on online social networks, fake news and its detection have become a major problem. Through these, smear campaigns can be generated, aimed for example at trying to change the political orientation of some people. Twitter has become one of the main spreaders of fake news in the network. Therefore, in this paper, we present a solution based on Text Mining that tries to find which text patterns are related to tweets that refer to fake news and which patterns in the tweets are related to true news. To test and validate the results, the system faces a pre-labelled dataset of fake and real tweets during the U.S. presidential election in 2016. In terms of results interesting patterns are obtained that relate the size and subtle changes of the real news to create fake news. Finally, different ways to visualize the results are provided.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ISCAIE47305.2020.9108841" target="_blank"> Fake News Detection using Deep Learning<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85086628785</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Kong S.H., Tan L.M., Gan K.H., Samsudin N.H.</b></td></tr><tr><td colspan="3">Organisations: <b>Universiti Sains Malaysia</b></td></tr><tr><td colspan="3">FAKE news has proliferated to a big crowd than before in this digital era, the main factor derives from the rise of social media and direct messaging platform. Techniques of fake news stories detection ingenious, varied, and exciting. This study aims to apply natural language processing (NLP) techniques for text analytics and train deep learning models for detecting fake news based on news title or news content. Solution proposed in this study aims to be applied in real-world social media and eliminate the bad experience for user to receive misleading stories that come from non-reputable source. For NLP techniques, text preprocessing such as regular expression, tokenization, lemmatization and stop words removal are used before vectorizing them into N-gram vectors or sequence vectors using terms frequency inverse document frequency (TF-IDF) or one-hot encoding respectively. Then, TensorFlow is chosen as the framework to be used with built in Keras deep learning libraries that is having a large community and number of commits on Tensorflow GitHub repository that can be enough to build deep learning neural network models. Results from the models are showing that models trained with news content can achieve better performance with computation time being sacrificed while models trained with news title require less computation time to achieve good performance. Also, overall performance of models fed with N-gram vectors are slightly better than models fed with sequence vectors.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.procs.2020.04.247" target="_blank"> Comparison of fake and real news based on morphological analysis<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85086635816</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Kapusta J., Munk M., Benko L., Hajek P.</b></td></tr><tr><td colspan="3">Organisations: <b>Philosopher University in Nitra, Pedagogical University of Cracow, University of Pardubice</b></td></tr><tr><td colspan="3">Easy access to information results in the phenomenon of false news spreading intentionally through social networks to manipulate people's opinions. Fake news detection has recently attracted growing interest from the general public and researchers. The paper deals with the morphological analysis of two datasets containing 28 870 news articles. The results were verified using the third dataset consisting of 402 news articles. The analysis of the datasets was carried out using lemmatization and POS tagging. The morphological analysis as a process of classifying the words into grammatical-semantic classes and assigning grammatical categories to these words. Individual words from articles were annotated and statistically significant differences were examined between the classes found in fake and real news articles. The results of the analysis show that statistically significant differences are mainly in the verbs and nouns word classes. Finding statistically significant differences in individual categories of word classes is an important piece of information for the future fake news classifier in terms of selecting appropriate variables for the classification.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/CINTI-MACRo49179.2019.9105317" target="_blank"> Deep learning methods for Fake News detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85086636561</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Kresnakova V.M., Sarnovsky M., Butka P.</b></td></tr><tr><td colspan="3">Organisations: <b>Technical University of Košice</b></td></tr><tr><td colspan="3">Spreading of misinformation on the web nowadays represents a serious issue, as their influence on peoples opinions may be significant. Fake news represents a specific type of misinformation. While its detection was mostly being performed manually in the past, automated methods using machine learning and related fields became more critical. On the other hand, deep learning methods became very popular and frequently used methods in the field of data analysis in recent years. The study presented in this paper deals with the detection of fake news from the textual data using deep learning techniques. Our main idea was to train different types of neural network models using both entire texts from the articles and to use just the title text. The models were trained and evaluated on the Fake News dataset obtained from the Kaggle competition.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3372278.3390713" target="_blank"> Fake news detection via knowledge-driven multimodal graph convolutional networks<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85086898653</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Wang Y., Hu J., Xu C., Qian S., Fang Q.</b></td></tr><tr><td colspan="3">Organisations: <b>Hefei University of Technology, University of Chinese Academy of Sciences</b></td></tr><tr><td colspan="3">Nowadays, with the rapid development of social media, there is a great deal of news produced every day. How to detect fake news automatically from a large of multimedia posts has become very important for people, the government and news recommendation sites. However, most of the existing approaches either extract features from the text of the post which is a single modality or simply concatenate the visual features and textual features of a post to get a multimodal feature and detect fake news. Most of them ignore the background knowledge hidden in the text content of the post which facilitates fake news detection. To address these issues, we propose a novel Knowledge-driven Multimodal Graph Convolutional Network (KMGCN) to model the semantic representations by jointly modeling the textual information, knowledge concepts and visual information into a unified framework for fake news detection. Instead of viewing text content as word sequences normally, we convert them into a graph, which can model non-consecutive phrases for better obtaining the composition of semantics. Besides, we not only convert visual information as nodes of graphs but also retrieve external knowledge from real-world knowledge graph as nodes of graphs to provide complementary semantics information to improve fake news detection. We utilize a well-designed graph convolutional network to extract the semantic representation of these graphs. Extensive experiments on two public real-world datasets illustrate the validation of our approach.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.21018/rjcpr.2020.1.289" target="_blank"> Evaluating the spread of fake news and its detection. Techniques on social networking sites<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85086911202</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Hassan I., Azmi M.N.L., Abdullahi A.M.</b></td></tr><tr><td colspan="3">Organisations: <b>Universiti Sultan Zainal Abidin, Taylor’s University</b></td></tr><tr><td colspan="3">The phenomenon of fake news has become a much contentious issue recently. The controversy regarding this issue has further been intensified by the openness of social media platforms. Via a systematic review, this paper offers a discussion on the spread and detection techniques of fake news on Social Networking Sites (SNSs). A total of 47 articles eventually fulfilled the inclusion criteria and were coded for the literature synthesis. The overall findings from the literature on fake news and social media have been extracted and synthesized to explore the creation, influence and popular techniques and dimensions used for fake news detection on SNSs. The results showed that various entities are involved in the creation and spread of fake news on SNSs, including malicious social and software agents. It was also found that early registered users, old people, female users, delusion-prone persons, dogmatic persons, and religious fundamentalists are more likely to believe in fake news than other groups of individuals. One of the major problems of the existing techniques is their deficiency in datasets. Therefore, future studies on fake news detection should focus on developing an all-inclusive model with comprehensive datasets. Social media users require fake news detection skills especially using linguistic ap-proach. This study provides the public with valuable information about the spread and detection of fake news on SNSs. This is because SNSs are an important avenue for fake news providers.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-15-5830-6_15" target="_blank"> A Statistical Analysis of Various Technologies to Detect and Prevent Fake News<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85087143044</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Singh S., Vishwakarma S., Yadav A., Kispotta S.</b></td></tr><tr><td colspan="3">Organisations: <b>Jabalpur Engineering College</b></td></tr><tr><td colspan="3">In today’s life social media has special importance in almost everyone’s life and it is being used as a great way to manipulate people’s mind using fake news and fake articles. The topic of fake news came into vision as a serious issue in coming years. To detect and prevent fake news many technologies like blockchain, machine learning, deep learning and natural language processing have been used. This survey paper tells about novel way to compare various technologies of fake news detection and prevention from social media.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.5373/JARDCS/V12I6/S20201175" target="_blank"> Fake news detection in benchmark dataset using hybrid deep neural model<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85087145251</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Kumar A., Patel P.</b></td></tr><tr><td colspan="3">Organisations: <b>Delhi Technological University</b></td></tr><tr><td colspan="3">The anonymity veil and virality related to the social platforms have been tactfully used to deceive and mislead society through creating or disseminating fake news. The content and meta-data associated with the information posted can serve as evidence to debunk its truth value. A hybrid deep neural model is proposed which combines a high-level representation of textual features learned using hierarchical attention network and meta-data features learnt using convolutional neural network for the multi-label classification of fake news in benchmark LIAR dataset. The experiments on this model-level fusion network achieves a performance accuracy of 43.8% and outperforms the existing state-of-the-art.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-50423-6_49" target="_blank"> Sentiment analysis for fake news detection by means of neural networks<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85087283182</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Kula S., Choras M., Kozik R., Ksieniewicz P., Wozniak M.</b></td></tr><tr><td colspan="3">Organisations: <b>UTP University of Science and Technology, Kazimierz Wielki University, Wrocław University of Science and Technology</b></td></tr><tr><td colspan="3">The problem of fake news has become one of the most challenging issues having an impact on societies. Nowadays, false information may spread quickly through social media. In that regard, fake news needs to be detected as fast as possible to avoid negative influence on people who may rely on such information while making important decisions (e.g., presidential elections). In this paper, we present an innovative solution for fake news detection that utilizes deep learning methods. Our experiments prove that the proposed approach allows us to achieve promising results.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICICCS48265.2020.9120902" target="_blank"> Unsupervised WhatsApp Fake News Detection using Semantic Search<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85087451370</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Gaglani J., Gandhi Y., Gogate S., Halbe A.</b></td></tr><tr><td colspan="3">Organisations: <b>Sardar Patel Institute of Technology</b></td></tr><tr><td colspan="3">Social media has become the backbone of today's lifestyle. It has a widespread effect on nearly every walk of life. One of the well-known social media applications WhatsApp Messenger is a free and cross-platform text messaging software that also provides services for sending and receiving multimedia messages. But at the same time in recent years, its easy accessibility has served a way for propagating fake and biased news articles, blogs and messages. Fake news and messages have paved their way for Political polarization, ethnic tensions, unwanted panic and mass hysteria. A solution is proposed that uses Natural Language Processing for analyzing the messages and leverage Transfer Learning Models to detect the authenticity of the information. Claims are filtered from the bulk of forwarded messages disseminated on WhatsApp. The solution comprises of a semantic search mechanism between each claim and associated news sources. The similarity comparison done by the model predicts the truthfulness of the claim.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICICCS48265.2020.9121005" target="_blank"> Multimodal, Semi-supervised and Unsupervised web content credibility analysis Frameworks<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85087458299</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Saini N., Singhal M., Tanwar M., Meel P.</b></td></tr><tr><td colspan="3">Organisations: <b>Delhi Technological University</b></td></tr><tr><td colspan="3">The Internet has evolved to become one of the main sources to access and consume news. The reason being the low cost and rapid transmission of news on it through various means. Nevertheless, such characteristics of the Internet also makes it a breeding ground for the spread of fake news. The outcomes of this are far-reaching, mounting negativity over individuals as well as society. Hence comes the requirement for fake news detection research effort which is constantly being carried out. "Fake News" refers to forged news. It is a lie made up out of nothing which deceives the reader appearing as real news. There is not much review work done in the field of fake news detection methods. In this paper, we provide a survey on types of fake news disseminated and the solutions proposed to deal with detecting it. We focus our survey on the latest research fields in Fake News Detection namely Multimodal Frameworks, Semi-Supervised Frameworks, and Unsupervised Frameworks. We also state the advantages and disadvantages of each of the work mentioned and finally, highlight challenges that still concern the field of fake news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICICCS48265.2020.9121030" target="_blank"> Fake News Detection: An Ensemble Learning Approach<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85087458732</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Agarwal A., Dixit A.</b></td></tr><tr><td colspan="3">Organisations: <b>Netaji Subhas University of Technology</b></td></tr><tr><td colspan="3">Due to easy access, rapid growth, and proliferation of the information available through regular news mediums or social media, it is becoming easy for people to look for news and consume it. But on the other hand, it is becoming a daunting task to differentiate between false information and true information thus leading to widespread fake news. We can define fake news as a type of deceiving journalism and statements that are used to artifice and mislead people. Also, the credibility of social media platforms is at stake where this news is mostly shared. These types of forged information news can have serious negative societal impacts and thus their detection has become the emerging area that is attracting research attention. In this paper, we propose a model for detecting fake news by examining the accuracy of a report and predicting its authenticity. By feature extraction and forming credibility scores from the textual information, this model builds an ensemble network to learn the portrayals of news reports, authors, and titles simultaneously. Different machine learning algorithms like SVM, CNN, LSTM, KNN, and Naive Bayes are used for higher accuracy and it was observed that LSTM showed better accuracy with 97%. The performance and effectiveness of classifiers were evaluated based on their precision, recall, and F1-Score. The usage of different algorithms shows the effectiveness of performance on the dataset.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/EAIS48028.2020.9122764" target="_blank"> Credulous Users and Fake News: A Real Case Study on the Propagation in Twitter<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85088141477</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Balestrucci A., De Nicola R.</b></td></tr><tr><td colspan="3">Organisations: <b>Gran Sasso Science Institute, IMT School for Advanced Study</b></td></tr><tr><td colspan="3">Recent studies have confirmed a growing trend, especially among youngsters, of using Online Social Media as favourite information platform at the expense of traditional mass media. Indeed, they can easily reach a wide audience at a high speed; but exactly because of this they are the preferred medium for influencing public opinion via so-called fake news. Moreover, there is a general agreement that the main vehicle of fakes news are malicious software robots (bots) that automatically interact with human users.In previous work we have considered the problem of tagging human users in Online Social Networks as credulous users. Specifically, we have considered credulous those users with relatively high number of bot friends when compared to total number of their social friends. We consider this group of users worth of attention because they might have a higher exposure to malicious activities and they may contribute to the spreading of fake information by sharing dubious content.In this work, starting from a dataset of fake news, we investigate the behaviour and the degree of involvement of credulous users in fake news diffusion. The study aims to: (i) fight fake news by considering the content diffused by credulous users; (ii) highlight the relationship between credulous users and fake news spreading; (iii) target fake news detection by focusing on the analysis of specific accounts more exposed to malicious activities of bots. Our first results demonstrate a strong involvement of credulous users in fake news diffusion. This findings are calling for tools that, by performing data streaming on credulous' users actions, enables us to perform targeted fact-checking.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3386253" target="_blank"> FNED: A Deep Network for Fake News Early Detection on Social Media<a></b></td></tr><tr><td>Type: Review</td><td>ID: S_2-s2.0-85088296412</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Liu Y., Wu Y.-F.B.</b></td></tr><tr><td colspan="3">Organisations: <b>New Jersey Institute of Technology</b></td></tr><tr><td colspan="3">The fast spreading of fake news stories on social media can cause inestimable social harm. Developing effective methods to detect them early is of paramount importance. A major challenge of fake news early detection is fully utilizing the limited data observed at the early stage of news propagation and then learning useful patterns from it for identifying fake news. In this article, we propose a novel deep neural network to detect fake news early. It has three novel components: (1) a status-sensitive crowd response feature extractor that extracts both text features and user features from combinations of users' text response and their corresponding user profiles, (2) a position-aware attention mechanism that highlights important user responses at specific ranking positions, and (3) a multi-region mean-pooling mechanism to perform feature aggregation based on multiple window sizes. Experimental results on two real-world datasets demonstrate that our proposed model can detect fake news with greater than 90% accuracy within 5 minutes after it starts to spread and before it is retweeted 50 times, which is significantly faster than state-of-the-art baselines. Most importantly, our approach requires only 10% labeled fake news samples to achieve this effectiveness under PU-Learning settings.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.5373/JARDCS/V12SP7/20202266" target="_blank"> Trust index based model to define news credibility in social media using blockchain technology<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85088788674</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Jing T.W., Murugesan R.K., Balakrishnan S.</b></td></tr><tr><td colspan="3">Organisations: <b>Taylor’s University</b></td></tr><tr><td colspan="3">Today’s exponential growth of social media platforms have enabled both reliable and fake news that appears to be genuine to be spread very quickly and widely. The current learning algorithms to automatically detect fake news based on their contents are not effective and efficient. Fake news detection on state-of-the-art social media platforms presents unique challenges to identify the source of the news, and to measure the credibility of the authors which is the major problem to define the trustworthiness or credibility of the news. The credibility of the news can be defined by verifying the source and measuring the author credibility using a trust index. This would help to determine whether a news received is reliable or false. Hence, the main objective of this research is to propose a trust index based model to define news credibility in social media using blockchain with source verification and author credibility check. Blockchain technology and architecture provides a transparent, distributed and reliable platform to achieve consensus, provenance, immutability, finality, and most importantly single views of truth. The outcome of this research would be to mitigate the spreading of fake news in social media that would reduce chaos facilitating in maintaining peace and social security among the community. With an increasing appetite for verifiable truth on the internet, the proposed model can provide a new ecosystem to verify the credibility of news on a social media platform.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1137/1.9781611976236.54" target="_blank"> Representation learning for imbalanced cross-domain classification<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85089183457</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Cheng L., Guo R., Candan K.S., Liu H.</b></td></tr><tr><td colspan="3">Organisations: <b>Arizona State University</b></td></tr><tr><td colspan="3">Deep architectures are trained on massive amounts of labeled data to guarantee the performance of classification. In the absence of labeled data, domain adaptation often provides an attractive option given that labeled data of a similar nature but from a different domain is available. Previous work has chiefly focused on learning domain invariant representations but overlooked the issues of label imbalance in a single domain or across domains, which are common in many machine learning applications such as fake news detection. In this paper, we study a new cross-domain classification problem where data in each domain can be imbalanced (data imbalance), i.e., the classes are not evenly distributed, and the ratio of the number of positive over negative samples varies across domains (domain imbalance). This cross-domain problem is challenging as it entails covariate bias in the input feature space and representation bias in the latent space where domain invariant representations are learned. To address the challenge, in this paper, we propose an effective approach that leverages a doubly balancing strategy to simultaneously control these two types of bias and learn domain invariant representations. To this end, the proposed method aims to learn representations that are (i) robust to data and domain imbalance, (ii) discriminative between classes, and (iii) invariant across domains. Extensive evaluations of two important real-world applications corroborate the effectiveness of the proposed framework.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1137/1.9781611976236.35" target="_blank"> Global-and-local aware data generation for the class imbalance problem<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85089194568</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Tang J., Wang S., Fan W., Liu Z., Wang W.</b></td></tr><tr><td colspan="3">Organisations: <b>Michigan State University, Pennsylvania State University, City University of Hong Kong, TAL Education Group</b></td></tr><tr><td colspan="3">In many real-world classification applications such as fake news detection, the training data can be extremely imbalanced, which brings challenges to existing classifiers as the majority classes dominate the loss functions of classifiers. Oversampling techniques such as SMOTE are effective approaches to tackle the class imbalance problem by producing more synthetic minority samples. Despite their success, the majority of existing oversampling methods only consider local data distributions when generating minority samples, which can result in noisy minority samples that do not fit global data distributions or interleave with majority classes. Hence, in this paper, we study the class imbalance problem by simultaneously exploring local and global data information since: (i) the local data distribution could give detailed information for generating minority samples; and (ii) the global data distribution could provide guidance to avoid generating outliers or samples that interleave with majority classes. Specifically, we propose a novel framework GL-GAN, which leverages the SMOTE method to explore local distribution in a learned latent space and employs GAN to capture the global information, so that synthetic minority samples can be generated under even extremely imbalanced scenarios. Experimental results on diverse real data sets demonstrate the effectiveness of our GL-GAN framework in producing realistic and discriminative minority samples for improving the classification performance of various classifiers on imbalanced training data. Our code is available at https://github.com/wentao-repo/GL-GAN.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.3390/s20164360" target="_blank"> Edge computing and blockchain for quick fake news detection in IoV<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85089211824</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Xiao Y., Liu Y., Li T.</b></td></tr><tr><td colspan="3">Organisations: <b>Chongqing University of Posts and Telecommunications</b></td></tr><tr><td colspan="3">The dissemination of false messages in Internet of Vehicles (IoV) has a negative impact on road safety and traffic efficiency. Therefore, it is critical to quickly detect fake news considering news timeliness in IoV. We propose a network computing framework Quick Fake News Detection (QcFND) in this paper, which exploits the technologies from Software-Defined Networking (SDN), edge computing, blockchain, and Bayesian networks. QcFND consists of two tiers: edge and vehicles. The edge is composed of Software-Defined Road Side Units (SDRSUs), which is extended from traditional Road Side Units (RSUs) and hosts virtual machines such as SDN controllers and blockchain servers. The SDN controllers help to implement the load balancing on IoV. The blockchain servers accommodate the reports submitted by vehicles and calculate the probability of the presence of a traffic event, providing time-sensitive services to the passing vehicles. Specifically, we exploit Bayesian Network to infer whether to trust the received traffic reports. We test the performance of QcFND with three platforms, i.e., Veins, Hyperledger Fabric, and Netica. Extensive simulations and experiments show that QcFND achieves good performance compared with other solutions.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s42452-020-2326-y" target="_blank"> A robust technique of fake news detection using Ensemble Voting Classifier and comparison with other classifiers<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85089234201</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Mahabub A.</b></td></tr><tr><td colspan="3">Organisations: <b>Khulna University of Engineering & Technology</b></td></tr><tr><td colspan="3">These days online networking is generally utilized as the wellspring of data as a result of its ease, simple to get to nature. In any case, expending news from online life is a twofold edged sword as a result of the widespread of fake news, i.e., news with purposefully false data. Fake news is a major issue since it affects people just as society substantial. In the internet based life, the data is spread quick and subsequently discovery component ought to almost certainly foresee news quick enough to stop the dispersal of fake news. Consequently, identifying fake news via web-based networking media is a critical and furthermore an in fact testing issue. In this paper, Ensemble Voting Classifier based, an intelligent detection system is proposed to deal with news classification both real and fake tasks. Here, eleven mostly well-known machine-learning algorithms like Naïve Bayes, K-NN, SVM, Random Forest, Artificial Neural Network, Logistic Regression, Gradient Boosting, Ada Boosting, etc. are used for detection. After cross-validation, we used the best three machine-learning algorithms in Ensemble Voting Classifier. The experimental outcomes affirm that the proposed framework can accomplish to about 94.5% outcomes as far as accuracy. The other parameters like ROC score, precision, recall and F1 are also outstanding. The proposed recognition framework can effectively find the most important highlights of the news. These can also be implemented in other classification techniques to detect fake profiles, fake message, etc.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-51859-2_31" target="_blank"> Survey on fake news detection techniques<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85089235520</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Dwivedi S.M., Wankhade S.B.</b></td></tr><tr><td colspan="3">Organisations: <b>Vidyalankar Institute of Technology, Rajiv Gandhi Institute of Technology</b></td></tr><tr><td colspan="3">In recent years widespread rumors and fake news has given rise to many social and political problems. Most of the information today is acquired from digital sources. In Digital media it is difficult to assign accountability to the opinion due to which the data received cannot be authenticated. Lack of constant supervision has motivated the miscreants to spread fake information. Fake news articles that are planted over digital media shares important linguistic features such as immoderate usage of unconfirmed hyperbole and non-verified quotes. It is necessary to invent an automated mechanism to identify fake news and also to minimize its impact by restricting its spread. This survey comprehensively and systematically studies different methodologies in the detection of fake news in digital media. The survey identifies and specifies fundamental theories in Machine Learning, to facilitate and enhance the research of fake news detection. By understanding the different methodologies in fake news studies, we highlight some potential research gaps at the end of this survey.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-35249-3_5" target="_blank"> Fake news detection on social networks with artificial intelligence tools: Systematic literature review<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85089240167</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Goksu M., Cavus N.</b></td></tr><tr><td colspan="3">Organisations: <b>Near East University</b></td></tr><tr><td colspan="3">Rapid advances in technology have enabled print media to be published online and the emergence of Facebook, Twitter, YouTube and other social networks. Social networks have become an important way for people to communicate with each other and share their ideas. The most important feature of social networks is the rapid information sharing. In this context, the accuracy of the news or information published is very important. The spread of fake news in social networks has recently become one of the biggest problems. Fake news affects people’s daily life and social order and may cause some negativity. In this study, the most comprehensive and prestigious electronic databases have been examined in order to find the latest articles about the detection of fake news in social networks by systematic literature review method. The main aim of the study is to reveal the benefits of artificial intelligence tools used in the detection of fake news and their success levels in different applications. As a result of the study, it was concluded that the success levels of artificial intelligence tools are over 90%. This study is thought to be a guide both researchers and individuals related to this field.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-15-4692-1_31" target="_blank"> Detection of deepfakes using visual artifacts and neural network classifier<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85089317100</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Sahla Habeeba M.A., Lijiya A., Chacko A.M.</b></td></tr><tr><td colspan="3">Organisations: <b>National Institute of Technology Calicut</b></td></tr><tr><td colspan="3">The field of Artificial Intelligence is so advanced that it made the creation and modification of synthetic images and videos very easy. Tampering of videos attained a new level of refinement due to the deep learning techniques and the availability of high computing power. This contributes to the ‘deepfake’ era. Deepfake is a term coined for the fake videos created using deep learning techniques. With this method, one can create fake videos of people that they never did by replacing their face in some other real videos. There is a great danger of misusing this technique to disseminate false information or fake news. Thus the detection of deepfakes is critical to protect the people’s pride and trust in the digital content. Most of the works in detecting deepfakes are using deep learning methods. In this paper, we are proposing an approach to identify deepfake videos with very less computational power. The proposed method exploits visual artifacts present in the face regions in the generated deepfakes. We use a three-layer neural network to classify the videos as deepfake or real. As a second step of confirmation, the variance of laplacian is calculated for different patches in the face, and based on their comparison, detection of deepfakes is assured. Our approach is tested in two datasets, UADF dataset, and the latest DeepFakeDetection dataset released by the Google AI team. The proposed method achieves better results in terms of computational requirements and accuracy, and are explained in detail in the analysis section.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3372923.3404783" target="_blank"> Unsupervised fake news detection: A graph-based approach<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85089523721</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Gangireddy S.C.R., Chakraborty T., Deepak P., Long C.</b></td></tr><tr><td colspan="3">Organisations: <b>Indraprastha Institute of Information Technology, Queen's University Belfast, Nanyang Technological University</b></td></tr><tr><td colspan="3">Fake news has become more prevalent than ever, correlating with the rise of social media that allows every user to rapidly publish their views or hearsay. Today, fake news spans almost every realm of human activity, across diverse fields such as politics and healthcare. Most existing methods for fake news detection leverage supervised learning methods and expect a large labelled corpus of articles and social media user engagement information, which are often hard, time-consuming and costly to procure. In this paper, we consider the task of unsupervised fake news detection, which considers fake news detection in the absence of labelled historical data. We develop GTUT, a graph-based approach for the task which operates in three phases. Starting off with identifying a seed set of fake and legitimate articles exploiting high-level observations on inter-user behavior in fake news propagation, it progressively expands the labelling to all articles in the dataset. Our technique draws upon graph-based methods such as biclique identification, graph-based feature vector learning and label spreading. Through an extensive empirical evaluation over multiple real-world datasets, we establish the improved effectiveness of our method over state-of-the-art techniques for the task.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3404512.3404515" target="_blank"> A fake news detection framework using social user graph<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85089580150</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Xie Y., Huang X., Xie X., Jiang S.</b></td></tr><tr><td colspan="3">Organisations: <b>Guangdong University of Foreign Studies, Guangzhou Key Laboratory of Multilingual Intelligent Processing</b></td></tr><tr><td colspan="3">In the contemporary era of information explosion, all kinds of false and misleading information are flooding our lives, which often impact politics and even our real world. How to detect these potential fake news from massive news texts is of great significance for maintaining social stability. The current fake news detection is mainly researched from supervised classification based on text content. However, it does not always work. Because fake news is often latent, they can imitate true news from the perspective of language style, etc. Therefore, we need to capture more effective feature information to improve the performance of fake news detection models. For example, the user connections on social networks. At present, some researches have used the characteristics of users in social networks, but the user's characteristic representation is often independent of the task of fake news detection, and some researches ignored the different influences of different users in fake news detection, such as the news released by official news agency is often more authentic. In this paper, we propose a fake news detection framework that makes full use of user characteristics. Firstly, the user's news dissemination behavior was classified based on GraphSage. Then, using multi-head attention to give the user representation that obtained through GraphSage to different weights, which was combined with the news text representation was used for classification. Compared with previous studies, we have achieved the state-of-the-art performance on two real datasets BuzzFeed and PolitiFact, which show the strength of our method.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> A survey on natural language processing for fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85089874044</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Oshikawa R., Qian J., Wang W.Y.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Tokyo, University of California</b></td></tr><tr><td colspan="3">Fake news detection is a critical yet challenging problem in Natural Language Processing (NLP). The rapid rise of social networking platforms has not only yielded a vast increase in information accessibility but has also accelerated the spread of fake news. Thus, the effect of fake news has been growing, sometimes extending to the offline world and threatening public safety. Given the massive amount of Web content, automatic fake news detection is a practical NLP problem useful to all online content providers, in order to reduce the human time and effort to detect and prevent the spread of fake news. In this paper, we describe the challenges involved in fake news detection and also describe related tasks. We systematically review and compare the task formulations, datasets and NLP solutions that have been developed for this task, and also discuss the potentials and limitations of them. Based on our insights, we outline promising research directions, including more fine-grained, detailed, fair, and practical detection models. We also highlight the difference between fake news detection and other related tasks, and the importance of NLP solutions for fake news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/LSP.2020.3008087" target="_blank"> A Sensitive Stylistic Approach to Identify Fake News on Social Networking<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85089875252</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>De Oliveira N.R., Medeiros D.S.V., Mattos D.M.F.</b></td></tr><tr><td colspan="3">Organisations: <b>Universidade Federal Fluminense (UFF)</b></td></tr><tr><td colspan="3">Human inefficiency to distinguish between true and false facts poses fake news as a threat to logical truth, which deteriorates democracy, journalism, and credibility in governmental institutions. In this letter, we propose a computational-stylistic analysis based on natural language processing, efficiently applying machine learning algorithms to detect fake news in texts extracted from social media. The analysis considers news from Twitter, from which approximately 33,000 tweets were collected, assorted between real and proven false. In assessing the quality of detection, 86% accuracy, and 94% precision stand out even employing a dimensional reduction to one-sixth of the number of original features. Our approach introduces a minimum overhead, while it has the potential of providing a high confidence index on discriminating fake from real news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICOEI48184.2020.9142971" target="_blank"> MYTHYA: Fake News Detector, Real Time News Extractor and Classifier<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85089971242</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Thakur A., Shinde S., Patil T., Gaud B., Babanne V.</b></td></tr><tr><td colspan="3">Organisations: <b>Savitribai Phule Pune University</b></td></tr><tr><td colspan="3">Fake news is a kind of exploitative journalism which is completely deprived of facts. It spreads disinformation, lies or hoaxes by means of traditional print media, televisions or radio media and nowadays through social media. The spreading of fake news on social media has changed the course of elections and thus impacted the future. Automating fake news detection is essential to maintain the integrity of news and journalism. In this Paper, a system that uses Gradient Boosted Decision Tree and Convolutional Neural network is provided to detect the stance of the news headlines and classify them as real or fake. By combining these two models systems gets the accuracy of 97.59%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-54832-2_10" target="_blank"> Fake News Detection Based on Subjective Opinions<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85090097203</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Zhang D., Zadorozhny V.I.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Pittsburgh</b></td></tr><tr><td colspan="3">Fake news fluctuates social media, leading to harmful consequences. Several types of information could be utilized to detect fake news, such as news content features and news propagation features. In this study, we focus on the user spreading news behaviors on social media platforms and aim to detect fake news more effectively with more accurate data reliability assessment. We introduce Subjective Opinions into reliability evaluation and proposed two new methods. Experiments on two popular real-world datasets, BuzzFeed and PolitiFact, validates that our proposed Subjective Opinions based method can detect fake news more accurately than all existing methods, and another proposed probability based method achieves state-of-art performance.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/CVPRW50498.2020.00334" target="_blank"> Fake news detection using higher-order user to user mutual-attention progression in propagation paths<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85090109386</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Mishra R.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Stavanger</b></td></tr><tr><td colspan="3">Social media has become a very prominent source of news consumption. It brings forth multifaceted, multimodal and real-time information on a silver platter for the users. Fake news or rumor mongering on social media is one of the most challenging issues pertaining to present web. Previously, researchers have tried to classify news propagation paths on social media (e.g. Twitter) to detect fake news. However, they do not utilize latent relationships among users efficiently to model the influence of the users with high prestige on the other users, which is a very significant factor in information propagation. In this paper, we propose a novel Higher-order User to User Mutual-attention Progression (HiMaP) method to capture the cues related to authority or influence of the users by modelling direct and indirect (multi-hop) influence relationships among each pair of users, present in the propagation sequence. The proposed higher order attention trick is a novel contribution which can also be very effective in case of transformer architectures[30]. Our model not only outperforms the state-of-the-art methods on two publicly available Twitter datasets but also explains the propagation patterns pertaining to fake news by visualizing higher order mutualattentions.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3397271.3401396" target="_blank"> BRENDA: Browser Extension for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85090117043</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Botnevik B., Sakariassen E., Setty V.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Stavanger</b></td></tr><tr><td colspan="3">Misinformation such as fake news has drawn a lot of attention in recent years. It has serious consequences on society, politics and economy. This has lead to a rise of manually fact-checking websites such as Snopes and Politifact. However, the scale of misinformation limits their ability for verification. In this demonstration, we propose BRENDA a browser extension which can be used to automate the entire process of credibility assessments of false claims. Behind the scenes BRENDA uses a tested deep neural network architecture to automatically identify fact check worthy claims and classifies as well as presents the result along with evidence to the user. Since BRENDA is a browser extension, it facilities fast automated fact checking for the end user without having to leave the Webpage.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ACCESS.2020.3009445" target="_blank"> A Survey on Trust Prediction in Online Social Networks<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85090288279</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Ghafari S.M., Beheshti A., Mahmood A., Yakhchi S., Orgun M.A., Joshi A., Paris C.</b></td></tr><tr><td colspan="3">Organisations: <b>Macquarie University, Csiro Data61</b></td></tr><tr><td colspan="3">Level of Trust can determine which source of information is reliable and with whom we should share or from whom we should accept information. There are several applications for measuring trust in Online Social Networks (OSNs), including social spammer detection, fake news detection, retweet behaviour detection and recommender systems. Trust prediction is the process of predicting a new trust relation between two users who are not currently connected. In applications of trust, trust relations among users need to be predicted. This process faces many challenges, such as the sparsity of user-specified trust relations, the context-awareness of trust and changes in trust values over time. In this paper, we analyse the state-of-the-art in pair-wise trust prediction models in OSNs, classify them based on different factors, and propose some future directions for researchers interested in this field.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3394486.3406466" target="_blank"> Learning with Small Data<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85090425260</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Yao H., Li Z., Jia X., Kumar V.</b></td></tr><tr><td colspan="3">Organisations: <b>Pennsylvania State University, University of Minnesota Twin Cities</b></td></tr><tr><td colspan="3">In the era of big data, data-driven methods have become increasingly popular in various applications, such as image recognition, traffic signal control, fake news detection. The superior performance of these data-driven approaches relies on large-scale labeled training data, which are probably inaccessible in real-world applications, i.e., "small (labeled) data" challenge. Examples include predicting emergent events in a city, detecting emerging fake news, and forecasting the progression of conditions for rare diseases. In most scenarios, people care about these small data cases most and thus improving the learning effectiveness of machine learning algorithms with small labeled data has been a popular research topic. In this tutorial, we will review the trending state-of-the-art machine learning techniques for learning with small (labeled) data. These techniques are organized from two aspects: (1) providing a comprehensive review of recent studies about knowledge generalization, transfer, and sharing, where transfer learning, multi-task learning, and meta-learning are discussed. Particularly, we will focus more on meta-learning, which improves the model generalization ability and has been proven to be an effective approach recently; (2) introducing the cutting-edge techniques which focus on incorporating domain knowledge into machine learning models. Different from model-based knowledge transfer techniques, in real-world applications, domain knowledge (e.g., physical laws) provides us with a new angle to deal with the small data challenge. Specifically, domain knowledge can be used to optimize learning strategies and/or guide the model design. In data mining field, we believe that learning with small data is a trending topic with important social impact, which will attract both researchers and practitioners from academia and industry.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-15-5341-7_58" target="_blank"> Supervised Machine Learning Algorithms for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85090522923</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Kesarwani A., Chauhan S.S., Verma G., Nair A.R.</b></td></tr><tr><td colspan="3">Organisations: <b>School of VLSI and Embedded Systems Design, Toshiba Software (India) Pvt. Ltd.</b></td></tr><tr><td colspan="3">In our modern era where the Internet is ubiquitous, everyone consumes various informations from the online resources. Along with the use of a huge amount of social media, news spread rapidly among the millions of users within a short interval of time. However, the quality of news on social media is lower than the traditional news outlets; the main reason behind that is the large amount of fake news. So in this paper, we have explored the application of machine learning techniques to identify the fake news. We have developed two models with the help of support vector machine, random forest, logistic regression, naive Bayes, and k-nearest neighbor machine learning algorithms, and this method is compared in terms of accuracy. A model focuses on identifying the fake news, based on multiple news articles (headline) and Facebook post data which gather informations about user social engagement. We achieved maximum classification accuracy of 98.25% (logistic regression) for a dataset A and 81.40% (KNN) accuracy for a dataset B.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/INCET49848.2020.9153985" target="_blank"> Recent state-of-the-art of fake news detection: A review<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85090586900</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Vishwakarma D.K., Jain C.</b></td></tr><tr><td colspan="3">Organisations: <b>Delhi Technological University</b></td></tr><tr><td colspan="3">In modern times, it has been observed that more number of people access news through search engines and social media rather than the traditional media like print media. However, there is no check on authenticity of the news which is present online. The spread of fake news is a severe problem which can have detrimental effects on the society. Given the challenges in detection of fake news, many researchers are trying to understand the problem statement and its characteristics. In this paper, the existing approaches and the new methods proposed by researchers have been summarized. The methods vary according to the content types (textual or image based) so that problem can be tackled in a better way and improved classification results can be obtained.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Some considerations on fake news detection<a></b></td></tr><tr><td>Type: Review</td><td>ID: S_2-s2.0-85090885811</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Hornoiu D.</b></td></tr><tr><td colspan="3">Organisations: <b>Ovidius University of Constanta</b></td></tr><tr><td colspan="3">The paper addresses the phenomenon of fake news. First, it provides an overview of definitions of fake news in recent research, with special focus on three categories of fake news, depending on the intent behind falsification: a) fabrication, b) hoaxing and c) satire. Second, it looks into the methodological issues related to gathering a relevant corpus for fake news detection, highlighting the conditions such a corpus is supposed to meet. Last but not least, the paper argues for a model of analysis for the detection of fake news within the framework of Natural language processing.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Some experiments on Deep Learning for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85090912036</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Chianese A., Masciari E., Moscato V., Picariello A., Sperli G.</b></td></tr><tr><td colspan="3">Organisations: <b>University Federico II of Naples</b></td></tr><tr><td colspan="3">The uncontrolled growth of fake news creation and dissemi-nation we observed in recent years causes continuous threats to democ-racy, justice, and public trust. This problem has significantly driven the effort of both academia and industries for developing more accurate fake news detection strategies. Early detection of fake news is crucial, how-ever the availability of information about news propagation is limited. Moreover, it has been shown that people tend to believe more fake news due to their features [13]. In this paper, we present our framework for fake news detection and we discuss in detail a solution based on deep learning methodologies we implemented by leveraging Google Bert fea-tures. Our experiments conducted on two well-known and widely used real-world datasets suggest that our method can outperform the state-of-the-art approaches and allows fake news accurate detection, even in the case of limited content information.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICoICT49345.2020.9166230" target="_blank"> Synonyms-Based Augmentation to Improve Fake News Detection using Bidirectional LSTM<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85091009093</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Ghinadya, Suyanto S.</b></td></tr><tr><td colspan="3">Organisations: <b>Telkom University</b></td></tr><tr><td colspan="3">Fake news is the news which contains propaganda and not relevant to the actual news. Today, the news in social media are troubling internet user. Hence, a fake news detector is needed to solve the problem. In this research, a fake news detector system based on Recurrent Neural Network (RNN) is developed. The architecture is designed using Bidirectional Long Short-Term Memories (Bi-LSTM) with exploit stance detection for the headline and the body of the news. Evaluation on 50 k news articles from FNC-1 shows that the proposed method produces F1-score of 0.2423 in detecting the fake news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3410566.3410595" target="_blank"> Emotion cognizance improves health fake news identification<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85091060245</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Anoop K., Lajish L.V., Deepak P.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Calicut, Queen's University Belfast</b></td></tr><tr><td colspan="3">Identifying fake news is increasingly being recognized as an important computational task with high potential social impact. Misinformation is routinely injected into almost every domain of news including politics, health, science, business, etc., among which, the fake news in the health domain poses serious risk and harm to health and well-being in modern societies. In this paper, we consider the utility of the affective character of news articles for fake news identification in the health domain and present evidence that emotion cognizant representations are significantly more suited for the task. We outline a simple technique that works by leveraging emotion intensity lexicons to develop emotion-Amplified text representations and evaluate the utility of such a representation for identifying fake news relating to health in various supervised and unsupervised scenarios. The consistent and notable empirical gains that we observe over a range of technique types and parameter settings establish the utility of the emotional information in news articles, an often overlooked aspect, for the task of misinformation identification in the health domain.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3410566.3410599" target="_blank"> Detecting fake news by image analysis<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85091076638</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Masciari E., Moscato V., Picariello A., Sperli G.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Naples "federico Ii"</b></td></tr><tr><td colspan="3">The uncontrolled growth of fake news creation and dissemination we observed in recent years causes continuous threats to democracy, justice, and public trust. This problem has significantly driven the effort of both academia and industries for developing more accurate fake news detection strategies. Early detection of fake news is crucial, however the availability of information about news propagation is limited. Moreover, it has been shown that people tend to believe more fake news due to their features [10]. In this paper, we present our framework for fake news detection and we discuss in detail an approach based on deep learning that we implemented by using Google Bert features. Our experiments conducted on two well-known and widely used real-world datasets suggest that our method can outperform the state-of-The-Art approaches and allows fake news accurate detection, even in the case of limited content information.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-58282-1_1" target="_blank"> User-Centered Detection of Fake News and Misinformation - Design and Prototypical Implementation in the System Contexter<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85091090490</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Englmeier K.</b></td></tr><tr><td colspan="3">Organisations: <b>Schmalkalden University of Applied Science</b></td></tr><tr><td colspan="3">Misinformation or fake news may threaten our democracies, societies, and economies, even individual health and well-being. Humans are usually careful about the things they are being told. They check news or tweets against their knowledge or beliefs and estimate to what extent propositions contain information that is bogus. People have abstract representations of facts in mind. That help them to validate propositions and to search for information suitable for their validation. This paper presents design and prototypical implementation of the Contexter system that enables users to define and manage blueprints of facts or fake news. Contexter takes these blueprints as a schema to detect facts or fake news. It also starts to find variants of these blueprints to detect pieces of text that come semantically close to the propositions addressed by the original blueprint.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.3233/JIFS-179905" target="_blank"> 'Bend the truth': Benchmark dataset for fake news detection in Urdu language and its evaluation<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85091092871</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Amjad M., Sidorov G., Zhila A., Gelbukh A., Gomez-Adorno H., Voronkov I.</b></td></tr><tr><td colspan="3">Organisations: <b>Instituto Politécnico, Universidad Nacional Autónoma de, Moscow Institute of Physics and Technology</b></td></tr><tr><td colspan="3">The paper presents a new corpus for fake news detection in the Urdu language along with the baseline classification and its evaluation. With the escalating use of the Internet worldwide and substantially increasing impact produced by the availability of ambiguous information, the challenge to quickly identify fake news in digital media in various languages becomes more acute. We provide a manually assembled and verified dataset containing 900 news articles, 500 annotated as real and 400, as fake, allowing the investigation of automated fake news detection approaches in Urdu. The news articles in the truthful subset come from legitimate news sources, and their validity has been manually verified. In the fake subset, the known difficulty of finding fake news was solved by hiring professional journalists native in Urdu who were instructed to intentionally write deceptive news articles. The dataset contains 5 different topics: (i) Business, (ii) Health, (iii) Showbiz, (iv) Sports, and (v) Technology. To establish our Urdu dataset as a benchmark, we performed baseline classification. We crafted a variety of text representation feature sets including word n-grams, character n-grams, functional word n-grams, and their combinations. After applying a variety of feature weighting schemes, we ran a series of classifiers on the train-test split. The results show sizable performance gains by AdaBoost classifier with 0.87 F1Fake and 0.90 F1Real. We provide the results evaluated against different metrics for a convenient comparison of future research. The dataset is publicly available for research purposes.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-57805-3_21" target="_blank"> Multi-stage news-stance classification based on lexical and neural features<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85091152374</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Hassan F.M., Lee M.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Birmingham, Simad University</b></td></tr><tr><td colspan="3">The amount of fake news present on the internet poses a great challenge for many online communities including manual fact-checkers who struggle to prevent the spread of misinformation and its negative impact. Detecting the stance of a news article involves classifying its perspective (e.g. agree, disagree, discuss, or unrelated) to a particular claim or headline which could support human fact-checkers to determine the veracity of the claims. Prior work on fake-news stance detection has proposed one-stage multi-class classification solutions which have limited success in detecting related pairs due to imbalanced class distributions in the data. This paper describes an improved approach to the stance detection of Fake News Challenge (FNC-1) based on multi-stage feature-assisted Deep Learning approaches. We break down the multi-class classification problem into two-stage and three-stage classifiers by combining the lexical-overlap features with Deep Learning techniques in an effort to mitigate the class imbalance problem. The experimental results demonstrate that the proposed models improve upon the state-of-the-art Accuracy and F1 score for stance detection. We also experimentally show that our models achieve solid results on minority classes i.e. agree and disagree without using fine-tuning approach or adding more training samples.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-57805-3_22" target="_blank"> Fake news detection: Do complex problems need complex solutions?<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85091155622</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Palacio Marin I., Arroyo D.</b></td></tr><tr><td colspan="3">Organisations: <b>Universidad Autónoma de Madrid, Spanish National Research Council (CSIC)</b></td></tr><tr><td colspan="3">Nowadays, information is crucial in the configuration of the socio-political space. Data relevance in both decision making and decision taking has exponentially increased. Content examination, social network analysis, information propagation (including epidemic and statistical modeling analysis), or sentiment analysis techniques are currently used to classify and curate information. Nonetheless, mis- and dis-information are among the major current cybersecurity challenges, as it is hindering the very health of our democratic systems. As a result, there is an urge to devise and implement technical solutions to detect and deter the propagation of unreliable information. In this work, we consider a specific case in the taxonomy of the complex scenarios of mis- and dis-information phenomena, the so-called fake news. In short, we used labeled data set containing fake news, which are going to be detected by means of traditional natural language processing techniques and advanced deep learning approaches. Our intention relies on comparing the accuracy of simple methods (namely, traditional natural language processing) with respect to modern and complex techniques in the deep learning family. The study of the above mentioned dataset hints that adopting complex techniques may not always guarantee achieving better classification performances.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-57805-3_20" target="_blank"> Distributed architecture for fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85091162818</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Kozik R., Choras M., Kula S., Pawlicki M.</b></td></tr><tr><td colspan="3">Organisations: <b>UTP University of Science and Technology, Kazimierz Wielki University</b></td></tr><tr><td colspan="3">Countering the fake news phenomenon has become one of the most important challenges for democratic societies, governments and non-profit organizations, as well as for the researchers coming from several domains. This is not a local problem, and demands a holistic approach to analyzing heterogeneous data and storing the results. The major contribution of this paper is the proposition of an innovative distributed architecture to tackle the above-mentioned problems. The architecture uses state-of-the-art technologies with focus on efficiency, scalability and also openness, so that community-created components and analyzers could be added.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-57805-3_23" target="_blank"> Application of the bert-based architecture in fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85091168287</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Kula S., Choras M., Kozik R.</b></td></tr><tr><td colspan="3">Organisations: <b>UTP University of Science and Technology, Kazimierz Wielki University</b></td></tr><tr><td colspan="3">Recent progress in the area of modern technologies confirms that information is not only a commodity but can also become a tool for competition and rivalry among governments and corporations, or can be applied by ill-willed people to use it in their hate speech practices. The impact of information is overpowering and can lead to many socially undesirable phenomena, such as panic or political instability. To eliminate the threats of fake news publishing, modern computer security systems need flexible and intelligent tools. The design of models meeting the above-mentioned criteria is enabled by artificial intelligence, and above all by the state-of-the-art neural network architectures, applied in NLP tasks. The BERT neural network belongs to this type of architectures. This paper presents a hybrid architecture connecting BERT with RNN; the architecture was used to create models for detecting fake news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-58323-1_3" target="_blank"> Multimodal fake news detection with textual, visual and semantic information<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85091185701</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Giachanou A., Zhang G., Rosso P.</b></td></tr><tr><td colspan="3">Organisations: <b>Universitat Politècnica de València, Wuhan University</b></td></tr><tr><td colspan="3">Recent years have seen a rapid growth in the number of fake news that are posted online. Fake news detection is very challenging since they are usually created to contain a mixture of false and real information and images that have been manipulated that confuses the readers. In this paper, we propose a multimodal system with the aim to differentiate between fake and real posts. Our system is based on a neural network and combines textual, visual and semantic information. The textual information is extracted from the content of the post, the visual one from the image that is associated with the post and the semantic refers to the similarity between the image and the text of the post. We conduct our experiments on three standard real world collections and we show the importance of those features on detecting fake news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ACCESS.2020.3019735" target="_blank"> Fake news stance detection using deep learning architecture (CNN-LSTM)<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85091199880</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Umer M., Imtiaz Z., Ullah S., Mehmood A., Choi G.S., On B.-W.</b></td></tr><tr><td colspan="3">Organisations: <b>Khwaja Fareed University of Engineering and Information Technology, Islamia University of Bahawalpur, Yeungnam University, Kunsan National University</b></td></tr><tr><td colspan="3">Society and individuals are negatively influenced both politically and socially by the widespread increase of fake news either way generated by humans or machines. In the era of social networks, the quick rotation of news makes it challenging to evaluate its reliability promptly. Therefore, automated fake news detection tools have become a crucial requirement. To address the aforementioned issue, a hybrid Neural Network architecture, that combines the capabilities of CNN and LSTM, is used with two different dimensionality reduction approaches, Principle Component Analysis (PCA) and Chi-Square. This work proposed to employ the dimensionality reduction techniques to reduce the dimensionality of the feature vectors before passing them to the classifier. To develop the reasoning, this work acquired a dataset from the Fake News Challenges (FNC) website which has four types of stances: agree, disagree, discuss, and unrelated. The nonlinear features are fed to PCA and chi-square which provides more contextual features for fake news detection. The motivation of this research is to determine the relative stance of a news article towards its headline. The proposed model improves results by 4% and 20% in terms of Accuracy and F1-score. The experimental results show that PCA outperforms than Chi-square and state-of-the-art methods with 97.8% accuracy.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-55789-8_33" target="_blank"> Automatic fake news detection by exploiting user’s assessments on social networks: A case study of twitter<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85091273885</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Tran V.C., Nguyen V.D., Nguyen N.T.</b></td></tr><tr><td colspan="3">Organisations: <b>Quang Binh University, Nong Lam University, Wroclaw University of Science and Technology, Nguyen Tat Thanh University</b></td></tr><tr><td colspan="3">Nowadays, social media has been becoming the main news source for millions of people all over the world. Users easily can create and share their information on social platforms. Information on social media can spread rapidly in the community. However, the spreading of misleading information is a critical issue. There are much intentionally written to mislead the readers, that are called fake news. The fake news represents the most forms of false or unverified information. The extensive spread of fake news has negative impacts on society. Detecting and blocking early fake news is very essential to avoid the negative effect on the community. In this paper, we exploit the news content, the wisdom of crowds in the social interaction and the user’s credibility characteristics to automatically detect fake news on Twitter. First, the user profile is exploited to measure the credibility level. Second, the users’ interactions for a post such as Comment, Favorite, Retweet are collected to determine the user’s opinion and exhortation level. Finally, a Support Vector Machine (SVM) model with the Radial Basis Function (RBF) kernel is applied to determine the authenticity of the news. Experiments conducted on a Twitter dataset and demonstrated the effectiveness of the proposed method.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICASSP40776.2020.9054673" target="_blank"> Emet: Embeddings from multilingual-encoder transformer for fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85091305103</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Schwarz S., Theophilo A., Rocha A.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Campinas, CTI Renato Archer</b></td></tr><tr><td colspan="3">In the last few years, social media networks have changed human life experience and behavior as it has broken down communication barriers, allowing ordinary people to actively produce multimedia content on a massive scale. On this wise, the information dissemination in social media platforms becomes increasingly common. However, misinformation is propagated with the same facility and velocity as real news, though it can result in irreversible damage to an individual or society at large. Solving this problem is not a trivial task, considering the reduced size of the text messages usually posted on these communication vehicles. This paper proposes an end-toend framework called EMET to classify the reliability of small messages posted on social media platforms. Our method leverages textembeddings from multilingual-encoder transformers that take into consideration the semantic knowledge from preceding trustworthy news and the use of the reader's reactions to detect misleading content. Our findings demonstrated the value of user interaction and prior information to check social media post's credibility.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICCES48766.2020.09137915" target="_blank"> Natural language processing based online fake news detection challenges - A detailed review<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85091341471</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Hirlekar V.V., Kumar A.</b></td></tr><tr><td colspan="3">Organisations: <b>Sir Padmapat Singhania University</b></td></tr><tr><td colspan="3">Online social media plays an important role during real world events such as natural calamities, election s, social movements etc. S ince the social media usage has increased, fake news has grown. The social media is often used by modifying true news or creating fake news to spread misinformation. The creation and distribution of fake news poses major threats i n several respects from a national security point of view. Hence Fake news identification becomes an essential goal for enhancing the trustworthiness of the information shared on online social network. Over the period of time many researcher has used different methods, algorithms, tools and techniques to identify fake news content from online social networks. The aim of this paper is to review and examine these methodologies, different tools, browser extensions and analyze the degree of output in question. In addition, this paper discuss the general approach of fake news detection as well as taxonomy of feature extraction which plays an important role to achieve maximum accuracy with the help of different Machine Learning and Natural Language Processing algorithms.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-15-5788-0_8" target="_blank"> Text-Convolutional Neural Networks for Fake News Detection in Tweets<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85091341591</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Sinha H., Sakshi, Sharma Y.</b></td></tr><tr><td colspan="3">Organisations: <b>Birla Institute of Technology and Science</b></td></tr><tr><td colspan="3">With the widespread use of online social networking websites, user-generated stories and social network platform have become critical in news propagation. The Web portals are being used to mislead users for political gains. Unreliable information is being shared without any fact-checking. Therefore, there is a dire need for automatic news verification system which can help journalists and the common users from misleading content. In this work, the task is defined as being able to classify a tweet as real or fake. The complexity of natural language constructs along with variegated languages makes this task very challenging. In this work, a deep learning model to learn semantic word embeddings is proposed to handle this complexity. The evaluations on the benchmark dataset (VMU 2015) show that deep learning methods are superior to traditional natural language processing algorithms.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICCSP48568.2020.9182398" target="_blank"> Multi-Model Fake News Detection based on Concatenation of Visual Latent Features<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85091344951</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Tanwar V., Sharma K.</b></td></tr><tr><td colspan="3">Organisations: <b>Delhi Technological University</b></td></tr><tr><td colspan="3">Online Social media for news consumption is a double-edged sword. If we ponder on the positives outcomes for this, it includes easy access, negligible cost, smart categorization and out reach to the very customer in seconds. But, as every coin has two sides and when we flip side of this, a series of issues come up which need immediate attention and most important among them is spreading of fake news. This has become a serious threat for the governments of countries to keep their harmony intact, keep faith of public in democracy and justice and sustenance of public trust. Therefore fake news detection, especially in social media platform has become an emerging research topic that is attracting tremendous attention. Current set of detection algorithms are specially showing their inability to learn the shared representation of texts and visuals combined (popularly known as multimodal) information. Therefore, we present a variational auto encoder based framework, which consists of three major components encoder, decoder and fake news detector. It utilize the concatenation of visual latent features from three popular CNN architecture (VGG19, ResNet50, InceptionV3) combined with textual information to detect fake news with the help of binary classifier. We conducted the experiment on publically available Twitter dataset. The experimental result shows that out model improves state of the art method by the margin of ∼2% in accuracy and ∼3% in F1-score.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Facing the appeal of social networks: Methodologies and tools to support students towards a critical use of the web<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85091456975</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Puvia E., Monteleone V., Fulantelli G., Taibi D.</b></td></tr><tr><td colspan="3">Organisations: <b>Istituto per le Tecnologie Didattiche</b></td></tr><tr><td colspan="3">In the present contribution, we introduce an integrated approach, grounded both on cognitive and computer science, to strengthen the capacity of adolescent students in discerning information on the Web and on social networks. The proposed approach includes methodologies and tools aimed at promoting critical thinking in students. It has been structured in four main operational phases to facilitate implementation and replication, and it is currently tested with 77 high-school students (14−16 years old). Preliminary insights from this pilot study are also presented in this paper. We argue that the integrated approach can be comprised in a more general framework designed to boost competences of reasoning of students, which are crucial in promoting fake news detection and, consequently, in preventing the spreading of on line false information.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Gradual argumentation evaluation for stance aggregation in automated fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85091707283</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Kotonya N., Toni F.</b></td></tr><tr><td colspan="3">Organisations: <b>Imperial College London</b></td></tr><tr><td colspan="3">Stance detection plays a pivot role in fake news detection. The task involves determining the point of view or stance - for or against - a text takes towards a claim. One very important stage in employing stance detection for fake news detection is the aggregation of multiple stance labels from different text sources in order to compute a prediction for the veracity of a claim. Typically, aggregation is treated as a credibility-weighted average of stance predictions. In this work, we take the novel approach of applying, for aggregation, a gradual argumentation semantics to bipolar argumentation frameworks mined using stance detection. Our empirical evaluation shows that our method results in more accurate veracity predictions.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.3233/FAIA200348" target="_blank"> Adaptive interaction fusion networks for fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85091791941</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Wu L., Rao Y.</b></td></tr><tr><td colspan="3">Organisations: <b>Xi'an Jiaotong University</b></td></tr><tr><td colspan="3">The majority of existing methods for fake news detection universally focus on learning and fusing various features for detection. However, the learning of various features is independent, which leads to a lack of cross-interaction fusion between features on social media, especially between posts and comments. Generally, in fake news, there are emotional associations and semantic conflicts between posts and comments. How to represent and fuse the cross-interaction between both is a key challenge. In this paper, we propose Adaptive Interaction Fusion Networks (AIFN) to fulfill cross-interaction fusion among features for fake news detection. In AIFN, to discover semantic conflicts, we design gated adaptive interaction networks (GAIN) to capture adaptively similar semantics and conflicting semantics between posts and comments. To establish feature associations, we devise semantic-level fusion self-attention networks (SFSN) to enhance semantic correlations and fusion among features. Extensive experiments on two real-world datasets, i.e., RumourEval and PHEME, demonstrate that AIFN achieves the state-of-the-art performance and boosts accuracy by more than 2.05% and 1.90%, respectively.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.14569/IJACSA.2020.0110917" target="_blank"> An empirical comparison of fake news detection using different machine learning algorithms<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85091956315</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Albahr A., Albahar M.</b></td></tr><tr><td colspan="3">Organisations: <b>King Saud bin Abdulaziz University for Health Sciences, Umm Al Qura University</b></td></tr><tr><td colspan="3">Relying on social networks to follow the news has its pros and cons. Social media websites indeed allow the spread of information among people quickly. However, such websites might be leveraged to circulate low-quality news full of misinformation, i.e., "fake news. " The wide distribution of fake news has a considerable negative impact on individuals and society as a whole. Thus, detecting fake news published on the various social media websites has lately become an evolving research area that is drawing great attention. Detecting the widespread fake news over the numerous social media platforms presents new challenges that make the currently deployed algorithms ineffective or not applicable anymore. Basically, fake news is deliberately written on the first place to mislead readers to accept false information as being true, which makes it difficult to detect based on news content solely; consequently, auxiliary information, like user social engagements on social media websites, need to be taken into account to help make a better detection. Using such auxiliary information is challenging because users' social engagements with fake news produce noisy, unstructured, and incomplete Big-Data. Due to the fact that fake news detection on social media is fundamental, this research aims at examining four well-known machine learning algorithms, namely the random forest, the Naive Bayes, the neural network, and the decision trees, distinctively to validate the efficiency of the classification performance on detecting fake news. We conducted an experiment on a widely used public dataset i.e. LIAR, and the results show that the Naive Bayes classifier defeats the other algorithms remarkably on this dataset.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/IAICT50021.2020.9172020" target="_blank"> Identifying fake news in indonesian via supervised binary text classification<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85091991212</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Rusli A., Young J.C., Iswari N.M.S.</b></td></tr><tr><td colspan="3">Organisations: <b>Universitas Multimedia Nusantara</b></td></tr><tr><td colspan="3">Fake news detection has gained growing interest from both the industry and research community all around the world, including Indonesia. Based on recent surveys, people could receive fake news daily, if not more than once. The research community and practitioners, supported by the government, are trying to fight back the spreading of fake news. This paper aims to implement a supervised machine learning approach using the Multi-Layer Perceptron (MLP) for classifying news article in order to detect fake news articles and differentiate them from the valid ones, via a binary text classification approach. Furthermore, this paper uses TF-IDF in comparison with the Bag of Words model to extract features along with the use of the n-gram model. Based on the result, our final model could achieve a hoax precision and recall score of 0.84 and 0.73, respectively, and a macro-averaged F1-score of 0.82. Furthermore, our paper shows that some preprocessing methods such as stemming and stop-word removal could be very time-consuming while only barely affecting the performance of our classifier model using the dataset in this research for identifying fake news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s13278-020-00696-x" target="_blank"> Deep learning for misinformation detection on online social networks: a survey and new perspectives<a></b></td></tr><tr><td>Type: Review</td><td>ID: S_2-s2.0-85091992323</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Islam M.R., Liu S., Xu G., Wang X.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Technology Sydney (UTS)</b></td></tr><tr><td colspan="3">Recently, the use of social networks such as Facebook, Twitter, and Sina Weibo has become an inseparable part of our daily lives. It is considered as a convenient platform for users to share personal messages, pictures, and videos. However, while people enjoy social networks, many deceptive activities such as fake news or rumors can mislead users into believing misinformation. Besides, spreading the massive amount of misinformation in social networks has become a global risk. Therefore, misinformation detection (MID) in social networks has gained a great deal of attention and is considered an emerging area of research interest. We find that several studies related to MID have been studied to new research problems and techniques. While important, however, the automated detection of misinformation is difficult to accomplish as it requires the advanced model to understand how related or unrelated the reported information is when compared to real information. The existing studies have mainly focused on three broad categories of misinformation: false information, fake news, and rumor detection. Therefore, related to the previous issues, we present a comprehensive survey of automated misinformation detection on (i) false information, (ii) rumors, (iii) spam, (iv) fake news, and (v) disinformation. We provide a state-of-the-art review on MID where deep learning (DL) is used to automatically process data and create patterns to make decisions not only to extract global features but also to achieve better results. We further show that DL is an effective and scalable technique for the state-of-the-art MID. Finally, we suggest several open issues that currently limit real-world implementation and point to future directions along this dimension.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Leveraging machine learning for fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85091994488</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Masciari E., Moscato V., Picariello A., Sperli G.</b></td></tr><tr><td colspan="3">Organisations: <b>University Federico II</b></td></tr><tr><td colspan="3">The uncontrolled growth of fake news creation and dissemination we observed in recent years causes continuous threats to democracy, justice, and public trust. This problem has significantly driven the effort of both academia and industries for developing more accurate fake news detection strategies. Early detection of fake news is crucial, however the availability of information about news propagation is limited. Moreover, it has been shown that people tend to believe more fake news due to their features (Vosoughi et al., 2018). In this paper, we present our complete framework for fake news detection and we discuss in detail a solution based on machine learning. Our experiments conducted on two well-known and widely used real-world datasets suggest that our settings can outperform the state-of-the-art approaches and allows fake news accurate detection, even in the case of limited content information.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICIRCA48905.2020.9183072" target="_blank"> Performance Comparison of Machine Learning Classifiers for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85092036885</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Smitha N., Bharath R.</b></td></tr><tr><td colspan="3">Organisations: <b>CMR Institute of Technology</b></td></tr><tr><td colspan="3">Information sharing on the web particularly via web-based networking media is increasing. Ability to identify, evaluate and address such information is significantly important. Fake information deliberately created is purposefully or unintentionally engendered over the internet. This is affecting a larger group of society who are blinded by technology. This paper illustrates model and methodology to detect fake news from news article with the assistance of Machine learning and Natural language processing. In this proposed work different feature engineering methods like count vector, TF-IDF and word embedding are used to generate feature vector. Seven different Machine learning Classification algorithms are trained to classify news as fake or real and are compared considering accuracy, F1 Score, recall, precision and best one is selected to build a model to classify news as fake or real.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/CEC48606.2020.9185643" target="_blank"> Multimodal fake news detection using a Cultural Algorithm with situational and normative knowledge<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85092053981</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Shah P., Kobti Z.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Windsor</b></td></tr><tr><td colspan="3">The proliferation of fake news on social media sites is a serious problem with documented negative impacts on individuals and organizations. A fake news item is usually created by manipulating photos, text, or videos that indicate the need for multimodal detection. Researchers are building detection algorithms with an aim for high accuracy as this will have a massive impact on the prevailing social and political issues. A shortcoming of existing strategies for identifying fake news is their inability to learn a feature representation of multimodal (textual+visual) information. In this paper, we present a novel approach using a Cultural Algorithm with situational and normative knowledge to detect fake news using both text and images. An extensive set of experiments have been carried out on real-world multimedia datasets collected from Weibo and Twitter. The proposed method outperforms the state-of-the-art methods for identifying fake news in terms of accuracy by 9% on average.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.eswa.2020.114090" target="_blank"> SemSeq4FD: Integrating global semantic relationship and local sequential order to enhance text representation for fake news detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85092102039</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Wang Y., Wang L., Yang Y., Lian T.</b></td></tr><tr><td colspan="3">Organisations: <b>Taiyuan University of Technology</b></td></tr><tr><td colspan="3">The wide spread of fake news has caused huge losses to both governments and the public. Many existing works on fake news detection utilized spreading information like propagators profiles and the propagation structure. However, such methods face the difficulty of data collection and cannot detect fake news at the early stage. An alternative approach is to detect fake news solely based on its content. Early content-based methods rely on manually designed linguistic features. Such shallow features are domain-dependent, and cannot easily be generalized to cross-domain data. Recently, many natural language processing tasks resort to deep learning methods to learn word, sentence, and document representations. In this paper, we propose a novel graph-based neural network model named SemSeq4FD for early fake news detection based on enhanced text representations. In SemSeq4FD, we model the global pair-wise semantic relations between sentences as a complete graph, and learn the global sentence representations via a graph convolutional network with self-attention mechanism. Considering the importance of local context in conveying the sentence meaning, we employ a 1D convolutional network to learn the local sentence representations. The two representations are combined to form the enhanced sentence representations. Then a LSTM-based network is used to model the sequence of enhanced sentence representations, yielding the final document representation for fake news detection. Experiments conducted on four real-world datasets in English and Chinese, including cross-source and cross-domain datasets, demonstrate that our model can outperform the state-of-the-art methods.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-15-7345-3_13" target="_blank"> Fake news detection using passive-aggressive classifier<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85092108172</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Gupta S., Meel P.</b></td></tr><tr><td colspan="3">Organisations: <b>Delhi Technological University</b></td></tr><tr><td colspan="3">People can get infected with fake news very quickly with misleading words and images and post them without any fact-checking. The social media life has been used to distribute counterfeit data, which has a significant negative influence on individual consumers and on a wider community. The fake news problem is tackled using a machine learning algorithm. Different classifiers are used for the purpose of identifying fake news. In this paper, Passive-Aggressive Classifier is implemented for this purpose. The approach is implemented on two datasets of fake and real news. After performing the experiment, it is observed that Passive-Aggressive Classifier provides an accuracy of 97.5%. The performance of the proposed model is compared with the existing methods. The Passive-Aggressive Classifier provides the best result compared to others.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-59491-6_11" target="_blank"> A Deep Learning Approach to Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85092110640</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Masciari E., Moscato V., Picariello A., Sperli G.</b></td></tr><tr><td colspan="3">Organisations: <b>University Federico II of Naples</b></td></tr><tr><td colspan="3">The uncontrolled growth of fake news creation and dissemination we observed in recent years causes continuous threats to democracy, justice, and public trust. This problem has significantly driven the effort of both academia and industries for developing more accurate fake news detection strategies. Early detection of fake news is crucial, however the availability of information about news propagation is limited. Moreover, it has been shown that people tend to believe more fake news due to their features[11]. In this paper, we present our framework for fake news detection and we discuss in detail a solution based on deep learning methodologies we implemented by leveraging Google Bert features. Our experiments conducted on two well-known and widely used real-world datasets suggest that our method can outperform the state-of-the-art approaches and allows fake news accurate detection, even in the case of limited content information.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-60152-2_35" target="_blank"> The influence of traits associated with autism spectrum disorder (asd) on the detection of fake news<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85092190372</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Taylor-Jackson J., Matthews S.</b></td></tr><tr><td colspan="3">Organisations: <b>Western Sydney University, Bournemouth University</b></td></tr><tr><td colspan="3">It has been suggested that neuro-diverse individuals may be particularly good at detecting online deception (Pick 2019). A small-scale exploratory study was conducted to investigate whether individuals with traits associated with Autism Spectrum Disorder (ASD) were more or less accurate in spotting different types of fake news. A non-clinical sample of university students completed an online identification task, where both fake and real articles items were manipulated in terms of their emotive content. When individuals with low and high scores on the Autism-Spectrum Quotient (Baron-Cohen et al. 2001) were compared, there were no significant main effects on detection accuracy. However, there were two significant interactions, indicating an interesting relationship between message emotiveness, ASD and fake news detection. The results contribute to an understanding of how psychological differences, in particular ASD, may affect online judgements and will contribute to a developing body of work relating positive skills of neuro-diverse individuals to the cybersecurity industry.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3404555.3404607" target="_blank"> BERT-Based Mental Model, a Better Fake News Detector<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85092226351</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Ding J., Chang H., Hu Y.</b></td></tr><tr><td colspan="3">Organisations: <b>Sun Yat-sen University, Guangzhou University</b></td></tr><tr><td colspan="3">Automatic fake news detection is a challenging problem which needs a number of verifiable facts support back. Wang et al. [16] introduced LIAR, a validated dataset, and presented a six classes classification task with several popular machine learning methods to detect fake news in linguistic level. However, empirical results have shown that the CNN and RNN based model can not perform very well especially when integrating all features with claim. In this paper, we are the first to present a method to build up a BERT-based [4] mental model to capture the mental feature in fake news detection. In details, we present a method to construct a patterned text in linguistic level to integrate the claim and features appropriately. Then we fine-tune the BERT model with all features integrated text. Empirical results show that our method provides significant improvement over the state-of-art model based on the LIAR dataset we have known by 16.71% in accuracy.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> ITcg's participation at mex-a3t 2020: Aggressive identification and fake news detection based on textual features for mexican Spanish<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85092239723</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Zaizar-Gutierrez D., Fajardo-Delgado D., Alvarez-Carmona M.A.</b></td></tr><tr><td colspan="3">Organisations: <b>Tecnológico Nacional de México/, Educación Superior de Ensenada (CICESE), Consejo Nacional de Ciencia y Tecnologiá (CONACYT)</b></td></tr><tr><td colspan="3">This paper explains our approach to Aggressiveness Identification and Fake News Classification in the 2020 MEX-A3T shared task. The tasks propose a binary classification for both tasks (aggressive and nonaggressive or fake news and non-fake news). We approached the problem using simple basic methods of features selection and terms weighing. We trained with a set of machine learning algorithms. Our best run for aggressiveness identification achieved an accuracy of 0.81, where the best result obtained 0.88. On the other hand, for the aggressiveness identification, our accuracy result was 0.78, where the best result was 0.85.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Overview of mex-a3t at iberlef 2020: Fake news and aggressiveness analysis in mexican Spanish<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85092258901</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Aragon M.E., Jarquin-Vasqueza H., Montes-Y-Gomez M., Escalante H.J., Villasenor-Pineda L., Gomez-Adorno H., Bel-Enguix G., Posadas-Duran J.-P.</b></td></tr><tr><td colspan="3">Organisations: <b>Laboratorio de Tecnologiás Del Lenguaje (INAOE), Université d'Artois, Instituto de Investigaciones en Matemáticas Aplicadas y en Sistemas (UNAM), Instituto de Ingenieriá (UNAM), Escuela Superior de Ingenieriá Mecánica y Eléctrica</b></td></tr><tr><td colspan="3">This paper presents the overview of MEX-A3T 2020, the third edition of this lab under the IberLEF conference. The main purpose of MEX-A3T is to explore different methodologies and strategies related to the analysis of social media content in Mexican Spanish. This year edition focuses in the identification of fake news and the detection of aggressive tweets. For this purpose, we provided different news from verified web sources and a corpus of tweets from Mexican users.v.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/INES49302.2020.9147195" target="_blank"> Fake News Detection with Generated Comments for News Articles<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85092669191</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Yanagi Y., Orihara R., Sei Y., Tahara Y., Ohsuga A.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Electro-Communications</b></td></tr><tr><td colspan="3">Recently, fake news is shared via social networks and makes wrong rumors more diffusible. This problem is serious because the wrong rumor sometimes make social damage by deceived people. Fact-checking is a solution to measure the credibility of news articles. However the process usually takes a long time and it is hard to make it before their diffusion. Automatic detection of fake news is a popular researching topic. It is confirmed that considering not only articles but also social contexts(i.e. likes, retweets, replies, comments) supports to spot fake news correctly. However, the social contexts are naturally unavailable when an article comes out, making early fake news detection by means of the social context useless. We propose a fake news detector with the ability to generate fake social contexts, aiming to detect fake news in the early stage of its diffusion where few social contexts are available. The fake context generation is based on a fake news generator model. This model is trained to generate comments using a dataset which consists of news articles and their social contexts. In addition, we also trained a classify model. This used news articles, real-posted comments, and generated comments. To measure our detector's effectiveness, we examined the performance of the generated comments for articles with real comments and generated ones by the classifying model. As a result, we conclude that considering a generated comment help detect more fake news than considering real comments only. It suggests that our proposed detector will be effective to spot fake news on social networks.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/IS48319.2020.9199931" target="_blank"> Bengali Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85092694758</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Islam F., Alam M.M., Shahadat Hossain S.M., Motaleb A., Yeasmin S., Hasan M., Rahman R.M.</b></td></tr><tr><td colspan="3">Organisations: <b>North South University</b></td></tr><tr><td colspan="3">Yellow journalism has become a buzzword for everyone nowadays. Increasing use of internet and social media makes people more vulnerable to fake news. To gain popularity and to have profit through clickbait news publisher and social media circulate fake news to deceive people by creating interesting content of a specific topic. The spread of falsified news has become severe in recent times throughout the world. Though recently some existing system is made to classify and to detect fake news for English news article, not much work has been reported for Bengali news. In this work, we consider Bengali fake news classification considering South Asian Context. More than 200 million people speak Bengali and their way of communication is Bengali. In our Bengali fake news classification system, data mining algorithm is used to classify fake and real news. We have also introduced web interface based on our classifier to check whether a news article written in Bengali language fake or real. The classification model has 85% accuracy with random forest classifier.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ISSC49989.2020.9180206" target="_blank"> Not Everything You Read Is True! Fake News Detection using Machine learning Algorithms<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85092705939</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Tiwari V., Lennon R.G., Dowling T.</b></td></tr><tr><td colspan="3">Organisations: <b>Letterkenny Institute of Technology</b></td></tr><tr><td colspan="3">This paper considers establishing if a news article is true or if it has been faked. To achieve the task accurately, the work compares different machine learning classification algorithm with the different feature extraction methods. The algorithm with the feature extraction method giving the highest accuracy is then used for future prediction of the labels of news headlines. In this work the algorithm show to have the highest accuracy was logistic regression with 71% percent accuracy when used with tf-idf feature extraction method.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICRITO48877.2020.9197817" target="_blank"> Fake News Detection with Integration of Embedded Text Cues and Image Features<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85093090405</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Mangal D., Sharma D.K.</b></td></tr><tr><td colspan="3">Organisations: <b>GLA University</b></td></tr><tr><td colspan="3">A novel approach using Convolution neural Network (CNN) and Long short-term memory (LSTM) has been proposed to find the reliability of the news. In this research, image visual feature with embedded text feature and headline texts have been considered to find the comprehensive results. First the semantic information from the images have been captured as text (news tag line) and this tag has been compared to the original headline text. Individually image and text both are insufficient to find the semantic knowledge of publish news. So, the cosine similarity index (CSI) has been used to predict the reliability of the news. The threshold of CSI has been constrained greater than 0.62 for the news real. A repository has been created named as' imaged fake news'. In this repository 1000 images have been considered with the headline texts, where 367 news were fake and 633 news were real. The accuracy of the proposed method is 91.07%. The result implies that the novel methodology is better than the state-of-the-art method.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/CONECCT50063.2020.9198610" target="_blank"> Identification of Fake News Using Machine Learning<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85093093444</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Mandical R.R., Mamatha N., Shivakumar N., Monica R., Krishna A.N.</b></td></tr><tr><td colspan="3">Organisations: <b>Sjb Institution of Technology</b></td></tr><tr><td colspan="3">Fake news has been a problem ever since the internet boomed. The very network that allows us to know what is happening globally is the perfect breeding ground for malicious and fake news. Combating this fake news is important because the world's view is shaped by information. People not only make important decisions based on information but also form their own opinions. If this information is false it can have devastating consequences. Verifying each news one by one by a human being is completely unfeasible. This paper attempts to expedite the process of identification of fake news by proposing a system that can reliably classify fake news. Machine Learning algorithms such as Naive Bayes, Passive Aggressive Classifier and Deep Neural Networks have being used on eight different datasets acquired from various sources. The paper also includes the analysis and results of each model. The arduous task of detection of fake news can be made trivial with the usage of the right models with the right tools.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICRITO48877.2020.9197914" target="_blank"> S-HAN: Hierarchical Attention Networks with Stacked Gated Recurrent Unit for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85093113864</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Ahuja N., Kumar S.</b></td></tr><tr><td colspan="3">Organisations: <b>Delhi Technological University</b></td></tr><tr><td colspan="3">Social Media has become an inseparable part of our daily lives. With the boon that it is, it also brings along with itself the biggest menace i.e. fake news. Encountering fake news while accessing social media has become a recurrent phenomenon nowadays. This problem is grabbing attention all over the world as it is becoming a threat to the society. It is leading to violence all over the world. We aim to create a model S-HAN to identify the fake news. Our model uses an improved version of Hierarchical Attention Networks using stacked bidirectional Gated Recurrent Units (GRU) to identify the important words and sentences in the news which assists in the identification of misinformation. We have obtained better results compared to the standard baseline models of deep learning. We have obtained an accuracy of 93.63% for our model on a real-world dataset.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.procs.2020.08.009" target="_blank"> An interpretable model to measure fakeness and emotion in news<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85093358445</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Gadek G., Guelorget P.</b></td></tr><tr><td colspan="3">Organisations: <b>_, Institut Polytechnique de Paris</b></td></tr><tr><td colspan="3">Fake news and post-truth are everywhere. The huge number of online news outlets and the frequency of content creation underlines the demand for automatic information evaluation tools. Previous work usually focuses either on automatic fact-checking, or on fake-looking identification: the former tries to match a piece of content with trustable information, enough to confirm or infirm the claims. The latter gathers clues to help the reader's assessment of the piece of content. In this domain, there is no silver bullet: the reader desires verifiable information, thus the fake news detector should be interpretable or explainable. In this article, we propose TC-CNN: an interpretable text classifier. We use it on two tasks: fake news detection and emotion classification. A second contribution relies on these two classifiers, and on a third-party hate detector, to perform a case study on this year real and fake-news press articles, in a comparison between mainstream and alt-right media.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICACCE49060.2020.9154997" target="_blank"> Fake News Detection on Social Media using K-Nearest Neighbor Classifier<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85093668212</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Kesarwani A., Chauhan S.S., Nair A.R.</b></td></tr><tr><td colspan="3">Organisations: <b>School of VLSI and ESD, Toshiba Software Pvt. Limited</b></td></tr><tr><td colspan="3">Consumption of news from social media is gradually increasing because of it's easy to access, cheap and more attractive and it's capable to spread the 'fake news'. The widespread of fake news has latent adverse impressions on people and culture. Some people spread wrong information on social media to get the attention or financial and political gain. We need to be smarter at the recognition of fake or real news. The unique feature of detecting fake news on social media that make current detection algorithms ine □ ective or not appropriate. Thereafter is essential to consider secondary information. Secondary information may include social activities of user on social media. So, in this research work we are presenting a simple approach for detecting fake news on social media with the help of K-Nearest Neighbor classifier. We achieved a classification accuracy of this model approximate 79% tested against Facebook news posts dataset.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/IJCNN48605.2020.9207477" target="_blank"> A Deep Transfer Learning Approach for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85093838969</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Saikh T., Ekbal A., Bhattacharyya P., Haripriya B.</b></td></tr><tr><td colspan="3">Organisations: <b>Indian Institute of Technology Patna, Indian Institute of Information Technology Senapati</b></td></tr><tr><td colspan="3">Fake or incorrect or miss-information detection has nowadays attracted attention to the researchers and developers because of the huge information overloaded in the web. This problem can be considered as equivalent to lie detection, truthfulness identification or stance detection. In our particular work, we focus on deciding whether the title of a news is consistent with its body text- a problem equivalent to fake information identification. In this paper, we propose a deep transfer learning approach where the problem of detecting title-body consistency is posed from the viewpoint of Textual Entailment (TE) where the title is considered as a hypothesis and news body is treated as a premise. The idea is to decide whether the body infers the title or not. Evaluation on the existing benchmark datasets, namely Fake News Challenge (FNC) dataset (released in Fake News Challenge Stage 1 (FNC-I): Stance Detection) show the efficacy of our proposed approach in comparison to the state-of-the-art systems.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/IJCNN48605.2020.9207498" target="_blank"> Fake News Detection from Data Streams<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85093847506</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Ksieniewicz P., Zyblewski P., Wozniak M., Choras M., Kozik R., Gielczyk A.</b></td></tr><tr><td colspan="3">Organisations: <b>Wroclaw Univ.of Science and Technology, UTP Univ.of Science and Technology</b></td></tr><tr><td colspan="3">Using fake news as a political or economic tool is not new, but the scale of their use is currently alarming, especially on social media. The authors of misinformation try to influence the users' decisions, both in the economic and political sphere. The facts of using disinformation during elections are well known. Currently, two fake news detection approaches dominate. The first approach, so-called fact or news checker, is based on the knowledge and work of volunteers, the second approach employs artificial intelligence algorithms for news analysis and manipulation detection. In this work, we will focus on using machine learning methods to detect fake news. However, unlike most approaches, we will treat incoming messages as stream data, taking into account the possibility of concept drift occurring, i.e., appearing changes in the probabilistic characteristics of the classification model during the exploitation of the classifier. The developed methods have been evaluated based on computer experiments on benchmark data, and the obtained results prove their usefulness for the problem under consideration. The proposed solutions are part of the distributed platform developed by the H2020 SocialTruth project consortium.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/IJCNN48605.2020.9206973" target="_blank"> BDANN: BERT-Based Domain Adaptation Neural Network for Multi-Modal Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85093848346</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Zhang T., Zeng Z., Guo W., Miao C., Cui L., Wang D., Chen H.</b></td></tr><tr><td colspan="3">Organisations: <b>Shandong University, Nanyang Technological University, University of Science and Technology of China</b></td></tr><tr><td colspan="3">Nowadays, with the rapid growth of microblogging networks for news propagation, there are increasingly more people accessing news through such emerging social media. In the meantime, fake news now spreads at a faster pace and affects a larger population than ever before. Compared with traditional text news, the news posted on microblog often has attached images in the context. So how to correctly and autonomously detect fakes news in a multi-modal manner becomes a prominent challenge to be addressed. In this paper, we propose an end-to-end model, named BERT-based domain adaptation neural network for multi-modal fake news detection (BDANN). BDANN comprises three main modules: a multi-modal feature extractor, a domain classifier and a fake news detector. Specifically, the multi-modal feature extractor employs the pretrained BERT model to extract text features and the pretrained VGG-19 model to extract image features. The extracted features are then concatenated and fed to the detector to distinguish fake news. The role of the domain classifier is mainly to map the multi-modal features of different events to the same feature space. To assess the performance of BDANN, we conduct extensive experiments on two multimedia datasets: Twitter and Weibo. The experimental results show that BDANN outperforms the state-of-the-art models. Moreover, we further discuss the existence of noisy images in the Weibo dataset that may affect the results.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/IJCNN48605.2020.9207406" target="_blank"> IARNet: An Information Aggregating and Reasoning Network over Heterogeneous Graph for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85093860719</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Yu J., Huang Q., Zhou X., Sha Y.</b></td></tr><tr><td colspan="3">Organisations: <b>Chinese Academy of Sciences, University of Chinese Academy of Sciences, Huazhong Agricultural University</b></td></tr><tr><td colspan="3">Fake News Detection on social network is still a challenging task that requires to integrate different types of information, e.g., source post, comments, and related users to verify the given news. However, previous solutions extract features from different aspects respectively, ignore the inherent relational and logical information among these features. In this paper, we propose IARNet, an Information Aggregating and Reasoning Network over heterogeneous graph for fake news detection, which exploits the interaction between information to aggregate multi-type information and grasps the inherent relationship simultaneously. Firstly, we construct a heterogeneous graph which takes source post, comments, and users as nodes and the interaction between them as edges. Then, a two-level attention mechanism is applied at the node level and type level. Specifically, the node-level attention aims to learn the importance between a node and its specific edge based neighbors, while the type-level attention aims to learn the importance of different types of edges. With the two-level attention mechanism, IARNet can aggregate multi-type information in a hierarchical manner and the information can reason over heterogeneous graph for the facticity of the news. Experimental result shows that our method outperforms the state-of-the-art competitors on real-world datasets with GloVe embeddings. We also demonstrate that using BERT representations further substantially boosts the performance. Our code is available at https://github.com/serryuer/IARNet.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/COMPSAC48688.2020.00-83" target="_blank"> Data Analytics for the COVID-19 Epidemic<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85094149840</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Wang R., Hu G., Jiang C., Lu H., Zhang Y.</b></td></tr><tr><td colspan="3">Organisations: <b>Zhongnan University of Economics and Law</b></td></tr><tr><td colspan="3">With the spread of COVID-19 worldwide, people¡¯s production and life have been significantly affected. Artificial intelligence and big data technologies have been vigorously developed in recent years. It is very significant to use data science and technology to help humans in a timely and accurate manner to prevent and control the development of the epidemic, maintain social stability and assess the impact of the epidemic. This paper explores how data science can play a role from the perspectives of epidemiology, social networking, and economics. In particular, for the existing epidemic model SIR, we present a parameter learning method using particle swarm optimization (PSO) and the least squares method, and use it to predict the trend of the epidemic. Aiming at the social network data, we provide a specific method to realize sentiment analysis during the epidemic and propose an explainable fake news detection technique based on a variety of data mining methods.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3395046" target="_blank"> A Survey of Fake News: Fundamental Theories, Detection Methods, and Opportunities<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85094319226</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Zhou X., Zafarani R.</b></td></tr><tr><td colspan="3">Organisations: <b>Syracuse University</b></td></tr><tr><td colspan="3">The explosive growth in fake news and its erosion to democracy, justice, and public trust has increased the demand for fake news detection and intervention. This survey reviews and evaluates methods that can detect fake news from four perspectives: the false knowledge it carries, its writing style, its propagation patterns, and the credibility of its source. The survey also highlights some potential research tasks based on the review. In particular, we identify and detail related fundamental theories across various disciplines to encourage interdisciplinary research on fake news. It is our hope that this survey can facilitate collaborative efforts among experts in computer and information sciences, social sciences, political science, and journalism to research fake news, where such efforts can lead to fake news detection that is not only efficient but, more importantly, explainable.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.ipm.2020.102418" target="_blank"> Convolutional neural network with margin loss for fake news detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85094324354</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Goldani M.H., Safabakhsh R., Momtazi S.</b></td></tr><tr><td colspan="3">Organisations: <b>Amirkabir University of Technology</b></td></tr><tr><td colspan="3">The advent of online news platforms such as social media, news blogs, and online newspapers in recent years and their facilitated features such as swift information flow, easy access, and low costs encourage people to seek and raise their information by consuming their provided news. Furthermore, these platforms increase the opportunities for deceiver parties to influence public opinion and awareness by producing fake news, i.e., the news which consists of false and deceptive information and is published for achieving specific political and economic gains. Since the discerning of fake news through their contents by individuals is very difficult, the existence of an automatic fake news detection approach for preventing the spread of such false information is mandatory. In this paper, Convolutional Neural Networks (CNN) with margin loss and different embedding models proposed for detecting fake news. We compare static word embeddings with the non-static embeddings that provide the possibility of incrementally up-training and updating word embedding in the training phase. Our proposed architectures are evaluated on two recent well-known datasets in the field, namely ISOT and LIAR. Our results on the best architecture show encouraging performance, outperforming the state-of-the-art methods by 7.9% on ISOT and 2.1% on the test set of the LIAR dataset.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ACCTHPA49271.2020.9213234" target="_blank"> Web Text Content Credibility Analysis using Max Voting and Stacking Ensemble Classifiers<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85094601351</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Meel P., Chawla P., Jain S., Rai U.</b></td></tr><tr><td colspan="3">Organisations: <b>Delhi Technological University</b></td></tr><tr><td colspan="3">The social media has become a great medium for people around the world to openly express their thoughts and views. But for all its advantages, it has also paved way for many people and organizations to intentionally spread fake news and misinform others. And the rate at which fake news is being currently generated, it has become critical to create a reliable mechanism that can efficiently classify a real news from a fake one. This research paper analyses the different approaches, involving ensemble learning, that can be used to accomplish the same by using only text features of the news data. We observe that a combination of three optimal ML algorithms, clubbed by an advanced ensemble learning technique, can give results with an accuracy of more than ninety eight percent.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s11063-020-10365-x" target="_blank"> Integrating Machine Learning Techniques in Semantic Fake News Detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85094674835</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Brasoveanu A.M.P., Andonie R.</b></td></tr><tr><td colspan="3">Organisations: <b>MODUL Technology GmbH, Central Washington University, Transilvania University of Braşov</b></td></tr><tr><td colspan="3">The nuances of languages, as well as the varying degrees of truth observed in news items, make fake news detection a difficult problem to solve. A news item is never launched without a purpose, therefore in order to understand its motivation it is best to analyze the relations between the speaker and its subject, as well as different credibility metrics. Inferring details about the various actors involved in a news item is a problem that requires a hybrid approach that mixes machine learning, semantics and natural language processing. This article discusses a semantic fake news detection method built around relational features like sentiment, entities or facts extracted directly from text. Our experiments are focused on short texts with different degrees of truth and show that adding semantic features improves accuracy significantly.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.3390/sym12111806" target="_blank"> Rumor detection on social media via fused semantic information and a propagation heterogeneous graph<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85094830494</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Ke Z., Li Z., Sheng J., Zhou C., Silamu W., Guo Q.</b></td></tr><tr><td colspan="3">Organisations: <b>Xinjiang University, Shukutoku Japanese Language School, China Academy of Electronics and Information Technology</b></td></tr><tr><td colspan="3">Social media had a revolutionary impact because it provides an ideal platform for share information; however, it also leads to the publication and spreading of rumors. Existing rumor detection methods have relied on finding cues from only user-generated content, user profiles, or the structures of wide propagation. However, the previous works have ignored the organic combination of wide dispersion structures in rumor detection and text semantics. To this end, we propose KZWANG, a framework for rumor detection that provides sufficient domain knowledge to classify rumors accurately, and semantic information and a propagation heterogeneous graph are symmetry fused together. We utilize an attention mechanism to learn a semantic representation of text and introduce a GCN to capture the global and local relationships among all the source microblogs, reposts, and users. An organic combination of text semantics and propagating heterogeneous graphs is then used to train a rumor detection classifier. Experiments on Sina Weibo, Twitter15, and Twitter16 rumor detection datasets demonstrate the proposed model’s superiority over baseline methods. We also conduct an ablation study to understand the relative contributions of the various aspects of the method we proposed.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> GCAN: Graph-aware co-attention networks for explainable fake news detection on social media<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85094849487</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Lu Y.-J., Li C.-T.</b></td></tr><tr><td colspan="3">Organisations: <b>National Cheng Kung University</b></td></tr><tr><td colspan="3">This paper solves the fake news detection problem under a more realistic scenario on social media. Given the source short-text tweet and the corresponding sequence of retweet users without text comments, we aim at predicting whether the source tweet is fake or not, and generating explanation by highlighting the evidences on suspicious retweeters and the words they concern. We develop a novel neural network-based model, Graph-aware Co-Attention Networks (GCAN), to achieve the goal. Extensive experiments conducted on real tweet datasets exhibit that GCAN can significantly outperform state-of-the-art methods by 16% in accuracy on average. In addition, the case studies also show that GCAN can produce reasonable explanations.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1155/2020/8885861" target="_blank"> Fake News Detection Using Machine Learning Ensemble Methods<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85094856426</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Ahmad I., Yousaf M., Yousaf S., Ahmad M.O.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Engineering and Technology, Karlstad University</b></td></tr><tr><td colspan="3">The advent of the World Wide Web and the rapid adoption of social media platforms (such as Facebook and Twitter) paved the way for information dissemination that has never been witnessed in the human history before. With the current usage of social media platforms, consumers are creating and sharing more information than ever before, some of which are misleading with no relevance to reality. Automated classification of a text article as misinformation or disinformation is a challenging task. Even an expert in a particular domain has to explore multiple aspects before giving a verdict on the truthfulness of an article. In this work, we propose to use machine learning ensemble approach for automated classification of news articles. Our study explores different textual properties that can be used to distinguish fake contents from real. By using those properties, we train a combination of different machine learning algorithms using various ensemble methods and evaluate their performance on 4 real world datasets. Experimental evaluation confirms the superior performance of our proposed ensemble learner approach in comparison to individual learners.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3422841.3423536" target="_blank"> Balancing Fairness and Accuracy in Sentiment Detection using Multiple Black Box Models<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85095406396</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Almuzaini A.A., Singh V.K.</b></td></tr><tr><td colspan="3">Organisations: <b>Rutgers University</b></td></tr><tr><td colspan="3">Sentiment detection is an important building block for multiple information retrieval tasks such as product recommendation, cyberbullying, fake news and misinformation detection. Unsurprisingly, multiple commercial APIs, each with different levels of accuracy and fairness, are now publicly available for sentiment detection. Users can easily incorporate these APIs in their applications. While combining inputs from multiple modalities or black-box models for increasing accuracy is commonly studied in multimedia computing literature, there has been little work on combining different modalities for increasingfairness of the resulting decision. In this work, we audit multiple commercial sentiment detection APIs for the gender bias in two-Actor news headlines settings and report on the level of bias observed. Next, we propose a "Flexible Fair Regression"approach, which ensures satisfactory accuracy and fairness by jointly learning from multiple black-box models. The results pave way for fair yet accurate sentiment detectors for multiple applications.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3340531.3412046" target="_blank"> FANG: Leveraging Social Context for Fake News Detection Using Graph Representation<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85095486253</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Nguyen V.-H., Kan M.-Y., Sugiyama K., Nakov P.</b></td></tr><tr><td colspan="3">Organisations: <b>National University of Singapore, Kyoto University, Qatar Computing Research Institute</b></td></tr><tr><td colspan="3">We propose Factual News Graph (FANG), a novel graphical social context representation and learning framework for fake news detection. Unlike previous contextual models that have targeted performance, our focus is on representation learning. Compared to transductive models, FANG is scalable in training as it does not have to maintain all nodes, and it is efficient at inference time, without the need to re-process the entire graph. Our experimental results show that FANG is better at capturing the social context into a high fidelity representation, compared to recent graphical and non-graphical models. In particular, FANG yields significant improvements for the task of fake news detection, and it is robust in the case of limited training data. We further demonstrate that the representations learned by FANG generalize to related tasks, such as predicting the factuality of reporting of a news medium.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> SpotFake+: A multimodal framework for fake news detection via transfer learning (student abstract)<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85095489730</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Singhal S., Sharma M., Shah R.R., Chakraborty T., Kumaraguru P., Kabra A.</b></td></tr><tr><td colspan="3">Organisations: <b>IIIT-Delhi, DTU</b></td></tr><tr><td colspan="3">In recent years, there has been a substantial rise in the consumption of news via online platforms. The ease of publication and lack of editorial rigour in some of these platforms have further led to the proliferation of fake news. In this paper, we study the problem of detecting fake news on the FakeNewsNet repository, a collection of full length articles along with associated images. We present SpotFake+, a multimodal approach that leverages transfer learning to capture semantic and contextual information from the news articles and its associated images and achieves the better accuracy for fake news detection. To the best of our knowledge, this is the first work that performs a multimodal approach for fake news detection on a dataset that consists of full length articles. It outperforms the performance shown by both single modality and multiple-modality models. We also release the pretrained model for the benefit of the community.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Ginger cannot cure cancer: Battling fake health news with a comprehensive data repository<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85095507029</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Dai E., Sun Y., Wang S.</b></td></tr><tr><td colspan="3">Organisations: <b>The Pennsylvania State University</b></td></tr><tr><td colspan="3">Nowadays, Internet is a primary source of attaining health information. Massive fake health news which is spreading over the Internet, has become a severe threat to public health. Numerous studies and research works have been done in fake news detection domain, however, few of them are designed to cope with the challenges in health news. For instance, the development of explainable is required for fake health news detection. To mitigate these problems, we construct a comprehensive repository, FakeHealth, which includes news contents with rich features, news reviews with detailed explanations, social engagements and a user-user social network. Moreover, exploratory analyses are conducted to understand the characteristics of the datasets, analyze useful patterns and validate the quality of the datasets for health fake news detection. We also discuss the novel and potential future research directions for the health fake news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Hierarchical propagation networks for fake news detection: Investigation and exploitation<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85095526090</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Shu K., Mahudeswaran D., Liu H., Wang S.</b></td></tr><tr><td colspan="3">Organisations: <b>Arizona State University, Penn State University</b></td></tr><tr><td colspan="3">Consuming news from social media is becoming increasingly popular. However, social media also enables the wide dissemination of fake news. Because of the detrimental effects of fake news, fake news detection has attracted increasing attention. However, the performance of detecting fake news only from news content is generally limited as fake news pieces are written to mimic true news. In the real world, news pieces spread through propagation networks on social media. The news propagation networks usually involve multi-levels. In this paper, we study the challenging problem of investigating and exploiting news hierarchical propagation network on social media for fake news detection. In an attempt to understand the correlations between news propagation networks and fake news, first, we build hierarchical propagation networks for fake news and true news pieces; second, we perform a comparative analysis of the propagation network features from structural, temporal, and linguistic perspectives between fake and real news, which demonstrates the potential of utilizing these features to detect fake news; third, we show the effectiveness of these propagation network features for fake news detection. We further validate the effectiveness of these features from feature importance analysis. We conduct extensive experiments on real-world datasets and demonstrate the proposed features can significantly outperform state-of-the-art fake news detection methods by at least 1.7% with an average F1>0.84. Altogether, this work presents a data-driven view of hierarchical propagation network and fake news and paves the way towards a healthier online news ecosystem.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Data augmentation using machine translation for fake news detection in the Urdu language<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85095683153</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Amjad M., Sidorov G., Zhila A.</b></td></tr><tr><td colspan="3">Organisations: <b>Instituto Politécnico Nacional, Independent researcher</b></td></tr><tr><td colspan="3">The task of fake news detection is to distinguish legitimate news articles that describe real facts from those which convey deceiving and fictitious information. As the fake news phenomenon is omnipresent across all languages, it is crucial to be able to efficiently solve this problem for languages other than English. A common approach to this task is supervised classification using features of various complexity. Yet supervised machine learning requires substantial amount of annotated data. For English and a small number of other languages, annotated data availability is much higher, whereas for the vast majority of languages, it is almost scarce. We investigate whether machine translation at its present state could be successfully used as an automated technique for annotated corpora creation and augmentation for fake news detection focusing on the English-Urdu language pair. We train a fake news classifier for Urdu on (1) the manually annotated dataset originally in Urdu and (2) the machine-translated version of an existing annotated fake news dataset originally in English. We show that at the present state of machine translation quality for the English-Urdu language pair, the fully automated data augmentation through machine translation did not provide improvement for fake news detection in Urdu.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s11704-020-9256-0" target="_blank"> The mass, fake news, and cognition security<a></b></td></tr><tr><td>Type: Review</td><td>ID: S_2-s2.0-85095816965</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Guo B., Ding Y., Li K., Yu Z., Sun Y., Ma S.</b></td></tr><tr><td colspan="3">Organisations: <b>Northwestern Polytechnical University, Tianjin University, Beihang University</b></td></tr><tr><td colspan="3">The widespread fake news in social networks is posing threats to social stability, economic development, and political democracy, etc. Numerous studies have explored the effective detection approaches of online fake news, while few works study the intrinsic propagation and cognition mechanisms of fake news. Since the development of cognitive science paves a promising way for the prevention of fake news, we present a new research area called Cognition Security (CogSec), which studies the potential impacts of fake news on human cognition, ranging from misperception, untrusted knowledge acquisition, targeted opinion/attitude formation, to biased decision making, and investigates the effective ways for fake news debunking. CogSec is a multidisciplinary research field that leverages the knowledge from social science, psychology, cognition science, neuroscience, AI and computer science. We first propose related definitions to characterize CogSec and review the literature history. We further investigate the key research challenges and techniques of CogSec, including humancontent cognition mechanism, social influence and opinion diffusion, fake news detection, and malicious bot detection. Finally, we summarize the open issues and future research directions, such as the cognition mechanism of fake news, influence maximization of fact-checking information, early detection of fake news, fast refutation of fake news, and so on.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3411564.3411648" target="_blank"> Fake news detection in social media: A systematic review<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85095833477</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Medeiros F.D.C., Braga R.B.</b></td></tr><tr><td colspan="3">Organisations: <b>Instituto Federal de Educação Ciência e Tecnologia do Ceará (IFCE)</b></td></tr><tr><td colspan="3">The growth of social networks platforms leverages the consumption of news due to its easy access, spreading behavior, and low cost. However, this revolution in the way that information is released has provided the growth of something that always walked side by side with the real news: we are talking about fake news. After the 2016 U.S. presidential election this term became more popular and dangerous because of its negative effect on society. In this context, recent contributions has appeared addressing several related topics, such as spreading behavior, methods for spreading contention, and fake news detection algorithms. Despite of the growth of this type of research, it is difficult for a researcher to identify the current state-of-the-art literature about fake news detection. To overcome this obstacle, this paper presents a systematic review of the literature that brings an overview of this research area and analyzes the the high-quality studies about fake news detection. Through this systematic literature review, more than 6,000 articles were found according to our search protocol. Then, we put these studies through stages of screening to ensure that they were quality assessed. Were elected 32 high-quality studies according to our PRISMA flow diagram defined in this paper. These studies were then categorized by their contribution type and algorithm. This work shown that Twitter and Weibo1 are the social media platform most applied by selected studies, and deep learning algorithms given the best detection results, specially LSTM. Besides, this SR exposes the lack of research for fake news detection in other language than english. Finally, we expect this study can help researchers identify the greatest contributions as well as research opportunities.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3377478" target="_blank"> Fake News Early Detection: A Theory-driven Model<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85095862719</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Zhou X., Jain A., Phoha V.V., Zafarani R.</b></td></tr><tr><td colspan="3">Organisations: <b>Syracuse University</b></td></tr><tr><td colspan="3">Massive dissemination of fake news and its potential to erode democracy has increased the demand for accurate fake news detection. Recent advancements in this area have proposed novel techniques that aim to detect fake news by exploring how it propagates on social networks. Nevertheless, to detect fake news at an early stage, i.e., when it is published on a news outlet but not yet spread on social media, one cannot rely on news propagation information as it does not exist. Hence, there is a strong need to develop approaches that can detect fake news by focusing on news content. In this article, a theory-driven model is proposed for fake news detection. The method investigates news content at various levels: lexicon-level, syntax-level, semantic-level, and discourse-level. We represent news at each level, relying on well-established theories in social and forensic psychology. Fake news detection is then conducted within a supervised machine learning framework. As an interdisciplinary research, our work explores potential fake news patterns, enhances the interpretability in fake news feature engineering, and studies the relationships among fake news, deception/disinformation, and clickbaits. Experiments conducted on two real-world datasets indicate the proposed method can outperform the state-of-the-art and enable fake news early detection when there is limited content information.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3340531.3412066" target="_blank"> Joint Estimation of User and Publisher Credibility for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85095865258</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Chowdhury R., Srinivasan S., Getoor L.</b></td></tr><tr><td colspan="3">Organisations: <b>University of California</b></td></tr><tr><td colspan="3">Fast propagation, ease-of-access, and low cost have made social media an increasingly popular means for news consumption. However, this has also led to an increase in the preponderance of fake news. Widespread propagation of fake news can be detrimental to society, and this has created enormous interest in fake news detection on social media. Many approaches to fake news detection use the news content, social context, or both. In this work, we look at fake news detection as a problem of estimating the credibility of both the news publishers and users that propagate news articles. We introduce a new approach called the credibility score-based model that can jointly infer fake news and credibility scores for publishers and users. We use a state-of-the-art statistical relational learning framework called probabilistic soft logic to perform this joint inference effectively. We show that our approach is accurate at both fake news detection and inferring credibility scores. Further, our model can easily integrate any auxiliary information that can aid in fake news detection. Using the FakeNewsNet dataset, we show that our approach significantly outperforms previous approaches at fake news detection by up to 10% in recall and 4% in accuracy. Furthermore, the credibility scores learned for both publishers and users are representative of their true behavior.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Annotating and analyzing biased sentences in news articles using crowdsourcing<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85095865651</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Lim S., Jatowt A., Yoshikawa M., Farber M.</b></td></tr><tr><td colspan="3">Organisations: <b>Kyoto Univiersity, Karlsruhe Institute of Technology</b></td></tr><tr><td colspan="3">The spread of biased news and its consumption by the readers has become a considerable issue. Researchers from multiple domains including social science and media studies have made efforts to mitigate this media bias issue. Specifically, various techniques ranging from natural language processing to machine learning have been used to help determine news bias automatically. However, due to the lack of publicly available datasets in this field, especially ones containing labels concerning bias on a fine-grained level (e.g., on sentence level), it is still challenging to develop methods for effectively identifying bias embedded in new articles. In this paper, we propose a novel news bias dataset which facilitates the development and evaluation of approaches for detecting subtle bias in news articles and for understanding the characteristics of biased sentences. Our dataset consists of 966 sentences from 46 English-language news articles covering 4 different events and contains labels concerning bias on the sentence level. For scalability reasons, the labels were obtained based on crowd-sourcing. Our dataset can be used for analyzing news bias, as well as for developing and evaluating methods for news bias detection. It can also serve as resource for related researches including ones focusing on fake news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3340531.3417463" target="_blank"> Truth be Told: Fake News Detection Using User Reactions on Reddit<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85095865758</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Setty V., Rekve E.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Stavanger</b></td></tr><tr><td colspan="3">In this paper, we provide a large dataset for fake news detection using social media comments. The dataset consists of 12,597 claims (of which 63% are labelled as fake) from four different sources (Snopes, Poltifact, Emergent and Twitter). The novel part of the dataset is that it also includes over 662K social media discussion comments related to these claims from Reddit. We make this dataset public for the research community. In addition, for the task of fake news detection using social media comments, we provide a simple but strong baseline solution deep neural network model which beats several solutions in the literature.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3340531.3412169" target="_blank"> The Battle Against Online Harmful Information: The Cases of Fake News and Hate Speech<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85095866048</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Giachanou A., Rosso P.</b></td></tr><tr><td colspan="3">Organisations: <b>Universitat Politècnica de València</b></td></tr><tr><td colspan="3">Social media have given the opportunity to users to express their opinions online in a fast and easy way. The ease of generating content online and the anonymity that social media provide have increased the amount of harmful content that is published. This tutorial will focus on the topic of online harmful information. First, we will analyse and explain the different types of online harmful information with a particular focus on fake news and hate speech. In addition, we will explain the different computational approaches proposed in the literature for the detection of fake news and hate speech. Next, we will present details regarding the evaluation process, datasets and shared tasks and finally, we will discuss future directions in the field of online harmful information detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1108/OIR-03-2020-0116" target="_blank"> User motivation in fake news sharing during the COVID-19 pandemic: an application of the uses and gratification theory<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85095943759</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Apuke O.D., Omar B.</b></td></tr><tr><td colspan="3">Organisations: <b>Universiti Sains Malaysia, Taraba State University</b></td></tr><tr><td colspan="3">Purpose: This study developed a predictive model that established the user motivational factors that predict COVID-19 fake news sharing on social media. Design/methodology/approach: The partial least squares structural equation modelling (PLS-SEM) was used for the analysis. Data were drawn from 152 Facebook and WhatsApp users in Nigeria to examine the research model formulated using the uses and gratification theory (UGT). Findings: We found that altruism, instant news sharing, socialisation and self-promotion predicted fake news sharing related to COVID-19 pandemic among social media users in Nigeria. Specifically, altruism was the strongest predictor to fake news sharing behaviour related to COVID-19, followed by instant news sharing and socialisation. On the contrary, entertainment had no association with fake news sharing on COVID-19. Practical implications: We suggest intervention strategies which nudge people to be sceptical of the information they come across on social media. We also recommend healthcare providers and the Nigerian government to provide relevant information on this current pandemic. That is, correct information should be shared widely to the public domain through various conventional and online media. This will lessen the spread of fake news on the concocted cure and prevention tips found online. Originality/value: The salient contributions of this study are as follows: First, it brings to the fore that the desire for self-promotion is associated with fake news sharing on social media; second, it shifts the focus of studies on fake news from detection methods to sharing behaviour, which fuels the uncontrollable spread of falsehood; third, it expands the existing literature on misinformation sharing by demonstrating the user motivation that leads to fake news sharing using the UGT.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/TCSS.2020.3027639" target="_blank"> Two-Path Deep Semisupervised Learning for Timely Fake News Detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85095979885</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Dong X., Victor U., Qian L.</b></td></tr><tr><td colspan="3">Organisations: <b>Texas AM University System</b></td></tr><tr><td colspan="3">News in social media, such as Twitter, has been generated in high volume and speed. However, very few of them are labeled (as fake or true news) by professionals in near real time. In order to achieve timely detection of fake news in social media, a novel framework of two-path deep semisupervised learning (SSL) is proposed where one path is for supervised learning and the other is for unsupervised learning. The supervised learning path learns on the limited amount of labeled data, while the unsupervised learning path is able to learn on a huge amount of unlabeled data. Furthermore, these two paths implemented with convolutional neural networks (CNNs) are jointly optimized to complete SSL. In addition, we build a shared CNN to extract the low-level features on both labeled data and unlabeled data to feed them into these two paths. To verify this framework, we implement a Word CNN-based SSL model and test it on two data sets: LIAR and PHEME. Experimental results demonstrate that the model built on the proposed framework can recognize fake news effectively with very few labeled data.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.ipm.2020.102437" target="_blank"> A multimodal fake news detection model based on crossmodal attention residual and multichannel convolutional neural networks<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85096177951</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Song C., Ning N., Wu B., Zhang Y.</b></td></tr><tr><td colspan="3">Organisations: <b>Beijing University of Posts and Telecommunications, North China Institute of Science and Technology</b></td></tr><tr><td colspan="3">In recent years, social media has increasingly become one of the popular ways for people to consume news. As proliferation of fake news on social media has the negative impacts on individuals and society, automatic fake news detection has been explored by different research communities for combating fake news. With the development of multimedia technology, there is a phenomenon that cannot be ignored is that more and more social media news contains information with different modalities, e.g., texts, pictures and videos. The multiple information modalities show more evidence of the happening of news events and present new opportunities to detect features in fake news. First, for multimodal fake news detection task, it is a challenge of keeping the unique properties for each modality while fusing the relevant information between different modalities. Second, for some news, the information fusion between different modalities may produce the noise information which affects model's performance. Unfortunately, existing methods fail to handle these challenges. To address these problems, we propose a multimodal fake news detection framework based on Crossmodal Attention Residual and Multichannel convolutional neural Networks (CARMN). The Crossmodal Attention Residual Network (CARN) can selectively extract the relevant information related to a target modality from another source modality while maintaining the unique information of the target modality. The Multichannel Convolutional neural Network (MCN) can mitigate the influence of noise information which may be generated by crossmodal fusion component by extracting textual feature representation from original and fused textual information simultaneously. We conduct extensive experiments on four real-world datasets and demonstrate that the proposed model outperforms the state-of-the-art methods and learns more discriminable feature representations.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-15-7234-0_35" target="_blank"> Boosting Approach for Multiclass Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85096417021</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Kareddula R., Singh P.</b></td></tr><tr><td colspan="3">Organisations: <b>National Institute of Technology</b></td></tr><tr><td colspan="3">In the modern era of information, data integrity is of utmost priority. With the rapid development in the field of Artificial Intelligence, one who has credible data owns the key to build a reliable future. But with the breakneck development of communication over social media the reliability of data is no more guaranteed. “Fake News” is data that doesn’t have any real-world significance (or) a fact which has been modified by some middleman over the chain of communication. Spreading of such fake news affects humanity in various unacceptable perspectives. As a solution, in this paper, a machine learning approach is proposed to verify the trustworthiness of news. Instead of just classifying the data as true or fake, various degrees of truth and falsehood are also explored. The proposed methodology has been applied to “Liar, Liar Pants on Fire”, a benchmark data set for fake news detection. The proposed approach with 41.1% accuracy, outperforms the baseline approaches.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-61841-4_10" target="_blank"> Fake News Detection on Twitter Using Propagation Structures<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85096425511</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Meyers M., Weiss G., Spanakis G.</b></td></tr><tr><td colspan="3">Organisations: <b>Maastricht University</b></td></tr><tr><td colspan="3">The growth of social media has revolutionized the way people access information. Although platforms like Facebook and Twitter allow for a quicker, wider and less restricted access to information, they also consist of a breeding ground for the dissemination of fake news. Most of the existing literature on fake news detection on social media proposes user-based or content-based approaches. However, recent research revealed that real and fake news also propagate significantly differently on Twitter. Nonetheless, only a few articles so far have explored the use of propagation features in their detection. Additionally, most of them have based their analysis on a narrow tweet retrieval methodology that only considers tweets to be propagating a news piece if they explicitly contain an URL link to an online news article. By basing our analysis on a broader tweet retrieval methodology that also allows tweets without an URL link to be considered as propagating a news piece, we contribute to fill this research gap and further confirm the potential of using propagation features to detect fake news on Twitter. We firstly show that real news are significantly bigger in size, are spread by users with more followers and less followings, and are actively spread on Twitter for a longer period of time than fake news. Secondly, we achieve an 87% accuracy using a Random Forest Classifier solely trained on propagation features. Lastly, we design a Geometric Deep Learning approach to the problem by building a graph neural network that directly learns on the propagation graphs and achieve an accuracy of 73.3%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-15-4409-5_40" target="_blank"> Stance Detection Using Transformer Architectures and Temporal Convolutional Networks<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85096496071</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Jain K., Doshi F., Kurup L.</b></td></tr><tr><td colspan="3">Organisations: <b>Dwarkadas J. Sanghvi College of Engineering</b></td></tr><tr><td colspan="3">Stance detection can be defined as the task of automatically detecting the relation between or the relative perspective of two pieces of text- a claim or headline and the corresponding article body. Stance detection is an integral part of the pipeline used for automatic fake news detection which is an open research problem in Natural Language Processing. The past year has seen a lot of developments in the field of NLP and the application of transfer learning to it. Bidirectional language models with recurrence and various transformer models have been consistently improving the state-of-the-art results on various NLP tasks. In this research work, we specifically focus on the application of embeddings from BERT and XLNet to solve the problem of stance detection. We extract the weights from the last hidden layer of the base models in both cases and use them as embeddings to train task-specific recurrent models. We also present a novel approach to tackle stance detection wherein we apply Temporal Convolutional Networks to solve the problem. Temporal Convolutional Networks are being seen as an ideal replacement for LSTM/GRUs for sequence modelling tasks. In this work, we implement models to investigate if they can be used for NLP tasks as well. We present our results with an exhaustive comparative analysis of multiple architectures trained on the Fake News Challenge (FNC) dataset.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.3390/math8112075" target="_blank"> Comparing deep-learning architectures and traditional machine-learning approaches for satire identification in spanish tweets<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85096496606</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Apolinario-Arzube O., Luna-Aveiga H., Garcia-Diaz J.A., Valencia-Garcia R., Medina-Moreira J.</b></td></tr><tr><td colspan="3">Organisations: <b>Universidad de Guayaquil, Universidad de Murcia, Universidad Agraria del Ecuador</b></td></tr><tr><td colspan="3">Automatic satire identification can help to identify texts in which the intended meaning differs from the literal meaning, improving tasks such as sentiment analysis, fake news detection or natural-language user interfaces. Typically, satire identification is performed by training a supervised classifier for finding linguistic clues that can determine whether a text is satirical or not. For this, the state-of-the-art relies on neural networks fed with word embeddings that are capable of learning interesting characteristics regarding the way humans communicate. However, as far as our knowledge goes, there are no comprehensive studies that evaluate these techniques in Spanish in the satire identification domain. Consequently, in this work we evaluate several deep-learning architectures with Spanish pre-trained word-embeddings and compare the results with strong baselines based on term-counting features. This evaluation is performed with two datasets that contain satirical and non-satirical tweets written in two Spanish variants: European Spanish and Mexican Spanish. Our experimentation revealed that term-counting features achieved similar results to deep-learning approaches based on word-embeddings, both outperforming previous results based on linguistic features. Our results suggest that term-counting features and traditional machine learning models provide competitive results regarding automatic satire identification, slightly outperforming state-of-the-art models.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Measuring the impact of readability features in fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85096518566</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Santos R.L.S., Leal S., Pardo T.A.S., Wick-Pedro G., Vale O.A., Bontcheva K., Scarton C.</b></td></tr><tr><td colspan="3">Organisations: <b>University of São Paulo, Federal University of São Carlos, University of Sheffield</b></td></tr><tr><td colspan="3">The proliferation of fake news is a current issue that influences a number of important areas of society, such as politics, economy and health. In the Natural Language Processing area, recent initiatives tried to detect fake news in different ways, ranging from language-based approaches to content-based verification. In such approaches, the choice of the features for the classification of fake and true news is one of the most important parts of the process. This paper presents a study on the impact of readability features to detect fake news for the Brazilian Portuguese language. The results show that such features are relevant to the task (achieving, alone, up to 92% classification accuracy) and may improve previous classification results.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> French tweet corpus for automatic stance detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85096524830</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Evrard M., Uro R., Herve N., Mazoyer B.</b></td></tr><tr><td colspan="3">Organisations: <b>Institut National de l'audiovisuel (INA)</b></td></tr><tr><td colspan="3">The automatic stance detection task consists in determining the attitude expressed in a text toward a target (text, claim, or entity). This is a typical intermediate task for the fake news detection or analysis, which is a considerably widespread and a particularly difficult issue to overcome. This work aims at the creation of a human-annotated corpus for the automatic stance detection of tweets written in French. It exploits a corpus of tweets collected during July and August 2018. To the best of our knowledge, this is the first freely available stance annotated tweet corpus in the French language. The four classes broadly adopted by the community were chosen for the annotation: support, deny, query, and comment with the addition of the ignore class. This paper presents the corpus along with the tools used to build it, its construction, an analysis of the inter-rater reliability, as well as the challenges and questions that were raised during the building process.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> CLFD: A novel vectorization technique and its application in fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85096548257</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Mersinias M., Chalkiadakis G., Afantenos S.</b></td></tr><tr><td colspan="3">Organisations: <b>Technical University of Crete, Universite Paul Sabatier</b></td></tr><tr><td colspan="3">In recent years, fake news detection has been an emerging research area. In this paper, we put forward a novel statistical approach for the generation of feature vectors to describe a document. Our so-called class label frequency distance (clfd), is shown experimentally to provide an effective way for boosting the performance of machine learning methods. Specifically, our experiments, carried out in the fake news detection domain, verify that efficient traditional machine learning methods that use our vectorization approach, consistently outperform deep learning methods that use word embeddings for small and medium sized datasets, while the results are comparable for large datasets. In addition, we demonstrate that a novel hybrid method that utilizes both a clfd-boosted logistic regression classifier and a deep learning one, clearly outperforms deep learning methods even in large datasets.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.eswa.2020.114340" target="_blank"> Exploiting discourse structure of traditional digital media to enhance automatic fake news detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85096581272</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Bonet-Jover A., Saquete E., Martinez-Barco P., Piad-Morffis A., Angel Garcia-Cumbreras M.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Alicante, University of Havana, CEATIC/Universidad de Jaén</b></td></tr><tr><td colspan="3">This paper presents a novel architecture for dealing with Automatic Fake News detection. The architecture factors in the discourse structure of news in traditional digital media and is based on two premises. First, fake news tends to mix true and false information with the purpose of confusing readers. Second, this research is focused on fake news delivered in traditional digital media, so our approach considers the influence of the journalistic structure of news, and the way journalists tend to introduce the essential content in a news story using 5W1H answer. Considering both premises, this proposal deals with the news components separately because some may be true or false, instead of considering the veracity value of the news article as a unit. A two-layer architecture is proposed, Structure and Veracity layers. To demonstrate the validity of the proposal, a new dataset was created and annotated with a new fine-grained annotation scheme (FNDeepML) that considers the different elements of the news document and their veracity. Due to the severity of the COVID-19 pandemic crisis, health is the chosen domain, and Spanish is the language used to validate the architecture, given the lack of research in this language. However, the proposal can be applied to any other language or domain. The performance of the Veracity layer of our proposal, which factors in the traditional news article structure and the 5W1H annotation, is capable of delivering a result of F1=0.807. This represents a strong improvement when compared to the baseline, which uses the whole document with a single veracity value, obtaining F1=0.605. These findings validate the suitability and effectiveness of our approach.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> r/Fakeddit: A new multimodal benchmark dataset for fine-grained fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85096587943</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Nakamura K., Levy S., Wang W.Y.</b></td></tr><tr><td colspan="3">Organisations: <b>Laguna Blanca School, University of California</b></td></tr><tr><td colspan="3">Fake news has altered society in negative ways in politics and culture. It has adversely affected both online social network systems as well as offline communities and conversations. Using automatic machine learning classification models is an efficient way to combat the widespread dissemination of fake news. However, a lack of effective, comprehensive datasets has been a problem for fake news research and detection model development. Prior fake news datasets do not provide multimodal text and image data, metadata, comment data, and fine-grained fake news categorization at the scale and breadth of our dataset. We present Fakeddit, a novel multimodal dataset consisting of over 1 million samples from multiple categories of fake news. After being processed through several stages of review, the samples are labeled according to 2-way, 3-way, and 6-way classification categories through distant supervision. We construct hybrid text+image models and perform extensive experiments for multiple variations of classification, demonstrating the importance of the novel aspect of multimodality and fine-grained classification unique to Fakeddit.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> BanFakeNews: A dataset for detecting fake news in Bangla<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85096594965</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Hossain M.Z., Rahman M.A., Islam M.S., Kar S.</b></td></tr><tr><td colspan="3">Organisations: <b>Shahjalal University of Science and Technology, University of Houston</b></td></tr><tr><td colspan="3">Observing the damages that can be done by the rapid propagation of fake news in various sectors like politics and finance, automatic identification of fake news using linguistic analysis has drawn the attention of the research community. However, such methods are largely being developed for English where low resource languages remain out of the focus. But the risks spawned by fake and manipulative news are not confined by languages. In this work, we propose an annotated dataset of ? 50K news that can be used for building automated fake news detection systems for a low resource language like Bangla. Additionally, we provide an analysis of the dataset and develop a benchmark system with state of the art NLP techniques to identify Bangla fake news. To create this system, we explore traditional linguistic features and neural network based methods. We expect this dataset will be a valuable resource for building technologies to prevent the spreading of fake news and contribute in research with low resource languages. The dataset and source code are publicly available at https://github.com/Rowan1697/FakeNews.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Localization of fake news detection via multitask transfer learning<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85096600507</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Cruz J.C.B., Tan J.A., Cheng C.</b></td></tr><tr><td colspan="3">Organisations: <b>De La Salle University</b></td></tr><tr><td colspan="3">The use of the internet as a fast medium of spreading fake news reinforces the need for computational tools that combat it. Techniques that train fake news classifiers exist, but they all assume an abundance of resources including large labeled datasets and expert-curated corpora, which low-resource languages may not have. In this work, we make two main contributions: First, we alleviate resource scarcity by constructing the first expertly-curated benchmark dataset for fake news detection in Filipino, which we call “Fake News Filipino.” Second, we benchmark Transfer Learning (TL) techniques and show that they can be used to train robust fake news classifiers from little data, achieving 91% accuracy on our fake news dataset, reducing the error by 14% compared to established few-shot baselines. Furthermore, lifting ideas from multitask learning, we show that augmenting transformer-based transfer techniques with auxiliary language modeling losses improves their performance by adapting to writing style. Using this, we improve TL performance by 4-6%, achieving an accuracy of 96% on our best model. Lastly, we show that our method generalizes well to different types of news articles, including political news, entertainment news, and opinion articles.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Transfer learning from transformers to fake news challenge stance detection (FNC-1) task<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85096608388</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Slovikovskaya V., Attardi G.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Pisa</b></td></tr><tr><td colspan="3">Transformer models, trained and publicly released over the last couple of years, have proved effective in many NLP tasks. We wished to test their usefulness in particular on the stance detection task. We performed experiments on the data from the Fake News Challenge Stage 1 (FNC-1). We were indeed able to improve the reported SotA on the challenge, by exploiting the generalization power of large language models based on Transformer architecture. Specifically (1) we improved the FNC-1 best performing model adding BERT sentence embedding of input sequences as a model feature, (2) we fine-tuned BERT, XLNet, and RoBERTa transformers on FNC-1 extended dataset and obtained state-of-the-art results on FNC-1 task.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.3233/APC200124" target="_blank"> Polarity detection on real-time news data using opinion mining<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85096670392</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Prathap B.R., Sujatha A.K., Yadav C.B.S., Mounika M.</b></td></tr><tr><td colspan="3">Organisations: <b>CHRIST (Deemed to be University)</b></td></tr><tr><td colspan="3">Sentimental Analysis or Opinion Mining plays a vital role in the experimentation field that determines the user’s opinions, emotions and sentiments concealing a text. News on the Internet is becoming vast, and it is drawing attention and has reached the point of adequately affecting political and social realities. The popular way of checking online content, i.e. manual knowledge-based on the facts, is practically impossible because of the enormous amount of data that has now generated online. The issue can address by using Machine Learning Algorithms and Artificial Intelligence. One of the Machine Learning techniques used in this is Naive Bayes classifier. In this paper, the polarity of the news article determined whether the given news article is a positive, negative or neutral Naive Bayes Classifier, which works well with NLP (Natural Language problems) used for many purposes. It is a family of probabilistic algorithms that used to identify a word from a given text. In this, we calculate the probability of each word in a given text. Using Bayes theorem, they are getting the probabilities based on the given conditions. Topic Modeling is analytical modelling for finding the abstract of topics from a cluster of documents. Latent Dirichlet Allocation (LDA) is a topic model is used to classify the text in a given document to a specified topic. The news article is classified as positive or negative or neutral using Naive Bayes classifier by calculating the probabilities of each word from a given news article. By using topic modelling (LDA), topics of articles are detected and record data separately. The calculation of the overall sentiment of a chosen topic from different newspapers from previously recorded data done.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s12652-020-02698-1" target="_blank"> Hoax news-inspector: a real-time prediction of fake news using content resemblance over web search results for authenticating the credibility of news articles<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85096804204</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Varshney D., Vishwakarma D.K.</b></td></tr><tr><td colspan="3">Organisations: <b>Delhi Technological University</b></td></tr><tr><td colspan="3">Nowadays social media is one of the important medium of sharing thoughts and opinions of the individual due to its easy access and also it provides an opportunity to the malicious user to post deliberately fabricated false content to influence people for creating controversies, playing with public emotions, etc. The spread of contaminated information such as Rumours, Hoax, Accidental misinformation, etc. over the web is becoming an emergency situation that can have a very harmful impact on society and individuals. In this paper, we have developed an automated system “Hoax-News Inspector” for the detection of fake news that propagates through the web and social media in the form of text. To distinguish fake and real reports on an early basis, we identified prominent features by exploring two sets of attributes that lead to information spread: Article/post-content-based features, Sentiment based features and the mixture of both called as Hybrid features. The proposed algorithm is trained and tested on the self-generated dataset as well as one of the popular existing datasets Liar. It has been found that the proposed algorithm gives the best results using the Random Forest classifier with an accuracy of 95% by considering all sets of features. Detecting and verifying news have many practical applications for business markets, news consumers, and time-sensitive services, which generally help to minimize the spread of false information. Our proposed system Hoax News-Inspector can automatically collect fabricated news data and classify it into binary classes Fake or Real, which later benefits further research for predicting and understanding Fake news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.future.2020.11.022" target="_blank"> An ensemble machine learning approach through effective feature extraction to classify fake news<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85096860267</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Hakak S., Alazab M., Khan S., Gadekallu T.R., Maddikunta P.K.R., Khan W.Z.</b></td></tr><tr><td colspan="3">Organisations: <b>University of New Brunswick, Charles Darwin University, Air University Islamabad, School of Information Technology and Engineering, Jazan University</b></td></tr><tr><td colspan="3">There are numerous channels available such as social media, blogs, websites, etc., through which people can easily access the news. It is due to the availability of these platforms that the dissemination of fake news has become easier. Anyone using these platforms can create and share fake news content based on personal or professional motives. To address the issue of detecting fake news, numerous studies based on supervised and unsupervised learning methods have been proposed. However, all those studies do suffer from a certain limitation of poor accuracy. The reason for poor accuracy can be attributed due to several reasons such as the poor selection of features, inefficient tuning of parameters, imbalanced datasetsred, etc. In this article, we have proposed an ensemble classification model for detection of the fake news that has achieved a better accuracy compared to the state-of-the-art. The proposed model extracts important features from the fake news datasets, and the extracted features are then classified using the ensemble model comprising of three popular machine learning models namely, Decision Tree, Random Forest and Extra Tree Classifier. We achieved a training and testing accuracy of 99.8% and 44.15% respectively on the ISOT dataset. For the Liar dataset, we achieved the training and testing accuracy of 100%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-61705-9_2" target="_blank"> Fake News Detection by Means of Uncertainty Weighted Causal Graphs<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85097065147</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Garrido-Merchan E.C., Puente C., Palacios R.</b></td></tr><tr><td colspan="3">Organisations: <b>Universidad Autónoma de Madrid, Universidad Pontificia Comillas</b></td></tr><tr><td colspan="3">Society is experimenting changes in information consumption, as new information channels such as social networks let people share news that do not necessarily be trust worthy. Sometimes, these sources of information produce fake news deliberately with doubtful purposes and the consumers of that information share it to other users thinking that the information is accurate. This transmission of information represents an issue in our society, as can influence negatively the opinion of people about certain figures, groups or ideas. Hence, it is desirable to design a system that is able to detect and classify information as fake and categorize a source of information as trust worthy or not. Current systems experiment difficulties performing this task, as it is complicated to design an automatic procedure that can classify this information independent on the context. In this work, we propose a mechanism to detect fake news through a classifier based on weighted causal graphs. These graphs are specific hybrid models that are built through causal relations retrieved from texts and consider the uncertainty of causal relations. We take advantage of this representation to use the probability distributions of this graph and built a fake news classifier based on the entropy and KL divergence of learned and new information. We believe that the problem of fake news is accurately tackled by this model due to its hybrid nature between a symbolic and quantitative methodology. We describe the methodology of this classifier and add empirical evidence of the usefulness of our proposed approach in the form of synthetic experiments and a real experiment involving lung cancer.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/BigMM50055.2020.00033" target="_blank"> SGG: Spinbot, Grammarly and GloVe based Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85097212398</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Gautam A., Jerripothula K.R.</b></td></tr><tr><td colspan="3">Organisations: <b>Indraprastha Institute of Information Technology Delhi</b></td></tr><tr><td colspan="3">Recently, news consumption using online news portals has increased exponentially due to several reasons, such as low cost and easy accessibility. However, such online platforms inadvertently also become the cause of spreading false information across the web. They are being misused quite frequently as a medium to disseminate misinformation and hoaxes. Such malpractices call for a robust automatic fake news detection system that can keep us at bay from such misinformation and hoaxes. We propose a robust yet simple fake news detection system, leveraging the tools for paraphrasing, grammar-checking, and word-embedding. In this paper, we try to the potential of these tools in jointly unearthing the authenticity of a news article. Notably, we leverage Spinbot (for paraphrasing), Grammarly (for grammar-checking), and GloVe (for word-embedding) tools for this purpose. Using these tools, we were able to extract novel features that could yield state-of-the-art results on the Fake News AMT dataset and comparable results on Celebrity datasets when combined with some of the essential features. More importantly, the proposed method is found to be more robust empirically than the existing ones, as revealed in our cross-domain analysis and multi-domain analysis.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/BigMM50055.2020.00074" target="_blank"> Attributional analysis of Multi-Modal Fake News Detection Models (Grand Challenge)<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85097214128</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Madhusudhan S., Mahurkar S., Nagarajan S.K.</b></td></tr><tr><td colspan="3">Organisations: <b>Department of Electrical and Electronics Engineering, School of Computer Science and Engineering</b></td></tr><tr><td colspan="3">Fake news detection is a procedure for identifying a particular news article as counterfeit or real. In this paper, we propose and assess the ability of two approaches for the task of multi-modal fake news detection. For the first approach, we fuse the textual and image modalities. The textual features are obtained from the pre-trained language models such as BERT and SBERT and image features are extracted from ResNet-18 pre-trained on ImageNet dataset. In the second approach, we use Visual Attention for fake news detection. We test both the strategies on Gossipcop and Politifact dataset. Our experiments show that the complete text of the article and the BERT model setting provides the best result. Further, we use Integrated gradients to analyze our models by observing input attributions.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-15-7907-3_25" target="_blank"> A dynamic approach for detecting the fake news using random forest classifier and nlp<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85097215059</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Antony Vijay J., Anwar Basha H., Arun Nehru J.</b></td></tr><tr><td colspan="3">Organisations: <b>Hindusthan College of Engineering and Technology, SRM Institute of Science and Technology</b></td></tr><tr><td colspan="3">Social media’s presence can have big and very negative impacts on the individuals and on society too. The widespread of intentionally hoax news could mislead the reader. These are all false story with an intention to fool people, so this fake news analysis built, detection and intervention on social media platforms have become one of the hot topics to research that is grasping very huge attention of the truth seekers. The survey properly reviews fake or false news research. The survey finds different ways in which the random forest algorithm and NLP can be used for detecting a fake or false piece of news. Our model is emanated from counting vector which is used for word tallies. It also uses the technique repetition inverse document also called as RID matrix which tallies the words which inform that continuity of words copied from various reports of paper in the given volume of data. These do not consider tasks which are similar to arranging the word and context. There can be many possibilities where two or more articles which are having similarity in word count can be totally different in their meaning or understanding. There are fewer possibilities which could predict either “Real “or “Fake” piece of information presented in the news as it is harder to spot any hoax/fake news. Our suggested task on gathering the dataset of which contains both rumour and true news and employing Random Forest Algorithm and NLP to design or develop a model which can classify an article and tell whether it is untrustworthy information or real news based on the words, phrases or sentences. Our goal is to achieve the trustworthiness of the readers.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/BigMM50055.2020.00034" target="_blank"> Classification of Propagation Path and Tweets for Rumor Detection using Graphical Convolutional Networks and Transformer based Encodings<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85097221493</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Malhotra B., Vishwakarma D.K.</b></td></tr><tr><td colspan="3">Organisations: <b>Delhi Technological University</b></td></tr><tr><td colspan="3">Social media platforms have become an integral part of our lives. We rely on them for entertainment purpose, social interactions and to learn what's happening around the world. One such social media network 'Twitter' has become extensively popular around the world, majorly for sharing news and important information. As it is rapidly being used to share news and information, it is also causing a problem which implicitly comes with sharing of news without fact checking in place, which is, spreading of misinformation and rumors. To tackle this challenge, we propose a novel method wherein we leverage the structural and graphical properties of a tweet's propagation and tweet's text which tells us how a news of a specific class spreads, the characteristics of users involved in spreading that news and the linguistic cue of the source of news. This methodology extracts user features (like account verified, user description, followers count etc.) by modeling each user as a node and creating a graphical network of users retweeting the source tweet. We are extracting the textual content of source tweets in form of RoBERTa text's vector representations which is the current state-of-the-art for text embedding. The model is trained on benchmark datasets of Twitter15 and Twitter16 along with scrapped data of users retweeting in their current state. The results have been promising for rumor and fake detection and outperforms current state-of-the-art algorithms.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3428658.3430965" target="_blank"> FakeNewsSetGen: a Process to Build Datasets that Support Comparison among Fake News Detection Methods<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85097353830</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Goldschmidt R.R., Da Silva F.R.M., Freire P.M.S., De Souza M.P., De A. B. Plenamente G.</b></td></tr><tr><td colspan="3">Organisations: <b>Instituto Militar de Engenharia (IME)</b></td></tr><tr><td colspan="3">Due to easy access and low cost, social media online news consumption has increased significantly for the last decade. Despite their benefits, some social media allow anyone to post news with intense spreading power, which amplifies an old problem: the dissemination of Fake News. In the face of this scenario, several machine learning-based methods to automatically detect Fake News (MLFN) have been proposed. All of them require datasets to train and evaluate their detection models. Although recent MLFN were designed to consider data regarding the news propagation on social media, most of the few available datasets do not contain this kind of data. Hence, comparing the performances amid those recent MLFN and the others is restricted to a very limited number of datasets. Moreover, all existing datasets with propagation data do not contain news in Portuguese, which impairs the evaluation of the MLFN in this language. Thus, this work proposes FakeNewsSetGen, a process that builds Fake News datasets that contain news propagation data and support comparison amid the state-of-the-art MLFN. FakeNewsSetGen's software engineering process was guided to include all kind of data required by the existing MLFN. In order to illustrate FakeNewsSetGen's viability and adequacy, a case study was carried out. It encompassed the implementation of a FakeNewsSetGen prototype and the application of this prototype to create a dataset called FakeNewsSet, with news in Portuguese. Five MLFN with different kind of data requirements (two of them demanding news propagation data) were applied to FakeNewsSet and compared, demonstrating the potential use of both the proposed process and the created dataset.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3428658.3430978" target="_blank"> Analysis of the Subjectivity Level in Fake News Fragments<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85097355417</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Vieira L.L., Jeronimo C.L.M., Campelo C.E.C., Marinho L.B.</b></td></tr><tr><td colspan="3">Organisations: <b>DSC - UFCG</b></td></tr><tr><td colspan="3">The widespread of fake news is increasingly worrying society and demanding approaches for mitigation. Although many approaches have been proposed to fake news detection, there is still a lack of works that deeply investigate their structure. Our study has been motivated by two findings discussed in existing works: the first is the fact that fake news usually mix real and fake information to mislead readers; the second is that subjective language is a resource commonly exploited by fake news producers. Therefore, to better understand how fake news is structured, we perform an analysis on the way the subjective language is exploited in different situations inside the fake news documents. For this, we built a dataset by manually identifying fake parts of news articles, and we also propose tags to categorize the fragments in documents. The proposed tags categorize the fake news fragments according to their kind of falsehood in document. To reveal subjectivity nuances within the fragments, we use the Word Movers Distance and a set of subjectivity lexicons in the Portuguese language. Our results indicate that the fragmentation of news allows the identification of subjectivity markers that cannot be identified when considering the entire documents.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3428658.3430975" target="_blank"> A Linguistic-Based Method that Combines Polarity, Emotion and Grammatical Characteristics to Detect Fake News in Portuguese<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85097355567</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>De Souza M.P., Da Silva F.R.M., Freire P.M.S., Goldschmidt R.R.</b></td></tr><tr><td colspan="3">Organisations: <b>Instituto Militar de Engenharia (IME)</b></td></tr><tr><td colspan="3">In the last decades, the dissemination of News through digital media has increased the information accessibility previously offered by traditional channels. Despite their benefits, digital media have exacerbated an old problem: the spread of Fake News, (i.e., false News intentionally published). Faced with this scenario, the linguistic approaches to automatic Fake News detection use information that can be directly extracted from the News' text. Several methods based on these approaches use grammatical classification and sentiment analysis over News writing in Portuguese. However, as far as it was possible to observe in the related literature, these methods are limited to the identification of polarity of sentiment (i.e., positive, neutral or negative) existing in the text. Although polarity classification be an effective method for a wide range of natural language processing applications, it does not address language nuances (e.g., emotions such as anger, sadness, etc.) that can provide evidence that a text contains false information. Hence, this study proposes an extended method that, in addition to the grammatical classification and polarity based sentiment analysis, also uses the analysis of emotions to detect Fake News written in Portuguese. The extended method showed promising results in experimental data, obtaining accuracy greater than 92%. In average, the proposed method overcame polarity and gramatical classification based methods in 1.4 percentage points.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Embedding partial propagation network for fake news early detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85097560575</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Silva A., Han Y., Luo L., Karunasekera S., Leckie C.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Melbourne</b></td></tr><tr><td colspan="3">Detecting fake news as early as possible has attracted growing attention due to its fast-spreading nature and the significant harm it can cause. As demonstrated in recent studies, the propagation pattern of fake news on social media differs from that of real news, and a number of works have extracted different types of features from the propagation pattern for detection. However, a major limitation of this approach is that the propagation network is not fully available in the early stages, and may take a long time to complete. As a result, existing network-based fake news detection methods yield low accuracy during the early stages of propagation. To bridge the research gap, in this work we: (1) propose a novel network embedding algorithm, based on the investigation of a wide range of features obtained from the propagation network, which are not well studied in previous work; and (2) design an autoencoder-based neural architecture to predict the embedding of the complete propagation network using the partially available network in the early stages of propagation. Our experiments show that with the predicted embedding for the complete propagation network, our model can achieve state-of-the-art performance while only having access to the early stage propagation network.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Epidemiology inspired framework for fake news mitigation in social networks<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85097566839</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Rath B., Srivastava J.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Minnesota</b></td></tr><tr><td colspan="3">Research in fake news detection and prevention has gained a lot of attention over the past decade, with most models using features generated from content and propagation paths. Complementary to these approaches, in this position paper we outline a framework inspired from the domain of epidemiology that proposes to identify people who are likely to become fake news spreaders. The proposed framework can serve as motivation to build fake news mitigation models, even for the scenario when fake news has not yet originated. Some models based on the framework have been successfully evaluated on real world Twitter datasets and can provide motivation for new research directions.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-63426-1_12" target="_blank"> MVFNN: Multi-Vision Fusion Neural Network for Fake News Picture Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85097650303</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Xue J., Wang Y., Xu S., Shi L., Wei L., Song H.</b></td></tr><tr><td colspan="3">Organisations: <b>Zhengzhou University, Zhongyuan Network Security Research Institute</b></td></tr><tr><td colspan="3">During this year’s Novel Coronavirus (2019-nCoV) outbreak, the spread of fake news has caused serious social panic. This fact necessitates a focus on fake news detection. Pictures could be viewed as fake news indicators and hence could be used to identify fake news effectively. However, fake news pictures detection is more challenging since fake news picture identification is more difficult than the fake picture recognition. This paper proposes a multi-vision fusion neural network (MVFNN) which consists of four main components: the visual modal module, the visual feature fusion module, the physical feature module and the ensemble module. The visual modal module is responsible for extracting image features from images pixel domain, frequency domain, and tamper detection. It cooperates with the visual features fusion module to detect fake news images from multi-vision fusion. And the ensemble module combines visual features and physical features to detect the fake news pictures. Experimental results show that our model could achieve better detection performance by at least 4.29% than the existing methods in benchmark datasets.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.asoc.2020.106983" target="_blank"> Multiple features based approach for automatic fake news detection on social networks using deep learning<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85097710327</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Sahoo S.R., Gupta B.B.</b></td></tr><tr><td colspan="3">Organisations: <b>National Institute of Technology Kurukshetra, Asia University, Macquarie University</b></td></tr><tr><td colspan="3">In recent years, the rise of Online Social Networks has led to proliferation of social news such as product advertisement, political news, celebrity's information, etc. Some of the social networks such as Facebook, Instagram and Twitter affected by their user through fake news. Unfortunately, some users use unethical means to grow their links and reputation by spreading fake news in the form of texts, images, and videos. However, the recent information appearing on an online social network is doubtful, and in many cases, it misleads other users in the network. Fake news is spread intentionally to mislead readers to believe false news, which makes it difficult for detection mechanism to detect fake news on the basis of shared content. Therefore, we need to add some new information related to user's profile, such as user's involvement with others for finding a particular decision. The disseminated information and their diffusion process create a big problem for detecting these contents promptly and thus highlighting the need for automatic fake news detection. In this paper, we are going to introduce automatic fake news detection approach in chrome environment on which it can detect fake news on Facebook. Specifically, we use multiple features associated with Facebook account with some news content features to analyze the behavior of the account through deep learning. The experimental analysis of real-world information demonstrates that our intended fake news detection approach has achieved higher accuracy than the existing state of art techniques.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/SoutheastCon44009.2020.9249688" target="_blank"> Fake News Detection by Decision Tree<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85097840988</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Lyu S., Lo D.C.-T.</b></td></tr><tr><td colspan="3">Organisations: <b>Kennesaw State University</b></td></tr><tr><td colspan="3">Fake news detection research has appeared for a couple of years and is a relatively new and difficult research field. The difficulties come from the semantics of natural languages and manual identification via human beings, let along machines. In this project, we propose to analyze the performance of several machine learning algorithms integrating tools such as FakeNewsTracker[1], doc2vec, Support Vector Machine (SVM), and decision trees. Our preliminary results indicate that the SVM and the decision trees are suitable to identify fake news with an acceptable accuracy of 95 percent. Typically, the decision trees method shows a better result than SVM. Future research directions will be addressed.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/DSAA49011.2020.00111" target="_blank"> Fake news detection using multilingual evidence<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85097988670</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Dementieva D., Panchenko A.</b></td></tr><tr><td colspan="3">Organisations: <b>Skolkovo Institute of Science and Technology</b></td></tr><tr><td colspan="3">Nowadays, misleading information spreads over the internet at an incredible speed, which can lead to irreparable consequences. As a result, it is becoming more and more essential to combat fake news, especially in the early stages of its origins. Over the past years, a lot of work has been done in this direction. However, all existed solutions have their limitations. One of the main limitations of the current approaches is that the majority of the models are focused only on one language and do not use any multilingual information. In this work, we investigate the new approach of fake news detection based on multilingual evidence. We show effectiveness of the proposed approach in a manual and an automated evaluation experiments.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/DSAA49011.2020.00084" target="_blank"> Detecting fake news spreaders on twitter from a multilingual perspective<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85097994608</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Vogel I., Meghana M.</b></td></tr><tr><td colspan="3">Organisations: <b>Fraunhofer Institute SIT</b></td></tr><tr><td colspan="3">The creators of fake news often use facts from verified news sources and layer them with misinformation to confuse the reader, either intentionally or unintentionally. It can be increasingly seen as a threat to democracy, public order and free debate that can cause confusion and provoke unrest. Several websites have taken on the mission of fact-checking rumors and claims - particularly those that get thousands of views and likes before being debunked and dismissed by expert sources. To prevent fake news from being spread among online users, a near real-time reaction is crucial. Fact-checking websites are often not fast enough to verify the content of all the news being spread. Fake news detection is a challenging task aiming to reduce human time and effort to check the truthfulness of news. In this paper, we propose an approach that is able to identify possible fake news spreaders on social media as a first step towards preventing fake news from being propagated among online users. Therefore, we conduct different learning experiments from a multilingual perspective, English and Spanish. We evaluate different textual features that are primarily not tied to a specific language and compare different machine learning algorithms. Our results indicate that language-independent features can be used to distinguish between possible fake news spreaders and users who share credible information with an average detection accuracy of 78% for the English and 87% for the Spanish corpus.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/DSAA49011.2020.00091" target="_blank"> Multimodal multi-image fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85097998514</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Giachanou A., Zhang G., Rosso P.</b></td></tr><tr><td colspan="3">Organisations: <b>Universitat Politècnica de València</b></td></tr><tr><td colspan="3">Recent years have seen a large increase in the amount of false information that is posted online. Fake news are created and propagated in order to deceive users and manipulate opinions and subsequently have a negative impact on the society. The automatic detection of fake news is very challenging since some of those news are created in sophisticated ways containing text or images that have been deliberately modified. Combining information from different modalities can be very useful for determining which of the online articles are fake. In this paper, we propose a multimodal multi-image system that combines information from different modalities in order to detect fake news posted online. In particular, our system combines textual, visual and semantic information. For the textual representation we use the Bidirectional Encoder Representations from Transformers (BERT) to better capture the underlying semantic and contextual meaning of the text. For the visual representation we extract image tags from multiple images that the articles contain using the VGG-16 model. The semantic representation refers to the text-image similarity calculated using the cosine similarity between the title and image tags embeddings. Our experimental results on a real world dataset show that combining features from the different modalities is effective for fake news detection. In particular, our multimodal multi-image system significantly outperforms the BERT baseline by 4.19% and SpotFake by 5.39%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> The power of related articles - Improving fake news detection on social media platforms<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85098011543</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Gimpel H., Heger S., Kasper J., Schafer R.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Augsburg</b></td></tr><tr><td colspan="3">Social media is increasingly used as a platform for news consumption, but it has also become a breeding ground for fake news. This serious threat poses significant challenges to social media providers, society, and science. Several studies have investigated automated approaches to fighting fake news, but little has been done to improve fake news detection on the users' side. A simple but promising approach could be to broaden users' knowledge and thus the perceptual process in order to improve detection behavior. This study evaluates the impact of a digital nudging approach, which aims to fight fake news through the help of related articles. 322 participants took part in an online experiment simulating the Facebook Newsfeed. In addition to a control group, three treatment groups were exposed to different combinations of related articles. Results indicate that the presence of controversial related articles has a positive influence on the detection of fake news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-15-8767-2_16" target="_blank"> A Walk Through Various Paradigms for Fake News Detection on Social Media<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85098066403</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Divya T.V., Banik B.G.</b></td></tr><tr><td colspan="3">Organisations: <b>Koneru Lakshmaiah Education Foundation</b></td></tr><tr><td colspan="3">Around the globe, social media is serving as a significant source of news for millions of people because of its rapid dissemination, easy access and low cost. However, it has a significant risk in exposing fake news, which may mislead the readers, and it comes at the cost of dubious trustworthiness. Existing content-based analysis techniques are challenged by automatic detection of fake news. On social media, merits and demerits of different techniques of fake detection are studied in review work. For fake news detection, various techniques have been proposed in recent days. For given news, the precise statistical rating is not produced by existing works. Less variance is made by news category and input restrictions. Automatic fake news detection methods are studied in this review and concluded a method for detecting various news. Also, studied the ability of a technique in predicting fake news based on data sources.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-15-8354-4_26" target="_blank"> An LSTM-Based Fake News Detection System Using Word Embeddings-Based Feature Extraction<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85098157991</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Sharma R., Agarwal V., Sharma S., Arya M.S.</b></td></tr><tr><td colspan="3">Organisations: <b>SRM Institute of Science and Technology</b></td></tr><tr><td colspan="3">Fake news is manipulated news or misinformation that is spread across the Internet with an intention to impose certain ideas and to damage an agency, organization and person often using dishonest, sensationalist and outright fabricated headlines to increase readership. Due to the propagation of fake news, there is a need for computational methods to detect them. Fake news existed for decades, and in the research community, the detection of fake news has been a desired topic. Around 70% of people are concerned about the propagation of fake news. Given the challenges related to the detection of fake news research problems, the researchers globally are trying to figure out the basic attributes of the problem statement. The objective of this paper is to detect whether the online articles are fake or credible, using various machine learning techniques like GloVe word embeddings and long short-term memory (LSTM) as feature extraction and as a classifier technique to find the best fit for the model.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICDM50108.2020.00037" target="_blank"> MALCOM: Generating malicious comments to attack neural fake news detection models<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85098219836</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Le T., Wang S., Lee D.</b></td></tr><tr><td colspan="3">Organisations: <b>The Pennsylvania State University</b></td></tr><tr><td colspan="3">In recent years, the proliferation of so-called 'fake news' has caused much disruptions in society and weakened the news ecosystem. Therefore, to mitigate such problems, researchers have developed state-of-the-art (SOTA) models to autodetect fake news on social media using sophisticated data science and machine learning techniques. In this work, then, we ask 'what if adversaries attempt to attack such detection models?' and investigate related issues by (i) proposing a novel attack scenario against fake news detectors, in which adversaries can post malicious comments toward news articles to mislead SOTA fake news detectors, and (ii) developing Malcom, an end-to-end adversarial comment generation framework to achieve such an attack. Through a comprehensive evaluation, we demonstrate that about 94% and 93.5% of the time on average Malcom can successfully mislead five of the latest neural detection models to always output targeted real and fake news labels. Furthermore, Malcom can also fool black box fake news detectors to always output real news labels 90% of the time on average. We also compare our attack model with four baselines across two real-world datasets, not only on attack performance but also on generated quality, coherency, transferability, and robustness. We release the source code of Malcom at https://github.com/lethaiq/MALCOM1.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-15-9309-3_26" target="_blank"> Analysis design study for fake news identification and evaluation<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85098250348</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Park L.W., Chang H.</b></td></tr><tr><td colspan="3">Organisations: <b>Chung-Ang University, Chung-Ang University</b></td></tr><tr><td colspan="3">With the spread of the Internet and increasing amounts of self-proclaimed journalists, articles both true and inaccurate fill the web. These inaccurate articles, most commonly referred to as fake news, have proved to spread quickly and have immense social influence in society. Attempts to detect fake news articles through deep learning techniques and artificial intelligence prove the challenges in fake news detection. While detection techniques are still in development, there is not much research on how readers can discern fake news without technological aid. This paper addresses such limitations regarding the study of fake news detection and provide a detection model for readers. The model is based on logical steps built on detection cues mentioned in previous works. The appropriateness of the detection cues will be determined based on case studies.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICEE50131.2020.9261053" target="_blank"> A semi-supervised learning method for fake news detection in social media<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85098333460</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Mansouri R., Naderan-Tahan M., Rashti M.J.</b></td></tr><tr><td colspan="3">Organisations: <b>Shahid Chamran University of Ahvaz</b></td></tr><tr><td colspan="3">'Fake news' is one of the most frequent terms in news media and their spread in online social medias has been grown in recent years. Their impact affect both personal and political decisions where the latter is more important. Due to the variety of news sources and the complexity of validations, machine learning approaches are used to automatically analyze the news. The aim of this research is to detect fake news using deep learning techniques. The method is based on a semi-supervised learning framework targeting both labeled and unlabeled data using convolutional neural network. In this method, first, various features of text and image data are extracted using CNN. Then, linear discrimination analysis (LDA) is used to predict the classes of unclassified data. Also, the fitness function is modified in a way to increase the effect of estimated class in each step. Results show that the proposed method outperforms other methods in terms of recall, specificity, and sensitivity with a precision value of 95.5%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.eswa.2020.114171" target="_blank"> Linguistic feature based learning model for fake news detection and classification<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85098453070</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Choudhary A., Arora A.</b></td></tr><tr><td colspan="3">Organisations: <b>Jaypee Institute of Information Technology</b></td></tr><tr><td colspan="3">Social media is used as a dominant source of news distribution among users. The world's preeminent decisions such as politics are acclaimed by social media to influence users for enclosing users' decisions in their favor. However, the adoption of social media is much needed for awareness but the authenticity of content is an unknown factor in the current scenario. Therefore, this research work finds it imperative to propose a solution to fake news detection and classification. In the case of fake news, content is the prime entity that captures the human mind towards trust for specific news. Therefore, a linguistic model is proposed to find out the properties of content that will generate language-driven features. This linguistic model extracts syntactic, grammatical, sentimental, and readability features of particular news. Language driven model requires an approach to handle time-consuming and handcrafted features problems in order to deal with the curse of dimensionality problem. Therefore, the neural-based sequential learning model is used to achieve superior results for fake news detection. The results are drawn to validate the importance of the linguistic model extracted features and finally combined linguistic feature-driven model is able to achieve the average accuracy of 86% for fake news detection and classification. The sequential neural model results are compared with machine learning based models and LSTM based word embedding based fake news detection model as well. Comparative results show that features based sequential model is able to achieve comparable evaluation performance in discernable less time.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.asoc.2020.106991" target="_blank"> Detecting fake news with capsule neural networks<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85098460876</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Goldani M.H., Momtazi S., Safabakhsh R.</b></td></tr><tr><td colspan="3">Organisations: <b>Amirkabir University of Technology</b></td></tr><tr><td colspan="3">Fake news has increased dramatically in social media in recent years. This has prompted the need for effective fake news detection algorithms. Capsule neural networks have been successful in computer vision and are receiving attention for use in Natural Language Processing (NLP). This paper aims to use capsule neural networks in the fake news detection task. We use different embedding models for news items of different lengths. Static word embedding is used for short news items, whereas non-static word embeddings that allow incremental uptraining and updating in the training phase are used for medium length or long news statements. Moreover, we apply different levels of n-grams for feature extraction. Our proposed models are evaluated on two recent well-known datasets in the field, namely ISOT and LIAR. The results show encouraging performance, outperforming the state-of-the-art methods by 7.8% on ISOT and 3.1% on the validation set, and 1% on the test set of the LIAR dataset.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/SCCC51225.2020.9281258" target="_blank"> A Brazilian Portuguese Moral Foundations Dictionary for Fake News classification<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85098657036</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Carvalho F., Okuno H.Y., Baroni L., Guedes G.</b></td></tr><tr><td colspan="3">Organisations: <b>CEFET/RJ</b></td></tr><tr><td colspan="3">The Moral Foundations Theory defines foundations to explain human moral reasoning and its role in the decision-making process, including how information is perceived and interpreted a problem related to aspects of moral values that is currently gaining notoriety is the spread of false information known as "Fake News". Natural language processing techniques are being used in social sciences studies to deal with the Fake News detection task. This work introduces and brings details from the development of MFD-BR, a Brazilian Portuguese lexicon based on the Moral Foundations Theory, designed to measure Moral Sentiment in texts. It also contributes to Fake News detection strategies by assessing the difference in moral dimensions to distinguish between reliable sources texts and texts originated from low-reputation sources (considered by fact-checking agencies).</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s42979-020-00165-4" target="_blank"> Fake News Detection Using a Blend of Neural Networks: An Application of Deep Learning<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85098686955</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Agarwal A., Pathak A., Mittal M., Goyal L.M.</b></td></tr><tr><td colspan="3">Organisations: <b>Thapar Institute of Engineering and Technology, G. B. Pant Government Engineering College, J. C. Bose University of Science and Technology</b></td></tr><tr><td colspan="3">Fake news and its consequences carry the potential of impacting different aspects of different entities, ranging from a citizen’s lifestyle to a country’s global relations, there are many related works for collecting and determining fake news, but no reliable system is commercially available. This study aims to propose a deep learning model which predicts the nature of an article when given as an input. It solely uses text processing and is insensitive to history and credibility of the author or the source. In this paper, authors have discussed and experimented using word embedding (GloVe) for text pre-processing in order to construct a vector space of words and establish a lingual relationship. The proposed model which is the blend of convolutional neural network and recurrent neural networks architecture has achieved benchmark results in fake news prediction, with the utility of word embeddings complementing the model altogether. Further, to ensure the quality of prediction, various model parameters have been tuned and recorded for the best results possible. Among other variations, addition of dropout layer reduces overfitting in the model, hence generating significantly higher accuracy values. It can be a better solution than already existing ones, viz: gated recurrent units, recurrent neural networks or feed-forward networks for the given problem, which generates better precision values of 97.21% while considering more input features.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s00521-020-05611-1" target="_blank"> EchoFakeD: improving fake news detection in social media with an efficient deep neural network<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85098717412</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Kaliyar R.K., Goswami A., Narang P.</b></td></tr><tr><td colspan="3">Organisations: <b>Bennett University, BITS Pilani</b></td></tr><tr><td colspan="3">The increasing popularity of social media platforms has simplified the sharing of news articles that have led to the explosion in fake news. With the emergence of fake news at a very rapid rate, a serious concern has produced in our society because of enormous fake content dissemination. The quality of the news content is questionable and there exists a necessity for an automated tool for the detection. Existing studies primarily focus on utilizing information extracted from the news content. We suggest that user-based engagements and the context related group of people (echo-chamber) sharing the same opinions can play a vital role in the fake news detection. Hence, in this paper, we have focused on both the content of the news article and the existence of echo chambers in the social network for fake news detection. Standard factorization methods for fake news detection have limited effectiveness due to their unsupervised nature and primarily employed with traditional machine learning models. To design an effective deep learning model with tensor factorization approach is the priority. In our approach, the news content is fused with the tensor following a coupled matrix–tensor factorization method to get a latent representation of both news content as well as social context. We have designed our model with a different number of filters across each dense layer along with dropout. To classify on news content and social context-based information individually as well as in combination, a deep neural network (our proposed model) was employed with optimal hyper-parameters. The performance of our proposed approach has been validated on a real-world fake news dataset: BuzzFeed and PolitiFact. Classification results have demonstrated that our proposed model (EchoFakeD) outperforms existing and appropriate baselines for fake news detection and achieved a validation accuracy of 92.30%. These results have shown significant improvements over the existing state-of-the-art models in the area of fake news detection and affirm the potential use of the technique for classifying fake news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICCCS49678.2020.9277353" target="_blank"> DeepNet: An efficient neural network for fake news detection using news-user engagements<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85098873932</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Kaliyar R.K., Kumar P., Kumar M., Narkhede M., Namboodiri S., Mishra S.</b></td></tr><tr><td colspan="3">Organisations: <b>Bennett University, Civil Engineering IIT(BHU), Computer Science and Engineering Nit Agartala, Electronics and Telecommunication College of Engineering, Electronics and Communication Vidya Academy of Science and Technology, Galgotias University</b></td></tr><tr><td colspan="3">The rise of social media allows every user to share and immediately publish their views. Today, the problem of fake news has obtained significant consideration among researchers due to its harmful nature to deceive the people of the society. It has created an alarming situation in the world. News ecosystem evolved from a small set of trusted and regulated sources to numerous online news sources. Fake news has an adverse impact on society as it may manipulate public opinions. Thus, it is essential to investigate the credibility of news articles shared on social media outlets. In this paper, we have designed an effective deep neural network that is capable of handling not only the content of the news article but also the user-relationships in the social network. We have designed our proposed approach using tensor factorization method. A tensor expresses the social context of news articles formed by a combination of the news, user, and user-group information. Our proposed method (DeepNet) has validated on a real-world fake news dataset: BuzzFeed and Fakeddit. DeepNet outperforms from existing fake news detection methods by employing deep architecture with different kernelsizes convolutional layers combining news content and social context-based features.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3430984.3431064" target="_blank"> MCNNet: Generalizing Fake News Detection with a Multichannel Convolutional Neural Network using a Novel COVID-19 Dataset<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85098884119</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Kaliyar R.K., Goswami A., Narang P.</b></td></tr><tr><td colspan="3">Organisations: <b>Bennett University, Bits Pilani</b></td></tr><tr><td colspan="3">During the pandemic of COVID-19, the propagation of fake news is spreading like wildfire on social media. Such fake news articles have created confusion among people and serious social disruptions as well. To detect such news articles effectively, we propose a generalized classification model (MCNNet) having the power of learning across different kernel-sized convolutional layers in different parallel channel network. The capability of MCNNet is lucrative towards any real-world fake news dataset. Experimental results have demonstrated the performance of our model with different real-world fake news datasets.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ISI49825.2020.9280531" target="_blank"> Political Fake Statement Detection via Multistage Feature-assisted Neural Modeling<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85098994886</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Hassan F.M., Lee M.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Birmingham, Simad University</b></td></tr><tr><td colspan="3">Fake news detection has recently gained much attention from the wider NLP community due to its importance for preventing the spread of misinformation and its negative impact through the social media. The goal of this task is to classify the veracity labels of a statement expressed by a politician into fine-grained classes (degrees of truth). Previous deep learning approaches have significantly improved the performance of Political Fake Statement Detection by modeling statement with the speaker's credit history. However, the credit history may not be available in reality and most approaches did not consider about the evidence that supporting or denying claims when detecting fake news. In addition, state-of-the-art models may struggle to detect fine-grained labels because the statement of the speaker expresses factual and incorrect instances at the same time. In this paper, we approach the Political Fake Statement Detection problem by proposing two multi-stage feature-assisted neural models that consider claims and justifications as an input in a stance detection manner. We explore five-stage and three-stage classification strategies to better discern between the fine-grained labels of fake news. The proposed model in each stage is built on the powerful combination between dual GRU layers and lexical features which we further optimise by using Gaussian Noise. An extensive experimental work on a real-world benchmark LIARPLUS (an extended version of LIAR) dataset shows that three-stage model achieves state-of-the-art Accuracy (46.13%) and F1score (45.13%) without using metadata and the credit history of the speaker. We also experimentally show that modeling the credit history in conjunction with statement and justification gives more than 6% improvement (e.g. 52.23% and 52.26% respectively).</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Sifting the arguments in fake news to boost a disinformation analysis tool<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85099035090</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Delobelle J., Cabrio E., Villata S., Delamaire A., Ruti R.</b></td></tr><tr><td colspan="3">Organisations: <b>Universite Cote d'Azur, Storyzy</b></td></tr><tr><td colspan="3">The problem of disinformation spread on the Web is receiving an increasing attention, given the potential danger fake news represents for our society. Several approaches have been proposed in the literature to fight fake news, depending on the media such fake news are concerned with, i.e., text, images, or videos. Considering textual fake news, many open problems arise to go beyond simple keywords extraction based approaches. In this paper, we present a concrete application scenario where a fake news detection system is empowered with an argument mining model, to highlight and aid the analysis of the arguments put forward to support or oppose a given target topic in articles containing fake information.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.asoc.2020.107050" target="_blank"> Advanced Machine Learning techniques for fake news (online disinformation) detection: A systematic mapping study<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85099037687</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Choras M., Gielczyk A., Demestichas K., Remoundou K., Herrero A., Urda D., Ksieniewicz P., Wozniak M.</b></td></tr><tr><td colspan="3">Organisations: <b>UTP University of Science and Technology, National Technical University of Athens, Universidad de Burgos, Wrocław University of Science and Technology</b></td></tr><tr><td colspan="3">Fake news has now grown into a big problem for societies and also a major challenge for people fighting disinformation. This phenomenon plagues democratic elections, reputations of individual persons or organizations, and has negatively impacted citizens, (e.g., during the COVID-19 pandemic in the US or Brazil). Hence, developing effective tools to fight this phenomenon by employing advanced Machine Learning (ML) methods poses a significant challenge. The following paper displays the present body of knowledge on the application of such intelligent tools in the fight against disinformation. It starts by showing the historical perspective and the current role of fake news in the information war. Proposed solutions based solely on the work of experts are analysed and the most important directions of the application of intelligent systems in the detection of misinformation sources are pointed out. Additionally, the paper presents some useful resources (mainly datasets useful when assessing ML solutions for fake news detection) and provides a short overview of the most important R&D projects related to this subject. The main purpose of this work is to analyse the current state of knowledge in detecting fake news; on the one hand to show possible solutions, and on the other hand to identify the main challenges and methodological gaps to motivate future research.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s11042-020-10183-2" target="_blank"> FakeBERT: Fake news detection in social media with a BERT-based deep learning approach<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85099110861</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Kaliyar R.K., Goswami A., Narang P.</b></td></tr><tr><td colspan="3">Organisations: <b>Bennett University, BITS Pilani</b></td></tr><tr><td colspan="3">In the modern era of computing, the news ecosystem has transformed from old traditional print media to social media outlets. Social media platforms allow us to consume news much faster, with less restricted editing results in the spread of fake news at an incredible pace and scale. In recent researches, many useful methods for fake news detection employ sequential neural networks to encode news content and social context-level information where the text sequence was analyzed in a unidirectional way. Therefore, a bidirectional training approach is a priority for modelling the relevant information of fake news that is capable of improving the classification performance with the ability to capture semantic and long-distance dependencies in sentences. In this paper, we propose a BERT-based (Bidirectional Encoder Representations from Transformers) deep learning approach (FakeBERT) by combining different parallel blocks of the single-layer deep Convolutional Neural Network (CNN) having different kernel sizes and filters with the BERT. Such a combination is useful to handle ambiguity, which is the greatest challenge to natural language understanding. Classification results demonstrate that our proposed model (FakeBERT) outperforms the existing models with an accuracy of 98.90%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/TBDATA.2020.3048961" target="_blank"> A Memory Network Information Retrieval Model for Identification of News Misinformation<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85099218409</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Ebadi N., Jozani M., Choo K.R., Rad P.</b></td></tr><tr><td colspan="3">Organisations: <b>_, _, _, _</b></td></tr><tr><td colspan="3">The speed and volume at which misinformation spreads on social media have motivated efforts to automate fact-checking which begins with stance detection. For fake news stance detection, for example, many classification-based models have been proposed often with high complexity and hand-crafted features. Although these models can achieve high accuracy scores on a targeted small corpus of fake news, few are evaluated on a larger corpus of fake and conspiracy sites due to efficiency limitations and the lack of compatibility with the actual fact-checking process. In this research, we propose a practical two-stage stance detection model that is tailored to the real-life problem. Specifically, we integrate an information retrieval system with an end to end memory network model to sort articles based on their relevance to the claim and then identify the fine-grained stance of each relevant article towards its given claim. We evaluate our model on the Fake News Challenge dataset. The results show that the performance of our model is comparable to those of the state-of-the-art models, average weighted accuracy of 82.1, while it closely follows the real-life process of fact-checking. We also validate our model with a large dataset from a real-life fact-checking website, and the findings demonstrate</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/Blockchain50366.2020.00026" target="_blank"> WhistleBlower: Towards A Decentralized and Open Platform for Spotting Fake News<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85099258484</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Ramachandran G., Nemeth D., Neville D., Zhelezov D., Yalcin A., Fohrmann O., Krishnamachari B.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Southern California, Helix Foundation</b></td></tr><tr><td colspan="3">The vast majority of the population is consuming news from various digital sources, including social networking applications such as Twitter and Facebook and other online digital platforms. Such Internet platforms provide malicious entities an opportunity to spread fake news and hoaxes to mislead the population. Besides, Internet users may start to form an opinion and make certain personal or business decisions based on misinformation, leading to undesirable consequences. This paper introduces WhistleBlower, a decentralized and open platform based on the blockchain and distributed ledger technology (DLT) for spotting fake news. The key components of WhistleBlower include a fake news processing engine powered by Artificial Intelligence (AI)/Machine Learning (ML) algorithms, a verifiable computation engine, and a token-curated registry (TCR).WhistleBlower allows the community members to participate in the fake news identification process by running the fake news detection algorithm on their nodes, which would then be validated by a verifiable computation engine to ensure that the public nodes executed the computation honestly and correctly. Whenever a news feed is submitted to WhistleBlower for fake news assessment, it issues a genuineness score, which can then be posted along with the news article to let the newsreaders gauge its legitimacy. However, the genuineness score's accuracy depends on the machine learning model's effectiveness that processes the news item. To improve the machine learning algorithm's reliability, we introduce a Token-curated registry, which enables the public and community members to challenge the algorithm used to estimate the genuineness score. TCR lets the community curate fake news detection algorithms by providing feedback to the ML/AI algorithm developers through the token-curated content moderation process. WhistleBlower is the first open and democratic fake news assessment platform that combines ML/AI, verifiable computation, and TCR to the best of our knowledge.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.6017/ITAL.V39I4.12483" target="_blank"> Automated fake news detection in the age of digital libraries<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85099259062</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Mertoglu U., Genc B.</b></td></tr><tr><td colspan="3">Organisations: <b>Hacettepe University</b></td></tr><tr><td colspan="3">The transformation of printed media into the digital environment and the extensive use of social media have changed the concept of media literacy and people's habits of news consumption. While online news is faster, easier, comparatively cheaper, and offers convenience in terms of people's access to information, it speeds up the dissemination of fake news. Due to the free production and consumption of large amounts of data, fact-checking systems powered by human efforts are not enough to question the credibility of the information provided, or to prevent its rapid dissemination like a virus. Libraries, long known as sources of trusted information, are facing challenges caused by misinformation as mentioned in studies about fake news and libraries.1 Considering that libraries are undergoing digitization processes all over the world and are providing digital media to their users, it is very likely that unverified digital content will be served by world's libraries. The solution is to develop automated mechanisms that can check the credibility of digital content served in libraries without manual validation. For this purpose, we developed an automated fake news detection system based on Turkish digital news content. Our approach can be modified for any other language if there is labelled training material. This model can be integrated into libraries' digital systems to label served news content as potentially fake whenever necessary, preventing uncontrolled falsehood dissemination via libraries.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3430199.3430220" target="_blank"> Automatic Differentiation between Legitimate and Fake News Using Named Entity Recognition<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85099337374</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Xu B.S., Tsai C.M.</b></td></tr><tr><td colspan="3">Organisations: <b>Xiamen International School, Hsing Wu University</b></td></tr><tr><td colspan="3">Today, the increasing ease of publishing information online combined with a gradual shift of paradigm from consuming news via conventional media to non-conventional media calls for a computational and automatic approach to the identification of an article's legitimacy. In this study, we propose an approach for cross-domain fake news detection focusing on the identification of legitimate content from a pool of articles that are of varying degrees of legitimacy. We present a model as a proof of concept as well as data gathered from evaluating the model on Fake-News AMT, a dataset released for cross-domain fake news detection. The results of our model are then compared against a baseline model which has served as the benchmark for the dataset. We find all results in support of our hypothesis. Our proof-of-concept model has also outperformed the benchmark in the domains Technology and Entertainment as well as when it was run on the whole dataset at once.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.3390/info12010020" target="_blank"> Combating fake news in “low-resource” languages: Amharic fake news detection accompanied by resource crafting<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85099398282</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Gereme F., Zhu W., Ayall T., Alemu D.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Electronic Science and Technology of China</b></td></tr><tr><td colspan="3">The need to fight the progressive negative impact of fake news is escalating, which is evi-dent in the strive to do research and develop tools that could do this job. However, a lack of adequate datasets and good word embeddings have posed challenges to make detection methods sufficiently accurate. These resources are even totally missing for “low-resource” African languages, such as Amharic. Alleviating these critical problems should not be left for tomorrow. Deep learning methods and word embeddings contributed a lot in devising automatic fake news detection mechanisms. Several contributions are presented, including an Amharic fake news detection model, a general-purpose Amharic corpus (GPAC), a novel Amharic fake news detection dataset (ETH_FAKE), and Amharic fasttext word embedding (AMFTWE). Our Amharic fake news detection model, evaluated with the ETH_FAKE dataset and using the AMFTWE, performed very well.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Automatic detection of fake news<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85099418946</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Nordberg P., Kavrestad J., Nohlberg M.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Skövde</b></td></tr><tr><td colspan="3">Following the American presidential election in 2016, the terms”fake news” was popularized and has since been a common term in the public vocabulary. While quite recently popularized, fake news is a phenomenon that is as old as news itself and is most commonly defined as purposeful disinformation used to untrue information or skewed reporting intended to push a certain narrative. In recent years, fake news has seen frequently in attempts to influence elections or by organized crime organizations in various efforts to make money, not least drawing from the ongoing CoVid-19 pandemic. We argue that the phenomenon must be researched from technical as well as from social aspects, since it involved using technical tools to spread information targeted humans. In this paper, we identify key methods for automatic fake news detection in order to lay the foundation for end-user support system designed to help users identify and avoid fake news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/iThings-GreenCom-CPSCom-SmartData-Cybermatics50389.2020.00061" target="_blank"> Adversarial Domain Adaptation for Crisis Data Classification on Social Media<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85099441877</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Chen Q., Wang W., Huang K., De S., Coenen F.</b></td></tr><tr><td colspan="3">Organisations: <b>Xi'an Jiaotong Liverpool University, University of Winchester, University of Liverpool</b></td></tr><tr><td colspan="3">Smart cities are cyber-physical-social systems, where city data from different sources could be collected, processed and analyzed to extract useful knowledge. As the volume of data from the social world is exploding, social media data analysis has become an emerging area in many different disciplines. During crisis events, users may post informative tweets about affected individuals, utility damage or cautions on social media platforms. If such tweets are efficiently and effectively processed and analyzed, city organizations may gain a better situational awareness of the affected citizens and provide better response actions. Advances in deep neural networks have significantly improved the performance in many social media analyzing tasks, e.g., sentiment analysis, fake news detection, crisis data classification, etc. However, deep learning models require a large amount of labeled data for model training, which is impractical to collect, especially at the early stage of a crisis event. To address this limitation, we proposed a BERT-based Adversarial Domain Adaptation model (BERT-ADA) for crisis tweet classification. Our experiments with three real-world crisis datasets demonstrate the advantages of the proposed model over several baselines.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICDSE50459.2020.9310133" target="_blank"> BiLSTM-Autoencoder Architecture for Stance Prediction<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85099533448</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Padnekar S.M., Kumar G.S., Deepak P.</b></td></tr><tr><td colspan="3">Organisations: <b>Cochin University of Science and Technology, Queen's University</b></td></tr><tr><td colspan="3">The recent surge in the abundance of fake news appearing on social media and news websites poses a potential threat to high-quality journalism. Misinformation hurts people, society, science, and democracy. This reason has led many researchers to develop techniques to identify fake news. In this paper, we discuss a stance prediction technique using the Deep Learning approach, which can be used as a factor to determine the authenticity of news articles. The Fake News Stance Prediction is the process of automatically classifying the stance of a news article towards a target into one of the following classes: Agree, Disagree, Discuss, Unrelated. The stance prediction task's input is the news articles containing a pair: a headline as the target and a body as a claim. This paper proposes a deep learning architecture using Bi-directional Long Short Term Memory and Autoencoder for stance prediction. We illustrate, through empirical studies, that the method is reasonably accurate at predicting stance, achieving a classification accuracy as high as 94%. The proposed stance detection method would be useful for assessing the credibility of news articles.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Educational approaches to address fake news - Preliminary insights from a systematic review<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85099542520</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Eisemann C., Pimmer C.</b></td></tr><tr><td colspan="3">Organisations: <b>FHNW University of Applied Sciences and Arts Northwestern Switzerland</b></td></tr><tr><td colspan="3">Fake and false news, an unfortunate hallmark of today's information society, have serious political and societal consequences. Little systematic knowledge is available about effective learning, teaching and awareness-raising strategies that help users in addressing fake news. This study reports preliminary results from a systematic literature review aimed at systematising different approaches and determining their effectiveness. Three main approaches emerged in the analysis: Firstly, the findings suggest that strategies to correct existing misconceptions caused by fake news have limited effectiveness and can be even counterproductive, particularly for polarising topics. Secondly, the evidence on the effectiveness of training on fake news detection methods is encouraging but inconclusive. Thirdly, despite the common perception that fake news detection needs to be linked to an understanding of the economic, ideological and cultural dimensions of media systems, the few empirical studies found in this area did little to support this claim. A tentative conclusion from these findings is the need to integrate education on false news and training on fake news detection strategies in educational programmes as early as children's media consumption starts.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> From clickbait to fake news detection: An approach based on detecting the stance of headlines to articles<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85099567002</td><td>Year: <b>2017</b></td></tr><tr><td colspan="3">Authors: <b>Bourgonje P., Schneider J.M., Rehm G.</b></td></tr><tr><td colspan="3">Organisations: <b>Dfki GmbH</b></td></tr><tr><td colspan="3">We present a system for the detection of the stance of headlines with regard to their corresponding article bodies. The approach can be applied in fake news, especially clickbait detection scenarios. The component is part of a larger platform for the curation of digital content; we consider veracity and relevancy an increasingly important part of curating online information. We want to contribute to the debate on how to deal with fake news and related online phenomena with technological means, by providing means to separate related from unrelated headlines and further classifying the related headlines. On a publicly available data set annotated for the stance of headlines with regard to their corresponding article bodies, we achieve a (weighted) accuracy score of 89.59.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/SSCI47803.2020.9308298" target="_blank"> The Adversarial UFP/UFN Attack: A New Threat to ML-based Fake News Detection Systems?<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85099686900</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Brown B., Richardson A., Smith M., Dozier G., King M.C.</b></td></tr><tr><td colspan="3">Organisations: <b>Auburn University, School of Computing</b></td></tr><tr><td colspan="3">In this paper, we propose two new attacks: the Adversarial Universal False Positive (UFP) Attack and the Adversarial Universal False Negative (UFN) Attack. The objective of this research is to introduce a new class of attack using only feature vector information. The results show the potential weaknesses of five machine learning (ML) classifiers. These classifiers include k-Nearest Neighbor (KNN), Naive Bayes (NB), Random Forrest (RF), a Support Vector Machine (SVM) with a Radial Basis Function (RBF) Kernel, and XGBoost (XGB).</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/SSCI47803.2020.9308613" target="_blank"> A Study of the Impact of Evolutionary-Based Feature Selection for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85099707023</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Smith M., Richardson A., Brown B., Dozier G., King M., Morris J.</b></td></tr><tr><td colspan="3">Organisations: <b>Auburn University, School of Computing, University of Missouri</b></td></tr><tr><td colspan="3">Fake news is becoming an increasingly invasive problem within our society. As our society becomes more ingrained in technology, news has become more susceptible to technological predation. In this paper, we demonstrate how evolutionary-based feature selection increases fake news detection while dramatically reducing the number of features needed.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/AICCSA50499.2020.9316504" target="_blank"> A Semantic Model for Context-Based Fake News Detection on Social Media<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85099791575</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Bani-Hani A., Majdalawieh M., Al-Obeidat F., Adedugbe O., Benkhelifa E.</b></td></tr><tr><td colspan="3">Organisations: <b>Zayed University, Staffordshire University</b></td></tr><tr><td colspan="3">Context-based fake news detection provides means to define and describe a social context for news objects on social media, thereby facilitating detection of fake news through data analysis and patterns recognition. However, while content-based fake news detection has gained popularity with machine learning and NLP techniques, the context-based approach has seen very little exploitation. Therefore, it has become pertinent to significantly explore and integrate other technologies for context-based detection of fake news on social media. With semantic technologies capabilities to provide context-awareness for data, this paper analyses social media context and develops a taxonomy for entities classification. Furthermore, a semantic model is developed to describe classes extracted from the taxonomy towards fully semantically describing concepts, relations, instances, and axioms. The model would enhance fake news detection through semantic annotation for contextual features of news objects and datasets, providing a basis for patterns recognition, analysis, and identification of news articles on social media as either fake or not.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICPAI51961.2020.00009" target="_blank"> Bidirectional Perspective with Topic Information for Stance Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85100023188</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Lin S.-X., Wu B.-Y., Chou T.-H., Lin Y.-J., Kao H.-Y.</b></td></tr><tr><td colspan="3">Organisations: <b>National Cheng Kung University</b></td></tr><tr><td colspan="3">Because of the convenience of the Internet, there are many websites or online news spread misinformation, cause panic and trepidation in society. Automatic fake news detection can classify fake news and help the society to clarify the information is true or false without human checking. Detecting fake news by analyzing the stance is one of the mainstream methods, stance detection has become a new popular research field in recent years. How to accurately detect stance has become the primary goal of detecting fake news. This research aims to detect the news stance accurately, and we propose a method based on a pre-trained BERT language model. Most of the previous work only used the knowledge of single inference direction when classifying the stance, which may lose some important information. Therefore, we propose a bidirectional inference stance detection model, which can leverage bidirectional perspective information to classify the stance more comprehensively. We also define the stance detection task as a hierarchical structure task, and use the hierarchical classification and incorporate the topic information to help the stance classification. Experiment results show that our model can classify the stance more accurately.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICCWAMTIP51612.2020.9317325" target="_blank"> Fake News Detection using Deep Recurrent Neural Networks<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85100036063</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Jiang T., Li J.P., Haq A.U., Saboor A.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Electronic Science and Technology of China</b></td></tr><tr><td colspan="3">The widely spread of fake news has significantly impacted our life in politics and economics. To solve this problem, different researchers have proposed various machine learning and deep learning models. However, most of them detect fake news without desired accuracy. Therefore, we proposed a deep learning framework that classifies fake news from real ones with 99.82% accuracy. This BiLSTM model was trained and tested on a fact-checking dataset. Furthermore, we used different model evaluation metrics like precision, recall, Fl-meassure, execution time to prove the efficiency of our model.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICITR51448.2020.9310890" target="_blank"> Hybrid Approach and Architecture to Detect Fake News on Twitter in Real-Time using Neural Networks<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85100080443</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Thilakarathna M.P., Wijayasekara V.A., Gamage Y., Peiris K.H., Abeysinghe C., Rafaideen I., Vekneswaran P.</b></td></tr><tr><td colspan="3">Organisations: <b>Informatics Institute of Technology</b></td></tr><tr><td colspan="3">Fake news has been a key issue since the dawn of social media. Currently, we are at a stage where it is merely impossible to differentiate between real and fake news. This directly and indirectly affects people's decision patterns and makes us question the credibility of the news shared via social media platforms. Twitter is one of the leading social networks in the world by active users. There has been an exponential spread of fake news on Twitter in the recent past. In this paper, we will discuss the implementation of a browser extension which will identify fake news on Twitter using deep learning models with a focus on real-world applicability, architectural stability and scalability of such a solution. Experimental results show that the proposed browser extension has an accuracy of 86% accuracy in fake news detection. To the best of our knowledge, our work is the first of its kind to detect fake news on Twitter real-time using a hybrid approach and evaluate using real users.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/CICT51604.2020.9312099" target="_blank"> Fake news detection: A comparison between available Deep Learning techniques in vector space<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85100209478</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Singh L.</b></td></tr><tr><td colspan="3">Organisations: <b>Punjab Engineering College</b></td></tr><tr><td colspan="3">Fake News Detection is an essential problem in the field of Natural Language Processing. The benefits of an effective solution in this area are manifold for the goodwill of society. On a surface level, it broadly matches with the general problem of text classification. Researchers have proposed various approaches to tackle fake news using simple as well as some complex techniques. In this paper, we try to make a comparison between the present Deep Learning techniques by representing the news instances in some vector space using a combination of common mathematical operations with available vector space representations. We do a number of experiments using various combinations and permutations. Finally, we conclude with a sound analysis of the results and evaluate the reasons for such results.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> A literature review of nlp approaches to fake news detection and their applicability to romanian-language news analysis<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85100220032</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Busioc C., Ruseti S., Dascalu M.</b></td></tr><tr><td colspan="3">Organisations: <b>Politehnica University of Bucharest</b></td></tr><tr><td colspan="3">Fighting fake news is a difficult and challenging task. With an increasing impact on the social and political environment, fake news exert an unprecedently dramatic influence on people’s lives. In response to this phenomenon, initiatives addressing automated fake news detection have gained popularity, generating widespread research interest. However, most approaches targeting English and low-resource languages experience problems when devising such solutions. This study focuses on the progress of such investigations, while highlighting existing solutions, challenges, and observations shared by various research groups. In addition, given the limited amount of automated analyses performed on Romanian fake news, we inspect the applicability of the available approaches in the Romanian context, while identifying future research paths.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3428757.3429107" target="_blank"> ReSCo-CC: Unsupervised Identification of Key Disinformation Sentences<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85100356222</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Ghosal S.S., Deepak P., Jurek-Loughrey A.</b></td></tr><tr><td colspan="3">Organisations: <b>NIT Durgapur, Queen's University</b></td></tr><tr><td colspan="3">Disinformation is often presented in long textual articles, especially when it relates to domains such as health, often seen in relation to COVID-19. These articles are typically observed to have a number of trustworthy sentences among which core disinformation sentences are scattered. In this paper, we propose a novel unsupervised task of identifying sentences containing key disinformation within a document that is known to be untrustworthy. We design a three-phase statistical NLP solution for the task which starts with embedding sentences within a bespoke feature space designed for the task. Sentences represented using those features are then clustered, following which the key sentences are identified through proximity scoring. We also curate a new dataset with sentence level disinformation scorings to aid evaluation for this task; the dataset is being made publicly available to facilitate further research. Based on a comprehensive empirical evaluation against techniques from related tasks such as claim detection and summarization, as well as against simplified variants of our proposed approach, we illustrate that our method is able to identify core disinformation effectively.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3441501.3441541" target="_blank"> UrduFake@FIRE2020: Shared Track on Fake News Identification in Urdu<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85100401805</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Amjad M., Sidorov G., Gelbukh A., Zhila A., Rosso P.</b></td></tr><tr><td colspan="3">Organisations: <b>Instituto Politécnico Nacional, Independent Researcher, Universitat Politècnica de València</b></td></tr><tr><td colspan="3">This paper gives the overview of the first shared task at FIRE 2020 on fake news detection in the Urdu language. This is a binary classification task in which the goal is to identify fake news using a dataset composed of 900 annotated news articles for training and 400 news articles for testing. The dataset contains news in five domains: (i) Health, (ii) Sports, (iii) Showbiz, (iv) Technology, and (v) Business. 42 teams from 6 different countries (India, China, Egypt, Germany, Pakistan, and the UK) registered for the task. 9 teams submitted their experimental results. The participants used various machine learning methods ranging from feature-based traditional machine learning to neural network techniques. The best performing system achieved an F-score value of 0.90, showing that the BERT-based approach outperforms other machine learning classifiers.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Overview of the shared task on fake news detection in urdu at FIRE 2020<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85100434476</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Amjad M., Sidorov G., Gelbukh A., Zhila A., Rosso P.</b></td></tr><tr><td colspan="3">Organisations: <b>Instituto Politécnico Nacional (IPN), Independent Researcher, Universitat Politècnica de València</b></td></tr><tr><td colspan="3">This overview paper describes the first shared task on fake news detection in Urdu language. The task was posed as a binary classification task, in which the goal is to differentiate between real and fake news. We provided a dataset divided into 900 annotated news articles for training and 400 news articles for testing. The dataset contained news in five domains: (i) Health, (ii) Sports, (iii) Showbiz, (iv) Technology, and (v) Business. 42 teams from 6 different countries (India, China, Egypt, Germany, Pakistan, and the UK) registered for the task. 9 teams submitted their experimental results. The participants used various machine learning methods ranging from feature-based traditional machine learning to neural networks techniques. The best performing system achieved an F-score value of 0.90, showing that the BERT-based approach outperforms other machine learning techniques.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/SCSE49731.2020.9313024" target="_blank"> Keyword extraction from Tweets using NLP tools for collecting relevant news<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85100463498</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Jayasiriwardene T.D., Ganegoda G.U.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Moratuwa</b></td></tr><tr><td colspan="3">Keywords play a major role in representing the gist of a document. Therefore, a lot of Natural Language processing tools have been implemented to identify keywords in both structured and unstructured texts. Text that appears in social media platforms such as twitter is mostly unstructured because of the character limitation. Consequently, a lot of short terms and symbols such as emoticons and URLs are included in tweets. Keyword extraction from grammatically ambiguous text is not easy compared to structured text since it is hard to rely on the linguistic features in unstructured texts. But when it comes to news on twitter, it may contain somewhat structured text than informal text does but it depends on the tweeter, the person who posts the tweet. In this paper, a methodology is proposed to extract keywords from a given tweet to retrieve relevant news that has been posted on twitter, for fake news detection. The intention of extracting keywords is to find more related news efficiently and effectively. For this approach, a corpus that contains tweet texts from different domains is built in order to make this approach more generic instead of making it a domain-specific approach. In fact, the Stanford Core NLP tool kit, Wordnet linguistic database and statistical method are used for extracting keywords from a tweet. For the system evaluation, the Turing test which has human intervention is used. The system was able to acquire an accuracy of 67.6% according to the evaluation conducted.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/TKDE.2021.3054993" target="_blank"> An Integrated Multi-Task Model for Fake News Detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85100466428</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Liao Q., Chai H., Han H., Zhang X., Wang X., Xia W., Ding Y.</b></td></tr><tr><td colspan="3">Organisations: <b>Harbin Institute of Technology(Shenzhen), Peng Cheng Laboratory, National University of Defence Technology, Dongguan University of Technology</b></td></tr><tr><td colspan="3">Fake news detection attracts many researchers' attention due to the negative impacts on the society. Most existing fake news detection approaches mainly focus on semantic analysis of news' contents. However, the detection performance will dramatically decrease when the content of news is short. In this paper, we propose a novel fake news detection multi-task learning (FDML) model based on the following observations: 1) some certain topics have higher percentages of fake news; and 2) some certain news authors have higher intentions to publish fake news. FDML model investigates the impact of topic labels for the fake news and introduce contextual information of news at the same time to boost the detection performance on the short fake news. Specifically, the FDML model consists of representation learning and multi-task learning parts to train the fake news detection task and the news topic classification task, simultaneously. As far as we know, this is the first fake news detection work that integrates the above two tasks. The experiment results show that the FDML model outperforms state-of-the-art methods on real-world fake news dataset.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1177/0165551520985486" target="_blank"> Detection of conspiracy propagators using psycho-linguistic characteristics<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85100474281</td><td>Year: <b>2023</b></td></tr><tr><td colspan="3">Authors: <b>Giachanou A., Ghanem B., Rosso P.</b></td></tr><tr><td colspan="3">Organisations: <b>Universitat Politècnica de València, Utrecht University, Symanto Research</b></td></tr><tr><td colspan="3">The rise of social media has offered a fast and easy way for the propagation of conspiracy theories and other types of disinformation. Despite the research attention that has received, fake news detection remains an open problem and users keep sharing articles that contain false statements but which they consider real. In this article, we focus on the role of users in the propagation of conspiracy theories that is a specific type of disinformation. First, we compare profile and psycho-linguistic patterns of online users that tend to propagate posts that support conspiracy theories and of those who propagate posts that refute them. To this end, we perform a comparative analysis over various profile, psychological and linguistic characteristics using social media texts of users that share posts about conspiracy theories. Then, we compare the effectiveness of those characteristics for predicting whether a user is a conspiracy propagator or not. In addition, we propose ConspiDetector, a model that is based on a convolutional neural network (CNN) and which combines word embeddings with psycho-linguistic characteristics extracted from the tweets of users to detect conspiracy propagators. The results show that ConspiDetector can improve the performance in detecting conspiracy propagators by 8.82% compared with the CNN baseline with regard to F1-metric.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICTer51097.2020.9325477" target="_blank"> CNN, RNN-LSTM Based Hybrid Approach to Detect State-of-the-Art Stance-Based Fake News on Social Media<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85100490946</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Goonathilake M.D.P.P., Kumaral P.P.N.V.</b></td></tr><tr><td colspan="3">Organisations: <b>General Sir John Kotelawala Defence University</b></td></tr><tr><td colspan="3">Fake news is a new phenomenon related to false information and fraud that spreads through online social media or traditional news media. Today, fake news can be easily created and distributed across many social media platforms and has a widespread impact on the real world. It is critical to develop efficient algorithms and tools for early detection of how false information is disseminated on social media platforms and why it is successful in deceiving users. Most research methods today are based on machine learning, deep learning, feature engineering, graph mining, image and video analysis and newly developed datasets and web services for detecting deceptive content. Therefore, a strong need emerges to find a suitable method that can easily detect false information. A hybrid approach has suggested using the CNN model and RNN-LSTM model to detect false information from this study. First, NLTK toolkit has used to remove stop words, punctuations and special characters from the text. Then the same toolkit applies to tokenize the text and preprocesses the text. From there on, GloVe word embeddings have added to the preprocessed text. Higher-level features of the input text extract from the CNN model using convolutional layers and max-pooling layers. Long-term dependencies between word sequences capture from RNN-LSTM model. The suggested model also applies dropout technology with Dense layers to enhance the efficiency of the hybrid model. Results of the suggested hybrid model have shown that the suggested CNN, RNN-LSTM based Hybrid approach achieves the highest accuracy of 92% by surpassing most of the classical models today with Adam optimizer and Binary Cross-Entropy loss function.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ACCESS.2020.3022867" target="_blank"> Detecting misleading information on COVID-19<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85100510115</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Elhadad M.K., Li K.F., Gebali F.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Victoria</b></td></tr><tr><td colspan="3">This article addresses the problem of detecting misleading information related to COVID-19. We propose a misleading-information detection model that relies on the World Health Organization, UNICEF, and the United Nations as sources of information, as well as epidemiological material collected from a range of fact-checking websites. Obtaining data from reliable sources should assure their validity. We use this collected ground-truth data to build a detection system that uses machine learning to identify misleading information. Ten machine learning algorithms, with seven feature extraction techniques, are used to construct a voting ensemble machine learning classifier. We perform 5-fold cross-validation to check the validity of the collected data and report the evaluation of twelve performance metrics. The evaluation results indicate the quality and validity of the collected ground-truth data and their effectiveness in constructing models to detect misleading information.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/iCAST51195.2020.9319485" target="_blank"> A fake news dissemination model based on updating reliability and doubt among individuals<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85100628654</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Yoshikawa K., Awa T., Kusano R., Sato H., Ichino M., Yoshiura H.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Electro-Communications</b></td></tr><tr><td colspan="3">As social media has become more widely used, fake news has become an increasingly serious problem. The representative countermeasures against fake news are fake news detection and automated fact-checking. However, these countermeasures are not sufficient because people using social media tend to ignore facts that contradict their current beliefs. Therefore, developing effective countermeasures requires understanding the nature of fake news dissemination. Previous models related to this aim have been proposed for describing and analyzing opinion dissemination among people. However, these models are not adequate because they are based on the assumptions that ignore the presence of fake. That is, they assume that people believe their friends equally without doubting and that reliability among people does not change. In this paper, we propose a model that can better describe the opinion dissemination in the presence of fake news. In our model, each person updates the reliability of and doubt about his or her friends and exchanges opinions among each other. Applying the proposed model to artificial and real-world social networks, we found three clues to analyze the nature of fake news dissemination: 1) people can less accurately perceive that fake news is fake than they can perceive that real news is real. 2) it takes much more time for people to perceive fake news to be fake than to perceive real news to be real. 3) the results of findings 1 and 2 concerning fake news are because people become skeptical about friends in the presence of fake news and therefore people do not update opinions much.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1088/1757-899X/1022/1/012060" target="_blank"> Demystifying automatic rumour detection in social networks: A review<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85100704747</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Sharma O., Ahuja S., Kamal P.</b></td></tr><tr><td colspan="3">Organisations: <b>Chitkara University, GGDSD College</b></td></tr><tr><td colspan="3">The increase in the connectivity and availability of network has subsequently increased the use of social media. Social Media has emerged as the most readily accessible and fastest platform for updates related to events happening worldwide. The increase in the use of social media has also increased the misuse of resources for spreading unverified information generally termed as a rumour. The biggest problem in social media is the speed at which the information spreads without verifying its credibility. There has been lot of research for detection and prevention of rumours over social media. This paper focuses on presenting the present state of the art in automatic rumour detection in social networks. The paper highlights the prominent researches done in detecting these rumours in social network over the last 5 years. This paper shows both manual and automatic approaches that can be used. Also various tools have been identified which were developed for rumour detection in social media platforms. This paper shows the different available approaches that are being used and can be used in future with improvement.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ACCESS.2021.3056079" target="_blank"> A Novel Stacking Approach for Accurate Detection of Fake News<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85100779470</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Jiang T., Li J.P., Haq A.U., Saboor A., Ali A.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Electronic Science and Technology of China, University of Swat</b></td></tr><tr><td colspan="3">With the increasing popularity of social media, people has changed the way they access news. News online has become the major source of information for people. However, much information appearing on the Internet is dubious and even intended to mislead. Some fake news are so similar to the real ones that it is difficult for human to identify them. Therefore, automated fake news detection tools like machine learning and deep learning models have become an essential requirement. In this paper, we evaluated the performance of five machine learning models and three deep learning models on two fake and real news datasets of different size with hold out cross validation. We also used term frequency, term frequency-inverse document frequency and embedding techniques to obtain text representation for machine learning and deep learning models respectively. To evaluate models' performance, we used accuracy, precision, recall and F1-score as the evaluation metrics and a corrected version of McNemar's test to determine if models' performance is significantly different. Then, we proposed our novel stacking model which achieved testing accuracy of 99.94% and 96.05 % respectively on the ISOT dataset and KDnugget dataset. Furthermore, the performance of our proposed method is high as compared to baseline methods. Thus, we highly recommend it for fake news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/SNAMS52053.2020.9336542" target="_blank"> Fane-KG: A semantic knowledge graph for context-based fake news detection on social media<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85100889534</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Hani A.B., Al-Obeidat F., Majdalawieh M., Adedugbe O., Benkhelifa E.</b></td></tr><tr><td colspan="3">Organisations: <b>Innovation Zayed University, School of Computing Staffordshire University</b></td></tr><tr><td colspan="3">Fake news detection on social media has been very challenging, with diverse techniques already implemented based on content of social media data. However, there is a growing need for use of social data context as well for detection techniques. Leveraging semantic technologies capabilities, this research focused on contextual modelling for social media data, with Twitter data utilised as case study. The raw data is aggregated, processed and transformed into a semantic knowledge graph based on RDF data which is subsequently stored within a graph database. With the tweets initially classified as either fake or real using Fakenewsnet application, the knowledge graph facilitates advanced data analytics and potential extension to the social context modelling developed. Furthermore, the modelled data, alongside ensuing inferential data based on class relationships within the knowledge graph constitute a vital input for data analytics with machine learning towards subsequent classification of other news articles as either fake or not.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICDM50108.2020.00054" target="_blank"> Adversarial active learning based heterogeneous graph neural network for fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85100904378</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Ren Y., Zhang J., Wang B., Chang Y.</b></td></tr><tr><td colspan="3">Organisations: <b>Florida State University, Jilin University</b></td></tr><tr><td colspan="3">The explosive growth of fake news along with destructive effects on politics, economy, and public safety has increased the demand for fake news detection. Fake news on social media does not exist independently in the form of an article. Many other entities, such as news creators, news subjects, and so on, exist on social media and have relationships with news articles. Different entities and relationships can be modeled as a heterogeneous information network (HIN). In this paper, we attempt to solve the fake news detection problem with the support of a news-oriented HIN. We propose a novel fake news detection framework, namely Adversarial Active Learning-based Heterogeneous Graph Neural Network (AA-HGNN) which employs a novel hierarchical attention mechanism to perform node representation learning in the HIN. AA-HGNN utilizes an active learning framework to enhance learning performance, especially when facing the paucity of labeled data. An adversarial selector will be trained to query high-value candidates for the active learning framework. When the adversarial active learning is completed, AA-HGNN detects fake news by classifying news article nodes. Experiments with two real-world fake news datasets show that our model can outperform text-based models and other graph-based models when using less labeled data benefiting from the adversarial active learning. As a model with generalizability, AA-HGNN also has the ability to be widely used in other node classification-related applications on heterogeneous graphs.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-15-8677-4_44" target="_blank"> A Novel Approach to Detect, Characterize, and Analyze the Fake News on Social Media<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85101085024</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Sajini G., Kallimani J.S.</b></td></tr><tr><td colspan="3">Organisations: <b>M S Ramaiah Institute of Technology, Visvesvaraya Technological University</b></td></tr><tr><td colspan="3">Due to the upsurge in the usage of social media in the recent past, communication between people has undergone a great change. Users interact with each other by sharing a lot of information about the ongoing trends. But most of the information shared recently is misleading with the spread of false news which is known as fake news. Spreading a huge volume of such fake news can lead to many complications. The research field has been more concentrating on the inception, spread, and consequences, nowadays. Detecting the truthfulness of the news is of great concern. It can face many technical difficulties on many grounds. Usage of online tools has made the generation of content easy and is expanded fast, where this can lead to a huge amount of data for analysis. The online content is divergent, which deals with numerous fields, contributing to the job complication. Only the computers will not be able to evaluate the truthfulness and purpose, where it is completely dependent on the human and computer interaction. Sometimes, the information that might be termed as fake by a specialist might delude people. Such availability will always remain in restricted quantity but it could be a base for the mutual endeavor. Here, a broad summary of the fake news discoveries pertaining to the news will be given. The unfavorable effects, particularly the ongoing work on the methods to detect such news are demonstrated. The readily available datasets are studied to classify the fake news. An assuring solution is recommended to analyze the online fake news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.asoc.2021.107175" target="_blank"> A real-time hostile activities analyses and detection system<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85101111750</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Dadkhah S., Shoeleh F., Yadollahi M.M., Zhang X., Ghorbani A.A.</b></td></tr><tr><td colspan="3">Organisations: <b>University of New Brunswick (UNB)</b></td></tr><tr><td colspan="3">Over recent years, the development of online social media has dramatically changed the way people connect and share information. It is undeniable that social platform has promoted the quickest type of spread for fake stories. Almost all the current online fact-checking sources and researches are concentrating on the validating political content and context. The proposed system in this paper provides a complete visual data analytics methods to assist users in achieving a comprehensive understanding of malicious activities at multiple levels such as adversary's behavior, victim's behavior, content, and context level. In this paper, we investigate a variety of datasets from different aspects such as role, vulnerabilities, influential level, and distribution pattern. The proposed method in this paper focuses on automatic fake/hostile activity detection by utilizing a variety of machine learning (ML) techniques, deep learning models, natural language processes (NLP), and social network analysis (SNA) techniques. Different auxiliary models, such as bot detection, user credibility, and text readability, are deployed to generate additional influential features. The classification performance of ten different machine learning algorithms using a variety of well-known datasets is evaluated by utilizing 10-fold cross-validation.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-15-8297-4_61" target="_blank"> A Review on Enhanced Techniques for Multimodal Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85101240225</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Tanwar V., Sharma K.</b></td></tr><tr><td colspan="3">Organisations: <b>Delhi Technological University</b></td></tr><tr><td colspan="3">This paper is a review of enhanced techniques for detecting the multimodal fake news. It helps to develop an insight into the characterization of a news story with different content types and its influence among the readers. We review different techniques on machine learning and deep learning with its merits and demerits. The paper is concluded with the open research challenges that can assist the upcoming researchers.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Identification of fake news by contradiction detection in texts<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85101273753</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Sepulveda-Torres R.</b></td></tr><tr><td colspan="3">Organisations: <b>Universidad de Alicante</b></td></tr><tr><td colspan="3">The dissemination of fake news through digital media has increased significantly in recent years. The volume of generation of this kind of news is so high that it is impossible to verify them manually, being necessary to use technologies that allow automating the verification process. This work is focus on creating models and technologies that allow supporting the fake news detection process. The main advances in the area are showed, as well as planning to carry out the research. Finally, the results obtained so far in the research are explained.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-66046-8_27" target="_blank"> A Multi-feature Bayesian Approach for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85101328115</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Casillo M., Colace F., De Santo M., Lombardi M., Santaniello D., Conte D., Mottola S.</b></td></tr><tr><td colspan="3">Organisations: <b>Università degli Studi di Salerno, Università degli Studi di Napoli Parthenope</b></td></tr><tr><td colspan="3">In a world flooded with information, often irrelevant, lucidity is power. Never as in this historical period can anyone, thanks to new technologies, participate as a protagonist in the debates raised about events and issues that affect our society. In this flood of information, remaining lucid and knowing how to discriminate between real and false becomes fundamental. In this scenario, a leading role is played by Fake News, information that is partly or entirely untrue, divulged through the Web, the media, or digital communication technologies. Fake news is characterized by an apparent plausibility, the latter fed by a distorted system of public opinion expectations, and by an amplification of the prejudices based on it, which facilitates its sharing and diffusion even in the absence of verification of the sources. Fake News is becoming a severe problem that affects various sectors of society: medicine, politics, culture, history are some of the areas that suffer most from the phenomenon of fake news, which can often generate significant social problems. This paper will introduce a probabilistic approach to determining the degree of truthfulness of the information. The system is based on the definition of some features, identified after an analysis of fake news in the literature through NLP-based approaches and statistical methods. The specified features will highlight the syntactic, semantic, and social features of the information. These features are combined in a Bayesian Network, previously trained on a dataset composed of fake news, to provide a probabilistic level of the truthfulness of the information analyzed. The proposed method has been tested in some real cases with very satisfactory results.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-66046-8_28" target="_blank"> Propagation of Fake News on Social Media: Challenges and Opportunities<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85101364405</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Hakak S., Khan W.Z., Bhattacharya S., Reddy G.T., Choo K.-K.R.</b></td></tr><tr><td colspan="3">Organisations: <b>University of New Brunswick, Jazan University, School of Information Technology and Engineering, University of Texas at San Antonio</b></td></tr><tr><td colspan="3">Fake news, particularly with the speed and reach of unverified/false information dissemination, is a troubling trend with potential political and societal consequences, as evidenced in the 2016 United States presidential election, the ongoing COVID-19 pandemic, and the ongoing protests. To mitigate such threats, a broad range of approaches have been designed to detect and mitigate online fake news. In this paper, we systematically review existing fake news mitigation and detection approaches, and identify a number of challenges and potential research opportunities (e.g., the importance of a data sharing platform that can also be used to facilitate machine/deep learning). We hope that the findings reported in this paper will motivate further research in this area.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICDMW51313.2020.00022" target="_blank"> An Experimental Evaluation of Data Classification Models for Credibility Based Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85101369560</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Ramkissoon A.N., Mohammed S.</b></td></tr><tr><td colspan="3">Organisations: <b>The University of the West Indies</b></td></tr><tr><td colspan="3">The existence of fake news is a problem challenging today's social media enabled world. Fake news can be classified using varying methods. Predicting and detecting fake news has proven to be challenging even for machine learning algorithms. This research attempts to investigate nine such machine learning algorithms to understand their performance with Credibility Based Fake News Detection. This study uses a standard dataset with features relating to the credibility of news publishers. These features are analysed using each of these algorithms. The results of these experiments are analysed using four evaluation methodologies. The analysis reveals varying performance with the use of each of the nine methods. Based upon our selected dataset, one of these methods has proven to be most appropriate for the purpose of Credibility Based Fake News Detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-66046-8_32" target="_blank"> A Novel Approach for Fake News Detection in Vehicular Ad-Hoc Network (VANET)<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85101386490</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Gaurav A., Gupta B.B., Castiglione A., Psannis K., Choi C.</b></td></tr><tr><td colspan="3">Organisations: <b>National Institute of Technology Kurukshetra, University of Salerno, University of Macedonia, Gachon University</b></td></tr><tr><td colspan="3">In Vehicular ad-hoc network (VANET) vehicles communicate with other vehicles and with the RSU(Road Side Unit). It provides safety and other help to the drivers and the passengers of the vehicles. It is important for Intelligent Transport Systems, hence in recent years the Industrial sector and researchers give it special importance and did much research for its development. In VANET vehicle nodes exchange messages to gain information to make the travel efficient for the passengers of the vehicle. But sometimes attacker start broadcasting the fake news about the surroundings like information of fake accident of traffic jam which in turn produce a negative impact on the safety a efficiency of vehicle. In this paper, we have introduced an entropy-based approach to detect fake news. The attacker uses the spoofed IP address for broadcasting the fake news packets, so we use the entropy of the source IP address for the identification of fake news packets.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ACCESS.2021.3058809" target="_blank"> Unsupervised Fake News Detection Based on Autoencoder<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85101437522</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Li D., Guo H., Wang Z., Zheng Z.</b></td></tr><tr><td colspan="3">Organisations: <b>Zhengzhou University</b></td></tr><tr><td colspan="3">With the development of social networks, the spread of fake news brings great negative effects to people's daily life, and even causes social panic. Fake news can be regarded as an anomaly on social networks, and autoencoder can be used as the basic unsupervised learning method. So, an unsupervised fake news detection method based on autoencoder (UFNDA) is proposed. This paper firstly considers some forms of news in social networks, integrates the text content, images, propagation, and user information of publishing news to improve the performance of fake news detection. Next, to obtain the hidden information and internal relationship between features, Bidirectional GRU(Bi-GRU) layer and Self-Attention layer are added into the autoencoder, and then reconstruct residual to detect fake news. The experimental results compared with the existence of other four methods, on two real-world datasets, show that UFNDA obtains the more positive results.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/INDICON49873.2020.9342247" target="_blank"> Automatic Detection of Fake News Using Textual Entailment Recognition<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85101571595</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Rath P.K., Basak R.</b></td></tr><tr><td colspan="3">Organisations: <b>Jadavpur University Tata Consultancy Services, Jadavpur University</b></td></tr><tr><td colspan="3">Every day we access news from various sources such as social media, news blogs, online newspapers, and many other diverse sources. This has made the task of identifying trustworthy sources of news more and more critical.This paper describes techniques for utilizing textual entailment recognition in detecting fake news articles. At first, we discuss the architecture of the textual entailment recognizer and the steps for training the recognizer. We then describe the algorithms which uses the trained textual entailment recognizer for detecting fake news articles. We compare our proposed method with the popular state-of-the-art methods such as cosine similarity and word mover's distance based methods. We also compare our work with other related works in this field. In our work, we train the textual entailment recognizer using the datasets from the Stanford Natural Language Inference corpus and show the effectiveness of using the trained textual entailment recognizer in detecting fake news on the FakeNewsAMT dataset. The proposed method achieves accuracy of more than 90% for fake news detection on the FakeNewsAMT dataset.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Evaluation of the precision of the binary classification models for the identification of true or false news in Costa Rica<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85101604621</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Salazar Miranda E., Tenorio Arce G., Naranjo Zeledon L.</b></td></tr><tr><td colspan="3">Organisations: <b>_, _</b></td></tr><tr><td colspan="3">This article describes the investigative process for creating a first beta dataset with news broadcast in Costa Rica and evaluating the level of accuracy of data mining models for news detection as true or potentially false. For this purpose, a linguistic analysis of the news content is carried out using the LIWC tool to extract quantitative characteristics and six variations are offered for models such as Logistic Regression, Decision Trees, Random Forests, Vector Support Machines and Neural Networks, making a comparison of the linguistic variables and analyzing the results obtained in the models which are satisfactory for the proposed evaluation scale.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/BESC51023.2020.9348311" target="_blank"> A Deep Learning Model for Early Detection of Fake News on Social Media*<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85101633276</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Konkobo P.M., Zhang R., Li L., Huang S., Minoungou T.T., Ouedraogo J.A.</b></td></tr><tr><td colspan="3">Organisations: <b>Wuhan University of Technology, George Washington University, University of Nebraska at Omaha, Ecole Superieure d'Informatique Universite Nazi Boni</b></td></tr><tr><td colspan="3">Fake news detection has recently become an important topic of research. This is due to the impact of fake news on the internet especially on social media. Numerous of the models proposed in the previous studies are based on supervised learning. Therefore, these models are unable to deal with the huge amount of unlabeled data about fake news. Few studies focused on early detection. In this study, we built a semi-supervised learning model to detect fake news on social media at an early stage. By using a semi-supervised learning, we make our model able to deal with the huge amount of unlabeled data on social media. We first built a model to extract users' opinion expressed in comments, then we used CredRank Algorithm to evaluate users' credibility and built a small network of users involved in the spread of a given news. The outputs of these three steps serve as inputs of our news classifier SSLNews. SSLNews is composed of three networks: A shared CNN, an unsupervised CNN and a supervised CNN. We used real world datasets to evaluate our model, Politifact and Gossipcop. When using 25% of labeled data, SSLNews reaches an accuracy of 72.25% on Politifact and 70.35% on Gossipcop. When using data produced in the first 10 minutes of the beginning of the spread of the news, SSLNews reaches an accuracy of 71.10% on Politifact and 68.07% on Gossipcop.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/MPCIT51588.2020.9350457" target="_blank"> A Novel Model of Supervised Clustering using Sentiment and Contextual Analysis for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85101693465</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>De S., Agarwal D.</b></td></tr><tr><td colspan="3">Organisations: <b>SAP Labs India Pvt. Ltd.</b></td></tr><tr><td colspan="3">Unorganized data is a massive source of cluttered information available over the web. It possesses a major problem when this data originates from unauthenticated sources creating confusion among the general public. The amount of fake news regarding the current COVID-19 scenario and political movements have had an adverse effect on the world. It is necessary to devise models and a step by step algorithm to tackle this challenge. This paper talks about a model that identifies data available over the web and performs crawling to get information about the data sources and maps the information with regards to the authenticity of the source. We look at possible web perspectives of data sources, official social media handles, reviewed agency lists, sentiment analysis, and calculate a value for a piece of particular news. The observed critical value looks for identifying the authenticity of the news and forms the basis of this idea. This paper also looks at a model that uses supervised learning to classify various news items depending on the defined criteria.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.3390/computation9020020" target="_blank"> Deep learning for fake news detection in a pairwise textual input schema<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85101945049</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Mouratidis D., Nikiforos M.N., Kermanidis K.L.</b></td></tr><tr><td colspan="3">Organisations: <b>Ionian University</b></td></tr><tr><td colspan="3">In the past decade, the rapid spread of large volumes of online information among an increasing number of social network users is observed. It is a phenomenon that has often been exploited by malicious users and entities, which forge, distribute, and reproduce fake news and propaganda. In this paper, we present a novel approach to the automatic detection of fake news on Twitter that involves (a) pairwise text input, (b) a novel deep neural network learning architecture that allows for flexible input fusion at various network layers, and (c) various input modes, like word embeddings and both linguistic and network account features. Furthermore, tweets are innova-tively separated into news headers and news text, and an extensive experimental setup performs classification tests using both. Our main results show high overall accuracy performance in fake news detection. The proposed deep learning architecture outperforms the state-of-the-art classifiers, while using fewer features and embeddings from the tweet text.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/MASS50613.2020.00015" target="_blank"> Tracing the source of fake news using a scalable blockchain distributed network<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85102177163</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Dwivedi A.D., Singh R., Dhall S., Srivastava G., Pal S.K.</b></td></tr><tr><td colspan="3">Organisations: <b>Technical University of Denmark, Copenhagen Business School, Jamia Millia Islamia, Brandon University, Defence Research and Development Organization (DRDO)</b></td></tr><tr><td colspan="3">In the news industry, as well as in social media, fake news detection and identification of news sources has become a central topic of discussion. In the era of digitization, anyone can easily generate or manipulate digital content and publish them on social media websites. On the one hand, these social networking platforms provide ample ease in modern-day communication but on the other hand, using such platforms has posed new challenges to real-world implementation like viral spreading of false/fake information with malicious intentions. In this paper, a naive blockchain and watermarking based social media framework is proposed to control the fake news propagation. We postulate a new blockchain model to mitigate existing challenges in this field. Moreover, the novel solution can help in reducing the spread of fake news by tracing the root or origin of the fake news on social media. Through our experimental results, we show that our blockchain-based solution is able to immediately stream data through a bloXroute server that can propagate data up to 100 times faster than conventional solutions.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1063/5.0042264" target="_blank"> Classification of fake news using multi-layer percepti on<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85102298077</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Jehad R., Yousif S.</b></td></tr><tr><td colspan="3">Organisations: <b>Al-Ncihrain University Baghdad</b></td></tr><tr><td colspan="3">Fake News (FNs) is defined as a made-up story to deceive or to| mislead." The problem of FNs spread widely in recent years, especially on social media such as Facebook, Twitter, and other sources like webs and blogs. It has become a significant problem in society as a result of changing people's ideas and opinions about the direction of this news. In this paper, FNs detection can be proposed by using the Term Frequency-Inverse Document Frequency (TF-IDF) as features extraction, and Multi-Layer perceptron (MLP) algorithm as a classifier. Two phases (feed-forward and back-propagation) are used with a three-layers, which are (input layer, one hidden layer, and output layer). After running our proposed algorithm on a FNs dataset, the classification accuracy achieved equals 95.47%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/iSSSC50941.2020.9358890" target="_blank"> Fake news detection using machine learning<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85102460969</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Shaikh J., Patil R.</b></td></tr><tr><td colspan="3">Organisations: <b>K.J. Somaiya College of Engineering</b></td></tr><tr><td colspan="3">This work helps us to detect the accuracy of the fake news using different classification techniques. Fake news is significantly affecting our social life, in fact in every field mainly in politics, education. In this work, we have presented the solution for Fake news problem by implementing fake news detection model by using different classification techniques. Fake News Detection becomes complicated when it comes to resources. Resources like datasets are limited. In this model, we have used classification techniques like Support Vector Machine(SVM), Naïve Bayes, Passive Aggressive Classifier. Output of our model using feature extraction techniques as Term Frequency-Inverted Document Frequency (TF-IDF) and Support Vector Machine (SVM) as classifier, has accuracy of 95.05%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICMLA51294.2020.00127" target="_blank"> Towards Machine Learning Explainability in Text Classification for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85102496989</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Kurasinski L., Mihailescu R.-C.</b></td></tr><tr><td colspan="3">Organisations: <b>Malmö University</b></td></tr><tr><td colspan="3">The digital media landscape has been exposed in recent years to an increasing number of deliberately misleading news and disinformation campaigns, a phenomenon popularly referred as fake news. In an effort to combat the dissemination of fake news, designing machine learning models that can classify text as fake or not has become an active line of research. While new models are continuously being developed, the focus so far has mainly been aimed at improving the accuracy of the models for given datasets. Hence, there is little research done in the direction of explainability of the deep learning (DL) models constructed for the task of fake news detection.In order to add a level of explainability, several aspects have to be taken into consideration. For instance, the pre-processing phase, or the length and complexity of the text play an important role in achieving a successful classification. These aspects need to be considered in conjunction with the model's architecture. All of these issues are addressed and analyzed in this paper. Visualizations are further employed to grasp a better understanding how different models distribute their attention when classifying fake news texts. In addition, statistical data is gathered to deepen the analysis and to provide insights with respect to the model's interpretability.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1038/s41598-021-84993-1" target="_blank"> From rumor to genetic mutation detection with explanations: a GAN approach<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85102526339</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Cheng M., Nazarian S., Bogdan P., Li Y.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Southern California, Beijing University of Posts and Telecommunications</b></td></tr><tr><td colspan="3">Social media have emerged as increasingly popular means and environments for information gathering and propagation. This vigorous growth of social media contributed not only to a pandemic (fast-spreading and far-reaching) of rumors and misinformation, but also to an urgent need for text-based rumor detection strategies. To speed up the detection of misinformation, traditional rumor detection methods based on hand-crafted feature selection need to be replaced by automatic artificial intelligence (AI) approaches. AI decision making systems require to provide explanations in order to assure users of their trustworthiness. Inspired by the thriving development of generative adversarial networks (GANs) on text applications, we propose a GAN-based layered model for rumor detection with explanations. To demonstrate the universality of the proposed approach, we demonstrate its benefits on a gene classification with mutation detection case study. Similarly to the rumor detection, the gene classification can also be formulated as a text-based classification problem. Unlike fake news detection that needs a previously collected verified news database, our model provides explanations in rumor detection based on tweet-level texts only without referring to a verified news database. The layered structure of both generative and discriminative models contributes to the outstanding performance. The layered generators produce rumors by intelligently inserting controversial information in non-rumors, and force the layered discriminators to detect detailed glitches and deduce exactly which parts in the sentence are problematic. On average, in the rumor detection task, our proposed model outperforms state-of-the-art baselines on PHEME dataset by 26.85 % in terms of macro-f1. The excellent performance of our model for textural sequences is also demonstrated by the gene mutation case study on which it achieves 72.69 % macro-f1 score.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-67187-7_12" target="_blank"> Frequent Pattern Mining Approach for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85102527333</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Pranave S., Uppada S.K., Vishnu Priya A., SivaSelvan B.</b></td></tr><tr><td colspan="3">Organisations: <b>IIITDM Kancheepuram</b></td></tr><tr><td colspan="3">Spreading of Fake news is not a new problem, many people have been using News or online social media for propaganda or to influence for centuries. The rise of web-generated news on social media makes fake news a more powerful force that challenges traditional journalistic norms.The extensive spread of fake news has the potential for extremely negative impacts on individuals and society. Therefore, fake news detection has recently become an emerging research that is attracting tremendous attention. To help mitigating the negative effects caused by fake news - both to benefit the public and the news ecosystem, it is critical to develop methods to automatically detect fake news on social media. This paper has analyzed the existing approaches to Fake news detection such as Naive Bayes Classifier, Decision tree and has proposed a novel approach for Fake news detection by implementing Association rule based classification ARBC). Experimental results has indicated notable improvement in detection accuracy.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-16-0401-0_20" target="_blank"> MultiDeepFake: Improving Fake News Detection with a Deep Convolutional Neural Network Using a Multimodal Dataset<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85102636297</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Kaliyar R.K., Mohnot A., Goswami A., Singh N., Raghhul R., Prathyushaa V.K., Dash P.</b></td></tr><tr><td colspan="3">Organisations: <b>Bennett University, Sri Ramakrishna Engineering College, IIIT Bhubaneswar</b></td></tr><tr><td colspan="3">Nowadays, the news ecosystem has shifted from traditional print media to social media outlets. It has resulted in the inaccuracy and irrelevancy in updating information by people which is commonly known as fake news. Due to the increasing number of users in social media, fake news is quickly publishing by an individual, and its credibility stands compromised, which brings in a need for effective detection of fake news. Since a large proportion of the population uses social media for updating themselves with news, delivering accurate and altruistic information to them is of utmost importance. Fake news detection has recently garnered much attention from researchers and developers alike. This work proposes to detect fake news using various modalities available, such as text, image, and text in the image in an effective manner using Deep Learning algorithms. In this paper, we propose a deep convolutional neural network for handling diverse multi-domain fake news data. Our proposed model (MultiDeepFake) has obtained more accurate results as compared to the existing state-of-the-art benchmarks. Classification results will motivate the researchers to use our proposed model in future for fake news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-68527-0_13" target="_blank"> Fake News Detection Without External Knowledge<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85102636753</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Bodo Z.</b></td></tr><tr><td colspan="3">Organisations: <b>Babeş–Bolyai University</b></td></tr><tr><td colspan="3">Although written deception is not a new invention, the emergence and progress of electronic media—and more recently social media—has changed the speed and extent of access to information in a good way, but at the same time facilitating the proliferation of disinformation as well. Automatic veracity determination, therefore, became a widely studied problem in the last years. We claim that without using a knowledge base and fact-checking, that is based solely on textual content features one cannot truly fight this phenomenon, nevertheless, such a deception detection system can be used beneficially in certain situations. In the present study we apply text categorization methods to detect fake news without involving any external knowledge base (e.g. lexicons, unlabeled corpora, pre-trained word vectors, etc.). We employ traditional bag-of-words and more recent end-to-end neural network models, and evaluate them on eight—five smaller and three larger—fake news datasets. The experimental results show that one can attain considerably precise detection performance, in some cases even in the very close vicinity of the perfect F1 score, using solely the labeled data. We also strive to explain why some of these approaches imply a better performance than others.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1371/journal.pone.0246757" target="_blank"> Detecting fake news on Facebook: The role of emotional intelligence<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85102638686</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Preston S., Anderson A., Robertson D.J., Shephard M.P., Huhe N.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Strathclyde, School of Government and Public Policy</b></td></tr><tr><td colspan="3">The proliferation of fake news on social media is now a matter of considerable public and governmental concern. In 2016, the UK EU referendum and the US Presidential election were both marked by social media misinformation campaigns, which have subsequently reduced trust in democratic processes. More recently, during the COVID-19 pandemic, the acceptance of fake news has been shown to pose a threat to public health. Research on how to combat the false acceptance of fake news is still in its infancy. However, recent studies have started to focus on the psychological factors which might make some individuals less likely to fall for fake news. Here, we adopt that approach to assess whether individuals who show high levels of ‘emotional intelligence’ (EQ) are less likely to fall for fake news items. That is, are individuals who are better able to disregard the emotionally charged content of such items, better equipped to assess the veracity of the information. Using a sample of UK participants, an established measure of EQ and a novel fake news detection task, we report a significant positive relationship between individual differences in emotional intelligence and fake news detection ability. We also report a similar effect for higher levels of educational attainment, and we report some exploratory qualitative fake news judgement data. Our findings are discussed in terms of their applicability to practical short term (i.e. current Facebook user data) and medium term (i.e. emotional intelligence training) interventions which could enhance fake news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/PuneCon50868.2020.9362384" target="_blank"> Fake News Detection System using Web-Extension<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85102660984</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Khivasara Y., Khare Y., Bhadane T.</b></td></tr><tr><td colspan="3">Organisations: <b>Mit World Peace University</b></td></tr><tr><td colspan="3">Internet is a supreme one-stop source of information that enables the sharing of news and curated user-content at a rapid, effortless, and in a routine manner. News is a global medium of daily events worldwide, offering absorption of quick information. With ample availability of news content online, these news articles has by-products in information generation in both ways-real and fake news. Considering the context and volume of information shared online, it is challenging to establish authenticity of news. This leads to the immense growth of fake news on various websites, which can lead to serious concerns in society, fading away the correct news content to reach the users creating misconceptions and deceived views of the readers. To ensure the readers have the credibility of the content, we propose a web-based extension enabling them to distinguish from the fake and real news content. The proposed web extension in the paper uses multiple deep learning models. The first is based on our model trained on LSTM, and the other uses OPEN AI's well-developed AI-generated text classifier GPT-2. The devised web-extension displays both probabilities of news being either AI-generated or written by an individual.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Automatic detection of fake news<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85102849576</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Perez-Rosas V., Lefevre A., Mihalcea R., Kleinberg B.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Michigan, University of Amsterdam</b></td></tr><tr><td colspan="3">The proliferation of misleading information in everyday access media outlets such as social media feeds, news blogs, and online newspapers have made it challenging to identify trustworthy news sources, thus increasing the need for computational tools able to provide insights into the reliability of online content. In this paper, we focus on the automatic identification of fake content in online news. Our contribution is twofold. First, we introduce two novel datasets for the task of fake news detection, covering seven different news domains. We describe the collection, annotation, and validation process in detail and present several exploratory analyses on the identification of linguistic differences in fake and legitimate news content. Second, we conduct a set of learning experiments to build accurate fake news detectors, and show that we can achieve accuracies of up to 76%. In addition, we provide comparative analyses of the automatic and manual identification of fake news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.ipm.2021.102569" target="_blank"> Combat COVID-19 infodemic using explainable natural language processing models<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85102851698</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Ayoub J., Zhou F., Yang X.J.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Michigan-Dearborn, University of Michigan</b></td></tr><tr><td colspan="3">Misinformation of COVID-19 is prevalent on social media as the pandemic unfolds, and the associated risks are extremely high. Thus, it is critical to detect and combat such misinformation. Recently, deep learning models using natural language processing techniques, such as BERT (Bidirectional Encoder Representations from Transformers), have achieved great successes in detecting misinformation. In this paper, we proposed an explainable natural language processing model based on DistilBERT and SHAP (Shapley Additive exPlanations) to combat misinformation about COVID-19 due to their efficiency and effectiveness. First, we collected a dataset of 984 claims about COVID-19 with fact-checking. By augmenting the data using back-translation, we doubled the sample size of the dataset and the DistilBERT model was able to obtain good performance (accuracy: 0.972; areas under the curve: 0.993) in detecting misinformation about COVID-19. Our model was also tested on a larger dataset for AAAI2021 — COVID-19 Fake News Detection Shared Task and obtained good performance (accuracy: 0.938; areas under the curve: 0.985). The performance on both datasets was better than traditional machine learning models. Second, in order to boost public trust in model prediction, we employed SHAP to improve model explainability, which was further evaluated using a between-subjects experiment with three conditions, i.e., text (T), text+SHAP explanation (TSE), and text+SHAP explanation+source and evidence (TSESE). The participants were significantly more likely to trust and share information related to COVID-19 in the TSE and TSESE conditions than in the T condition. Our results provided good implications for detecting misinformation about COVID-19 and improving public trust.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> SSNCSE_NLP@Fake news detection in the Urdu language (UrduFake) 2020<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85102929491</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Balaji N.N.A., Bharathi B.</b></td></tr><tr><td colspan="3">Organisations: <b>Sri Siva Subramaniya Nadar College of Engineering</b></td></tr><tr><td colspan="3">The broadcasting of fake news always hammers out the truth with considerable growth. Fake news and false rumors are spreading further and faster, reaching more people, and penetrating deeper into social networks. Social media interaction is one of the major sources of spreading the news across the world nowadays. The fake news also spread among the people very faster using digital media. The objective of this proposed work to detect unreliable information from the news content in the Urdu language using digital media text collected from different sources. We have experimented with this task using the features namely TFIDF, fastText. We have achieved an accuracy of 90% for development data and 78.7% for test data respectively.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.3389/fcomm.2020.562588" target="_blank"> Going Viral: How Fear, Socio-Cognitive Polarization and Problem-Solving Influence Fake News Detection and Proliferation during COVID-19 Pandemic<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85102933561</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Salvi C., McClay M., Dunsmoor J.E., Iannello P., Cancer A., Rago S., Antonietti A.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Texas at Austin, Università Cattolica Del Sacro Cuore</b></td></tr><tr><td colspan="3">In times of uncertainty, people often seek out information to help alleviate fear, possibly leaving them vulnerable to false information. During the COVID-19 pandemic, we attended to a viral spread of incorrect and misleading information that compromised collective actions and public health measures to contain the spread of the disease. We investigated the influence of fear of COVID-19 on social and cognitive factors including believing in fake news, bullshit receptivity, overclaiming, and problem-solving - within two of the populations that have been severely hit by COVID-19: Italy and the United States of America. To gain a better understanding of the role of misinformation during the early height of the COVID-19 pandemic, we also investigated whether problem-solving ability and socio-cognitive polarization were associated with believing in fake news. Results showed that fear of COVID-19 is related to seeking out information about the virus and avoiding infection in the Italian and American samples, as well as a willingness to share real news (COVID and non-COVID-related) headlines in the American sample. However, fear positively correlated with bullshit receptivity, suggesting that the pandemic might have contributed to creating a situation where people were pushed toward pseudo-profound existential beliefs. Furthermore, problem-solving ability was associated with correctly discerning real or fake news, whereas socio-cognitive polarization was the strongest predictor of believing in fake news in both samples. From these results, we concluded that a construct reflecting cognitive rigidity, neglecting alternative information, and black-and-white thinking negatively predicts the ability to discern fake from real news. Such a construct extends also to reasoning processes based on thinking outside the box and considering alternative information such as problem-solving.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> NITP-AI-NLP@UrduFake-FIRE2020: Multi-layer dense neural network for fake news detection in urdu news articles<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85102944298</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Kumar A., Singh J.P., Saumya S.</b></td></tr><tr><td colspan="3">Organisations: <b>National Institute of Technology Patna, Indian Institute of Information Technology</b></td></tr><tr><td colspan="3">Fake news can mislead public opinion, weaken social order, limit the legitimacy of government, and lead to a serious threat to social stability. Therefore, the early detection of fake news from the online platform is extremely important. Most of the previous literature has focused on finding fake news from resource-rich languages like English, Hindi, and Spanish. The current work utilizes the dataset of Urdu language for fake news detection. Two different models have been proposed in the paper. The first one is an ensemble-based technique and the second one is a multi-layer dense neural network. The multilayer dense neural network-based approach performed better with character n-gram TF-IDF features to achieve a macro F1-score of 0.8101.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Fake news detection in the urdu language using CharCNN-RoBERTa<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85102960146</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Lin N., Fu S., Jiang S.</b></td></tr><tr><td colspan="3">Organisations: <b>Guangdong University of Foreign Studies, Guangzhou Key Laboratory of Multilingual Intelligent Processing</b></td></tr><tr><td colspan="3">In this article, we report the solution of the team BERT 4EVER for the Fake News Detection in the Urdu Language task in FIRE 2020, which aims to identify deceiving news articles in the Urdu language spread via digital media. We propose the CharCNN-RoBERTa model to tackle the problem. In addition, we adopt label smoothing and ensemble learning to improve the generalization capability. Experimental results as well as the leading position of our team on the task leaderboard demonstrate the effectiveness of our method.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Urdu fake news detection using generalized autoregressors<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85102962458</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Khilji A.F.U.R., Laskar S.R., Pakray P., Bandyopadhyay S.</b></td></tr><tr><td colspan="3">Organisations: <b>National Institute of Technology</b></td></tr><tr><td colspan="3">Automated fake news detection has become vital in today’s digital age. Differentiating legit news from fake ones has become an important classification challenge in natural language processing (NLP). Various transformer-based deep learning approaches have taken widespread adoption from the research community due to its outstanding performance. We have participated in the 2020 Fake News Detection Challenge in the Urdu Language organized by Center for Computing Research (CIC), Instituto Politécnico Nacional (IPN), Mexico and have stood second. In this work, we have implemented a generalized autoregressor based model to classify news into fake or real. We have achieved an overall accuracy of 0.8400 and F1 macro score of 0.8370.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Learning models for urdu fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85102962507</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Balouchzahi F., Shashirekha H.L.</b></td></tr><tr><td colspan="3">Organisations: <b>Mangalore University</b></td></tr><tr><td colspan="3">Detecting fake news from the real news can be modeled as a typical binary text classification problem. Most of the models proposed for fake news detection address the resource rich languages such as English and Spanish but, languages such as Urdu, Persian, Balouchi and many Indian native languages have received very less attention due to unavailability of bench marked corpus. To promote text processing activities on Urdu, which happens to be a resource poor language FIRE 2020 (Forum for Information Retrieval Evaluation) has called for UrduFake, a shared task to detect fake news in Urdu language. High speed of news broadcast and the importance of detecting fake news from the real news made us (team MUCS) to propose three different learning models namely, an ensemble of Machine Learning (ML) models, Transfer Learning (TL) model based on ULMFiT and a hybrid model made up of an ensemble of ML approaches, TL approach and Deep Learning (DL). The proposed methodology utilizes word and character n-grams to train ML model and word embedding vectors to train BiLSTM networks of DL model and for TL model, a pre-trained general domain Urdu Language Model is fine-tuned with the Urdu fake news dataset. Our ML model obtained 5th place among 9 teams that participated in this task.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.11591/eei.v10i2.2745" target="_blank"> The covid-19 fake news detection in thai social texts<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85103039190</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Mookdarsanit P., Mookdarsanit L.</b></td></tr><tr><td colspan="3">Organisations: <b>Chandrakasem Rajabhat University</b></td></tr><tr><td colspan="3">One important obstruction against Thai COVID-19 recovery is fake news shared on social media that is one of the “Artificial Intelligence Open Issues against COVID-19” reported by Montreal.AI. Misinformation spread is one of the main cyber-security threats that should be filtered out as the IDS for maintaining COVID-19 information quality. To detect fake news in Thai texts, Thai-NLP techniques are necessary. This paper proposes a state-of-the-art Thai COVID-19 fake news detection among word relations using transfer learning models. For pre-training from the global open COVID-19 datasets, the source dataset is constructed by English to Thai translating. The novel feature shifting is formulated to enlarge Thai text examples in target dataset. Machine translation can be used for constructing Thai source dataset to cope with the lack of local dataset for future Thai-NLP applications. To lead the knowledge in Thai text understanding forward, feature shifting is a promising accuracy improvement in fine-tuning stage.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-58624-9_5" target="_blank"> Technological Approaches to Detecting Online Disinformation and Manipulation<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85103080229</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Horak A., Baisa V., Herman O.</b></td></tr><tr><td colspan="3">Organisations: <b>Masaryk University</b></td></tr><tr><td colspan="3">Disseminating propaganda and disinformation in the online environment is possible thanks to the fact that, within the last decade, digital information channels have radically increased in popularity as a source of news. This has occurred because the main advantage of such media lies in the speed of creating and disseminating information. The price paid for this speed is fast editorial work (if any) and quick checking of facts and source credibility. In this chapter, an overview of computer-supported approaches for detecting disinformation and manipulative techniques based on several criteria is presented. We concentrate on the technical aspects of automatic methods which support fact checking, topic identification, text style analysis, or message filtering in social media channels. Most of the techniques employ artificial intelligence and machine learning with feature extraction and combine available information resources.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.7717/peerj-cs.425" target="_blank"> Supervised ensemble learning methods towards automatically filtering Urdu fake news within social media<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85103090042</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Akhter M.P., Zheng J., Afzal F., Lin H., Riaz S., Mehmood A.</b></td></tr><tr><td colspan="3">Organisations: <b>Northwestern Polytechnical University, National University of Sciences and Technology, Xidian University</b></td></tr><tr><td colspan="3">The popularity of the internet, smartphones, and social networks has contributed to the proliferation of misleading information like fake news and fake reviews on news blogs, online newspapers, and e-commerce applications. Fake news has a worldwide impact and potential to change political scenarios, deceive people into increasing product sales, defaming politicians or celebrities, and misguiding visitors to stop visiting a place or country. Therefore, it is vital to find automatic methods to detect fake news online. In several past studies, the focus was the English language, but the resource-poor languages have been completely ignored because of the scarcity of labeled corpus. In this study, we investigate this issue in the Urdu language. Our contribution is threefold. First, we design an annotated corpus of Urdu news articles for the fake news detection tasks. Second, we explore three individual machine learning models to detect fake news. Third, we use five ensemble learning methods to ensemble the base-predictors’ predictions to improve the fake news detection system’s overall performance. Our experiment results on two Urdu news corpora show the superiority of ensemble models over individual machine learning models. Three performance metrics balanced accuracy, the area under the curve, and mean absolute error used to find that Ensemble Selection and Vote models outperform the other machine learning and ensemble learning models.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> On the role of images for analyzing claims in social media<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85103154894</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Cheema G.S., Hakimov S., Muller-Budack E., Ewerth R.</b></td></tr><tr><td colspan="3">Organisations: <b>Leibniz Information Centre for Science and Technology, Leibniz University Hannover</b></td></tr><tr><td colspan="3">Fake news is a severe problem in social media. In this paper, we present an empirical study on visual, textual, and multimodal models for the tasks of claim, claim check-worthiness, and conspiracy detection, all of which are related to fake news detection. Recent work suggests that images are more influential than text and often appear alongside fake text. To this end, several multimodal models have been proposed in recent years that use images along with text to detect fake news on social media sites like Twitter. However, the role of images is not well understood for claim detection, specifically using transformer-based textual and multimodal models. We investigate state-of-the-art models for images, text (Transformer-based), and multimodal information for four different datasets across two languages to understand the role of images in the task of claim and conspiracy detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Detecting fake news in tweets from text and propagation graph: IRISA's participation to the fakenews task at MediaEval 2020<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85103171906</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Claveau V.</b></td></tr><tr><td colspan="3">Organisations: <b>Univ. Rennes</b></td></tr><tr><td colspan="3">This paper presents the participation of IRISA to the task of fake news detection from tweets, relying either on the text or on propagation information. For the text based detection, variants of BERTbased classification are proposed. In order to improve this standard approach, we investigate the interest of augmenting the dataset by creating tweets with fine-tuned generative models. For the graph based detection, we have proposed models characterizing the propagation of the news or the users' reputation.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-67664-3_39" target="_blank"> Early Detection of Fake News with Multi-source Weak Social Supervision<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85103280407</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Shu K., Zheng G., Mukherjee S., Awadallah A.H., Li Y., Ruston S., Liu H.</b></td></tr><tr><td colspan="3">Organisations: <b>Illinois Institute of Technology, Microsoft Research AI, Arizona State University</b></td></tr><tr><td colspan="3">Social media has greatly enabled people to participate in online activities at an unprecedented rate. However, this unrestricted access also exacerbates the spread of misinformation and fake news which cause confusion and chaos if not detected in a timely manner. Given the rapidly evolving nature of news events and the limited amount of annotated data, state-of-the-art systems on fake news detection face challenges for early detection. In this work, we exploit multiple weak signals from different sources from user engagements with contents (referred to as weak social supervision), and their complementary utilities to detect fake news. We jointly leverage limited amount of clean data along with weak signals from social engagements to train a fake news detector in a meta-learning framework which estimates the quality of different weak instances. Experiments on real-world datasets demonstrate that the proposed framework outperforms state-of-the-art baselines for early detection of fake news without using any user engagements at prediction time.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s13218-021-00714-w" target="_blank"> Stance Detection Benchmark: How Robust is Your Stance Detection?<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85103349049</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Schiller B., Daxenberger J., Gurevych I.</b></td></tr><tr><td colspan="3">Organisations: <b>Technical University of Darmstadt</b></td></tr><tr><td colspan="3">Stance detection (StD) aims to detect an author’s stance towards a certain topic and has become a key component in applications like fake news detection, claim validation, or argument search. However, while stance is easily detected by humans, machine learning (ML) models are clearly falling short of this task. Given the major differences in dataset sizes and framing of StD (e.g. number of classes and inputs), ML models trained on a single dataset usually generalize poorly to other domains. Hence, we introduce a StD benchmark that allows to compare ML models against a wide variety of heterogeneous StD datasets to evaluate them for generalizability and robustness. Moreover, the framework is designed for easy integration of new datasets and probing methods for robustness. Amongst several baseline models, we define a model that learns from all ten StD datasets of various domains in a multi-dataset learning (MDL) setting and present new state-of-the-art results on five of the datasets. Yet, the models still perform well below human capabilities and even simple perturbations of the original test samples (adversarial attacks) severely hurt the performance of MDL models. Deeper investigation suggests overfitting on dataset biases as the main reason for the decreased robustness. Our analysis emphasizes the need of focus on robustness and de-biasing strategies in multi-task learning approaches. To foster research on this important topic, we release the dataset splits, code, and fine-tuned weights.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s10489-021-02345-y" target="_blank"> ConvNet frameworks for multi-modal fake news detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85103349430</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Raj C., Meel P.</b></td></tr><tr><td colspan="3">Organisations: <b>Delhi Technological University</b></td></tr><tr><td colspan="3">An upsurge of false information revolves around the internet. Social media and websites are flooded with unverified news posts. These posts are comprised of text, images, audio, and videos. There is a requirement for a system that detects fake content in multiple data modalities. We have seen a considerable amount of research on classification techniques for textual fake news detection, while frameworks dedicated to visual fake news detection are very few. We explored the state-of-the-art methods using deep networks such as CNNs and RNNs for multi-modal online information credibility analysis. They show rapid improvement in classification tasks without requiring pre-processing. To aid the ongoing research over fake news detection using CNN models, we build textual and visual modules to analyze their performances over multi-modal datasets. We exploit latent features present inside text and images using layers of convolutions. We see how well these convolutional neural networks perform classification when provided with only latent features and analyze what type of images are needed to be fed to perform efficient fake news detection. We propose a multi-modal Coupled ConvNet architecture that fuses both the data modules and efficiently classifies online news depending on its textual and visual content. We thence offer a comparative analysis of the results of all the models utilized over three datasets. The proposed architecture outperforms various state-of-the-art methods for fake news detection with considerably high accuracies.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.engappai.2021.104230" target="_blank"> Suspicious news detection through semantic and sentiment measures<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85103394977</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>G. Martin A., Fernandez-Isabel A., Gonzalez-Fernandez C., Lancho C., Cuesta M., Martin de Diego I.</b></td></tr><tr><td colspan="3">Organisations: <b>Rey Juan Carlos University</b></td></tr><tr><td colspan="3">Misinformation has always existed in society. Nowadays, the technological development and the appearance of social networks, pseudo-newspapers and blogs, have aggravated this problem by facilitating the rapid spread of malicious news. This fact makes it easier to use disinformation as an attack vector for huge communities. This has led to the development of procedures that detect the appearance of this type of news and mitigate its influence. This article presents the Knowledge Recovering Architecture based on Keywords Extraction from Narratives for Suspicious News Detection (KRAKEN-SND) system. Its main goal is to support human experts to detect suspicious news articles that should be verified. In order to achieve this objective, it gathers narratives from multiple reliable information sources. Then, it extracts the semantic and sentiment relevant features from these narratives. This information is structured by date using a conceptual graph to generate trustworthy knowledge. The system includes a novel similarity measure that combines three specific components. This measure uses the stored knowledge to detect the peculiarity of a reported narrative that may contain suspicious information. Several experiments using relevant topics as Brexit and the COVID-19 pandemic among others have been carried out to validate the proposal, obtaining promising results.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> An explainable machine learning framework for fake financial news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85103442321</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Zhang X., Zhang Z., Du Q.</b></td></tr><tr><td colspan="3">Organisations: <b>Arizona State University, Nanjing University</b></td></tr><tr><td colspan="3">In recent years, we have witnessed a continuing onslaught of fake news, or other forms of biased information on social media platforms. These types of information can influence people's beliefs, attitudes, and behaviors by its ubiquity with significant social and economic implications. In this study, we examine fake news on crowd-sourced platforms for financial markets. Assembling a unique dataset of unambiguous fake news articles that were prosecuted by the Securities and Exchange Commission, along with propagation data of such news on other digital platforms and the financial performance data of the focal firm, we develop a well-justified and explainable machine-learning framework to predict fake financial news on social media platforms. Our framework design is rooted in the Truth Default Theory, which emphasizes contextualized information for deception detection. Extensive analyses are conducted to evaluate the performance and efficacy of the proposed framework.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-15-8221-9_289" target="_blank"> Detection of Rumors in Tweets Using Machine Learning Techniques<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85103470642</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Dhanya N.M., Harish U.C.</b></td></tr><tr><td colspan="3">Organisations: <b>Amrita School of Engineering, Guruvayurappan Institute of Management</b></td></tr><tr><td colspan="3">In this booming era of technology, social media web sites like Facebook, Twitter, WhatsApp are the most popular and trending applications for communication and information exchange. Despite being able to connect ourselves to this world, there is no guarantee that the information shared is credible or not. This results in online social media becoming highly vulnerable to the spread of fake news, i.e., rumors. Hence, the need for designing a rumor detection model is very much essential today. The main objective of this work is to classify tweets into rumor or not using machine learning models. In order to predict whether the information that is spread online is fake or not, we have built a model using machine learning techniques by comparing four different machine learning algorithms. Tweets related to Chennai floods, which happened in 2015, is used for analysis by retrieving tweets using hashtag #ChennaiFloods. These are preprocessed and our model is used to predict whether a particular tweet is a rumor or not. The model can be used to predict and this analysis can be used in debunking the rumor tweets for different rumor topics.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-33-4069-5_25" target="_blank"> Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85103502507</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Long S.H., Hamzah M.P.B.</b></td></tr><tr><td colspan="3">Organisations: <b>Universiti Malaysia Terengganu</b></td></tr><tr><td colspan="3">Everyday people receive a lot of information through social media and online news portals. To distinguish whether the information is fake or true is a big problem. An algorithm has been developed to distinguish fake news and true news by searching the relevant news from reliable news website based on the news given. This results in the similarity percentage between news and the relevant news. The algorithm has been tested with the dataset collected by Dr. Victoria L. Rubin that consists of 180 true news and 180 fake news from several American and Canadian news websites. The precision of 69.44% has been achieved with the dataset.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ASONAM49781.2020.9381422" target="_blank"> Truth or Lie: Pre-emptive Detection of Fake News in Different Languages through Entropy-based Active Learning and Multi-model Neural Ensemble<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85103684686</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Hasan M.S., Alam R., Adnan M.A.</b></td></tr><tr><td colspan="3">Organisations: <b>Bangladesh University of Engineering and Technology</b></td></tr><tr><td colspan="3">In recent times, the circulation of fake news on social networks has increased exponentially with spikes in propagation seen during and after the 2016 US elections. Hence, there has been a surge in research into automated fake news detection. However, most research tends towards supervised learning which requires a significant amount of labeled data which is difficult to obtain. Thus, in this paper, we develop a semi-supervised learning method for fake news detection incorporating active learning based on entropy as a query strategy to train a multi-model neural ensemble architecture. The goal of the research is to achieve high accuracy on fake news detection while using lower amounts of data. Our experiments against other standards indicate promising results, with our model achieving high accuracy with 4% to 28% of the dataset.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ASONAM49781.2020.9381466" target="_blank"> Detecting Fake News Spreaders in Social Networks using Inductive Representation Learning<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85103687788</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Rath B., Salecha A., Srivastava J.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Minnesota</b></td></tr><tr><td colspan="3">An important aspect of preventing fake news dissemination is to proactively detect the likelihood of its spreading. Research in the domain of fake news spreader detection has not been explored much from a network analysis perspective. In this paper, we propose a graph neural network based approach to identify nodes that are likely to become spreaders of false information. Using the community health assessment model and interpersonal trust we propose an inductive representation learning framework to predict nodes of densely-connected community structures that are most likely to spread fake news, thus making the entire community vulnerable to the infection. Using topology and interaction based trust properties of nodes in real-world Twitter networks, we are able to predict false information spreaders with an accuracy of over 90%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/UPCON50219.2020.9376576" target="_blank"> Machine Learning based Fake News Detection using linguistic features and word vector features<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85103693954</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Kumar Jain M., Gopalani D., Kumar Meena Y., Kumar R.</b></td></tr><tr><td colspan="3">Organisations: <b>Malaviya National Institute of Technology</b></td></tr><tr><td colspan="3">Nowadays on the internet, lots of information is spread every second by the people. On social media, most of the users do not verify the information and propagate it. Manually identifying fake news is a very tremendous problem for all. So, the need for an automatic system that efficiently detects fake news. This paper estimated a model that intuitionally distinguishes fake news from a news article. A new feature set for machine learning classifier has been proposed. Within the experiment, the dataset used has a combination of two datasets that contain equal true news and fake news articles of politics. From text fields of the dataset extract linguistic/stylometric features, a bag of words TF and BOW TF-IDF vector, after that apply the various machine learning models including bagging and boosting methods to achieve the best accuracy.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICETA51985.2020.9379254" target="_blank"> Annotated dataset for the fake news classification in Slovak language<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85103738897</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Sarnovsky M., Maslej-Kresnakova V., Hrabovska N.</b></td></tr><tr><td colspan="3">Organisations: <b>Technical University of Kosice</b></td></tr><tr><td colspan="3">Fake news detection currently presents an active field of research. Detection methods based on natural language processing and machine learning are being developed to automatically identify the possible misinformation contained within the news articles. To successfully train these models, annotated data are needed. In English language, multiple human-annotated datasets already are available and are being widely used in the research. The main objective of the work presented in this paper, was to create similar dataset consisting of articles in Slovak language. We collected the data from the various local news portals including reputable publishers as well as suspicious conspiratory portals. To obtain the annotations, we used crowdsourcing approach. Annotated dataset was used in preliminary experiments, in which neural network classifier was trained and evaluated.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1186/s41235-021-00292-3" target="_blank"> The role of analytical reasoning and source credibility on the evaluation of real and fake full-length news articles<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85103744977</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Pehlivanoglu D., Lin T., Deceus F., Heemskerk A., Ebner N.C., Cahill B.S.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Florida, University of Florida</b></td></tr><tr><td colspan="3">Aim: Previous research has focused on accuracy associated with real and fake news presented in the form of news headlines only, which does not capture the rich context news is frequently encountered in real life. Additionally, while previous studies on evaluation of real and fake news have mostly focused on characteristics of the evaluator (i.e., analytical reasoning), characteristics of the news stimuli (i.e., news source credibility) and the interplay between the two have been largely ignored. To address these research gaps, this project examined the role of analytical reasoning and news source credibility on evaluation of real and fake full-length news story articles. The project considered both accuracy and perceived credibility ratings as outcome variables, thus qualifying previous work focused solely on news detection accuracy. Method: We conducted two independent but parallel studies, with Study 2 as a direct replication of Study 1, employing the same design but in a larger sample (Study 1: N = 292 vs. Study 2: N = 357). In both studies, participants viewed 12 full-length news articles (6 real, 6 fake), followed by prompts to evaluate each article’s veracity and credibility. Participants were randomly assigned to view articles with a credible or non-credible source and completed the Cognitive Reflection Test as well as short demographic questions. Findings: Consistent across both studies, higher analytical reasoning was associated with greater fake news accuracy, while analytical reasoning was not associated with real news accuracy. In addition, in both studies, higher analytical reasoning was associated with lower perceived credibility for fake news, while analytical reasoning was not associated with perceived credibility for real news. Furthermore, lower analytical reasoning was associated with greater accuracy for real (but not fake) news from credible compared to non-credible sources, with this effect only detected in Study 2. Conclusions: The novel results generated in this research are discussed in light of classical vs. naturalistic accounts of decision-making as well as cognitive processes underlying news articles evaluation. The results extend previous findings that analytical reasoning contributes to fake news detection to full-length news articles. Furthermore, news-related cues such as the credibility of the news source systematically affected discrimination ability between real and fake news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/IHSH51661.2021.9378748" target="_blank"> Fake News detection Using Machine Learning<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85103815196</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Baarir N.F., Djeffal A.</b></td></tr><tr><td colspan="3">Organisations: <b>Mohamed Khider University of Biskra</b></td></tr><tr><td colspan="3">The phenomenon of Fake news is experiencing a rapid and growing progress with the evolution of the means of communication and Social media. Fake news detection is an emerging research area which is gaining big interest. It faces however some challenges due to the limited resources such as datasets and processing and analysing techniques. In this work, we propose a system for Fake news detection that uses machine learning techniques. We used term frequency-inverse document frequency (TF-IDF) of bag of words and n-grams as feature extraction technique, and Support Vector Machine (SVM) as a classifier. We propose also a dataset of fake and true news to train the proposed system. Obtained results show the efficiency of the system. In this work, we propose a system for Fake news detection that uses machine learning techniques. We used term frequency-inverse document frequency (TF-IDF) of bag of words and n-grams as feature extraction technique, and Support Vector Machine (SVM) as a classifier. We propose also a dataset of fake and true news to train the proposed system. Obtained results show the efficiency of the system.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/Confluence51648.2021.9377172" target="_blank"> Deep neural architecture for veracity analysis of multimodal online information<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85103839974</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Meel P., Vishwakarma D.K.</b></td></tr><tr><td colspan="3">Organisations: <b>Delhi Technological University</b></td></tr><tr><td colspan="3">The extensive digital communication among users around the world in various fields such as politics, sports, religious beliefs, product promotions, celebrities, etc. has given rise to a huge volume of unauthenticated and unverified information. So, it has become imperative in the current scenario to design methods for veracity analysis of online information in various data formats mainly text and images. This work introduces a novel automatic fake news detection framework by utilizing the capabilities of Deep Neural Networks namely VGG16 for Image, Bi-LSTM for Text and Title part of online news. The designed model is intended to be robust enough for handling the forgeries present in the online news articles. Finally, the three parallel architectures for each part of the news are combined using the late fusion approach by some sets of normalized weights. Effective experimental analysis has been carried out on two different real-world news datasets which comprise of real and fake news articles. The highest classification accuracy achieved is 97.74% on the All Data dataset. The state-of-the-art comparison advocates the advantages of the proposed model over other contemporary techniques.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/BigData50022.2020.9378472" target="_blank"> Toward A Multilingual and Multimodal Data Repository for COVID-19 Disinformation<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85103845721</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Li Y., Jiang B., Liu H., Shu K.</b></td></tr><tr><td colspan="3">Organisations: <b>Worcester Polytechnic Institute, Arizona State University, Illinois Institute of Technology</b></td></tr><tr><td colspan="3">The COVID-19 epidemic is considered as the global health crisis of the whole society and the greatest challenge mankind faced since World War Two. Unfortunately, the fake news about COVID-19 is spreading as fast as the virus itself. The incorrect health measurements, anxiety, and hate speeches will have bad consequences on people's physical health, as well as their mental health in the whole world. To help better combat the COVID-19 fake news, we propose a new fake news detection dataset MM-COVID1 (Multilingual and Multidimensional COVID-19 Fake News Data Repository). This dataset provides the multilingual fake news and the relevant social context. We collect 3981 pieces of fake news content and 7192 trustworthy information from English, Spanish, Portuguese, Hindi, French and Italian, 6 different languages. We present a detailed and exploratory analysis of MM-COVID from different perspectives.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> WICO graph: A labeled dataset of twitter subgraphs based on conspiracy theory and 5G-corona misinformation tweets<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85103850285</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Schroeder D.T., Schaal F., Filkukova P., Pogorelov K., Langguth J.</b></td></tr><tr><td colspan="3">Organisations: <b>Simula Metropolitan Center for Digital Engineering, Technical University of Berlin, Technical University of Denmark, Simula Research Laboratory</b></td></tr><tr><td colspan="3">In the wake of the COVID-19 pandemic, a surge of misinformation has flooded social media and other internet channels, and some of it has the potential to cause real-world harm. To counteract this misinformation, reliably identifying it is a principal problem to be solved. However, the identification of misinformation poses a formidable challenge for language processing systems since the texts containing misinformation are short, work with insinuation rather than explicitly stating a false claim, or resemble other postings that deal with the same topic ironically. Accordingly, for the development of better detection systems, it is not only essential to use hand-labeled ground truth data and extend the analysis with methods beyond Natural Language Processing to consider the characteristics of the participant's relationships and the diffusion of misinformation. This paper presents a novel dataset that deals with a specific piece of misinformation: the idea that the 5G wireless network is causally connected to the COVID-19 pandemic. We have extracted the subgraphs of 3,000 manually classified Tweets from Twitter's follower network and distinguished them into three categories. First, subgraphs of Tweets that propagate the specific 5G misinformation, those that spread other conspiracy theories, and Tweets that do neither. We created the WICO (Wireless Networks and Coronavirus Conspiracy) dataset to support experts in machine learning experts, graph processing, and related fields in studying the spread of misinformation. Furthermore, we provide a series of baseline experiments using both Graph Neural Networks and other established classifiers that use simple graph metrics as features. The dataset is available at https://datasets.simula.no/wico-graph..</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/SAMI50585.2021.9378650" target="_blank"> Fake news detection in Slovak language using deep learning techniques<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85103855859</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Ivancova K., Sarnovski M., Maslej-Krcsnakova V.</b></td></tr><tr><td colspan="3">Organisations: <b>Technical University Košice</b></td></tr><tr><td colspan="3">In recent years, the spreading of fake news presents a serious issue in the online environment. Automatic methods able to identify them from the text are being massively explored and deployed on social platforms and online media. Such detection methods are based on a combination of natural language processing and machine learning techniques. Deep learning became a very popular choice in many text processing tasks, fake news detection included. Numerous studies apply the advanced deep learning models to detect fake news and related phenomena from the English text. This paper focuses on the detection of fake news from the news articles written in the Slovak language. To successfully train deep learning models, we created a labelled dataset consisting of the political news articles published by online news portals as well as suspicious conspiratory portals. We trained two architectures, CNN and LSTM neural networks using this data. The performance of the models was experimentally evaluated using standard classification metrics.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> A hybrid model for effective fake news detection with a novel COVID-19 dataset<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85103857640</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Kaliyar R.K., Goswami A., Narang P.</b></td></tr><tr><td colspan="3">Organisations: <b>Bennett University, BITS-Pilani</b></td></tr><tr><td colspan="3">Due to the increasing number of users in social media, news articles can be quickly published or share among users without knowing its credibility and authenticity. Fast spreading of fake news articles using different social media platforms can create inestimable harm to society. These actions could seriously jeopardize the reliability of news media platforms. So it is imperative to prevent such fraudulent activities to foster the credibility of such social media platforms. An efficient automated tool is a primary necessity to detect such misleading articles. Considering the issues mentioned earlier, in this paper, we propose a hybrid model using multiple branches of the convolutional neural network (CNN) with Long Short Term Memory (LSTM) layers with different kernel sizes and filters. To make our model deep, which consists of three dense layers to extract more powerful features automatically. In this research, we have created a dataset (FN-COV) collecting 69976 fake and real news articles during the pandemic of COVID-19 with tags like social-distancing, covid19, and quarantine. We have validated the performance of our proposed model with one more real-time fake news dataset: PHEME. The capability of combined kernels and layers of our C-LSTM network is lucrative towards both the datasets. With our proposed model, we achieved an accuracy of 91.88% with PHEME, which is higher as compared to existing models and 98.62% with FN-COV dataset.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/Confluence51648.2021.9377080" target="_blank"> Fake news detection and analysis using multitask learning with BiLSTM CapsNet model<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85103861462</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Sridhar S., Sanagavarapu S.</b></td></tr><tr><td colspan="3">Organisations: <b>Anna University</b></td></tr><tr><td colspan="3">In today’s world, information is of paramount importance in any field and controls our lives. With increasing number of people taking to social media and websites hosted on the internet as their everyday sources of information, the impact of spreading misinformation has high affecting causes rapidly. The proposed system is a Multitask Learning model that can categorize the news articles collected from the web as fake or not. The title and content of the articles are modeled as BiLSTM subtasks and the CapsNet model is the meta classifier. The model predicts with an accuracy of 97.96% which helps to flag the articles posted on the internet so that the readers are well informed. Further, the system is also able to rate the articles on a 5-point scale to determine the degree of misinformation in the article for further analysis.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/TCSS.2021.3068519" target="_blank"> WELFake: Word Embedding over Linguistic Features for Fake News Detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85103915853</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Verma P.K., Agrawal P., Prodan R., Amorim I.</b></td></tr><tr><td colspan="3">Organisations: <b>GLA University, Lovely Professional University, University of Klagenfurt, MOG Technologies, University of Porto</b></td></tr><tr><td colspan="3">Social media is a popular medium for the dissemination of real-time news all over the world. Easy and quick information proliferation is one of the reasons for its popularity. An extensive number of users with different age groups, gender, and societal beliefs are engaged in social media websites. Despite these favorable aspects, a significant disadvantage comes in the form of fake news, as people usually read and share information without caring about its genuineness. Therefore, it is imperative to research methods for the authentication of news. To address this issue, this article proposes a two-phase benchmark model named WELFake based on word embedding (WE) over linguistic features for fake news detection using machine learning classification. The first phase preprocesses the data set and validates the veracity of news content by using linguistic features. The second phase merges the linguistic feature sets with WE and applies voting classification. To validate its approach, this article also carefully designs a novel WELFake data set with approximately 72 000 articles, which incorporates different data sets to generate an unbiased classification output. Experimental results show that the WELFake model categorizes the news in real and fake with a 96.73% which improves the overall accuracy by 1.31% compared to bidirectional encoder representations from transformer (BERT) and 4.25% compared to convolutional neural network (CNN) models. Our frequency-based and focused analyzing writing patterns model outperforms predictive-based related works implemented using the Word2vec WE method by up to 1.73%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.ipm.2021.102597" target="_blank"> Stance detection on social media: State of the art and trends<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85103964289</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>ALDayel A., Magdy W.</b></td></tr><tr><td colspan="3">Organisations: <b>School of Informatics. The University of Edinburgh</b></td></tr><tr><td colspan="3">Stance detection on social media is an emerging opinion mining paradigm for various social and political applications in which sentiment analysis may be sub-optimal. There has been a growing research interest for developing effective methods for stance detection methods varying among multiple communities including natural language processing, web science, and social computing, where each modeled stance detection in different ways. In this paper, we survey the work on stance detection across those communities and present an exhaustive review of stance detection techniques on social media, including the task definition, different types of targets in stance detection, features set used, and various machine learning approaches applied. Our survey reports state-of-the-art results on the existing benchmark datasets on stance detection, and discusses the most effective approaches. In addition, we explore the emerging trends and different applications of stance detection on social media, including opinion mining and prediction and recently using it for fake news detection. The study concludes by discussing the gaps in the current existing research and highlights the possible future directions for stance detection on social media.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.ins.2021.03.037" target="_blank"> HAN, image captioning, and forensics ensemble multimodal fake news detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85104104376</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Meel P., Vishwakarma D.K.</b></td></tr><tr><td colspan="3">Organisations: <b>Delhi Technological University</b></td></tr><tr><td colspan="3">Nowadays, news publication, propagation, and consumption have been diverted to online social media networks and web portals, which has given rise to falsified and fabricated news articles containing both textual and visual information formats. Most of the research to date is centered on textual fake news detection using machine learning approaches, where multimedia data forgery is hardly addressed. Hence, a multimodal fake news detection framework is proposed, which unitedly exploits hidden pattern extraction capabilities from text using Hierarchical Attention Network (HAN) and visual image features using image captioning and forensic analysis. We specifically focused on four different techniques of multimodal data analysis, such as HAN deep model for text, generating image caption and headline matching with news text (CHM), Noise Variance Inconsistency (NVI), and Error Level Analysis (ELA). All these algorithms have been tested, first independently and then collectively using the max voting Ensemble method on three different datasets. The experimental results and comparisons with contemporary techniques put forward the fact that the proposed method outperforms state-of-the-art with 95.90% highest accuracy on the Fake News Samples dataset. The achieved results also prove that the combined model beats individual methods’ capabilities in classifying fake news accurately.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.eswa.2021.115002" target="_blank"> A temporal ensembling based semi-supervised ConvNet for the detection of fake news articles<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85104157470</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Meel P., Vishwakarma D.K.</b></td></tr><tr><td colspan="3">Organisations: <b>Delhi Technological University</b></td></tr><tr><td colspan="3">Internet-based information circulation has given rise to the proliferation of fake and misleading contents, which has extreme hostile effects on individuals and humanity. Supervised artificial intelligence techniques require a huge amount of annotated data which is a time-consuming, expensive and laborious task as the speed and volume of social media news generation is very high. To counter this situation, we propose an innovative Convolutional Neural Network semi-supervised framework built on the self-ensembling concept to take leverage of the linguistic and stylometric information of annotated news articles, at the same time explore the hidden patterns in unlabelled data as well. Self-ensembling provides consensus predictions of the labels of unannotated data using previous epochs outputs of network-in-training. These accumulated ensemble predictions are supposed to be a better predictor for the unknown labels than the output of most recent training epoch, thus suitable to be used as a proxy for the labels of unannotated data. The uniqueness of the framework is that it ensembles all the outputs of previous training epochs of the neural network to use them as an unsupervised target for comparing them with current output prediction of unlabelled articles. The framework is validated with extensive experiments on three datasets for different proportions of labelled and unlabelled data. It can achieve highest 97.45% fake news classification accuracy using 50% labelled articles on Fake News Data Kaggle dataset. Contemporary baseline methods are placed in juxtaposition with the proposed architecture which demonstrates the robustness of our work compared to the state-of-the-art.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.asoc.2021.107393" target="_blank"> Cross-SEAN: A cross-stitch semi-supervised neural attention model for COVID-19 fake news detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85104329411</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Paka W.S., Chakraborty T., Bansal R., Kaushik A., Sengupta S.</b></td></tr><tr><td colspan="3">Organisations: <b>IIIT-Delhi, DTU-Delhi, IIT-Kanpur, Accenture Labs</b></td></tr><tr><td colspan="3">As the COVID-19 pandemic sweeps across the world, it has been accompanied by a tsunami of fake news and misinformation on social media. At the time when reliable information is vital for public health and safety, COVID-19 related fake news has been spreading even faster than the facts. During times such as the COVID-19 pandemic, fake news can not only cause intellectual confusion but can also place people's lives at risk. This calls for an immediate need to contain the spread of such misinformation on social media. We introduce CTF, a large-scale COVID-19 Twitter dataset with labelled genuine and fake tweets. Additionally, we propose Cross-SEAN, a cross-stitch based semi-supervised end-to-end neural attention model which leverages the large amount of unlabelled data. Cross-SEAN partially generalises to emerging fake news as it learns from relevant external knowledge. We compare Cross-SEAN with seven state-of-the-art fake news detection methods. We observe that it achieves 0.95 F1 Score on CTF, outperforming the best baseline by 9%. We also develop Chrome-SEAN, a Cross-SEAN based chrome extension for real-time detection of fake tweets.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-68787-8_45" target="_blank"> Automatic Fake News Detection with Pre-trained Transformer Models<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85104417667</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Schutz M., Siegel M., Nazemi K., Schindler A.</b></td></tr><tr><td colspan="3">Organisations: <b>Darmstadt University for Applied Sciences, Austrian Institute of Technology GmbH</b></td></tr><tr><td colspan="3">The automatic detection of disinformation and misinformation has gained attention during the last years, since fake news has a critical impact on democracy, society, and journalism and digital literacy. In this paper, we present a binary content-based classification approach for detecting fake news automatically, with several recently published pre-trained language models based on the Transformer architecture. The experiments were conducted on the FakeNewsNet dataset with XLNet, BERT, RoBERTa, DistilBERT, and ALBERT and various combinations of hyperparameters. Different preprocessing steps were carried out with only using the body text, the titles and a concatenation of both. It is concluded that Transformers are a promising approach to detect fake news, since they achieve notable results, even without using a large dataset. Our main contribution is the enhancement of fake news’ detection accuracy through different models and parametrizations with a reproducible result examination through the conducted experiments. The evaluation shows that already short texts are enough to attain 85% accuracy on the test set. Using the body text and a concatenation of both reach up to 87% accuracy. Lastly, we show that various preprocessing steps, such as removing outliers, do not have a significant impact on the models prediction output.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICIPTM52218.2021.9388356" target="_blank"> Evaluation of tools and extension for fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85104463370</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Sharma D.K., Garg S., Shrivastava P.</b></td></tr><tr><td colspan="3">Organisations: <b>GLA University</b></td></tr><tr><td colspan="3">Exposing Fake news is required in today's digital era. In this paper, we discussed several ways to detect the misleading content which the general public can follow. We also provide a detailed discussion of existing tools and extension which are already available for fake news detection. We present several systems designed by researchers to fight against misinformation. Several Fact-checking websites are discussed here to help social media users verify the information present in Social-media. The public should access these tools to determine the fabricated content. This paper will help the general public to know the basic techniques for fake news identification. We ran LSTM and BI-LSTM Classifier on existing Kaggle dataset and achieved 91.51% accuracy using Bi-LSTM classifier.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-16-1160-5_15" target="_blank"> Fake News Detection Using Knowledge Vector<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85104484725</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>He H., Sun G., Yu Q., Li H.</b></td></tr><tr><td colspan="3">Organisations: <b>Nanjing University of Posts and Telecommunications, Key Laboratory of Urban Natural Resources Monitoring and Simulation Ministry of Natural Resources</b></td></tr><tr><td colspan="3">In recent years, social media takes the advantages of fast spreading speed, wide range and low cost to become the main channel for people to obtain news, which also makes it to be a hotbed for the proliferation of fake news, exposing users and society to huge risks. Due to the fact that there is some true information in fake news, traditional text feature detection algorithms are more difficult to detect the fake news. Therefore, it is necessary to use knowledge as auxiliary information to help detection. We propose a fake news detection framework using knowledge vectors, which can adopt existing and reliable news as knowledge sources and reduce the dependence on expert verification. The framework consists of three parts: event triple extraction based on reliable content, fusion knowledge vector and fake news detector. The experimental results on the data set show that the framework can fuse part of the knowledge information and optimize the detection performance.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.3390/sym13040556" target="_blank"> Intelligent detection of false information in arabic tweets utilizing hybrid harris hawks based feature selection and machine learning models<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85104512594</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Thaher T., Saheb M., Turabieh H., Chantar H.</b></td></tr><tr><td colspan="3">Organisations: <b>Arab American University, Palestine Polytechnic University, Taif University, Sebha University</b></td></tr><tr><td colspan="3">Fake or false information on social media platforms is a significant challenge that leads to deliberately misleading users due to the inclusion of rumors, propaganda, or deceptive information about a person, organization, or service. Twitter is one of the most widely used social media platforms, especially in the Arab region, where the number of users is steadily increasing, accompanied by an increase in the rate of fake news. This drew the attention of researchers to provide a safe online environment free of misleading information. This paper aims to propose a smart classification model for the early detection of fake news in Arabic tweets utilizing Natural Language Processing (NLP) techniques, Machine Learning (ML) models, and Harris Hawks Optimizer (HHO) as a wrapper-based feature selection approach. Arabic Twitter corpus composed of 1862 previously annotated tweets was utilized by this research to assess the efficiency of the proposed model. The Bag of Words (BoW) model is utilized using different term-weighting schemes for feature extraction. Eight well-known learning algorithms are investigated with varying combinations of features, including user-profile, content-based, and words-features. Reported results showed that the Logistic Regression (LR) with Term Frequency-Inverse Document Frequency (TF-IDF) model scores the best rank. Moreover, feature selection based on the binary HHO algorithm plays a vital role in reducing dimensionality, thereby enhancing the learning model’s performance for fake news detection. Interestingly, the proposed BHHO-LR model can yield a better enhancement of 5% compared with previous works on the same dataset.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/CRC50527.2021.9392458" target="_blank"> Comparison of Fake News Detection using Machine Learning and Deep Learning Techniques<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85104532127</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Alameri S.A., Mohd M.</b></td></tr><tr><td colspan="3">Organisations: <b>Seiyun University, Universiti Kebangsaan Malaysia</b></td></tr><tr><td colspan="3">Fake news has spread widely on the Web in recent years due to the massive amount of information exchanged on digital media. This has motivates our study to determine the best-performing model among two Machine Learning models: Naïve Bayes (NB), Support Vector Machine (SVM), and three Deep Learning models: Long Short-Term Memory (LSTM), Neural Network with Keras (NN-Keras), and Neural Network with TensorFlow (NN-TF). We examined five models using two different English language news datasets. The performance of the models was evaluated using four metrics; accuracy, precision, recall and F1-score. The obtained results showed that deep learning models had achieved better accuracy than traditional ML models. The LSTM model has outperformed all other models examined. It achieved an average accuracy of 94.21%. The NN-Keras has also produced a good performance with an average accuracy of 92.99%. The words' order carries critical information and plays a significant role in the fake news classification, where our LSTM makes a prediction based on this.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICCIT51783.2020.9392662" target="_blank"> Evaluating Machine Learning Algorithms for Bengali Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85104538043</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Mugdha S.B.S., Ferdous S.M., Fahmin A.</b></td></tr><tr><td colspan="3">Organisations: <b>United International University</b></td></tr><tr><td colspan="3">In this world of modern technologies and media, online news publications and portals are increasing at a high speed. That is why, nowadays, it has become almost impossible to check out the traditional fact of news headlines and examine them due to the increase in the number of content writers, online media portals, and news portals. Mostly, fake headlines are filled with bogus or misleading content. They attract the commoners by putting phony words or misleading fraudulent content in the headlines to increase their views and share. But, these fake and misleading headlines create havoc in the commoner's life and misguide them in many ways. That is why we took a step so that the commoners can differentiate between fake and real news. We proposed a model that can successfully detect whether the story is fake or accurate based on the news headlines. We created a novel data set of Bengali language and achieved our aim and reached the target using the Gaussian Naive Bayes algorithm. We have used other algorithms, but the Gaussian Naive Algorithm has performed well in our model. This algorithm used a text feature dependent on TF-IDF and an Extra Tree Classifier to choose the attribute. In our model, using Gaussian Naive Bayes we got 87% accuracy which is comparatively best than any other algorithm we used in this model.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICCCIS51004.2021.9397228" target="_blank"> Machine Learned Classifiers for Trustworthiness Assessment of Web Information Contents<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85104586321</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Meel P., Vishwakarma D.K.</b></td></tr><tr><td colspan="3">Organisations: <b>Delhi Technological University</b></td></tr><tr><td colspan="3">Social networking, information sharing, knowledge imparting, discussions on current happenings etc. are always a part of human society. With the fast pace of life and advancement in technology; people rely more on online information, as a result of this web platforms have become a dominant place for social interactions. This has given rise to unverified and unauthenticated news that has extremely negative effects. Fake news, rumor, misinformation, disinformation, satire, hoax, clickbait, propaganda are all different flavors of the same malice of information pollution. The research community is constantly trying to figure out a viable technical solution to this problem in different ways. In this work, we designed a framework based on five independent supervised machine-learned classifiers Support Vector Machine, K-Nearest Neighbor, Logistic Regression, Naïve Bayes and Random Forest for trustworthiness assessment of web information contents. The classifiers are being trained and tested on two different datasets: Fake News Detection (Jruvika/FND) and Real or Fake News that contains full news articles in the form of headline and body. Experiments and result analysis verify that the highest accuracy attained by the projected method is 96.61% on the Fake News Detection dataset using the SVM classifier. The work is also compared with other contemporary techniques.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/JIOT.2021.3073904" target="_blank"> Harnessing the Power of Smart and Connected Health to Tackle COVID-19: IoT, AI, Robotics, and Blockchain for a Better World<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85104588125</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Firouzi F., Farahani B., Daneshmand M., Grise K., Song J., Saracco R., Wang L.L., Lo K., Angelov P., Soares E., Loh P.-S., Talebpour Z., Moradi R., Goodarzi M., Ashraf H., Talebpour M., Talebpour A., Romeo L., Das R., Heidari H., Pasquale D., Moody J., Woods C., Huang E.S., Barnaghi P., Sarrafzadeh M., Li R., Beck K.L., Isayev O., Sung N., Luo A.</b></td></tr><tr><td colspan="3">Organisations: <b>Duke University</b></td></tr><tr><td colspan="3">As COVID-19 hounds the world, the common cause of finding a swift solution to manage the pandemic has brought together researchers, institutions, governments, and society at large. The Internet of Things (IoT), artificial intelligence (AI) - including machine learning (ML) and Big Data analytics - as well as Robotics and Blockchain, are the four decisive areas of technological innovation that have been ingenuity harnessed to fight this pandemic and future ones. While these highly interrelated smart and connected health technologies cannot resolve the pandemic overnight and may not be the only answer to the crisis, they can provide greater insight into the disease and support frontline efforts to prevent and control the pandemic. This article provides a blend of discussions on the contribution of these digital technologies, propose several complementary and multidisciplinary techniques to combat COVID-19, offer opportunities for more holistic studies, and accelerate knowledge acquisition and scientific discoveries in pandemic research. First, four areas, where IoT can contribute are discussed, namely: 1) tracking and tracing; 2) remote patient monitoring (RPM) by wearable IoT (WIoT); 3) personal digital twins (PDTs); and 4) real-life use case: ICT/IoT solution in South Korea. Second, the role and novel applications of AI are explained, namely: 1) diagnosis and prognosis; 2) risk prediction; 3) vaccine and drug development; 4) research data set; 5) early warnings and alerts; 6) social control and fake news detection; and 7) communication and chatbot. Third, the main uses of robotics and drone technology are analyzed, including: 1) crowd surveillance; 2) public announcements; 3) screening and diagnosis; and 4) essential supply delivery. Finally, we discuss how distributed ledger technologies (DLTs), of which blockchain is a common example, can be combined with other technologies for tackling COVID-19.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-73696-5_17" target="_blank"> Identification of COVID-19 Related Fake News via Neural Stacking<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85104693400</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Koloski B., Pollak S., Skrlj B., Stepisnik-Perdih T.</b></td></tr><tr><td colspan="3">Organisations: <b>Jožef Stefan Institute, University of Ljubljana</b></td></tr><tr><td colspan="3">Identification of Fake News plays a prominent role in the ongoing pandemic, impacting multiple aspects of day-to-day life. In this work we present a solution to the shared task titled COVID19 Fake News Detection in English, scoring the 50th place amongst 168 submissions. The solution was within 1.5% of the best performing solution. The proposed solution employs a heterogeneous representation ensemble, adapted for the classification task via an additional neural classification head comprised of multiple hidden layers. The paper consists of detailed ablation studies further displaying the proposed method’s behavior and possible implications. The solution is freely available. https://gitlab.com/boshko.koloski/covid19-fake-news</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> End-to-end argumentation knowledge graph construction<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85104696065</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Al-Khatib K., Stein B., Hou Y., Jochim C., Bonin F., Wachsmuth H.</b></td></tr><tr><td colspan="3">Organisations: <b>Bauhaus-Universitat, IBM Research, Paderborn University</b></td></tr><tr><td colspan="3">This paper studies the end-to-end construction of an argumentation knowledge graph that is intended to support argument synthesis, argumentative question answering, or fake news detection, among others. The study is motivated by the proven effectiveness of knowledge graphs for interpretable and controllable text generation and exploratory search. Original in our work is that we propose a model of the knowledge encapsulated in arguments. Based on this model, we build a new corpus that comprises about 16k manual annotations of 4740 claims with instances of the model’s elements, and we develop an end-to-end framework that automatically identifies all modeled types of instances. The results of experiments show the potential of the framework for building a web-based argumentation graph that is of high quality and large scale.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-73696-5_14" target="_blank"> ECOL: Early Detection of COVID Lies Using Content, Prior Knowledge and Source Information<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85104700343</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Baris I., Boukhers Z.</b></td></tr><tr><td colspan="3">Organisations: <b>Technical University of Valencia, University of Koblenz-Landau</b></td></tr><tr><td colspan="3">Social media platforms are vulnerable to fake news dissemination, which causes negative consequences such as panic and wrong medication in the healthcare domain. Therefore, it is important to automatically detect fake news in an early stage before they get widely spread. This paper analyzes the impact of incorporating content information, prior knowledge, and credibility of sources into models for the early detection of fake news. We propose a framework modeling those features by using BERT language model and external sources, namely Simple English Wikipedia and source reliability tags. The conducted experiments on CONSTRAINT datasets demonstrated the benefit of integrating these features for the early detection of fake news in the healthcare domain.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-73696-5_12" target="_blank"> g2tmn at Constraint@AAAI2021: Exploiting CT-BERT and Ensembling Learning for COVID-19 Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85104710211</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Glazkova A., Trifonov T., Glazkov M.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Tyumen, “Organization of Cognitive Associative Systems” LLC</b></td></tr><tr><td colspan="3">The COVID-19 pandemic has had a huge impact on various areas of human life. Hence, the coronavirus pandemic and its consequences are being actively discussed on social media. However, not all social media posts are truthful. Many of them spread fake news that cause panic among readers, misinform people and thus exacerbate the effect of the pandemic. In this paper, we present our results at the Constraint@AAAI2021 Shared Task: COVID-19 Fake News Detection in English. In particular, we propose our approach using the transformer-based ensemble of COVID-Twitter-BERT (CT-BERT) models. We describe the models used, the ways of text preprocessing and adding extra data. As a result, our best model achieved the weighted F1-score of 98.69 on the test set (the first place in the leaderboard) of this shared task that attracted 166 submitted teams in total.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-73696-5_10" target="_blank"> Tackling the Infodemic: Analysis Using Transformer Based Models<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85104714887</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Zutshi A., Raj A.</b></td></tr><tr><td colspan="3">Organisations: <b>Netaji Subhas Institute of Technology</b></td></tr><tr><td colspan="3">This paper presents how we tackled the COVID 19 Fake News Detection in English subtask in the SHARED TASK@ CONSTRAINT 2021 using RoBERTa. We perform extensive analysis to understand the pattern of the data distribution. To achieve an F1 score of 0.96, we incorporate external sources of misinformation and fine tune multiple state of the art pretrained deep learning models. In the end, we visualise the true and false positives predicted by our model as improvement in future work.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-73696-5_6" target="_blank"> LaDiff ULMFiT: A Layer Differentiated Training Approach for ULMFiT<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85104725758</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Azhan M., Ahmad M.</b></td></tr><tr><td colspan="3">Organisations: <b>Jamia Millia Islamia</b></td></tr><tr><td colspan="3">In our paper we present Deep Learning models with a layer differentiated training method which were used for the SHARED TASK @ CONSTRAINT 2021 sub-tasks COVID19 Fake News Detection in English and Hostile Post Detection in Hindi. We propose a Layer Differentiated training procedure for training a pre-trained ULMFiT [8] model. We used special tokens to annotate specific parts of the tweets to improve language understanding and gain insights on the model making the tweets more interpretable. The other two submissions included a modified RoBERTa model and a simple Random Forest Classifier. The proposed approach scored a precision and f1-score of 0.96728972 and 0.967324832 respectively for sub-task COVID19 Fake News Detection in English. Also, Coarse Grained Hostility f1 Score and Weighted Fine Grained f1 score of 0.908648 and 0.533907 respectively for sub-task Hostile Post Detection in Hindi. The proposed approach ranked 61st out of 164 in the sub-task “COVID19 Fake News Detection in English” and 18th out of 45 in the sub-task “Hostile Post Detection in Hindi”. The complete code implementation can be found at: GitHub Repository (https://github.com/sheikhazhanmohammed/AAAI-Constraint-Shared- Tasks-2021 ).</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-73696-5_7" target="_blank"> Extracting Latent Information from Datasets in CONSTRAINT 2021 Shared Task<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85104737411</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Liu R., Zhou X.</b></td></tr><tr><td colspan="3">Organisations: <b>Yunnan University</b></td></tr><tr><td colspan="3">This paper introduces the result of Team Grenzlinie’s experiment in CONSTRAINT 2021 shared task. This task has two subtasks. Subtask1 is the COVID-19 Fake News Detection task in English, a binary classification task. This paper chooses RoBERTa as the pre-trained model, and tries to build a graph from news datasets. Finally, our system achieves an accuracy of 98.64% and an F1-score of 98.64% on the test dataset. Subtask2 is a Hostile Post Detection task in Hindi, a multi-labels task. In this task, XLM-RoBERTa is chosen as the pre-trained model. The adapted threshold is adopted to solve the data unbalanced problem, and then Bi-LSTM, LEAM, LaSO approaches are adopted to obtain more abundant semantic information. The final approach achieves the accuracy of 74.11% and weight F1-score of 81.77% on the test dataset.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-73696-5_18" target="_blank"> Fake News Detection System Using XLNet Model with Topic Distributions: CONSTRAINT@AAAI2021 Shared Task<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85104746756</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Gautam A., Venktesh V., Masud S.</b></td></tr><tr><td colspan="3">Organisations: <b>Indraprastha Institute of Information Technology</b></td></tr><tr><td colspan="3">With the ease of access to information, and its rapid dissemination over the internet (both velocity and volume), it has become challenging to filter out truthful information from fake ones. The research community is now faced with the task of automatic detection of fake news, which carries real-world socio-political impact. One such research contribution came in the form of the Constraint@AAA12021 Shared Task on COVID19 Fake News Detection in English. In this paper, we shed light on a novel method we proposed as a part of this shared task. Our team introduced an approach to combine topical distributions from Latent Dirichlet Allocation (LDA) with contextualized representations from XLNet. We also compared our method with existing baselines to show that XLNet + Topic Distributions outperforms other approaches by attaining an F1-score of 0.967.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-73696-5_9" target="_blank"> Transformer-Based Language Model Fine-Tuning Methods for COVID-19 Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85104775301</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Chen B., Chen B., Gao D., Chen Q., Huo C., Meng X., Ren W., Zhou Y.</b></td></tr><tr><td colspan="3">Organisations: <b>Alibaba Group</b></td></tr><tr><td colspan="3">With the pandemic of COVID-19, relevant fake news is spreading all over the sky throughout the social media. Believing in them without discrimination can cause great trouble to people’s life. However, universal language models may perform weakly in these fake news detection for lack of large-scale annotated data and sufficient semantic understanding of domain-specific knowledge. While the model trained on corresponding corpora is also mediocre for insufficient learning. In this paper, we propose a novel transformer-based language model fine-tuning approach for these fake news detection. First, the token vocabulary of individual model is expanded for the actual semantics of professional phrases. Second, we adapt the heated-up softmax loss to distinguish the hard-mining samples, which are common for fake news because of the disambiguation of short text. Then, we involve adversarial training to improve the model’s robustness. Last, the predicted features extracted by universal language model RoBERTa and domain-specific model CT-BERT are fused by one multiple layer perception to integrate fine-grained and high-level specific representations. Quantitative experimental results evaluated on existing COVID-19 fake news dataset show its superior performances compared to the state-of-the-art methods among various evaluation metrics. Furthermore, the best weighted average F1 score achieves 99.02%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-73696-5_15" target="_blank"> Evaluating Deep Learning Approaches for Covid19 Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85104794025</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Wani A., Joshi I., Khandve S., Wagh V., Joshi R.</b></td></tr><tr><td colspan="3">Organisations: <b>Pune Institute of Computer Technology, Indian Institute of Technology Madras</b></td></tr><tr><td colspan="3">Social media platforms like Facebook, Twitter, and Instagram have enabled connection and communication on a large scale. It has revolutionized the rate at which information is shared and enhanced its reach. However, another side of the coin dictates an alarming story. These platforms have led to an increase in the creation and spread of fake news. The fake news has not only influenced people in the wrong direction but also claimed human lives. During these critical times of the Covid19 pandemic, it is easy to mislead people and make them believe in fatal information. Therefore it is important to curb fake news at source and prevent it from spreading to a larger audience. We look at automated techniques for fake news detection from a data mining perspective. We evaluate different supervised text classification algorithms on Contraint@AAAI 2021 Covid-19 Fake news detection dataset. The classification algorithms are based on Convolutional Neural Networks (CNN), Long Short Term Memory (LSTM), and Bidirectional Encoder Representations from Transformers (BERT). We also evaluate the importance of unsupervised learning in the form of language model pre-training and distributed word representations using unlabelled covid tweets corpus. We report the best accuracy of 98.41% on the Covid-19 Fake news detection dataset.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-73696-5_11" target="_blank"> Exploring Text-Transformers in AAAI 2021 Shared Task: COVID-19 Fake News Detection in English<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85104799755</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Li X., Xia Y., Li Z., Li S., Long X.</b></td></tr><tr><td colspan="3">Organisations: <b>Peking University, Beijing University of Posts and Telecommunications</b></td></tr><tr><td colspan="3">In this paper, we describe our system for the AAAI 2021 shared task of COVID-19 Fake News Detection in English, where we achieved the 3rd position with the weighted F1 score of 0.9859 on the test set. Specifically, we proposed an ensemble method of different pre-trained language models such as BERT, Roberta, Ernie, etc. with various training strategies including warm-up, learning rate schedule and k-fold cross-validation. We also conduct an extensive analysis of the samples that are not correctly classified. The code is available at: https://github.com/archersama/3rd-solution-COVID19-Fake-News-Detection-in-English.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-73696-5_13" target="_blank"> Model Generalization on COVID-19 Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85104804209</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Bang Y., Ishii E., Cahyawijaya S., Ji Z., Fung P.</b></td></tr><tr><td colspan="3">Organisations: <b>The Hong Kong University of Science and Technology</b></td></tr><tr><td colspan="3">Amid the pandemic COVID-19, the world is facing unprecedented infodemic with the proliferation of both fake and real information. Considering the problematic consequences that the COVID-19 fake-news have brought, the scientific community has put effort to tackle it. To contribute to this fight against the infodemic, we aim to achieve a robust model for the COVID-19 fake-news detection task proposed at CONSTRAINT 2021 (FakeNews-19) by taking two separate approaches: 1) fine-tuning transformers based language models with robust loss functions and 2) removing harmful training instances through influence calculation. We further evaluate the robustness of our models by evaluating on different COVID-19 misinformation test set (Tweets-19) to understand model generalization ability. With the first approach, we achieve 98.13% for weighted F1 score (W-F1) for the shared task, whereas 38.18% W-F1 on the Tweets-19 highest. On the contrary, by performing influence data cleansing, our model with 99% cleansing percentage can achieve 54.33% W-F1 score on Tweets-19 with a trade-off. By evaluating our models on two COVID-19 fake-news test sets, we suggest the importance of model generalization ability in this task to step forward to tackle the COVID-19 fake-news problem in online social media platforms.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-73696-5_16" target="_blank"> A Heuristic-Driven Ensemble Framework for COVID-19 Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85104809919</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Das S.D., Basak A., Dutta S.</b></td></tr><tr><td colspan="3">Organisations: <b>Razorthink Inc, IIT Madras</b></td></tr><tr><td colspan="3">The significance of social media has increased manifold in the past few decades as it helps people from even the most remote corners of the world stay connected. With the COVID-19 pandemic raging, social media has become more relevant and widely used than ever before, and along with this, there has been a resurgence in the circulation of fake news and tweets that demand immediate attention. In this paper, we describe our Fake News Detection system that automatically identifies whether a tweet related to COVID-19 is “real” or “fake”, as a part of CONSTRAINT COVID19 Fake News Detection in English challenge. We have used an ensemble model consisting of pre-trained models that has helped us achieve a joint 8th position on the leader board. We have achieved an F1-score of 0.9831 against a top score of 0.9869. Post completion of the competition, we have been able to drastically improve our system by incorporating a novel heuristic algorithm based on username handles and link domains in tweets fetching an F1-score of 0.9883 and achieving state-of-the art results on the given dataset.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-73696-5_5" target="_blank"> Overview of CONSTRAINT 2021 Shared Tasks: Detecting English COVID-19 Fake News and Hindi Hostile Posts<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85104812705</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Patwa P., Pykl S., Bhardwaj M., Sharma S., Akhtar M.S., Chakraborty T., Kumari G., Ekbal A., Guptha V., Das A.</b></td></tr><tr><td colspan="3">Organisations: <b>IIIT Sri City, IIIT Delhi, IIT Patna, Wipro Research</b></td></tr><tr><td colspan="3">Fake news, hostility, defamation are some of the biggest problems faced in social media. We present the findings of the shared tasks (https://constraint-shared-task-2021.github.io/ ) conducted at the CONSTRAINT Workshop at AAAI 2021. The shared tasks are ‘COVID19 Fake News Detection in English’ and ‘Hostile Post Detection in Hindi’. The tasks attracted 166 and 44 team submissions respectively. The most successful models were BERT or its variations.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-71119-1_43" target="_blank"> An Approach to Detecting the Spread of False Information on the Internet Using Data Science Algorithms<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85104878800</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Vitkova L., Valieva K., Kozlov D.</b></td></tr><tr><td colspan="3">Organisations: <b>St. Petersburg Institute for Informatics and Automation of Russian Academy of Sciences, The Bonch-Bruevich Saint-Petersburg State University of Telecommunications</b></td></tr><tr><td colspan="3">Today we are all witnessing the rapid immersion of society into the digital world. The amount of information is huge, and it is often difficult to distinguish normal news and comments from unreliable information. In this regard, the issue of detecting fake news and countering its spread becomes urgent. This task is not trivial for the following reasons: firstly, the volume of content that is created every day on the Internet is enormous; secondly, the detection system requires news plots that are obviously true; thirdly, the system must be able to analyze information in close to real time. The article presents a new approach to detecting the spread of false information on the Internet based on the use of data science algorithms. The concept of a fake news detection system includes 4 components and a data storage system. The article presents an experimental evaluation of methods implemented in the framework of the neural network training component and the detection of false information.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICACITE51222.2021.9404648" target="_blank"> Discover Pretend Disease News Misleading Data in Social Media Networks Using Machine Learning Techniques<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85104932208</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Anandhan K., Damodharan D., Lakhanpal A., Shanker Singh A., Manoj Sagar K., Murugan K.</b></td></tr><tr><td colspan="3">Organisations: <b>Galgotias University, Vsb Engineering College, Sri Ganesh College of Engineering and Technology</b></td></tr><tr><td colspan="3">The expansion of fake news in online world starts with a trendy topic around us whether it is related to environment, politics, healthcare or any pandemic like Coronavirus. Flashy altered headlines attract the users to help media enhance their business. Fake news hoaxes related to pandemic like Coronavirus can lead to much harm than coronavirus itself. This extensive spread of fake news comes with negative impact on all the citizens. Therefore it's very important to detect, intervene analyze any pretend news. The main purpose of writing this research article is to come out with the best approach to monitor the misleading information of various diseases around the internet by investigating the principles, methodologies algorithms. The false news comes with the big, unstructured, irrelevant, incomplete noisy data and for its detection some evaluation metrics, representative datasets, network analysis approach algorithm like Naïve Bayes Classifier will be on the role leading to the most effective accurate way to detect fake news related to fake disease news all around the globe. We achieved fake disease news detection accuracy of approximately 82.49%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1002/asi.24480" target="_blank"> The impact of emotional signals on credibility assessment<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85104963832</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Giachanou A., Rosso P., Crestani F.</b></td></tr><tr><td colspan="3">Organisations: <b>Universitat Politècnica de València, Università della Svizzera italiana, Utrecht University</b></td></tr><tr><td colspan="3">Fake news is considered one of the main threats of our society. The aim of fake news is usually to confuse readers and trigger intense emotions to them in an attempt to be spread through social networks. Even though recent studies have explored the effectiveness of different linguistic patterns for fake news detection, the role of emotional signals has not yet been explored. In this paper, we focus on extracting emotional signals from claims and evaluating their effectiveness on credibility assessment. First, we explore different methodologies for extracting the emotional signals that can be triggered to the users when they read a claim. Then, we present emoCred, a model that is based on a long-short term memory model that incorporates emotional signals extracted from the text of the claims to differentiate between credible and non-credible ones. In addition, we perform an analysis to understand which emotional signals and which terms are the most useful for the different credibility classes. We conduct extensive experiments and a thorough analysis on real-world datasets. Our results indicate the importance of incorporating emotional signals in the credibility assessment problem.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICAIS50930.2021.9395978" target="_blank"> A Survey on Analysis of Fake News Detection Techniques<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85104997370</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Kumar S., Kumar S., Yadav P., Bagri M.</b></td></tr><tr><td colspan="3">Organisations: <b>Delhi Technological University</b></td></tr><tr><td colspan="3">Social media is one of the most available news sources these days for many folks worldwide due to their low value, quick access, and fast spread. However, this comes with some confusing signs and significant risks of exposure to 'false stories' written to mislead readers. Such information can affect the public's voice and allow evil groups to control the outcome of public events, such as elections. Fake and misleading news can have a real impact on those who find themselves as targets. This paper focuses on analysis of 2017 to 2021 papers and analysis of different fake news detection techniques. This survey gives a far-reaching review about the recent and past examinations on false news detection using different ML algorithms.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICAIS50930.2021.9395896" target="_blank"> A Novel Score-Based Multi-Source Fake News Detection using Gradient Boosting Algorithm<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85105000502</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Selva Birunda S., Kanniga Devi R.</b></td></tr><tr><td colspan="3">Organisations: <b>Kalasalingam Academy of Research and Education</b></td></tr><tr><td colspan="3">The dissemination of fake news in an online social network platform has been a real concern nowadays. Through social media, news articles are posted by many sources like news channels, websites, or even newspaper websites. There is a need to be sure that the information posted is only from credible sources and these posts have to authenticate. The intensity of genuineness of the news posted online cannot be measured absolutely and is still challenging. A novel Score-based Multi-Source Fake News Detection framework is proposed in this work to automate the detection of fake news from multiple news sources. This framework extracts the text-based features from genuine and fake news articles using Term Frequency-Inverted Document Frequency. Then the credibility score of the source s is calculated based on the site features and Top Level Domain. By assimilating the text-based features with the credibility score of multi-source, the credibility of the news is estimated. The proposed framework is applied to the Machine Learning (ML) classifiers to examine their performance in the detection of fake news. The experimental results determine the efficacy of the proposed framework with the Gradient Boosting algorithm of about 99.5% to the utmost level.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.ipm.2021.102610" target="_blank"> Detecting fake news by exploring the consistency of multimodal data<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85105087267</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Xue J., Wang Y., Tian Y., Shi L., Wei L., Li Y.</b></td></tr><tr><td colspan="3">Organisations: <b>Zhengzhou University</b></td></tr><tr><td colspan="3">During the outbreak of the new Coronavirus (2019-nCoV) in 2020, the spread of fake news has caused serious social panic. Fake news often uses multimedia information such as text and image to mislead readers, spreading and expanding its influence. One of the most important problems in fake news detection based on multimodal data is to extract the general features as well as to fuse the intrinsic characteristics of the fake news, such as mismatch of image and text and image tampering. This paper proposes a Multimodal Consistency Neural Network (MCNN) that considers the consistency of multimodal data and captures the overall characteristics of social media information. Our method consists of five subnetworks: the text feature extraction module, the visual semantic feature extraction module, the visual tampering feature extraction module, the similarity measurement module, and the multimodal fusion module. The text feature extraction module and the visual semantic feature extraction module are responsible for extracting the semantic features of text and vision and mapping them to the same space for a common representation of cross-modal features. The visual tampering feature extraction module is responsible for extracting visual physical and tamper features. The similarity measurement module can directly measure the similarity of multimodal data for the problem of mismatching of image and text. We assess the constructed method in terms of four datasets commonly used for fake news detection. The accuracy of the detection is improved clearly compared to the best available methods.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Fake news detection model based on credibility measurement for Indonesian online news<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85105178883</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Arianto R., Harco Leslie S.W., Heryadi Y., Abdurachman E.</b></td></tr><tr><td colspan="3">Organisations: <b>Malang State Polytechnic, Bina Nusantara University</b></td></tr><tr><td colspan="3">The spread of fake news is a problem faced by all active internet users, especially in Indonesian society. Fake news can have an impact on readers' misperceptions, causing harm to certain individuals or groups so that the Indonesian government issued Law number 19 of 2016 which serves to protect internet users from misinformation from fake news. The research that has been done in detecting fake news in Indonesian is still very much dependent on the results of detection from third parties and the Indonesian government in determining whether a news title is included in fake news or not, but if no similarity is found it will be considered as factual news so that this research proposes a fake news detection model based on the level of credibility of online news headlines. This model has 5 stages, namely: Scrapping Web, Document Similarity, Online News Search, Online News Scoring, and Classification. This research has also tested the use of the K-Means, Support Vector Machine with various kernel, and Multilayer Perceptron methods to obtain optimal classification. The results showed that at the Document Similarity stage an optimal threshold value is needed at 0.6, while the Classification stage determines that the most effective method on the data used is the Multilayer Perceptron with the provisions of Hidden Layer 30,20,10 so that you get a mean accuracy of 0.6 and accuracy maximum of 0.8.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1155/2021/5516945" target="_blank"> Arabic Fake News Detection: Comparative Study of Neural Networks and Transformer-Based Approaches<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85105363178</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Al-Yahya M., Al-Khalifa H., Al-Baity H., Alsaeed D., Essam A.</b></td></tr><tr><td colspan="3">Organisations: <b>King Saud University, Helwan University</b></td></tr><tr><td colspan="3">Fake news detection (FND) involves predicting the likelihood that a particular news article (news report, editorial, expose, etc.) is intentionally deceptive. Arabic FND started to receive more attention in the last decade, and many detection approaches demonstrated some ability to detect fake news on multiple datasets. However, most existing approaches do not consider recent advances in natural language processing, i.e., the use of neural networks and transformers. This paper presents a comprehensive comparative study of neural network and transformer-based language models used for Arabic FND. We examine the use of neural networks and transformer-based language models for Arabic FND and show their performance compared to each other. We also conduct an extensive analysis of the possible reasons for the difference in performance results obtained by different approaches. The results demonstrate that transformer-based models outperform the neural network-based solutions, which led to an increase in the F1 score from 0.83 (best neural network-based model, GRU) to 0.95 (best transformer-based model, QARiB), and it boosted the accuracy by 16% compared to the best in neural network-based solutions. Finally, we highlight the main gaps in Arabic FND research and suggest future research directions.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/CSDE50874.2020.9411638" target="_blank"> Fake News Detection Using Content-Based Features and Machine Learning<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85105485601</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Ngada O., Haskins B.</b></td></tr><tr><td colspan="3">Organisations: <b>Nelson Mandela University</b></td></tr><tr><td colspan="3">The problem of fake news is a complex problem and is accompanied with social and economic ramifications. Targeted individuals and entities may lose trustworthiness, credibility and ultimately, suffer from reputation damages to their brand. Economically, an individual or brand may see fluctuations in revenue streams. In addition, the complex nature of the human language makes the problem of fake news a complex problem to solve for currently available computational remedies. The fight against the spread of fake news is a multi-disciplinary effort that will require research, collaboration and rapid development of tools and paradigms aimed at understanding and combating false information dissemination. This study explores fake news detection techniques using machine learning technology. Using a feature set which captures article structure, readability, and the similarity between the title and body, we show such features can deliver promising results. In the experiment, we select 6 machine learning algorithms, namely, AdaBoost as AB, Decision Tree as DT, K-Nearest Neighbour as KNN, Random Forest as RF, Support Vector Machine as SVM and XGBoost as XGB. To quantify a classifier's performance, we use the confusion matrix model and other performance metrics. Given the structure of the experiment, we show the Support Vector Machine classifier provided the best overall results.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.ipm.2021.102618" target="_blank"> Propagation2Vec: Embedding partial propagation networks for explainable fake news early detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85105547150</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Silva A., Han Y., Luo L., Karunasekera S., Leckie C.</b></td></tr><tr><td colspan="3">Organisations: <b>The University of Melbourne</b></td></tr><tr><td colspan="3">Many recent studies have demonstrated that the propagation patterns of news on social media can facilitate the detection of fake news. Most of these studies rely on the complete propagation networks to build their model, which is not fully available in the early stages and may take a long time to complete. Hence, relying on the complete propagation network is not ideal for fake news early detection. However, detecting fake news as early as possible is important due to their fast-spreading nature and the significant harm they can cause. In addition, most existing propagation network-based fake news detection techniques are not explicitly designed to jointly emphasise informative cascades and nodes in the propagation networks to detect fake news. To bridge these research gaps, this work proposes Propagation2Vec, a novel fake news early detection technique, which assigns varying levels of importance for the nodes and cascades in propagation networks, and reconstructs the knowledge of complete propagation networks based on their partial propagation networks at an early detection deadline. Our experiments show that our model can achieve state-of-the-art performance while only having access to the early stage propagation networks. Furthermore, we devise general explanations for the underlying logic of Propagation2Vec based on its attention weights assigned to different nodes and cascades, which improves the applicability of our approach and facilitates future research on propagation network-based fake news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Fake news detection based on word and document embedding using machine learning classifiers<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85105584185</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Desouky Fattoh I.E.L., Mousa F.A.</b></td></tr><tr><td colspan="3">Organisations: <b>Beni-Suef University</b></td></tr><tr><td colspan="3">Fake news is a problem that has a major effect on our life. Detection of fake news considered an interesting research area that has some limitation of the available resources. In this research, we propose a classification model that is capable of detecting fake news based on both Doc2vec and Word2vec embedding as feature extraction methods. Firstly, we compare between the two approaches using different classification algorithms. According to the applied experiments, the classification based on Doc2vec model provided promising results with more than one classifier. The Support vector machine resulted the best accuracy with 95.5% followed by Logistic Regression 94.7% and the Long Short Term Memory produced the lowest accuracy. On the other hand, the classification based Word2vec embedding model results high accuracy only with Long Short Term Memory classifier with 94.3%. Secondly, the classification models based on proposed Doc2vec have shown to outperform a corresponding model that based on TF-IDF on the same dataset using Support Vector Machine and Logistic Regression classifiers.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1155/2021/5557784" target="_blank"> Fake Detect: A Deep Learning Ensemble Model for Fake News Detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85105764570</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Aslam N., Ullah Khan I., Alotaibi F.S., Aldaej L.A., Aldubaikil A.K.</b></td></tr><tr><td colspan="3">Organisations: <b>Imam Abdulrahman Bin Faisal University</b></td></tr><tr><td colspan="3">Pervasive usage and the development of social media networks have provided the platform for the fake news to spread fast among people. Fake news often misleads people and creates wrong society perceptions. The spread of low-quality news in social media has negatively affected individuals and society. In this study, we proposed an ensemble-based deep learning model to classify news as fake or real using LIAR dataset. Due to the nature of the dataset attributes, two deep learning models were used. For the textual attribute "statement,"Bi-LSTM-GRU-dense deep learning model was used, while for the remaining attributes, dense deep learning model was used. Experimental results showed that the proposed study achieved an accuracy of 0.898, recall of 0.916, precision of 0.913, and F-score of 0.914, respectively, using only statement attribute. Moreover, the outcome of the proposed models is remarkable when compared with that of the previous studies for fake news detection using LIAR dataset.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-73050-5_44" target="_blank"> Detection of Fake News Based on Domain Analysis and Social Network Psychology<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85105938398</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Deb D., Pavan R.S., Nautiyal A., Phadnis A., Rathore H.</b></td></tr><tr><td colspan="3">Organisations: <b>BITS Pilani</b></td></tr><tr><td colspan="3">Fake news is becoming a massive issue from being used to manipulate elections to spread chaos and to being darn right annoying. Fake news has become a thriving business where many companies and state agencies offer services to spread fake news deliberately to benefit their clients. Hence new techniques are required to identify and detect fake news. In this paper, we propose a novel 3-phase approach for the identification of fake news. We extracted features like WHOIS and DNS from domain information and used for the model construction. We also combine psychological factors of both the people trying to spread the fake news and the general population. We train our model on journalist labelled data and achieved more than 80% accuracy. We are also able to increase the precision and recall of fake and genuine news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-15-9938-5_8" target="_blank"> Fake News Detection Based on Machine Learning<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85105941378</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Choudhary P., Pandey S., Tripathi S., Chaurasiya S.</b></td></tr><tr><td colspan="3">Organisations: <b>G. L. Bajaj Institute of Technology and Management</b></td></tr><tr><td colspan="3">Mob lynchings, misrepresentation of government policies, manipulated history, and communal disharmony are some of the events that recently occurred due to fake news propagation. Hence, fake news detection model will help to spread awareness and harmony among individuals. According to BBC Report, 72% Indians fail to distinguish between ‘real’ and ‘fake’ news. Hence, in this paper a model is proposed in which natural language processing has been used for rectification of the text along with machine learning algorithms. The model predicted fake and real news successfully with 90.2% accuracy.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s11042-021-11006-8" target="_blank"> Adaptive Salp swarm optimization algorithms with inertia weights for novel fake news detection model in online social media<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85105947991</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Ozbay F.A., Alatas B.</b></td></tr><tr><td colspan="3">Organisations: <b>Firat University</b></td></tr><tr><td colspan="3">Recently, social media are the most popular way of consuming news for people due to their fast, low cost, and easy accessibility. Unfortunately, in order to provide financial, political, or personal interests on social media, a large amount of fake news is intentionally produced that contains false information. Although fake news detection is a very important problem to avoid negative effects, efficient studies on this issue are limited. More efficient models are required in order to obtain better solutions with respect to different metrics for fake news detection. In this paper, a novel model was proposed that uses optimization methods for fake news detection. In addition, an improved Salp Swarm Optimization (SSO) based on a nonlinear decreasing coefficient and oscillating inertia weight was proposed to find the best optimum solution for fake news detection for the first time. The standard SSO, Grey Wolf Optimization (GWO) which is one of the most recent swarm intelligence algorithms, and two new adaptive SSO methods were modeled to detect fake news for the first time in this study. These methods were tested over four different real-world fake news data sets to verify the performance of the algorithms proposed in this paper. Furthermore, Friedman test was conducted to distinguish the differences among these methods. The obtained results prove that the proposed new model is significantly superior to standard SSA and GWO on the real-world fake news data sets.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-73103-8_37" target="_blank"> Fact Checking: Detection of Check Worthy Statements Through Support Vector Machine and Feed Forward Neural Network<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85105957377</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Ahmed S., Balla K., Hinkelmann K., Corradini F.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Camerino, FHNW University of Applied</b></td></tr><tr><td colspan="3">Detection of check-worthy statements is a subtask in the fact-checking process, automation of which would decrease the time and burden required to fact-check a statement. This paper proposes an approach focused on the classification of statements into check-worthy and not check-worthy. For the current paper, a dataset is constructed by consulting different fact-checking organizations. It contains debates and speeches in the domain of politics. Thus, even the ability of check worthy approach is evaluated on this domain. It starts with extracting sentence-level and context features from the sentences, and classifying them based on these features. The feature set and context were chosen after several experiments, based on how well they differentiate check-worthy statements. The findings indicated that the context in the approach gives considerable contribution in the classification, while also using more general features to capture information from the sentences. The results were analyzed by examining all features used, assessing their contribution in classification, and how well the approach performs in speeches and debates separately to detect the check worthy statements to reduce the time and burden of fact checking process.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-62696-9_2" target="_blank"> On Unsupervised Methods for Fake News Detection<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85105975495</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>P D., Chakraborty T., Long C., G S.K.</b></td></tr><tr><td colspan="3">Organisations: <b>Queen’s University Belfast, Indraprastha Institute of Information Technology, Nanyang Technological University, Cochin University of Science and Technology</b></td></tr><tr><td colspan="3">In this chapter, we consider a reasonably underexplored area in fake news analytics, that of unsupervised learning. We intend to keep the narrative accessible to a broader audience than machine learning specialists and accordingly start with outlining the structure of different learning paradigms vis-à-vis supervision. This is followed by an analysis of the challenges that are particularly pertinent for unsupervised fake news detection. Third, we provide an overview of unsupervised learning methods with a focus on their conceptual foundations. We analyze the conceptual bases with a critical eye and outline other kinds of conceptual building blocks that could be used in devising unsupervised fake news detection methods. Fourth, we survey the limited work in unsupervised fake news detection in detail with a methodological focus, outlining their relative strengths and weaknesses. Lastly, we discuss various possible directions in unsupervised fake news detection and consider the challenges and opportunities in the space.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICCMC51019.2021.9418446" target="_blank"> Evaluating Pretrained Transformer-based Models for COVID-19 Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85105978729</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Hande A., Puranik K., Priyadharshini R., Thavareesan S., Chakravarthi B.R.</b></td></tr><tr><td colspan="3">Organisations: <b>Indian Institute of Information Technology Tiruchirappalli, Ultra Arts and Science College, Eastern University, National University of Ireland Galway</b></td></tr><tr><td colspan="3">The expeditious growth of technology with social media as a platform for communication has led to a proliferous increase in the spread of misinformation and fake news. The ongoing COVID-19 widespread has pushed us to review posts on various social media platforms to stop people from being subjected to false and perilous posts. Detecting fake news in social media has been the need of an hour. The proposed research work has approached it with various Transformer and recurrent models with several contextual word embedding models. Furthermore, the effectiveness of the proposed model is evaluated by using a different loss function instead of the conventional loss function, Binary cross Entropy. The fake news detection is considered as a sequence classification task, one of the downstream tasks of natural language processing. It has been observed that using domain-specific language models along with custom loss function has achieved the highest weighted average F1-score.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-62696-9_15" target="_blank"> Linguistic Approaches to Fake News Detection<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85105979037</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>P D., Chakraborty T., Long C., G S.K.</b></td></tr><tr><td colspan="3">Organisations: <b>Queen’s University Belfast, Indraprastha Institute of Information Technology, Nanyang Technological University, Cochin University of Science and Technology</b></td></tr><tr><td colspan="3">To date, there is no comprehensive linguistic description of fake news. This chapter surveys a range of fake news detection research, focusing specifically on that which adopts a linguistic approach as a whole or as part of an integrated approach. Areas where linguistics can support fake news characterisation and detection are identified, namely, in the adoption of more systematic data selection procedures as found in corpus linguistics, in the recognition of fake news as a probabilistic outcome in classification techniques, and in the proposal for integrating linguistics in hybrid approaches to fake news detection. Drawing on the research of linguist Douglas Biber, it is suggested that fake news detection might operate along dimensions of extracted linguistic features.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-62696-9_10" target="_blank"> Ethical Considerations in Data-Driven Fake News Detection<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85105990118</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>P D., Chakraborty T., Long C., G S.K.</b></td></tr><tr><td colspan="3">Organisations: <b>Queen’s University Belfast, Indraprastha Institute of Information Technology, Nanyang Technological University, Cochin University of Science and Technology</b></td></tr><tr><td colspan="3">Data-driven and AI-based detection of fake news has seen much recent interest. The focus of research on data-driven fake news detection has been on developing novel and effective machine learning pipelines. The field has flourished with the rapid advances in deep learning methodologies and the availability of several labelled datasets to benchmark methods. While treating fake news detection as yet another data analytics problem, there has been little work on analyzing the ethical and normative considerations within such a task. This work, in a first-of-its-kind effort, analyzes ethical and normative considerations in using data-driven automation for fake news detection. We first consider the ethical dimensions of importance within the task context, followed by a detailed discussion on adhering to fairness and democratic values while combating fake news through data-driven AI-based automation. Throughout this chapter, we place emphasis on acknowledging the nuances of the digital media domain and also attempt to outline technologically grounded recommendations on how fake news detection algorithms could evolve while preserving and deepening democratic values within society.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-62696-9_7" target="_blank"> Fact Checking on Knowledge Graphs<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85106034372</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>P D., Chakraborty T., Long C., G S.K.</b></td></tr><tr><td colspan="3">Organisations: <b>Queen’s University Belfast, Indraprastha Institute of Information Technology, Nanyang Technological University, Cochin University of Science and Technology</b></td></tr><tr><td colspan="3">Fact checking, which verifies whether a given statement is true, could play a vital role in fake news detection. For example, for a given piece of news, a potential solution could involve a series of steps, including extracting statements from the news via text parsing, checking the validity of the extracted statements (i.e., fact checking), and classifying the news as fake if some statements have been confirmed to be false and performing further fake news detection processes otherwise. Considering that knowledge graphs are a popular way of representing knowledge, which could be used for verifying or counter-verifying statements, several solutions have been proposed that make use of knowledge graphs for fact checking. In this chapter, recent studies on fact checking with the help of knowledge graphs are reviewed, and three representative solutions, namely, Knowledge Linker, PredPath, and Knowledge Stream, are introduced with some details. Specifically, Knowledge Linker utilizes the semantic proximity metrics for mining knowledge graphs, PredPath employs the link prediction method and introduces a newly defined metric, and Knowledge Stream models the fact-checking problem as an optimization problem and uses flow theory for solving the problem.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-62696-9_3" target="_blank"> Multi-modal Fake News Detection<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85106041807</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>P D., Chakraborty T., Long C., G S.K.</b></td></tr><tr><td colspan="3">Organisations: <b>Queen’s University Belfast, Indraprastha Institute of Information Technology, Nanyang Technological University, Cochin University of Science and Technology</b></td></tr><tr><td colspan="3">The primary motivation behind the spread of fake news is to convince the readers to believe false information related to certain events or entities. Human cognition tends to consume news more when it is visually depicted through multimedia content than just plain text. Fake news spreaders leverage this cognitive state to prepare false information in such a way that it looks attractive in the first place. Therefore, multi-modal representation of fake news has become highly popular. This chapter presents a thorough survey of the recent approaches to detect multi-modal fake news spreading on various social media platforms. To this end, we present a list of challenges and opportunities in detecting multi-modal fake news. We further provide a set of publicly available datasets, which is often used to design multi-modal fake news detection models. We then describe the proposed methods by categorizing them through a taxonomy.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Weak supervision for fake news detection via reinforcement learning<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85106041813</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Wang Y., Gao J., Yang W., Xu J., Zhong B., Deng Q., Ma F.</b></td></tr><tr><td colspan="3">Organisations: <b>State University of New York at Buffalo, Tencent Inc., Pennsylvania State University</b></td></tr><tr><td colspan="3">Today social media has become the primary source for news. Via social media platforms, fake news travel at unprecedented speeds, reach global audiences and put users and communities at great risk. Therefore, it is extremely important to detect fake news as early as possible. Recently, deep learning based approaches have shown improved performance in fake news detection. However, the training of such models requires a large amount of labeled data, but manual annotation is time-consuming and expensive. Moreover, due to the dynamic nature of news, annotated samples may become outdated quickly and cannot represent the news articles on newly emerged events. Therefore, how to obtain fresh and high-quality labeled samples is the major challenge in employing deep learning models for fake news detection. In order to tackle this challenge, we propose a reinforced weakly-supervised fake news detection framework, i.e., WeFEND, which can leverage users’ reports as weak supervision to enlarge the amount of training data for fake news detection. The proposed framework consists of three main components: the annotator, the reinforced selector and the fake news detector. The annotator can automatically assign weak labels for unlabeled news based on users’ reports. The reinforced selector using reinforcement learning techniques chooses high-quality samples from the weakly labeled data and filters out those low-quality ones that may degrade the detector’s prediction performance. The fake news detector aims to identify fake news based on the news content. We tested the proposed framework on a large collection of news articles published via WeChat official accounts and associated user reports. Extensive experiments on this dataset show that the proposed WeFEND model achieves the best performance compared with the state-of-the-art methods.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICCMC51019.2021.9418411" target="_blank"> Multi Domain Fake News Analysis using Transfer Learning<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85106044862</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Goel P., Singhal S., Aggarwal S., Jain M.</b></td></tr><tr><td colspan="3">Organisations: <b>Delhi Technological University</b></td></tr><tr><td colspan="3">Fake news detection is a significant problem where information is available from multiple sources across the internet. Most of the research on fake news has only targeted politics-related articles, but such models would not be robust enough to tackle fake news in the real world. To solve this problem, this research work incorporated transfer learning using attention-based transformers (BERT, RoBERTa, XLNet, DeBERTa, GPT2) and trained them on multi-domain datasets FakeNews AMT and Celebrity across different domains i.e. Politics, Entertainment, Sports, Business, Education and Technology. The proposed model has obtained state-of-the-art results while doing multi-domain and cross-domain testing, having beaten previous papers conformably. Also, the model has achieved a 99.3% accuracy on FakeNewsAMT and 84% accuracy on celebrity dataset. We believe the synergy of transfer learning in a multi-domain setting will make a robust model, which would be relevant in the real world. This idea originated from the fact that multi-domain research's critical challenge is that data distribution is varying, and the key benefit of transfer learning is that it can perform well even when it is trained and tested on different data distributions.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-62696-9_4" target="_blank"> Deep Learning for Fake News Detection<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85106045643</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>P D., Chakraborty T., Long C., G S.K.</b></td></tr><tr><td colspan="3">Organisations: <b>Queen’s University Belfast, Indraprastha Institute of Information Technology, Nanyang Technological University, Cochin University of Science and Technology</b></td></tr><tr><td colspan="3">The widespread usage of fake news through social media outlets causes unpleasant societal outcomes. The research efforts to automatically detect and mitigate its use are essential because of their potential to influence the information ecosystem. A vast amount of work using deep learning techniques paved a way to understand the anatomy of fake news and its spread through social media. This chapter attempts to take stock of such efforts and look beyond the possibilities in this regard. The focus is given mainly to deep learning models and its use in fake news detection. A comprehensive survey of the current literature and datasets used, along with evaluation metrics, are highlighted. Finally, promising research directions toward fake news detection are mentioned.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-62696-9_8" target="_blank"> Graph Mining Meets Fake News Detection<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85106060683</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>P D., Chakraborty T., Long C., G S.K.</b></td></tr><tr><td colspan="3">Organisations: <b>Queen’s University Belfast, Indraprastha Institute of Information Technology, Nanyang Technological University, Cochin University of Science and Technology</b></td></tr><tr><td colspan="3">Nowadays, the diversified services on social media make news diffused at higher rate and larger volumes, which poses unique challenges in terms of the efficiency, scalability, and accuracy on the fake news detection. To solve these issues, graph mining, as a promising direction of data mining, has successfully attracted attentions of recent studies. In this chapter, we present a comprehensive study on recent graph-based fake news detection approaches and show how graph mining enables the whole task. We first introduce different kinds of information related to fake news, then divide the existing graph-based approaches into two scenarios, where various graphs and graph patterns are introduced to model the information on social media and characterize features of the fake news, respectively.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1080/24751839.2020.1847379" target="_blank"> Trends in combating fake news on social media–a survey<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85106175419</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Collins B., Hoang D.T., Hwang D., Nguyen N.T.</b></td></tr><tr><td colspan="3">Organisations: <b>Yeungnam University, Wroclaw University of Science and Technology</b></td></tr><tr><td colspan="3">Social media following its introduction has witnessed a lot of scholarly attention in recent years due to its growing popularity. These various social media sites have become the mecca of information because of their less costly and easy accessibility. Although these sites were developed to enhance our lives, they are seen as both angelic and vicious. Growing misinformation and fake content by malicious users have not only plagued our online social media ecosystem into chaos, but it also meted untold suffering to humankind. Recently, social media has witnessed a reverberation amid the proliferation of fake news which has made people reluctant to engage in genuine news sharing for fear that such information is false. Consequently, there is a dire need for these fake content to be detected and removed from social media. This study explores the various methods of combating fake news on social media such as Natural Language Processing, Hybrid model. We surmised that detecting fake news is a challenging and complex issue, however, it remains a workable task. Revelation in this study holds that the application of hybrid-machine learning techniques and the collective effort of humans could stand a higher chance of fighting misinformation on social media.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/CSICC52343.2021.9420601" target="_blank"> A Novel Method for Detecting Fake news: Deep Learning Based on Propagation Path Concept<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85106184394</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Torgheh F., Masoumi B., Keyvanpour M.R., Shojaedini S.V.</b></td></tr><tr><td colspan="3">Organisations: <b>Islamic Azad University, Alzahra University, Iranian Research Organization for Science and Technology</b></td></tr><tr><td colspan="3">In the modern world, social media are extensively used for the purpose of communication, business and education. Although ease of use and simple accessibility to social media has expanded their applications, but unfortunately, they are associated with potential dangers which may negatively influence users. As main item, the publication of fake news can negatively affect various aspects of life (political, social, economic, etc.), therefore researchers have studied various methods to address the fake news detection. One way to check and detect fake news is to use the available features in news propagation path, news publisher and users. In this paper, an attempt has been made to investigate fake news detection based on these features and a proposed deep neural network model.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.ipm.2021.102631" target="_blank"> Misinformation detection using multitask learning with mutual learning for novelty detection and emotion recognition<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85107037061</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Kumari R., Ashok N., Ekbal A., Ghosal T.</b></td></tr><tr><td colspan="3">Organisations: <b>Indian Institute of Technology Patna, Charles University</b></td></tr><tr><td colspan="3">Fake news or misinformation is the information or stories intentionally created to deceive or mislead the readers. Nowadays, social media platforms have become the ripe grounds for misinformation, spreading them in a few minutes, which led to chaos, panic, and potential health hazards among people. The rapid dissemination and a prolific rise in the spread of fake news and misinformation create the most time-critical challenges for the Natural Language Processing (NLP) community. Relevant literature reveals that the presence of an element of surprise in the story is a strong driving force for the rapid dissemination of misinformation, which attracts immediate attention and invokes strong emotional stimulus in the reader. False stories or fake information are written to arouse interest and activate the emotions of people to spread it. Thus, false stories have a higher level of novelty and emotional content than true stories. Hence, Novelty of the news item and recognizing the Emotional state of the reader after reading the item seems two key tasks to tightly couple with misinformation Detection. Previous literature did not explore misinformation detection with mutual learning for novelty detection and emotion recognition to the best of our knowledge. Our current work argues that joint learning of novelty and emotion from the target text makes a strong case for misinformation detection. In this paper, we propose a deep multitask learning framework that jointly performs novelty detection, emotion recognition, and misinformation detection. Our deep multitask model achieves state-of-the-art (SOTA) performance for fake news detection on four benchmark datasets, viz. ByteDance, FNC, Covid-Stance and FNID with 7.73%, 3.69%, 7.95% and 13.38% accuracy gain, respectively. The evaluation shows that our multitask learning framework improves the performance over the single-task framework for four datasets with 7.8%, 28.62%, 11.46%, and 15.66% overall accuracy gain. We claim that textual novelty and emotion are the two key aspects to consider while developing an automatic fake news detection mechanism. The source code is available at https://github.com/Nish-19/Misinformation-Multitask-Attention-NE.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> A retrospective analysis of the fake news challenge stance detection task<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85107061132</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Hanselowski A., Avinesh P.V.S., Schiller B., Caspelherr F., Meyer C.M., Gurevych I., Chaudhuri D.</b></td></tr><tr><td colspan="3">Organisations: <b>Technische Universität Darmstadt, University of Bonn</b></td></tr><tr><td colspan="3">The 2017 Fake News Challenge Stage 1 (FNC-1) shared task addressed a stance classification task as a crucial first step towards detecting fake news. To date, there is no in-depth analysis paper to critically discuss FNC-1’s experimental setup, reproduce the results, and draw conclusions for next-generation stance classification methods. In this paper, we provide such an in-depth analysis for the three top-performing systems. We first find that FNC-1’s proposed evaluation metric favors the majority class, which can be easily classified, and thus overestimates the true discriminative power of the methods. Therefore, we propose a new F1-based metric yielding a changed system ranking. Next, we compare the features and architectures used, which leads to a novel feature-rich stacked LSTM model that performs on par with the best systems, but is superior in predicting minority classes. To understand the methods’ ability to generalize, we derive a new dataset and perform both in-domain and cross-domain experiments. Our qualitative and quantitative study helps interpreting the original FNC-1 scores and understand which features help improving performance and why. Our new dataset and all source code used during the reproduction study are publicly available for future research1</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3442381.3450004" target="_blank"> Mining dual emotion for fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85107185704</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Zhang X., Cao J., Sheng Q., Zhong L., Li X., Shu K.</b></td></tr><tr><td colspan="3">Organisations: <b>Chinese Academy of Sciences and University of Chinese Academy of Sciences, Renmin University of China, Illinois Institute of Technology</b></td></tr><tr><td colspan="3">Emotion plays an important role in detecting fake news online. When leveraging emotional signals, the existing methods focus on exploiting the emotions of news contents that conveyed by the publishers (i.e., publisher emotion). However, fake news often evokes high-arousal or activating emotions of people, so the emotions of news comments aroused in the crowd (i.e., social emotion) should not be ignored. Furthermore, it remains to be explored whether there exists a relationship between publisher emotion and social emotion (i.e., dual emotion), and how the dual emotion appears in fake news. In this paper, we verify that dual emotion is distinctive between fake and real news and propose Dual Emotion Features to represent dual emotion and the relationship between them for fake news detection. Further, we exhibit that our proposed features can be easily plugged into existing fake news detectors as an enhancement. Extensive experiments on three real-world datasets (one in English and the others in Chinese) show that our proposed feature set: 1) outperforms the state-of-the-art task-related emotional features; 2) can be well compatible with existing fake news detectors and effectively improve the performance of detecting fake news.1 2</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.3390/electronics10111348" target="_blank"> Sentiment analysis for fake news detection<a></b></td></tr><tr><td>Type: Review</td><td>ID: S_2-s2.0-85107211423</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Alonso M.A., Vilares D., Gomez-Rodriguez C., Vilares J.</b></td></tr><tr><td colspan="3">Organisations: <b>Universidade da Coruña and CITIC</b></td></tr><tr><td colspan="3">In recent years, we have witnessed a rise in fake news, i.e., provably false pieces of information created with the intention of deception. The dissemination of this type of news poses a serious threat to cohesion and social well-being, since it fosters political polarization and the distrust of people with respect to their leaders. The huge amount of news that is disseminated through social media makes manual verification unfeasible, which has promoted the design and implementation of automatic systems for fake news detection. The creators of fake news use various stylistic tricks to promote the success of their creations, with one of them being to excite the sentiments of the recipients. This has led to sentiment analysis, the part of text analytics in charge of determining the polarity and strength of sentiments expressed in a text, to be used in fake news detection approaches, either as a basis of the system or as a complementary element. In this article, we study the different uses of sentiment analysis in the detection of fake news, with a discussion of the most relevant elements and shortcomings, and the requirements that should be met in the near future, such as multilingualism, explainability, mitigation of biases, or treatment of multimedia elements.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Graph-based fake news detection using a summarization technique<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85107311180</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Kim G., Ko Y.</b></td></tr><tr><td colspan="3">Organisations: <b>Sungkyunkwan University</b></td></tr><tr><td colspan="3">Nowadays, fake news is spreading in various ways, and this fake information is causing a lot of social damages. Thus the need to detect fake information is increasing to prevent the damages caused by fake news. In this paper, we propose a novel graph-based fake news detection method using a summarization technique that uses only the document internal information. Our proposed method represents the relationship between all sentences using a graph and the reflection rate of contextual information among sentences is computed by using an attention mechanism. In addition, we improve the performance of fake news detection by utilizing summary information as an important subject of the document.The experimental results demonstrate that our method achieves high accuracy, 91.04%, that is 8.85%p better than the previous method.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> FakeFlow: Fake news detection by modeling the flow of affective information<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85107311553</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Ghanem B., Rosso P., Ponzetto S.P., Rangel F.</b></td></tr><tr><td colspan="3">Organisations: <b>Universitat Politècnica de València, University of Mannheim, Symanto Research</b></td></tr><tr><td colspan="3">Fake news articles often stir the readers' attention by means of emotional appeals that arouse their feelings. Unlike in short news texts, authors of longer articles can exploit such affective factors to manipulate readers by adding exaggerations or fabricating events, in order to affect the readers' emotions. To capture this, we propose in this paper to model the flow of affective information in fake news articles using a neural architecture. The proposed model, FakeFlow, learns this flow by combining topic and affective information extracted from text. We evaluate the model's performance with several experiments on four real-world datasets. The results show that FakeFlow achieves superior results when compared against state-ofthe-art methods, thus confirming the importance of capturing the flow of the affective information in news articles.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Hierarchical multi-head attentive network for evidence-aware fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85107316904</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Vo N., Lee K.</b></td></tr><tr><td colspan="3">Organisations: <b>Worcester Polytechnic Institute</b></td></tr><tr><td colspan="3">The widespread of fake news and misinformation in various domains ranging from politics, economics to public health has posed an urgent need to automatically fact-check information. A recent trend in fake news detection is to utilize evidence from external sources. However, existing evidence-aware fake news detection methods focused on either only word-level attention or evidence-level attention, which may result in suboptimal performance. In this paper, we propose a Hierarchical Multi-head Attentive Network to fact-check textual claims. Our model jointly combines multi-head word-level attention and multi-head document-level attention, which aid explanation in both word-level and evidence-level. Experiments on two real-word datasets show that our model outperforms seven state-of-the-art baselines. Improvements over baselines are from 6% to 18%. Our source code and datasets are released at https://github.com/nguyenvo09/EACL2021.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ACCESS.2021.3085875" target="_blank"> All Your Fake Detector Are Belong to Us: Evaluating Adversarial Robustness of Fake-News Detectors Under Black-Box Settings<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85107327225</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Ali H., Khan M.S., Alghadhban A., Alzamil A., Alazmi M., Al-Utaibi K., Qadir J.</b></td></tr><tr><td colspan="3">Organisations: <b>Information Technology University, University of Ha’il</b></td></tr><tr><td colspan="3">With the hyperconnectivity and ubiquity of the Internet, the fake news problem now presents a greater threat than ever before. One promising solution for countering this threat is to leverage deep learning (DL)-based text classification methods for fake-news detection. However, since such methods have been shown to be vulnerable to adversarial attacks, the integrity and security of DL-based fake news classifiers are under question. Although many works study text classification under the adversarial threat, to the best of our knowledge, we do not find any work in literature that specifically analyzes the performance of DL-based fake-news detectors under adversarial settings. We bridge this gap by evaluating the performance of fake-news detectors under various configurations under black-box settings. In particular, we investigate the robustness of four different DL architectural choices-multilayer perceptron (MLP), convolutional neural network (CNN), recurrent neural network (RNN) and a recently proposed Hybrid CNN-RNN trained on three different state-of-the-art datasets-under different adversarial attacks (Text Bugger, Text Fooler, PWWS, and Deep Word Bug) implemented using the state-of-the-art NLP attack library, Text-Attack. Additionally, we explore how changing the detector complexity, the input sequence length, and the training loss affect the robustness of the learned model. Our experiments suggest that RNNs are robust as compared to other architectures. Further, we show that increasing the input sequence length generally increases the detector’s robustness. Our evaluations provide key insights to robustify fake-news detectors against adversarial attacks.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3460620.3460753" target="_blank"> Fake news detection using machine learning methods<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85107481554</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Nagaraja A., Soumya K.N., Naik P., Sinha A., Rajendrakumar J.V.</b></td></tr><tr><td colspan="3">Organisations: <b>SET- Jain Deemed to be University</b></td></tr><tr><td colspan="3">The paper is about the detection of unauthenticated news using Machine-learning methods with different algorithms. There is lot of scope to check the reality of the news received from various sources like websites, blogs, e-content. To identify the fake news, there is a need of some application in real time. Many methods were proposed earlier to observe fake news such as style-based, propagation-based and user-based. Automatic fake news detection application can be generated using natural language processing, information retrieval techniques, as well as graph theory. Language modeling is used to predict the missing or next word in a sentence based on the context. It is believed that mainstream media platforms are publishing fake news to grasp the attention of readers; most likely, it is done to increase the number of visitors on that particular page so that with an increasing number of visitors the page could claim more advertisement. This paper proposes an efficient method to detect fake news with better accuracy by using the available data set to detect the news is FAKE or REAL. Various methods are used for collecting the data and the data mining techniques are applied to clean and visualize it. Data mining helps to differentiate between the qualities of data depending upon its properties. The performance of detecting news only from the body of news is not sufficient but also social engagements should be considered. The objective of the work is to provide end-users with a robust solution so that they can figure out phishy and misguiding information. This technique combines the title and the body of the news to predict fake news more efficiently. The application is concerned with finding a result that could be used to identify fake news to help users.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICICCS51141.2021.9432096" target="_blank"> A system for fake news detection by using supervised learning model for social media contents<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85107526791</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Kousika N., Deepa S., Deephika C., Dhatchaiyine B.M., Amrutha J.</b></td></tr><tr><td colspan="3">Organisations: <b>Sri Krishna College of Engineering and Technology</b></td></tr><tr><td colspan="3">The evolution of ICTs has dramatically increased the number of people with internet access, which has altered the way the information is consumed. As a result, fake news has become one of the main concerns because it could destabilize governments and put them at risk for contemporary society. This can be seen in the example, consider the United States. Electoral campaign, where the term 'fake news' became famous as a result of the hoaxes impact on the final outcome. This research work studies the possibility of using deep learning techniques to discriminate against counterfeit news on the Internet using only their text. To do so, three different neural network architectures are suggested, one on the basis of BERT, Google's modern linguistic model that achieves cutting-edge results. In this project are the applications for the detection of 'fake news, ' which is misleading news stories from reputable sources of the NLP (Natural Language Processing) methods. This approach has been implemented and examined in the form of a software system. Can you build a prototype that can differentiate between 'real' and 'fake' news? In this novel fake news detection approach by SVM achieved the accuracy of 92 % and Naive Bayes achieved the accuracy of 73%. In this study SVM can better than Naive Bayes classifier model in new prediction approach.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s13369-021-05780-8" target="_blank"> Fake News Detection Using BERT Model with Joint Learning<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85107702043</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Shishah W.</b></td></tr><tr><td colspan="3">Organisations: <b>Saudi Electronic University</b></td></tr><tr><td colspan="3">In the current Internet era, there exists rapid spread of fake news, which could lead to serious problems. Many artificial intelligence approaches have been deployed to address the problem; however, fake news detection remains a challenge. To detect a fake news, an understanding of certain actors, entities and the relation of between each word in a long text is essential. Many approaches fail to incorporate these attributes in a long text. We purpose a novel BERT approach with joint learning framework that combines relational features classification (RFC) and named entity recognition (NER). Experimenting on two real-world datasets, we observe the effectiveness of our proposed approach in three evaluation metrics: such as accuracy, F1, and area under the curve (AUC) scores. The uniqueness of our joint framework provides a meaningful weight to attributes, which leads to better performance compared to other baselines.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICOASE51841.2020.9436605" target="_blank"> Fake News Detection Using Machine Learning and Deep Learning Algorithms<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85107762552</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Abdulrahman A., Baykara M.</b></td></tr><tr><td colspan="3">Organisations: <b>Dohuk Polytechnic University, Firat University</b></td></tr><tr><td colspan="3">Classification of fake news on social media has gained a lot of attention in the last decade due to the ease of adding fake content through social media sites. In addition, people prefer to get news on social media instead of on traditional televisions. These trends have led to an increased interest in fake news and its identification by researchers. This study focused on classifying fake news on social media with textual content (text classification). In this classification, four traditional methods were applied to extract features from texts (term frequency-inverse document frequency, count vector, character level vector, and N-Gram level vector), employing 10 different machine learning and deep learning classifiers to categorize the fake news dataset. The results obtained showed that fake news with textual content can indeed be classified, especially using a convolutional neural network. This study obtained an accuracy range of 81 to 100% using different classifiers.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3442381.3450111" target="_blank"> The surprising performance of simple baselines for misinformation detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85107937616</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Pelrine K., Danovitch J., Rabbany R.</b></td></tr><tr><td colspan="3">Organisations: <b>McGill University and Mila - Quebec AI Institute</b></td></tr><tr><td colspan="3">As social media becomes increasingly prominent in our day to day lives, it is increasingly important to detect informative content and prevent the spread of disinformation and unverified rumours. While many sophisticated and successful models have been proposed in the literature, they are often compared with older NLP baselines such as SVMs, CNNs, and LSTMs. In this paper, we examine the performance of a broad set of modern transformer-based language models and show that with basic fine-tuning, these models are competitive with and can even significantly outperform recently proposed state-of-the-art methods. We present our framework as a baseline for creating and evaluating new methods for misinformation detection. We further study a comprehensive set of benchmark datasets, and discuss potential data leakage and the need for careful design of the experiments and understanding of datasets to account for confounding variables. As an extreme case example, we show that classifying only based on the first three digits of tweet ids, which contain information on the date, gives state-of-the-art performance on a commonly used benchmark dataset for fake news detection -Twitter16. We provide a simple tool to detect this problem and suggest steps to mitigate it in future datasets.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3460083" target="_blank"> Chasm in Hegemony: Explaining and Reproducing Disparities in Homophilous Networks<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85107960675</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Zhang Y., Mahajan I., Bengani P., Chaintreau A., Han J.X.</b></td></tr><tr><td colspan="3">Organisations: <b>Columbia University, Massachusetts Institute of Technology</b></td></tr><tr><td colspan="3">In networks with a minority and a majority community, it is well-studied that minorities are under-represented at the top of the social hierarchy. However, researchers are less clear about the representation of minorities from the lower levels of the hierarchy, where other disadvantages or vulnerabilities may exist. We offer a more complete picture of social disparities at each social level with empirical evidence that the minority representation exhibits two opposite phases: at the higher rungs of the social ladder, the representation of the minority community decreases; but, lower in the ladder, which is more populous, as you ascend, the representation of the minority community improves. We refer to this opposing phenomenon between the upper-level and lower-level as the chasm effect. Previous models of network growth with homophily fail to detect and explain the presence of this chasm effect. We analyze the interactions among a few well-observed network-growing mechanisms with a simple model to reveal the sufficient and necessary conditions for both phases in the chasm effect to occur. By generalizing the simple model naturally, we present a complete bi-affiliation bipartite network-growth model that could successfully capture disparities at all social levels and reproduce real social networks. Finally, we illustrate that addressing the chasm effect can create fairer systems with two applications in advertisement and fact-checks, thereby demonstrating the potential impact of the chasm effect on the future research of minority-majority disparities and fair algorithms.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICIST52614.2021.9440601" target="_blank"> CLACTA: Comment-Level-Attention and Comment-Type-Awareness for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85108004833</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Zhang Y., Tang X.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Chinese Academy of Sciences</b></td></tr><tr><td colspan="3">There are many popular communication tools for news sharing in recent years. However, propagation of fake news becomes a serious issue concerning the public and government due to openness and rapidity of online communication. It is widely concerned how to automatically detect fake news as soon as possible. Nevertheless, most existing methods do not well utilize comments which contain rich semantic information or ignore their effect. Inspired by the revealing role of some comments to the original post, we propose the neural network model which consists of comment-level-attention (CLA) and comment-type-awareness (CTA) for fake news detection. In CLA, we devise the attention mechanism which considers semantic relation between the post and the comments. Based on attention weights we take the weighted sum of different comment representations for the sample as corresponding comment feature, which can capture key comment information. As similar to stance, we assume comments can gather into several different types naturally. Therefore, in CTA, we store comment type representations by the memory matrix which is learned in the training process of sample stream. Comment feature for the sample is aware of the memory matrix, and then corresponding comment type feature is obtained. We concatenate the above two auxiliary features and learned post feature to help detect fake news. Our validation experiments using the Weibo dataset and Pheme dataset demonstrate the effectiveness of the proposed model.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/INDIACom51348.2021.00117" target="_blank"> A survey on video-based fake news detection techniques<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85108016825</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Agrawal R., Sharma D.K.</b></td></tr><tr><td colspan="3">Organisations: <b>GLA University</b></td></tr><tr><td colspan="3">In today's world, fake news identification is a critical problem. Fake news may exist in form of text, images and videos also. There are several techniques exist for fake news detection including forgery detection techniques. This paper discussed the existing forgery techniques used for the fake video detection. In this study, we addressed the existing issues and challenges which make the forgery detection task cumbersome. We have discussed the use of deep neural network, convolutional neural network, biological signal and spatio-temporal neural network for fake video identification. A comparative study of existing techniques, used for forgery detection, is also provided. This exhaustive survey will help the other researchers to combat deep fake problem.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICACCS51430.2021.9441715" target="_blank"> Stacked Bi-LSTM with Attention and Contextual BERT Embeddings for Fake News Analysis<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85108027627</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Agarwal A., Meel P.</b></td></tr><tr><td colspan="3">Organisations: <b>Delhi Technological University</b></td></tr><tr><td colspan="3">With the evolution of digital technology and media, there has been a surge in the number of internet users worldwide. Due to this growth, it has become necessary to stop fake news from being shared on social media platforms as it can mislead large sections of society by spreading unverified information. Therefore, it becomes vital to create a framework for the automatic verification of content shared online. In this work, we propose a deep learning framework using stacked Bi-LSTM with self-attention to detect fake news articles. The proposed model uses contextual embeddings pooled from BERT large model by fine-tuning its last ten layers on the training dataset. The proposed framework's effectiveness is being tested on four different open-source datasets, namely, News Articles Dataset, Kaggle Dataset, Gossipcop Dataset, and Politifact Dataset, through extensive experimentation and evaluation. The highest accuracy achieved by the proposed approach is 0.99 on the News Articles Dataset and Kaggle Dataset. State of the art comparison with contemporary methods shows that our proposed method achieves better performance than peers.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Fake news classification with BERT<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85108060670</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Malakhov A., Patruno A., Bocconi S.</b></td></tr><tr><td colspan="3">Organisations: <b>-</b></td></tr><tr><td colspan="3">This paper describes the usage of the BERT family transformers for the multi-class classification task "FakeNews: Corona virus and 5G conspiracy" track. This is a Natural Language Processing based Fake News detection challenge organized by MediaEval. It demonstrates how one can benefit from using pretrained transformers for tweet discrimination.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> On the pursuit of fake news : From graph convolutional networks to time series<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85108061090</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Pehlivan Z.</b></td></tr><tr><td colspan="3">Organisations: <b>Institut national de l'audiovisuel</b></td></tr><tr><td colspan="3">This paper presents the methods proposed by team INAFake team for MediaEval 2020 FakeNews: Corona virus and 5G conspiracy. We concentrate our work on the sub-task of structure-based fake news detection. Our aim is to test existing methods by leaning on temporal features of networks without taking any textual features into account. We applied two well known supervised graph classification approaches, graph convolutional layers (GCN) and Deep Graph Convolutional Neural Network (DGCNN). We also present the problem as a multivariate time series classification problem and tested multivariate long short term memory fully convolutional network method.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Fake news detection in social media using graph neural networks and NLP techniques: A COVID-19 use-case<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85108077241</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Hamid A., Said N., Hasan L., Sheikh N., Ahmad K., Al-Fuqaha A., Gul A.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Engineering and Technology, IBM Research - Almaden, Hamad Bin Khalifa University, Shaheed Benazir Bhutto Women University</b></td></tr><tr><td colspan="3">The paper presents our solutions for the MediaEval 2020 task namely FakeNews: Corona Virus and 5G Conspiracy Multimedia Twitter-Data-Based Analysis. The task aims to analyze tweets related to COVID-19 and 5G conspiracy theories to detect misinformation spreaders. The task is composed of two sub-tasks namely (i) text-based, and (ii) structure-based fake news detection. For the first task, we propose six different solutions relying on Bag of Words (BoW) and BERT embedding. Three of the methods aim at binary classification task by differentiating in 5G conspiracy and the rest of the COVID-19 related tweets while the rest of them treat the task as ternary classification problem. In the ternary classification task, our BoW and BERT based methods obtained an F1-score of .606% and .566% on the development set, respectively. On the binary classification, the BoW and BERT based solutions obtained an average F1-score of .666% and .693%, respectively. On the other hand, for structure-based fake news detection, we rely on Graph Neural Networks (GNNs) achieving an average ROC of .95% on the development set.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> FakeNews detection using pre-trained language models and graph convolutional networks<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85108092621</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Tuan N.M.D., Minh P.Q.N.</b></td></tr><tr><td colspan="3">Organisations: <b>Toyo Unversity, Aimesoft JSC.</b></td></tr><tr><td colspan="3">We introduce methods for detecting FakeNews related to coronavirus and 5G conspiracy based on textual data and graph data. For the Text-Based Fake News Detection subtask, we proposed a neural network that combines textual features encoded by a pre-trained BERT model and metadata of tweets encoded by a multi-layer perceptron model. In the Structure-Based Fake News Detection subtask, we applied Graph Convolutional Networks (GCN) and proposed some features at each node of GCN. Experimental results show that textual data contains more useful information for detecting FakeNews than graph data, and using meta-data of tweets improved the result of the text-based model.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> MediaEval 2020: An ensemble-based multimodal approach for coronavirus and 5g conspiracy tweet detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85108108282</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Raj C., Mehta M.P.</b></td></tr><tr><td colspan="3">Organisations: <b>Delhi Technological University, Indian Institute of Management Raipur</b></td></tr><tr><td colspan="3">In the wake of ongoing COVID-19 pandemic, a parallel stream of misinformation and conspiracies rises on the internet. People around the world are being flooded with texts and visuals claiming false statements linked with coronavirus disease. This paper presents a multi-modal fake news detection system that uses text and image features to detect conspiracy tweets. This research has been performed in context with the FakeNews: Coronavirus and 5G Conspiracy task of MediaEval 2020. The NLP subtask we have performed utilizes an ensemble of machine learning and deep learning algorithms for the analysis of textualvisual data. We demonstrate the performances of experiments performed for each modality and results obtained after their fusion.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Detecting conspiracy theories from tweets: Textual and structural approaches<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85108120265</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Guo H., Ash A., Chung D., Friedland G.</b></td></tr><tr><td colspan="3">Organisations: <b>University of California</b></td></tr><tr><td colspan="3">The sharing of biased and fake news on social media has skyrocketed in the past few years. These actions have caused real-world problems and harm. The Fake News Detection Task 2020 has two subtasks: NLP-based approach and graph-based approach (Analyzing the repost structure of social media posts). We present baseline models for these two different subtasks and their performance. For the NLP-based approach, Transformers yielded the best results with a Matthews Correlation Coefficient (MCC) score of 0.477. For the graph-based approach, the best results came from a Support Vector Machine (SVM) model with a MCC score of 0.366.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3463677.3463762" target="_blank"> Machine Learning Approach to Detect Fake News, Misinformation in COVID-19 Pandemic<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85108141589</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Bojjireddy S., Geller J., Chun S.A.</b></td></tr><tr><td colspan="3">Organisations: <b>Njit, Cuny College of Staten Island</b></td></tr><tr><td colspan="3">Fake news is false information about current events, intentionally created to mislead readers. The spread of such fake news has the potential to create a negative impact on individuals and society. With today's straightforward creation of social media posts, there has been an increasing amount of fake news, compared to traditional media in the past. We present one of the most serious societal issue of misinformation, specifically using Presidential Election and COVID-19 health related fake news. We present multi-dimensional approaches that organizations and individuals could utilize for detecting fake news, ranging from human/social approaches, to technical approaches to organizational trust/policy approaches. The Machine Learning approach as a technical solution is presented for automating the detection of fake news and misleading contents. A fake news detection web application is presented to make it easy for end users to determine whether an article is legitimate or fake.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Toward automatic fake news classification<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85108274538</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Ghosh S., Shah C.</b></td></tr><tr><td colspan="3">Organisations: <b>Rutgers University</b></td></tr><tr><td colspan="3">The interaction of technology with humans have many adverse effects. The rapid growth and outreach of the social media and the Web have led to the dissemination of questionable and untrusted content among a wider audience, which has negatively influenced their lives and judgment. Different election campaigns around the world highlighted how”fake news” - misinformation that looks genuine - can be targeted towards specific communities to manipulate and confuse them. Ever since, automatic fake news detection has gained widespread attention from the scientific community. As a result, many re-search studies have been conducted to tackle the detection and spreading of fake news. While the first step of such tasks would be to classify claims associated based on their credibility, the next steps would involve identifying hidden patterns in style, syntax, and content of such news claims. We provide a comprehensive overview of what has already been done in this domain and other similar fields, and then propose a generalized method based on Deep Neural Networks to identify if a given claim is fake or genuine. By using different features like the authenticity of the source, perceived cognitive authority, style, and content-based factors, and natural language features, it is possible to predict fake news accurately. We have used a modular approach by combining techniques from information retrieval, natural language processing, and deep learning. Our classifier comprises two main sub-modules. The first sub-module uses the claim to retrieve relevant articles from the know-ledge base which can then be used to verify the truth of the claim. It also uses word-level features for prediction. The second sub-module uses a deep neural network to learn the underlying style of fake content. Our experiments conducted on bench-mark datasets show that for the given classification task we can obtain up to 82.4% accuracy by using a combination of two models; the first model was up to 72% accurate while the second model was around 81% accurate. Our detection model has the potential to automatically detect and prevent the spread of fake news, thus, limiting the caustic influence of technology in the human lives.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3410220.3460109" target="_blank"> Chasm in Hegemony: Explaining and Reproducing Disparities in Homophilous Networks<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85108581617</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Zhang Y., Mahajan I., Bengani P., Chaintreau A., Han J.X.</b></td></tr><tr><td colspan="3">Organisations: <b>Columbia University, Massachusetts Institute of Technology</b></td></tr><tr><td colspan="3">In networks with a minority and a majority community, it is well-studied that minorities are under-represented at the top of the social hierarchy. However, researchers are less clear about the representation of minorities from the lower levels of the hierarchy, where other disadvantages or vulnerabilities may exist. We offer a more complete picture of social disparities at each social level with empirical evidence that the minority representation exhibits two opposite phases: at the higher rungs of the social ladder, the representation of the minority community decreases; but, lower in the ladder, which is more populous, as you ascend, the representation of the minority community improves. We refer to this opposing phenomenon between the upper-level and lower-level as the chasm effect. Previous models of network growth with homophily fail to detect and explain the presence of this chasm effect. We analyze the interactions among a few well-observed network-growing mechanisms with a simple model to reveal the sufficient and necessary conditions for both phases in the chasm effect to occur. By generalizing the simple model naturally, we present a complete bi-affiliation bipartite network-growth model that could successfully capture disparities at all social levels and reproduce real social networks. Finally, we illustrate that addressing the chasm effect can create fairer systems with two applications in advertisement and fact-checks, thereby demonstrating the potential impact of the chasm effect on the future research of minority-majority disparities and fair algorithms.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.asoc.2021.107559" target="_blank"> An effective fake news detection method using WOA-xgbTree algorithm and content-based features<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85108705355</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Sheikhi S.</b></td></tr><tr><td colspan="3">Organisations: <b>Islamic Azad University</b></td></tr><tr><td colspan="3">In recent years, with the fast development of the internet and online platforms such as social media feeds, news blogs, and online newspapers, deceptive reports have been universally spread online. This manipulated news is a matter of concern due to its potential role in shaping public opinion. Therefore, the fast spread of fake news creates an urgent need for automatic systems to detect deceitful articles. This motivates many researchers to introduce solutions for the automatic classification of news items. This paper proposed a novel system to detect fake news articles based on content-based features and the WOA-Xgbtree algorithm. The proposed system can be applied in different scenarios to classify news articles. The proposed approach consists of two main stages: first, the useful features are extracted and analyzed, and then an Extreme Gradient Boosting Tree (xgbTree) algorithm optimized by the Whale Optimization Algorithm (WOA) to classify news articles using extracted features. In our experiments, we considered the bases of the investigation on classification accuracy and the F1-measure. Then, we compared the optimized model with several benchmark classification algorithms based on a dataset that compiled over 40,000 various news articles recently. The results indicate that the proposed approach achieved good classification accuracy and F1 measure rate and successfully classified over 91 percent of articles.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.eswa.2021.115414" target="_blank"> Fake news detection based on explicit and implicit signals of a hybrid crowd: An approach inspired in meta-learning[Formula presented]<a></b></td></tr><tr><td>Type: Review</td><td>ID: S_2-s2.0-85109023627</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Souza Freire P.M., Matias da Silva F.R., Goldschmidt R.R.</b></td></tr><tr><td colspan="3">Organisations: <b>Military Institute of Engineering (IME)</b></td></tr><tr><td colspan="3">The problem of automatic Fake News detection in digital media of news distribution (DMND - e.g., social networks, online newspaper, etc) has become even more relevant. Among the main detection approaches, the one based on crowd signals from DMND users has stood out by obtaining promising results. In essence, in order to classify a piece of news as fake or not fake, such approach explores the collective sense by combining opinions (signals, i.e., votes about the classification of some news) of a high number of users (crowd), considering the reputations of these users regarding their capacity of identifying Fake News. Although promising, the Crowd Signals approach has a significant limitation: it depends on the explicit user opinion (which is not always available) about the classification of the analyzed news. Such unavailability may be caused by the absence of a functionality in the DMND that collects user opinion about the news, or by the simple option of the users in not giving their opinion. Facing this limitation, the present work raises the hypothesis that it is possible to build models of Fake News detection with a performance comparable to the Crowd Signals based approach, avoiding the dependence on the explicit opinion of DMND users. To validate this hypothesis, the present work proposes HCS, an approach based on crowd signals that considers implicit user opinions instead of the explicit ones. The implicit opinions are inferred from the behavior of users concerning the dissemination of the news analyzed. Inspired in Meta-Learning, the HCS can also use the explicit opinions from machines (news classification models) to complement the implicit user opinions by means of hybrid Crowds. Experiments carried out in five datasets presented significant evidence that confirms the raised hypothesis. Even without considering DMND users’ explicit opinions, HCS was able to achieve results comparable to the ones produced by the Crowd Signals approach. Besides that, the results also revealed a performance improvement of HCS when the implicit opinions of the users were combined with the explicit opinions of machines.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1049/ise2.12021" target="_blank"> A hybrid model for fake news detection: Leveraging news content and user comments in fake news<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85109031441</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Albahar M.</b></td></tr><tr><td colspan="3">Organisations: <b>Umm Al Qura University</b></td></tr><tr><td colspan="3">Nowadays, social media platforms such as Twitter have become a popular medium for people to spread and consume news because of their easy access and the rapid proliferation of news. However, the credibility of the news posted on these platforms has become a significant issue. In other words, written news that contains inaccurate information aiming to mislead readers has been rapidly disseminated on these platforms. In the literature, this news is called fake news. Detecting such news on social media platforms has become a challenging task. One of the main challenges is identifying useful information that is exploited as a way to detect fake news. A hybrid model comprising a recurrent neural network (RNN) and support vector machine (SVM) is incorporated to detect real and fake news. An RNN with bidirectional gated recurrent units was used to encode textual data, including news content and comments, to numerical feature vectors. The encoded features were fed to an SVM with radial basis function kernel to classify the given input of real and fake news. Experiments on the real-world dataset yield encouraging results and demonstrate that the proposed framework outperforms state-of-the-art methods.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1117/12.2589047" target="_blank"> Anomaly detection of unstructured big data via semantic analysis and dynamic knowledge graph construction<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85109042830</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Zhao Q., Liu J., Sullivan N., Chen G., Chang K., Spina J., Blasch E.</b></td></tr><tr><td colspan="3">Organisations: <b>Intelligent Fusion Technology,Inc., George Mason University, Air Force Research Laboratory</b></td></tr><tr><td colspan="3">There is an increasing need for both governments and businesses to discover latent anomalous activities in unstructured publicly-available data, produced by professional agencies and the general public. Over the past two decades, consumers have begun to use smart devices to both take in and generate a large volume of open-source text-based data, providing the opportunity for latent anomaly analysis. However, real-time data acquisition, and the processing and interpretation of various types of unstructured data, remains a great challenge. Recent efforts have focused on artificial intelligence / machine learning (AI/ML) solutions to accelerate the labor-intensive linear collection, exploitation, and dissemination analysis cycle and enhance it with a data-driven rapid integration and correlation process of open-source data. This paper describes an Activity Based Intelligence framework for anomaly detection of open-source big data using AI/ML to perform semantic analysis. The proposed Anomaly Detection using Semantic Analysis Knowledge (ADUSAK) framework includes four layers: input layer, knowledge layer, reasoning layer, and graphical user interface (GUI)/output layer. The corresponding main technologies include: Information Extraction, Knowledge Graph (KG) construction, Semantic Reasoning, and Pattern Discovery. Finally, ADUSAK was verified by performing Emerging Events Detection, Fake News Detection, and Suspicious Network Analysis. The generalized ADUSAK framework can be easily extended to a wide range of applications by adjusting the data collection, modeling construction, and event alerting.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.3390/sym13061091" target="_blank"> An evolutionary fake news detection method for covid-19 pandemic information<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85109045070</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Al-Ahmad B., Al-Zoubi A.M., Khurma R.A., Aljarah I.</b></td></tr><tr><td colspan="3">Organisations: <b>The University of Jordan, University of Granada</b></td></tr><tr><td colspan="3">As the COVID-19 pandemic rapidly spreads across the world, regrettably, misinformation and fake news related to COVID-19 have also spread remarkably. Such misinformation has confused people. To be able to detect such COVID-19 misinformation, an effective detection method should be applied to obtain more accurate information. This will help people and researchers easily differentiate between true and fake news. The objective of this research was to introduce an enhanced evolutionary detection approach to obtain better results compared with the previous approaches. The proposed approach aimed to reduce the number of symmetrical features and obtain a high accuracy after implementing three wrapper feature selections for evolutionary classifications using particle swarm optimization (PSO), the genetic algorithm (GA), and the salp swarm algorithm (SSA). The experiments were conducted on one of the popular datasets called the Koirala dataset. Based on the obtained prediction results, the proposed model revealed an optimistic and superior predictability performance with a high accuracy (75.4%) and reduced the number of features to 303. In addition, by comparison with other state-of-the-art classifiers, our results showed that the proposed detection method with the genetic algorithm model outperformed other classifiers in the accuracy.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.11591/ijeecs.v22.i3.pp1667-1671" target="_blank"> Tuned bidirectional encoder representations from transformers for fake news detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85109091408</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Pardamean A., Pardede H.F.</b></td></tr><tr><td colspan="3">Organisations: <b>Graduate School of Computer Science, Indonesian Institute of Sciences</b></td></tr><tr><td colspan="3">Online medias are currently the dominant source of Information due to not being limited by time and place, fast and wide distributions. However, inaccurate news, or often referred as fake news is a major problem in news dissemination for online medias. Inaccurate news is information that is not true, that is engineered to cover the real information and has no factual basis. Usually, inaccurate news is made in the form of news that has mass appeal and is presented in the guise of genuine and legitimate news nuances to deceive or change the reader's mind or opinion. Identification of inaccurate news from real news can be done with natural language processing (NLP) technologies. In this paper, we proposed bidirectional encoder representations from transformers (BERT) for inaccurate news identification. BERT is a language model based on deep learning technologies and it has found effective for many NLP tasks. In this study, we use transfer learning and fine-tuning to adapt BERT for inaccurate news identification. The experiments show that our method could achieve accuracy of 99.23%, recall 99.46%, precision 98.86%, and F-Score of 99.15%. It is largely better than traditional method for the same tasks.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.asoc.2021.107600" target="_blank"> Attention-based C-BiLSTM for fake news detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85109128262</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Trueman T.E., J. A.K., Vidya J., Narayanasamy P.</b></td></tr><tr><td colspan="3">Organisations: <b>Anna University, PSG College of Technology</b></td></tr><tr><td colspan="3">Social media platforms have radically transformed the creation and dissemination of news. Users can easily access this news in a fast and efficient manner. However, some users might post negative and fraudulent content in the form of comments or posts. Such content can constitute a threat to an individual or an organization. Therefore, the identification of fake news has become a major research field in natural language processing (NLP). The main challenge is to determine whether the news is real or fake. In this paper, we propose an attention-based convolutional bidirectional long short-term memory (AC-BiLSTM) approach for detecting fake news and classifying them into six categories. The evaluation of our proposed approach on a benchmarked dataset shows a significant improvement in accuracy rate in comparison with other existing classification models. In particular, this work contributes to the progress in the field of detecting fake news and confirms the feasibility of our proposed approach in classifying fake news on social media.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.14569/IJACSA.2021.0120691" target="_blank"> Fake News Detection in Arabic Tweets during the COVID-19 Pandemic<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85109150208</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Mahlous A.R., Al-Laith A.</b></td></tr><tr><td colspan="3">Organisations: <b>Prince Sultan University, University of Engineering and Technology</b></td></tr><tr><td colspan="3">In March 2020, the World Health Organization declared the COVID-19 outbreak to be a pandemic. Soon afterwards, people began sharing millions of posts on social media without considering their reliability and truthfulness. While there has been extensive research on COVID-19 in the English language, there is a lack of research on the subject in Arabic. In this paper, we address the problem of detecting fake news surrounding COVID-19 in Arabic tweets. We collected more than seven million Arabic tweets related to the corona virus pandemic from January 2020 to August 2020 using the trending hashtags during the time of pandemic. We relied on two fact-checkers: the France-Press Agency and the Saudi Anti-Rumors Authority to extract a list of keywords related to the misinformation and fake news topics. A small corpus was extracted from the collected tweets and manually annotated into fake or genuine classes. We used a set of features extracted from tweet contents to train a set of machine learning classifiers. The manually annotated corpus was used as a baseline to build a system for automatically detecting fake news from Arabic text. Classification of the manually annotated dataset achieved an F1-score of 87.8% using Logistic Regression (LR) as a classifier with the n-gram-level Term Frequency-Inverse Document Frequency (TF-IDF) as a feature, and a 93.3% F1-score on the automatically annotated dataset using the same classifier with count vector feature. The introduced system and datasets could help governments, decision-makers, and the public judge the credibility of information published on social media during the COVID-19 pandemic.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.eswa.2021.115412" target="_blank"> AMFB: Attention based multimodal Factorized Bilinear Pooling for multimodal Fake News Detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85109215869</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Kumari R., Ekbal A.</b></td></tr><tr><td colspan="3">Organisations: <b>Indian Institute of Technology Patna</b></td></tr><tr><td colspan="3">Fake news is the information or stories that are intentionally created to deceive or mislead the readers. In recent times, Fake news detection has attracted the attention of researchers and practitioners due to its many-fold benefits, including bringing in preventive measures to tackle the dissemination of misinformation that could otherwise disturb the social fabrics. Social media in recent times are heavily loaded with multimedia news and information. People prefer online news reading and find it more informative and convenient if they have access to multimedia content in the forms of text, images, audio, and videos. In early studies, researchers have proposed several fake news detection mechanisms that mostly utilize the textual features and not proper to learn multimodal (textual + visual) shared representation. To overcome these limitations, in this paper, we propose a multimodal fake news detection framework with appropriate multimodal feature fusion that leverages information from text and image and tries to maximize the correlation between them to get the efficient multimodal shared representation. We empirically show that text, when combined with the image, can improve the performance of the model. The model detects the post once it is introduced into the network in an early stage. At the early stage of a news post's introduction into the network, the model takes the text and image of the post as input and decides whether this is fake or genuine. Since this model only analyzes news contents, It does not require any prior information regarding the user and network details. This framework has four different sub-modules viz. Attention Based Stacked Bidirectional Long Short Term Memory (ABS-BiLSTM) for textual feature representation, Attention Based Multilevel Convolutional Neural Network–Recurrent Neural Network (ABM-CNN–RNN) for visual feature extraction, multimodal Factorized Bilinear Pooling (MFB) for feature fusion and finally Multi-Layer Perceptron (MLP) for the classification. We perform experiments on two publicly available datasets, viz. Twitter and Weibo. Evaluation results show the efficacy of our proposed approach that performs significantly better compared to the state-of-the-art models. It shows to outperform the current state-of-the-art by approximately 10 points for the Twitter dataset. In contrast, the Weibo dataset achieves an overall better performance with balanced F1-scores between fake and real classes. Furthermore, the complexity of our proposed model is significantly lower than the state-of-the-art.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.eswa.2021.115491" target="_blank"> A link2vec-based fake news detection model using web search results<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85109217462</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Shim J.-S., Lee Y., Ahn H.</b></td></tr><tr><td colspan="3">Organisations: <b>Kookmin University</b></td></tr><tr><td colspan="3">Today, the world is under siege from various kinds of fake news ranging from politics to COVID-19. Thus, many scholars have been researching automatic fake news detection based on artificial intelligence and machine learning (AI/ML) to prevent the spread of fake news. The mainstream research on detecting fake news so far has been text-based detection approaches, but they have inherent limitations such as the difficulty of short text processing and language dependency. Thus, as an alternative to the text-based approach, the context-based approach is emerging. The most common context-based approach the use of distributors’ network information in social media. However, such information is difficult to obtain, and only propagation within a single social media can be traced. Under this background, we propose the use of composition pattern of web links containing news content as a new source of information for fake news detection. To properly vectorize the composition pattern of web links, this study proposes a novel embedding technique, which is called link2vec, an extension of word2vec. To test the effectiveness and language independency of our link2vec-based model, we applied it to two real-world fake news datasets in different languages (English and Korean). As comparison models, we adopted the conventional text-based model and a hybrid model that combined text and whitelist-based link information proposed by a prior study. Results revealed that in the datasets in two languages, the link2vec-based detection models outperformed all the comparison models with statistical significance. Our research is expected to contribute to suggesting a completely new path for effective fake news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.2478/dim-2020-0025" target="_blank"> Cross-Language Fake News Detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85109322147</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Chu S.K.W., Xie R., Wang Y.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Hong Kong</b></td></tr><tr><td colspan="3">With increasing globalization, news from different countries, and even in different languages, has become readily available and has become a way for many people to learn about other cultures. As people around the world become more reliant on social media, the impact of fake news on public society also increases. However, most of the fake news detection research focuses only on English. In this work, we compared the difference between textual features of different languages (Chinese and English) and their effect on detecting fake news. We also explored the cross-language transmissibility of fake news detection models. We found that Chinese textual features in fake news are more complex compared with English textual features. Our results also illustrated that the bidirectional encoder representations from transformers (BERT) model outperformed other algorithms for within-language data sets. As for detection in cross-language data sets, our findings demonstrated that fake news monitoring across languages is potentially feasible, while models trained with data from a more inclusive language would perform better in cross-language detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s00521-021-06230-0" target="_blank"> Deep learning for fake news detection on Twitter regarding the 2019 Hong Kong protests<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85109339425</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Zervopoulos A., Alvanou A.G., Bezas K., Papamichail A., Maragoudakis M., Kermanidis K.</b></td></tr><tr><td colspan="3">Organisations: <b>Ionian University</b></td></tr><tr><td colspan="3">The dissemination of fake news on social media platforms is an issue of considerable interest, as it can be used to misinform people or lead them astray, which is particularly concerning when it comes to political events. The recent event of Hong Kong protests triggered an outburst of fake news posts that were identified on Twitter, which were then promptly removed and compiled into datasets to promote research. These datasets focusing on linguistic content were used in previous work to classify between tweets spreading fake and real news using traditional machine learning algorithms (Zervopoulos et al., in: IFIP international conference on artificial intelligence applications and innovations, Springer, Berlin, 2020). In this paper, the experimentation process on the previously constructed dataset is extended using deep learning algorithms along with a diverse set of input features, ranging from raw text to handcrafted features. Experiments showed that the deep learning algorithms outperformed the traditional approaches, reaching scores as high as 99.3% F1 Score, with the multilingual state-of-the-art model XLM-RoBERTa outperforming other algorithms using raw untranslated text. The combination of both traditional and deep learning algorithms allows for increased performance through the latter, while also gaining insight regarding tweet structure from the interpretability of the former.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s11277-021-08720-9" target="_blank"> Certain Investigation of Fake News Detection from Facebook and Twitter Using Artificial Intelligence Approach<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85109357141</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Setiawan R., Ponnam V.S., Sengan S., Anam M., Subbiah C., Phasinam K., Vairaven M., Ponnusamy S.</b></td></tr><tr><td colspan="3">Organisations: <b>Universitas Airlangga, Koneru Lakshmaiah Education Foundation, PSN College of Engineering and Technology, International Islamic University, National Engineering College, Pibulsongkram Rajabhat University</b></td></tr><tr><td colspan="3">The news platform has moved from traditional newspapers to online communities in the technologically advanced area of Artificial Intelligence. Because Twitter and Facebook allow us to consume news much faster and with less restricted editing, false information continues to spread at an impressive rate and volume. Online Fake News Detection is a promising field in research and captivates the attention of researchers. The sprawl of huge chunks of misinformation in social network platforms is vulnerable to global risk. This article recommends using a Machine Learning optimization technique for automated news article classification on Facebook and Twitter. The emergence of the research is facilitated by the strategic implementation of Natural Language Processing for social forum fake news findings in order to distort news reports from non-recurrent outlets. The relent from the study is outstanding with text document frequency words, which act as extraction technique’s attribute, and the classifier is acted upon by Hybrid Support Vector Machine by achieving 91.23% accuracy.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.ins.2021.05.074" target="_blank"> Coronavirus fake news detection via MedOSINT check in health care official bulletins with CBR explanation: The way to find the real information source through OSINT, the verifier tool for official journals<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85109358372</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Martinez Monterrubio S.M., Noain-Sanchez A., Verdu Perez E., Gonzalez Crespo R.</b></td></tr><tr><td colspan="3">Organisations: <b>Universidad Internacional de La Rioja - UNIR c/ Avenida de la Paz</b></td></tr><tr><td colspan="3">This research aims to design and prototype a tool to perform intelligence on open sources (OSINT), specifically on official medical bulletins for the detection of false news. MedOSINT is a modular tool that can be adapted to process information from different medical official bulletins. From the processed information, intelligence is generated for decision making, validating the veracity of the COVID-19 news. The tool is compared with other options and it is verified that MedOSINT outperforms the current options when analyzing official bulletins. Moreover, it is complemented with an expert explanation provided by a Case-Based Reasoning (CBR) system. This is proved to be an ideal complement because it can find explanatory cases for an explanation-by-example justification.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.7717/PEERJ-CS.518" target="_blank"> Fake news detection: A survey of evaluation datasets<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85109459867</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>D'Ulizia A., Caschera M.C., Ferri F., Grifoni P.</b></td></tr><tr><td colspan="3">Organisations: <b>Institute of Research on Population and Social Policies</b></td></tr><tr><td colspan="3">Fake news detection has gained increasing importance among the research community due to the widespread diffusion of fake news through media platforms. Many dataset have been released in the last few years, aiming to assess the performance of fake news detection methods. In this survey, we systematically review twenty-seven popular datasets for fake news detection by providing insights into the characteristics of each dataset and comparative analysis among them. A fake news detection datasets characterization composed of eleven characteristics extracted from the surveyed datasets is provided, along with a set of requirements for comparing and building new datasets. Due to the ongoing interest in this research topic, the results of the analysis are valuable to many researchers to guide the selection or definition of suitable datasets for evaluating their fake news detection methods.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-79357-9_12" target="_blank"> Text-Based Fake News Detection via Machine Learning<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85109914036</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Mertoglu U., Genc B., Sever H.</b></td></tr><tr><td colspan="3">Organisations: <b>Hacettepe University, Çankaya University</b></td></tr><tr><td colspan="3">The nature of information literacy is changing as people incline more towards using digital media to consume content. Consequently, this easier way of consuming information has sparked off a challenge called “Fake News”. One of the risky effects of this notorious term is to influence people’s views of the world as in the recent example of coronavirus misinformation that is flooding the internet. Nowadays, it seems the world needs “information hygiene” more than anything. Yet real-world solutions in practice are not qualified to determine verifiability of the information circulating. Presenting an automated solution, our work provides an adaptable solution to detect fake news in practice. Our approach proposes a set of carefully selected features combined with word-embeddings to predict fake or valid texts. We evaluated our proposed model in terms of efficacy through intensive experimentation. Additionally, we present an analysis linked with linguistic features for detecting fake and valid news content. An overview of text-based fake news detection guidance derived from experiments including promising results of our work is also presented in this work.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.7717/peerj-cs.467" target="_blank"> Stance detection with BERT embeddings for credibility analysis of information on social media<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85109956010</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Karande H., Kotecha K., Walambe R., Benjamin V., Raghu T.S.</b></td></tr><tr><td colspan="3">Organisations: <b>Symbiosis Institute of Technology, Arizona State University</b></td></tr><tr><td colspan="3">The evolution of electronic media is a mixed blessing. Due to the easy access, low cost, and faster reach of the information, people search out and devour news from online social networks. In contrast, the increasing acceptance of social media reporting leads to the spread of fake news. This is a minacious problem that causes disputes and endangers the societal stability and harmony. Fake news spread has gained attention from researchers due to its vicious nature. proliferation of misinformation in all media, from the internet to cable news, paid advertising and local news outlets, has made it essential for people to identify the misinformation and sort through the facts. Researchers are trying to analyze the credibility of information and curtail false information on such platforms. Credibility is the believability of the piece of information at hand. Analyzing the credibility of fake news is challenging due to the intent of its creation and the polychromatic nature of the news. In this work, we propose a model for detecting fake news. Our method investigates the content of the news at the early stage i.e., when the news is published but is yet to be disseminated through social media. Our work interprets the content with automatic feature extraction and the relevance of the text pieces. In summary, we introduce stance as one of the features along with the content of the article and employ the pre-trained contextualized word embeddings BERT to obtain the state-of-art results for fake news detection. The experiment conducted on the real-world dataset indicates that our model outperforms the previous work and enables fake news detection with an accuracy of 95.32%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-67051-1_14" target="_blank"> Multimodal Detection of COVID-19 Fake News and Public Behavior Analysis—Machine Learning Prospective<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85109992366</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Kakulapati V., Mahender Reddy S.</b></td></tr><tr><td colspan="3">Organisations: <b>Sreenidhi Institute of Science and Technology, Otto-Friedrich University of Bamberg</b></td></tr><tr><td colspan="3">Today, the world is struggling with an epidemic outbreak of COVID-19, 30 L people are suffering from this disease, and more than 28 k patients died with a combination of other chronic diseases. The death percentage of men is more than women all over the world. Regarding this virus, so much fake news is spreading in social media with the branching of technology over various domains and its accessibility to the general public being a significant concern. Social media hoaxes have become the new trend to gather popularity and fan base. Fake news will create unnecessary disturbance in public. This chapter describes machine learning approaches like domain theory to analyze fake news and its impact on public behavioral aspects. Multimodal classifiers (support vector machines, stochastic gradient descent, gradient boosting, bounded decision trees, and random forests): Most news embed media (videos, pictures) in the content, but it may not be related to the content and is there only for marketing purposes. Furthermore, we investigated the impact of fake news on society. Experimental evaluation of publicly available datasets and our proposed fake news detection combination can better detect fake news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.3389/fphy.2021.685730" target="_blank"> Detection of Fake News on COVID-19 on Web Search Engines<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85110110324</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Mazzeo V., Rapisarda A., Giuffrida G.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Catania, Complexity Science Hub Vienna (CSH), INFN Sezione di Catania</b></td></tr><tr><td colspan="3">In early January 2020, after China reported the first cases of the new coronavirus (SARS-CoV-2) in the city of Wuhan, unreliable and not fully accurate information has started spreading faster than the virus itself. Alongside this pandemic, people have experienced a parallel infodemic, i.e., an overabundance of information, some of which is misleading or even harmful, which has widely spread around the globe. Although social media are increasingly being used as the information source, web search engines, such as Google or Yahoo!, still represent a powerful and trustworthy resource for finding information on the Web. This is due to their capability to capture the largest amount of information, helping users quickly identify the most relevant, useful, although not always the most reliable, results for their search queries. This study aims to detect potential misleading and fake contents by capturing and analysing textual information, which flow through search engines. By using a real-world dataset associated with recent COVID-19 pandemic, we first apply re-sampling techniques for class imbalance, and then we use existing machine learning algorithms for classification of not reliable news. By extracting lexical and host-based features of associated uniform resource locators (URLs) for news articles, we show that the proposed methods, so common in phishing and malicious URL detection, can improve the efficiency and performance of classifiers. Based on these findings, we suggest that the use of both textual and URL features can improve the effectiveness of fake news detection methods.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3465480.3467844" target="_blank"> Web stream processing with RSP4J<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85110271205</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Tommasini R., Bonte P.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Tartu, Ghent University</b></td></tr><tr><td colspan="3">Social Media Analysis, Internet of Things, and Fake News detection have unveiled the relevance of real-time analytics on the Web. As a consequence, the Web infrastructure is evolving to enable continuous and reactive data access. Since data streams available on the Web originate from a variety of sources, they are highly heterogeneous. Indeed, addressing data variety and velocity simultaneously is inevitable. Stream Reasoning is the research field that studies how to combine data integration techniques with stream processing technologies. In particular, solutions for RDF Stream Processing (RSP) combine stream processing notions with data integration standards. This tutorial paper presents RSP4J, a innovative API that aims at fostering the adoption of RSP by simplifying the usage, benchmarking, and fast prototyping of Web Stream Processing applications.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3366424.3382706" target="_blank"> FakeFinder: Twitter Fake News Detection on Mobile<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85110321321</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Tian L., Zhang X., Peng M.</b></td></tr><tr><td colspan="3">Organisations: <b>RMIT University, Wuhan University</b></td></tr><tr><td colspan="3">Misinformation, or fake news, spreads quickly on the social media platform Twitter. Mobile devices are widely used to read Twitter posts. A mobile app that can detect fake news from the live Twitter stream and alert users in real time is an effective way to contain the spread of misinformation on Twitter. Towards this objective, the prediction model needs to be small to achieve fast prediction. In this paper, we design and develop a fake news detection mobile app with a device-based prediction model based on the small language model ALBERT. Experiments show that it can achieve real-time, accurate detection of fake news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.dss.2021.113633" target="_blank"> Improving fake news detection with domain-adversarial and graph-attention neural network<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85110353342</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Yuan H., Zheng J., Qian Y., Zhang Y., Ye Q.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Electronic Science and Technology of China, Yunnan University of Finance and Economics</b></td></tr><tr><td colspan="3">With the widespread use of online social media, we have witnessed that fake news causes enormous distress and inconvenience to people's social life. Although previous studies have proposed rich machine learning methods for identifying fake news in social media, the task of detecting fake news in emerging news events/domains remains a challenging problem due to the wide range of news topics on social media as well as the evolution and variation of fake news contents in the web. In this study, we propose an approach which we term “domain-adversarial and graph-attention neural network” (DAGA-NN) model to address the challenge. Its main advantage is that, in a text environment with multiple events/domains, only partial domain sample data are needed to train the model to achieve accurate cross-domain fake news detection in those domains with few (or even no) samples, which makes up for the limitations of traditional machine learning in fake news detection tasks due to news content evolution or cross-domain identification (where there is no sample data). Extensive experiments were conducted on two multimedia datasets of Twitter and Weibo, and the results showed that the proposed model was very effective in detecting fake news across events/domains.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.4018/IJITWE.2021070101" target="_blank"> FaD-CODS fake news detection on COVID-19 using description logics and semantic reasoning<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85110385651</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Goel K., Gupta C., Rawal R., Agrawal P., Madaan V.</b></td></tr><tr><td colspan="3">Organisations: <b>Bhagwan Parshuram Institute of Technology, Lovely Professional University</b></td></tr><tr><td colspan="3">COVID-19 has affected people in nearly 180 countries worldwide. This paper presents a novel and improved Semantic Web-based approach for implementing the disease pattern of COVID-19. Semantics gives meaning to words and defines the purpose of words in a sentence. Previous ontology approaches revolved around syntactic methods. In this paper, semantics gives due priority to understand the nature and meaning of the underlying text. The proposed approach, FaD-CODS, focuses on a specific application of fake news detection. The formal definition is given by depiction of knowledge patterns using semantic reasoning. The proposed approach based on fake news detection uses description logic for semantic reasoning. FaD-CODS will affect decision making in medicine and healthcare. Further, the state-of-the-art method performs best for semantic text incorporated in the model. FaD-CODS used a reasoning tool, RACER, to check the consistency of the collected study. Further, the reasoning tool performance is critically analyzed to determine the conflicts between a myth and fact.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.osnem.2021.100156" target="_blank"> Check-It: A plugin for detecting fake news on the web<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85110482026</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Paschalides D., Christodoulou C., Andreou R., Pallis G., Dikaiakos M.D., Kornilakis A., Markatos E., Orphanou K.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Cyprus, University of Crete, Open University of Cyprus</b></td></tr><tr><td colspan="3">The rapid proliferation of misinformation and disinformation on the Internet has brought dire consequences upon societies around the world, fostering extremism, undermining social cohesion and threatening the democratic process. This impact can be attested by recent events like the COVID-19 pandemic and the 2020 US presidential election. The impact of misinformation has been so deep and wide that several authors characterize the present historic period as the “post-truth” era. Many recent efforts seek to contain the proliferation of misinformation by automating the identification of fake news through various techniques that exploit signals derived from linguistic processing of online content, analysis of message diffusion patterns, reputation lists, etc. In this paper we describe the design, implementation of, and experimentation with Check-It, a lightweight, privacy preserving browser plugin that detects fake-news. Check-It combines knowledge extracted from a variety of signals, and outperforms state-of-the-art methods on commonly-used datasets, achieving more than 90% accuracy, as well as a smooth user experience.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.7544/issn1000-1239.2021.20200804" target="_blank"> Semantics-Enhanced Multi-Modal Fake News Detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85110495180</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Qi P., Cao J., Sheng Q.</b></td></tr><tr><td colspan="3">Organisations: <b>Chinese Academy of Sciences, University of Chinese Academy of Sciences</b></td></tr><tr><td colspan="3">In recent years, social media has become the main access where people acquire the latest news. However, the convenience and openness of social media have also facilitated the proliferation of fake news. With the development of multimedia technology, fake news on social media has been evolving from text-only posts to multimedia posts containing images or videos. Therefore, multi-modal fake news detection is attracting more and more attention. Existing methods for multi-modal fake news detection mostly focus on capturing appearance-level features that are highly dependent on the dataset distribution but insufficiently exploit the semantics-level features. Thus, the methods often fail to understand the deep semantics of textual and visual entities in the fake news, which indeed limits the generalizability of models in real applications. To tackle this problem, this paper proposes a semantics-enhanced multi-modal model for fake news detection, which better models the underlying semantics of multi-modal news by implicitly utilizing the factual knowledge in the pre-trained language model and explicitly extracting the visual entities. Furthermore, the proposed method extracts visual features of different semantic levels and models the semantic interaction between the textual and visual features by the text-guided attention mechanism, which better fuses the multi-modal heterogeneous features. Extensive experiments on the Weibo dataset strongly evidence that our method outperforms the state of the art significantly.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1386/cjcs_00044_7" target="_blank"> Tackling online disinformation through media literacy in spain: The project ‘que no te la cuelen’<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85110552204</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Carrillo N., Montagut M.</b></td></tr><tr><td colspan="3">Organisations: <b>Universitat Autònoma de Barcelona, Universitat Rovira i Virgili</b></td></tr><tr><td colspan="3">Media literacy of schoolchildren is a key political goal worldwide: institutions and citizens consider media literacy training to be essential – among other aspects – to combat falsehoods and generate healthy public opinion in democratic contexts. In Spain, various media literacy projects address this phenomenon one of which is ‘Que no te la cuelen’ (‘Don’t be fooled’, QNTLC). The project, which has been developed by the authors of this viewpoint, is implemented through theoretical– practical workshops aimed at public and private secondary pupils (academic years 2018–19, 2019–20 and 2020–21), based around training in fake news detection strategies and online fact-checking tools for students and teachers. This viewpoint describes and reflects on this initiative, conducted in 36 training sessions with schoolchildren aged 14–16 years attending schools in Madrid, Valencia and Barcelona. The workshops are based on van Dijk’s media literacy model, with a special focus on the ‘informational skills’ dimension. The amount of information available through all kinds of online platforms implies an extra effort in select-ing, evaluating and sharing information, and the workshop focuses on this process through seven steps: suspect, read/listen/watch carefully, check the source, look for other reliable sources, check the data/location, be self-conscious of your bias and decide whether to share the information or not. The QNTLC sessions teach and train these skills combining gamification strategies – online quiz, verification chal-lenges, ‘infoxication’ dynamics in the class – as well as through a public delibera-tion among students. Participants’ engagement and stakeholders’ interest in the programme suggest that this kind of training is important or, at least, attract the attention of these collectives in the Spanish context.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.jnca.2021.103112" target="_blank"> Fake news outbreak 2021: Can we stop the viral spread?<a></b></td></tr><tr><td>Type: Review</td><td>ID: S_2-s2.0-85110560571</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Khan T., Michalas A., Akhunzada A.</b></td></tr><tr><td colspan="3">Organisations: <b>Tampere University, RISE AB, Technical University of Denmark</b></td></tr><tr><td colspan="3">Social Networks' omnipresence and ease of use has revolutionized the generation and distribution of information in today's world. However, easy access to information does not equal an increased level of public knowledge. Unlike traditional media channels, social networks also facilitate faster and wider spread of disinformation and misinformation. Viral spread of false information has serious implications on the behaviours, attitudes and beliefs of the public, and ultimately can seriously endanger the democratic processes. Limiting false information's negative impact through early detection and control of extensive spread presents the main challenge facing researchers today. In this survey paper, we extensively analyze a wide range of different solutions for the early detection of fake news in the existing literature. More precisely, we examine Machine Learning (ML) models for the identification and classification of fake news, online fake news detection competitions, statistical outputs as well as the advantages and disadvantages of some of the available data sets. Finally, we evaluate the online web browsing tools available for detecting and mitigating fake news and present some open research challenges.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.11925/infotech.2096-3467.2020.0884" target="_blank"> Detecting social media fake news with semantic consistency between multi-model contents<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85110738776</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Guobiao Z., Jie L.</b></td></tr><tr><td colspan="3">Organisations: <b>Wuhan University, Soochow University</b></td></tr><tr><td colspan="3">[Objective] This study aims to detect fake news on social media earlier and curb the dissemination of mis/dis-information. [Methods] Based on the features of news images and texts, we mapped the images to semantic tags and calculated the semantic consistency between images and texts. Then, we constructed a model to detect fake news. Finally, we examined our new model with the FakeNewsNet dataset. [Results] The F1 value of our model was up to 0.775 on PolitiFact data and 0.879 on GossipCop data. [Limitations] Due to the limits of existing annotation methods for image semantics, we could not accurately describe image contents, and calculate semantic consistency. [Conclusions] The constructed model could effectively detect fake news from social media.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3447548.3467321" target="_blank"> Causal Understanding of Fake News Dissemination on Social Media<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85110856438</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Cheng L., Guo R., Liu H., Shu K.</b></td></tr><tr><td colspan="3">Organisations: <b>Arizona State University, Illinois Institute of Technology</b></td></tr><tr><td colspan="3">Recent years have witnessed remarkable progress towards computational fake news detection. To mitigate its negative impact, we argue that it is critical to understand what user attributes potentially cause users to share fake news. The key to this causal-inference problem is to identify confounders - variables that cause spurious associations between treatments (e.g., user attributes) and outcome (e.g., user susceptibility). In fake news dissemination, confounders can be characterized by fake news sharing behavior that inherently relates to user attributes and online activities. Learning such user behavior is typically subject to selection bias in users who are susceptible to share news on social media. Drawing on causal inference theories, we first propose a principled approach to alleviating selection bias in fake news dissemination. We then consider the learned unbiased fake news sharing behavior as the surrogate confounder that can fully capture the causal links between user attributes and user susceptibility. We theoretically and empirically characterize the effectiveness of the proposed approach and find that it could be useful in protecting society from the perils of fake news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-75768-7_32" target="_blank"> Incorporating Relational Knowledge in Explainable Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85111039771</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Wu K., Ning Y., Yuan X.</b></td></tr><tr><td colspan="3">Organisations: <b>Stevens Institute of Technology, University of Louisiana at Lafayette</b></td></tr><tr><td colspan="3">The greater public has become aware of the rising prevalence of untrustworthy information in online media. Extensive adaptive detection methods have been proposed for mitigating the adverse effect of fake news. Computational methods for detecting fake news based on the news content have several limitations, such as: 1) Encoding semantics from original texts is limited to the structure of the language in the text, making both bag-of-words and embedding-based features deceptive in the representation of a fake news, and 2) Explainable methods often neglect relational contexts in fake news detection. In this paper, we design a knowledge graph enhanced framework for effectively detecting fake news while providing relational explanation. We first build a credential-based multi-relation knowledge graph by extracting entity relation tuples from our training data and then apply a compositional graph convolutional network to learn the node and relation embeddings accordingly. The pre-trained graph embeddings are then incorporated into a graph convolutional network for fake news detection. Through extensive experiments on three real-world datasets, we demonstrate the proposed knowledge graph enhanced framework has significant improvement in terms of fake news detection as well as structured explainability.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-33-6546-9_53" target="_blank"> A Detailed Survey Study on Classification and Various Attributes of Fake News on Social Media<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85111090523</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Sajini G., Kallimani J.S.</b></td></tr><tr><td colspan="3">Organisations: <b>M S Ramaiah Institute of Technology, Visvesvaraya Technological University</b></td></tr><tr><td colspan="3">Due to the surge in the usage of social media in the recent past, communication between people has undergone a great change. Users interact with each other by sharing a lot of information about the ongoing trends. But most of the information shared recently is misleading with the spread of false news which is known as fake news. A huge volume of such fake news being spread can lead to many complications. The research field has been concentrating on the inception, spread and consequences more nowadays. Detecting the truthfulness of the news is of great concern. It can face many technical difficulties on many grounds. Usage of online tools has made the generation of content easy and is expanded fast, which can lead to a huge amount of data for analyzing. The online content is divergent, which deals with numerous fields, contributing to the job complication. Only computers are not able to evaluate the truthfulness and purpose; therefore, it is dependent on the person–computer interaction. Sometimes, the information that might be termed as fake by a specialist in the field might delude people. Such availability is in restricted quantity but could be a base for the mutual endeavor. Here, a broad summary of the discoveries pertaining to the news which are false is given. The unfavorable effects of ongoing work on methods to detect such news are demonstrated. The readily available datasets are studied which are used to classify fake news. An assuring solution is recommended to analyze online fake news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-33-6987-0_19" target="_blank"> Fake News Detection Using Passive-Aggressive Classifier and Other Machine Learning Algorithms<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85111130824</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Nagashri K., Sangeetha J.</b></td></tr><tr><td colspan="3">Organisations: <b>Ramaiah Institute of Technology</b></td></tr><tr><td colspan="3">Fake news means false facts generated for deceiving the readers. The generation of fake news has become very easy which can mislead people and cause panic. Therefore, fake news detection is gaining prominence in research field. As a solution, this paper aims at finding the best possible algorithms to detect fake news. In this paper, term frequency–inverse document frequency (TFIDF) as well as count vector techniques is used separately for text preprocessing. Six machine learning algorithms namely passive-aggressive classifier (PAC), naive Bayes (NB), random forest (RF), logistic regression (LR), support vector machine (SVM), and stochastic gradient descent (SGD) are compared using evaluation metrics such as accuracy, precision, recall, and F1 score, The results have shown that the TFIDF is a better text preprocessing technique. PAC and SVM algorithms show the best performance for the considered dataset.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s00521-021-06276-0" target="_blank"> Implementation of the BERT-derived architectures to tackle disinformation challenges<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85111137177</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Kula S., Kozik R., Choras M.</b></td></tr><tr><td colspan="3">Organisations: <b>UTP University of Science and Technology, Kazimierz Wielki University UKW</b></td></tr><tr><td colspan="3">Recent progress in the area of modern technologies confirms that information is not only a commodity but can also become a tool for competition and rivalry among governments and corporations, or can be applied by ill-willed people to use it in their hate speech practices. The impact of information is overpowering and can lead to many socially undesirable phenomena, such as panic or political instability. To eliminate the threats of fake news publishing, modern computer security systems need flexible and intelligent tools. The design of models meeting the above-mentioned criteria is enabled by artificial intelligence and, above all, by the state-of-the-art neural network architectures, applied in NLP tasks. The BERT neural network belongs to this type of architectures. This paper presents Transformer-based hybrid architectures applied to create models for detecting fake news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-75762-5_33" target="_blank"> Fake News Detection with Heterogenous Deep Graph Convolutional Network<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85111138582</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Kang Z., Cao Y., Shang Y., Liang T., Tang H., Tong L.</b></td></tr><tr><td colspan="3">Organisations: <b>Chinese Academy of Sciences, University of Chinese Academy of Sciences, National Computer Network Emergency Response Technical Team/Coordination Center of China</b></td></tr><tr><td colspan="3">Fake news detection is a challenging problem due to its tremendous real-world political and social impacts. Previous works judged the authenticity of news mainly based on the content of a single news, which is generally not effective because the fake news is often written to mislead users by mimicking the true news. This paper innovatively utilizes the connection between multiple news, such as their relevance in time, content, topic and source, to detect fake news. We construct a heterogeneous graph with different types of nodes and edges, which is named as News Detection Graph (NDG), to integrate various information of multiple news. In order to learn deep representation of news nodes, we propose a Heterogenous Deep Convolutional Network (HDGCN) which utilizes a wider receptive field, a neighbor sampling strategy and a hierarchical attention mechanism. Extensive experiments carried on two real-world datasets demonstrated the effectiveness of our work in solving the fake news detection problem.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-16-0733-2_31" target="_blank"> Comment Filtering Based Explainable Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85111265413</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Sharma D.K., Sharma S.</b></td></tr><tr><td colspan="3">Organisations: <b>GLA University</b></td></tr><tr><td colspan="3">Fake News Detection is one of the most currently researched areas over the globe; many methods have come to light using different features as their sources. Hence, there are also methods using existing comments on any news article which can be used to determine the credibility of the news article as fake or real. Here, we have introduced a hypothesis that uses a machine learning approach to check the credibility of comments before they can be analyzed for further fake news detection. So, we have used various text classification algorithms to check for our hypothesis that filtering comments since there is a high possibility that the comments used for any analysis can be useless and full of useless stuff. For example, the comments showing only the emotion of readers like ‘Yesss’ or ‘Nooo!’ and likewise or the comments built using only the curse words. Such comments would prove useless as a contributing factor for fake news detection and might also affect the results of fake news detection for any news article. These text classifiers are—Complement Naïve Bayes, Logistic Regression, Multinomial Naïve Bayes, and Support Vector Machine. Out of these, the best accuracy is provided by the MultinomialNB method of 75.7% and Decision Tree with 75.4% as opposed to the original algorithm with an accuracy of 73.3% using the same dataset. Since the MultinomialNB has provided the best improvement in all the metrics compared to the original method, and we are focusing our paper on this method. This hypothesis aims to classify comments as junky (useless) comments and utility (useful) comments. These utility comments will be further used for analysis to identify fake news. Also, since the size of comments per article may vary from a few tens to a few hundred or thousands, we have used the semi-supervised approach to classify the comments in junky or utility comments classes. We have also collected data from various sources and collaborated them to fetch ourselves from a usable dataset. It contains 415 records with contents or article data for each record, along with many comments for each record. Moreover, we have also classified those comments into junky and utility comment classes using the basic definition of spam filtering. This can be improvised for different uses using different criteria. Hence, eradicating the useless comments and only analyzing the useful comments for better identification of fake news is fake news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-73882-2_66" target="_blank"> HCODF: Hybrid Cognitive Ontology Driven Framework for Socially Relevant News Validation<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85111304306</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Deepak G., Santhanavijayan A., Adithya V.</b></td></tr><tr><td colspan="3">Organisations: <b>National Institute of Technology, SRM Institute of Science and Technology</b></td></tr><tr><td colspan="3">Nowadays everyone gets news from social media and most often it is very much difficult to validate its credibility. Social media platforms like twitter and WhatsApp are working on this for a long time, lots of research work has been done by many people but still an effective technique hasn’t been found out. This paper proposes a method to address this problem, with the use of a hybrid NLP model that uses an Event Ontology and LSTM to validate whether a news is authentic or not. The news dataset that has been used here are the tweets crawled and the news headlines, where the semantic similarity between the news and tweets on specific events are found out, which is later used to classify the tweets whether it is fake or not. This experiment’s performance is evaluated and it is compared with baseline models and it was found that the proposed approach is superior in terms of performance which recorded an F-Measure and False Negative Rate of 96.14% and 0.03 respectively.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-80599-9_18" target="_blank"> Detection of Misinformation About COVID-19 in Brazilian Portuguese WhatsApp Messages<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85111437905</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Forte Martins A.D., Cabral L., Monteiro J.M., Machado J., Chaves Mourao P.J.</b></td></tr><tr><td colspan="3">Organisations: <b>Federal University of Ceará, Universidade Estadual do Ceará</b></td></tr><tr><td colspan="3">During the coronavirus pandemic, the problem of misinformation arose once again, quite intensely, through social networks. In many developing countries such as Brazil, one of the primary sources of misinformation is the messaging application WhatsApp. However, due to WhatsApp’s private messaging nature, there still few methods of misinformation detection developed specifically for this platform. Additionally, a MID model built to Twitter or Facebook may have a poor performance when used to classify WhatsApp messages. In this context, the automatic misinformation detection (MID) about COVID-19 in Brazilian Portuguese WhatsApp messages becomes a crucial challenge. In this work, we present the COVID-19.BR, a data set of WhatsApp messages about coronavirus in Brazilian Portuguese, collected from Brazilian public groups and manually labeled. Besides, we evaluated a series of misinformation classifiers combining different techniques. Our best result achieved an F1 score of 0.778, and the analysis of errors indicates that they occur mainly due to the predominance of short texts. When texts with less than 50 words are filtered, the F1 score rises to 0.857.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-77970-2_3" target="_blank"> Transformer Based Models in Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85111439754</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Kula S., Kozik R., Choras M., Wozniak M.</b></td></tr><tr><td colspan="3">Organisations: <b>UTP University of Science and Technology, Kazimierz Wielki University, Wrocław University of Science and Technology</b></td></tr><tr><td colspan="3">The article presents models for detecting fake news and the results of the analyzes of the application of these models. The precision, f1-score, recall metrics were proposed as a measure of the model quality assessment. Neural network architectures, based on the state-of-the-art solutions of the Transformer type were applied to create the models. The computing capabilities of the Google Colaboratory remote platform, as well as the Flair library, made it feasible to obtain reliable, robust models for fake news detection. The problem of disinformation and fake news is an important issue for modern societies, which commonly use state-of-the-art telecommunications technologies. Artificial intelligence and deep learning techniques are considered to be effective tools in protection against these undesirable phenomena.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s00500-021-06043-2" target="_blank"> Tracing the fake news propagation path using social network analysis<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85111447361</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Sivasankari S., Vadivu G.</b></td></tr><tr><td colspan="3">Organisations: <b>School of Computing</b></td></tr><tr><td colspan="3">Nowadays, people rely mostly on social media for any kind of information sharing and also started acquiring information through social media platforms for e-news mostly related to politics via Twitter, Facebook, and YouTube. Fake news detection and identifying its propagation path are technically very challenging. In this work, we have implemented a novel method to learn discriminative features from tweets content, Facebook posts and followed their non-sequential propagation structure, and generated more powerful representations for identifying fake news and its propagation by constructing a social network graph. We proposed level order traversal up to three levels based on top-down tree structured networks for fake propagation learning and detected the neighbors of the fake news source and removed them from the network which naturally confirms the reduction of their propagation. We have considered the benchmark data set LIAR and used PolitiFact user data for our research work. The main objective of our work is to identify the propagation path of the fake news content by collecting news and verifying its authenticity using fact-checking websites, namely “www.politifact.com”, and creating a network among the users who have high similarity in their contents posted. Now it will be easier to trace the path if the source identified has fake content, then its neighbors can be tracked and moving forward the same idea can be iterated up to bottom levels.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-77970-2_2" target="_blank"> Fake or Real? The Novel Approach to Detecting Online Disinformation Based on Multi ML Classifiers<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85111463338</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Tarczewska M., Marciniak A., Gielczyk A.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Science and Technology</b></td></tr><tr><td colspan="3">Background: the machine learning (ML) techniques have been implemented in numerous applications and domains, including health-care, security, entertainment, and sports. This paper presents how ML can be used for detecting fake news. The problem of online disinformation has recently become one of the most challenging issues of computer science. Methods: in this research, a fake news detection method based on multi classifiers (CNN, XGBoost, Random Forest, Naive Bayes, SVM) has been developed. In the proposed method, two classifiers cooperate; consequently, they obtain better results. Realistic, publicly available data was used in order to train and test the classifiers, Results: in the article, several experiments were presented; they differ in the implemented classifiers, and some improved parameters. Promising results (accuracy = 0.95, precision = 0.99, recall = 0.91, and F1-score = 0.95) were reported. Conclusion: the presented research proves that machine learning is a promising approach to fake news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3404835.3462871" target="_blank"> Hierarchical Multi-modal Contextual Attention Network for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85111688171</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Qian S., Wang J., Hu J., Fang Q., Xu C.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Chinese Academy of Sciences</b></td></tr><tr><td colspan="3">Nowadays, detecting fake news on social media platforms has become a top priority since the widespread dissemination of fake news may mislead readers and have negative effects. To date, many algorithms have been proposed to facilitate the detection of fake news from the hand-crafted feature extraction methods to deep learning approaches. However, these methods may suffer from the following limitations: (1) fail to utilize the multi-modal context information and extract high-order complementary information for each news to enhance the detection of fake news; (2) largely ignore the full hierarchical semantics of textual content to assist in learning a better news representation. To overcome these limitations, this paper proposes a novel hierarchical multi-modal contextual attention network (HMCAN) for fake news detection by jointly modeling the multi-modal context information and the hierarchical semantics of text in a unified deep model. Specifically, we employ BERT and ResNet to learn better representations for text and images, respectively. Then, we feed the obtained representations of images and text into a multi-modal contextual attention network to fuse both inter-modality and intra-modality relationships. Finally, we design a hierarchical encoding network to capture the rich hierarchical semantics for fake news detection. Extensive experiments on three public real datasets demonstrate that our proposed HMCAN achieves state-of-the-art performance.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3404835.3463104" target="_blank"> Decoupling Representation and Regressor for Long-Tailed Information Cascade Prediction<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85111695532</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Zhou F., Yu L., Xu X., Trajcevski G.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Electronic Science and Technology of China, Iowa State University</b></td></tr><tr><td colspan="3">Effectively predicting the size of information cascades is crucial for understanding the evolution of many social applications, such as influence maximization and fake news detection. Conventional methods face the challenge of data imbalance which, in turn, yields unsatisfactory prediction performance. To prevent the loss functions or metrics from being affected by extreme values and assure numerical stability, previous works reformulate the problem definitions or adopt other types of evaluation metrics. However, solving the regression prediction of information cascades from a long-tailed distribution perspective is under explored. In this paper, we propose a general decoupling prediction solution - first extracting the representation, then fine-tuning the regressor, which combines the original prediction value and weighted bias generated by a sub-network (SUB) that we designed. Our experiments conducted on long-tailed benchmarks demonstrate that our method significantly improves the prediction accuracy over state-of-the-art methods and mitigates the long-tailed cascade prediction problem.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3404835.3463059" target="_blank"> SDG: A Simplified and Dynamic Graph Neural Network<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85111701443</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Fu D., He J.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Illinois at Urbana-Champaign</b></td></tr><tr><td colspan="3">Graph Neural Networks (GNNs) have achieved state-of-the-art performance in many high-impact applications such as fraud detection, information retrieval, and recommender systems due to their powerful representation learning capabilities. Some nascent efforts have been concentrated on simplifying the structures of GNN models, in order to reduce the computational complexity. However, the dynamic nature of these applications requires GNN structures to be evolving over time, which has been largely overlooked so far. To bridge this gap, in this paper, we propose a simplified and dynamic graph neural network model, called SDG. It is efficient, effective, and provides interpretable predictions. In particular, in SDG, we replace the traditional message-passing mechanism of GNNs with the designed dynamic propagation scheme based on the personalized PageRank tracking process. We conduct extensive experiments and ablation studies to demonstrate the effectiveness and efficiency of our proposed SDG. We also design a case study on fake news detection to show the interpretability of SDG.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3404835.3462990" target="_blank"> User Preference-aware Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85111701739</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Dou Y., Xia C., Yu P.S., Shu K., Sun L.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Illinois at Chicago, Illinois Institute of Technology, Lehigh University</b></td></tr><tr><td colspan="3">Disinformation and fake news have posed detrimental effects on individuals and society in recent years, attracting broad attention to fake news detection. The majority of existing fake news detection algorithms focus on mining news content and/or the surrounding exogenous context for discovering deceptive signals; while the endogenous preference of a user when he/she decides to spread a piece of fake news or not is ignored. The confirmation bias theory has indicated that a user is more likely to spread a piece of fake news when it confirms his/her existing beliefs/preferences. Users' historical, social engagements such as posts provide rich information about users' preferences toward news and have great potentials to advance fake news detection. However, the work on exploring user preference for fake news detection is somewhat limited. Therefore, in this paper, we study the novel problem of exploiting user preference for fake news detection. We propose a new framework, UPFD, which simultaneously captures various signals from user preferences by joint content and graph modeling. Experimental results on real-world datasets demonstrate the effectiveness of the proposed framework. We release our code and data as a benchmark for GNN-based fake news detection: https://github.com/safe-graph/GNN-FakeNews.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.5565/REV/ANALISI.3378" target="_blank"> DeepFakes: The Next Challenge in Fake News Detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85111711853</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Jose F., Garcia-Ull G.-U.</b></td></tr><tr><td colspan="3">Organisations: <b>Universidad Miguel Hernández</b></td></tr><tr><td colspan="3">A deepfake is a hyper-realistic video, digitally manipulated to represent people saying or doing things that never really happened. With the sophistication of techniques for developing these counterfeits, it is becoming increasingly difficult to detect whether public appearances or statements by influential people respond to parameters of reality or, on the contrary, are the result of fictitious representations. These synthetic documents, generated by computerized techniques based on Artificial Intelligence (AI), pose serious threats to privacy, in a new scenario in which the risks derived from identity theft are increasing. This study aims to advance the state of the art through the analysis of academic news and through an exhaustive literature review, seeking answers to the following questions, which we understand to be of general interest, from both an economic and a social perspective and in various areas of research. What are deepfakes? Who produces them and what technology supports them? What opportunities do they present? What risks are associated with them? What methods exist to combat them? And framing the study in terms of information theory: is this a revolution or an evolution of fake news? As we know, fake news influences public opinion and is effective in appealing to emotions and modifying behaviours. We can assume that these new audiovisual texts will be tremendously effective in undermining, even more if possible, the credibility of digital media, as well as accelerating the already evident exhaustion of critical thinking.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s10586-021-03361-w" target="_blank"> ProBlock: a novel approach for fake news detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85111777648</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Sengupta E., Nagpal R., Mehrotra D., Srivastava G.</b></td></tr><tr><td colspan="3">Organisations: <b>Amity University Uttar Pradesh, Brandon University, China Medical University</b></td></tr><tr><td colspan="3">The world is diving deeper into the digital age, and the sources of first information are moving towards social media and online news portals. The chances of being misinformed increase multifold as our reliance on sources of information are getting ambiguous. Traditional news sources followed strict codes of practice to verify stories, whereas today, users can upload news items on social media and unverified portals without proving their veracity. The absence of any determinants of such news articles’ truthfulness on the Internet calls for a novel approach to determine the realness quotient of unverified news items by leveraging technology. This study presents a dynamic model with a secure voting system, where news reviewers can provide feedback on news, and a probabilistic mathematical model is used for predicting the truthfulness of the news item based on the feedback received. A blockchain-based model, ProBlock is proposed; so that correctness of information propagated is ensured.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-79150-6_51" target="_blank"> An Approach Utilizing Linguistic Features for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85111856797</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Kasseropoulos D.P., Tjortjis C.</b></td></tr><tr><td colspan="3">Organisations: <b>International Hellenic University</b></td></tr><tr><td colspan="3">Easy propagation and access to information on the web has the potential to become a serious issue when it comes to disinformation. The term “fake news” describes the intentional propagation of news with the intention to mislead and harm the public and has gained more attention recently. This paper proposes a style-based Machine Learning (ML) approach, which relies on the textual information from news, such as manually extracted lexical features e.g. part of speech counts, and evaluates the performance of several ML algorithms. We identified a subset of the best performing linguistic features, using information-based metrics, which tend to agree with the literature. We also, combined Named Entity Recognition (NER) functionality with the Frequent Pattern (FP) Growth association rule algorithm to gain a deeper perspective of the named entities used in the two classes. Both methods reinforce the claim that fake and real news have limited differences in content, setting limitations to style-based methods. Results showed that convolutional neural networks resulted in the best accuracy, outperforming the rest of the algorithms.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.neucom.2021.07.077" target="_blank"> Knowledge augmented transformer for adversarial multidomain multiclassification multimodal fake news detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85112001397</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Song C., Wu B., Ning N., Zhang Y.</b></td></tr><tr><td colspan="3">Organisations: <b>Beijing University of Posts and Telecommunications, Henan University, North China Institute of Science and Technology</b></td></tr><tr><td colspan="3">The spread of disinformation and fake news on social platforms has an unfavorable impact on social harmony and stability. The timely and accurate identification of fake news might help restrain the propagation of fake news and mitigate its influence on society. In this paper, we propose a novel multimodal fake news detection framework: the Knowledge Augmented Transformer for adversarial Multidomain multiclassification multimodal Fake news detection framework (KATMF). In contrast to most of the existing studies, which ignore the differences among news articles from different domains in terms of the feature distribution, the KATMF employs a multimodal adversarial multitask learning module to capture these differences. Moreover, because social media news entities generally lack sufficient background knowledge, to enrich news with knowledge information in a homogeneous embedding space, we use the Knowledge Augmented Transformer (KAT) to selectively encode the information of entities from an external knowledge source into the representation of news. We evaluate our approach on a large-scale real-world dataset, and the experimental results demonstrate that our proposed model outperforms state-of-the-art fake news detection methods.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1080/0144929X.2021.1963475" target="_blank"> Fake news detection and social media trust: a cross-cultural perspective<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85112035239</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Dabbous A., Aoun Barakat K., de Quero Navarro B.</b></td></tr><tr><td colspan="3">Organisations: <b>Saint Joseph University of Beirut, INSEEC Grande Ecole, Universidad Loyola Andalucía</b></td></tr><tr><td colspan="3">Social media is increasingly being used worldwide to produce and exchange information. However, the absence of adequate control mechanisms on this medium has led to concerns about the credibility of information in circulation. While this topic has gained researchers’ attention, little is known about the factors which allow individuals to detect fake news and lead them to trust social media as a source of information, and whether this varies across cultures. This cross-cultural study conducted in Spain and Lebanon uses structural equation modelling to explore these factors and presents them within a behavioural model. Findings show that verification behaviour, information skills and education have a positive influence on fake news detection with a stronger impact in Lebanon. Trust is positively affected by virality with higher influence in Lebanon, while ability to detect is shown to decrease trust in Spain. Frequency of use impacts trust equally in both countries.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-77626-8_9" target="_blank"> Fake News Detection via English-to-Spanish Translation: Is It Really Useful?<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85112153413</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Ruiz S., Providel E., Mendoza M.</b></td></tr><tr><td colspan="3">Organisations: <b>Universidad de Valparaíso, Universidad Técnica Federico Santa María</b></td></tr><tr><td colspan="3">Social networks are used every day to report daily events, although the information published in them many times correspond to fake news. Detecting these fake news has become a research topic that can be approached using deep learning. However, most of the current research on the topic is available only for the English language. When working on fake news detection in other languages, such as Spanish, one of the barriers is the low quantity of labeled datasets available in Spanish. Hence, we explore if it is convenient to translate an English dataset to Spanish using Statistical Machine Translation. We use the translated dataset to evaluate the accuracy of several deep learning architectures and compare the results from the translated dataset and the original dataset in fake news classification. Our results suggest that the approach is feasible, although it requires high-quality translation techniques, such as those found in the translation’s neural-based models.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-77626-8_23" target="_blank"> Effects of Conspiracy Thinking Style, Framing and Political Interest on Accuracy of Fake News Recognition by Social Media Users: Evidence from Russia, Kazakhstan and Ukraine<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85112165571</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Porshnev A., Koltsova O., Miltsov A., Lokot T.</b></td></tr><tr><td colspan="3">Organisations: <b>National Research University Higher School of Economics, Bishop’s University, Dublin City University</b></td></tr><tr><td colspan="3">This study examines the effect of specific factors (including user features, such as propensity for conspiracy thinking, and news item features, such as news frame and news source) on the accuracy of social media users in fake news recognition. Being a part of a larger research on fake news perception, this study uses the data from an online experiment that asks social media users from three countries (Russia, Ukraine and Kazakhstan) to evaluate a set of news items constructed with specific conditions. Namely, the users receive true and fake news about the neighboring countries framed differently and ascribed to either domestic or foreign sources. We then assess users’ accuracy in detecting fake news. The results of the study confirm the important role of conspiracy thinking style in false news recognition (leading to a decrease in accuracy) and users’ capability for deliberation on social media more broadly. However, the influence of contextual factors is mixed. While news sources exhibit no influence on the accuracy of fake or true news detection, dominant framing tends to increase the accuracy of true news only. More predictors of news recognition accuracy are discussed in the paper. As a result, this research contributes to the theory of fake news susceptibility by revealing a rich set of individual factors and interaction effects that influence human judgment about news truthfulness and impact deliberation possibilities in socially mediated environments.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-16-0878-0_12" target="_blank"> Fake News Detection Using Text Analytics<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85112171367</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Amanchi U.M., Badam N., Elaganti R.L.</b></td></tr><tr><td colspan="3">Organisations: <b>Chaitanya Bharathi Institute of Technology</b></td></tr><tr><td colspan="3">Fake news is a form of news consisting of false statements from the real ones spread via news media or online social media. In this paper, we aim for the fake news detection model which is capable of detecting the fake news from large amounts of data that are daily produced on online platforms. The approach for our model is a machine learning technique which is text analysis and for classifying fake news we have used k means clustering. Using the data preprocessing, classification, and topic modeling we get topics from the article, and they are compared with legitimate news. We modeled a framework named Fake News Detection (FND) which is used to classify the news articles. By streaming detection of fake information, we can control false or inaccurate content.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-77074-7_29" target="_blank"> Deep Learning Model for Humor Recognition of Different Cultures<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85112179527</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Chen R., Rau P.-L.P.</b></td></tr><tr><td colspan="3">Organisations: <b>Tsinghua University</b></td></tr><tr><td colspan="3">In recent years, significant improvements have been made in the field of sentiment analysis, particularly in computational humor. In this research work, an AI-based cross-cultural humor recognition model has been developed and implemented. The model consists of a Convolutional Neural Network that can assess whether a given sentence is humorous or not and whether the sentence has a western or Chinese type of humor. The model has been trained and tested over the created dataset composed of 463314 English sentences and 111614 Chinese sentences. The initial model setting reached an accuracy of 64,48%. The analysis of the obtained results showed the importance of three main contributors to the model accuracy, namely, the dataset variety, dimension and model’s hyperparameters. Finally, these contributors were optimized by various tests, resulting in the final model obtaining an accuracy of 96,73%. The flexibility of the model allows applications in several areas such as private social media for cross-cultural communication, cross-cultural marketing and even fake news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-16-0882-7_40" target="_blank"> A Deep Learning Approach Toward Determining the Effects of News Trust Factor Based on Source Polarity<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85112217361</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Mukherjee A., Roy R.</b></td></tr><tr><td colspan="3">Organisations: <b>Areteans Tech, Dr. B. C. Roy Engineering College Academy of Professional Courses</b></td></tr><tr><td colspan="3">Fake news is one of the biggest threats in cyber-world nowadays. There are several categories of fake news like clickbait, propaganda, satire/parody, sloppy journalism, misleading headings, biased or slanted news. Now, due to limited time available generally to the readers, they are subjected to few of these form of fake news like misleading headlines, propaganda news, etc. These types of fake news are generally arised due to the inclination of news portals/firms toward ideologies or political allegiance. The cumulative effect of such circulation of fake news leads to group enmity, political misalignment, disruption of communal harmony and other society paralyzing problems. The work in this paper tries to identify and establish the effects of polarity and inclination of news portal on the trust factor of the news with the help of a systematic machine learning approach. This paper combines sentimental analysis and fake news detection using a multi-level classification model that validates the effect of source polarity and inclination on the news trust factor.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1155/2021/3434458" target="_blank"> Detection of Online Fake News Using Blending Ensemble Learning<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85112305026</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Hansrajh A., Adeliyi T.T., Wing J.</b></td></tr><tr><td colspan="3">Organisations: <b>Durban University of Technology</b></td></tr><tr><td colspan="3">The exponential growth in fake news and its inherent threat to democracy, public trust, and justice has escalated the necessity for fake news detection and mitigation. Detecting fake news is a complex challenge as it is intentionally written to mislead and hoodwink. Humans are not good at identifying fake news. The detection of fake news by humans is reported to be at a rate of 54% and an additional 4% is reported in the literature as being speculative. The significance of fighting fake news is exemplified during the present pandemic. Consequently, social networks are ramping up the usage of detection tools and educating the public in recognising fake news. In the literature, it was observed that several machine learning algorithms have been applied to the detection of fake news with limited and mixed success. However, several advanced machine learning models are not being applied, although recent studies are demonstrating the efcacy of the ensemble machine learning approach; hence, the purpose of this study is to assist in the automated detection of fake news. An ensemble approach is adopted to help resolve the identified gap. This study proposed a blended machine learning ensemble model developed from logistic regression, support vector machine, linear discriminant analysis, stochastic gradient descent, and ridge regression, which is then used on a publicly available dataset to predict if a news report is true or not. The proposed model will be appraised with the popular classical machine learning models, while performance metrics such as AUC, ROC, recall, accuracy, precision, and f1-score will be used to measure the performance of the proposed model. Results presented showed that the proposed model outperformed other popular classical machine learning models.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1108/IJICC-04-2021-0069" target="_blank"> A systematic survey on deep learning and machine learning approaches of fake news detection in the pre- and post-COVID-19 pandemic<a></b></td></tr><tr><td>Type: Review</td><td>ID: S_2-s2.0-85112361887</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Varma R., Verma Y., Vijayvargiya P., Churi P.P.</b></td></tr><tr><td colspan="3">Organisations: <b>Narsee Monjee Institute of Management and Higher Studies</b></td></tr><tr><td colspan="3">Purpose: The rapid advancement of technology in online communication and fingertip access to the Internet has resulted in the expedited dissemination of fake news to engage a global audience at a low cost by news channels, freelance reporters and websites. Amid the coronavirus disease 2019 (COVID-19) pandemic, individuals are inflicted with these false and potentially harmful claims and stories, which may harm the vaccination process. Psychological studies reveal that the human ability to detect deception is only slightly better than chance; therefore, there is a growing need for serious consideration for developing automated strategies to combat fake news that traverses these platforms at an alarming rate. This paper systematically reviews the existing fake news detection technologies by exploring various machine learning and deep learning techniques pre- and post-pandemic, which has never been done before to the best of the authors’ knowledge. Design/methodology/approach: The detailed literature review on fake news detection is divided into three major parts. The authors searched papers no later than 2017 on fake news detection approaches on deep learning and machine learning. The papers were initially searched through the Google scholar platform, and they have been scrutinized for quality. The authors kept “Scopus” and “Web of Science” as quality indexing parameters. All research gaps and available databases, data pre-processing, feature extraction techniques and evaluation methods for current fake news detection technologies have been explored, illustrating them using tables, charts and trees. Findings: The paper is dissected into two approaches, namely machine learning and deep learning, to present a better understanding and a clear objective. Next, the authors present a viewpoint on which approach is better and future research trends, issues and challenges for researchers, given the relevance and urgency of a detailed and thorough analysis of existing models. This paper also delves into fake new detection during COVID-19, and it can be inferred that research and modeling are shifting toward the use of ensemble approaches. Originality/value: The study also identifies several novel automated web-based approaches used by researchers to assess the validity of pandemic news that have proven to be successful, although currently reported accuracy has not yet reached consistent levels in the real world.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.3390/s21165496" target="_blank"> Misinformation vs. Situational awareness: The art of deception and the need for cross-domain detection<a></b></td></tr><tr><td>Type: Review</td><td>ID: S_2-s2.0-85112383199</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Xarhoulacos C.-G., Anagnostopoulou A., Stergiopoulos G., Gritzalis D.</b></td></tr><tr><td colspan="3">Organisations: <b>Athens University of Economics & Business</b></td></tr><tr><td colspan="3">The world has been afflicted by the rise of misinformation. The sheer volume of news produced daily necessitates the development of automated methods for separating fact from fiction. To tackle this issue, the computer science community has produced a plethora of approaches, documented in a number of surveys. However, these surveys primarily rely on one-dimensional solutions, i.e., deception detection approaches that focus on a specific aspect of misinformation, such as a particular topic, language, or source. Misinformation is considered a major obstacle for situational awareness, including cyber, both from a company and a societal point of view. This paper explores the evolving field of misinformation detection and analytics on information published in news articles, with an emphasis on methodologies that handle multiple dimensions of the fake news detection conundrum. We analyze and compare existing research on cross-dimensional methodologies. Our evaluation process is based on a set of criteria, including a predefined set of performance metrics, data pre-processing features, and domains of implementation. Furthermore, we assess the adaptability of each methodology in detecting misinformation in real-world news and thoroughly analyze our findings. Specifically, survey insights demonstrate that when a detection approach focuses on several dimensions (e.g., languages and topics, languages and sources, etc.), its performance improves, and it becomes more flexible in detecting false information across different contexts. Finally, we propose a set of research directions that could aid in furthering the development of more advanced and accurate models in this field.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/TMM.2021.3098988" target="_blank"> Entity-Oriented Multi-Modal Alignment and Fusion Network for Fake News Detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85112593216</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Li P., Sun X., Yu H., Tian Y., Yao F., Xu G.</b></td></tr><tr><td colspan="3">Organisations: <b>Chinese Academy of Sciences, University of Chinese Academy of Sciences</b></td></tr><tr><td colspan="3">The development of social media enables fake news to be expressed in a multi-modal form, which is disseminated on various social platforms and brings harmful social impacts. To handle this challenge, the fake news detection task was proposed to examine whether false information is contained in multi-modal news. Existing methods exploit various approaches with cross-modal interaction and fusion, which have proven to be effective in detecting common fake news. However, although the description of multi-modal news is narrated around entities, the previously developed methods pay less attention to this characteristic. They do not explore its benefits to the detection task and underperform with respect to the detection of fake news that requires entity-centric comparisons. To make up for this omission, we explore a novel paradigm to detect fake news by aligning and fusing multi-modal entities and propose the Entity-oriented Multi-modal Alignment and Fusion network (EMAF). Our work adopts entity-centric cross-modal interaction, which can reserve semantic integrity and capture the details of multi-modal entities. Specifically, we design an Alignment module with the improved dynamic routing algorithm and introduce a Fusion module based on the comparison, the former aligns and captures the important entities and the latter compares and aggregates entity-centric features. Comparative experiments conducted on multiple public datasets, including Weibo, Twitter, and Reddit, reveal the superiority of the proposed EMAF method, and extensive analytical experiments demonstrate the effectiveness of our proposed modules.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/TCSS.2021.3096038" target="_blank"> Analyzing Biases in Perception of Truth in News Stories and Their Implications for Fact Checking<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85112619856</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Babaei M., Redmiles E.M., Gummadi K.P., Kulshrestha J., Chakraborty A., Cha M.</b></td></tr><tr><td colspan="3">Organisations: <b>Max Planck Institute for Software Systems, University of Konstanz, IIT Delhi, Institute for Basic Science, Advanced Institute of Science and Technology</b></td></tr><tr><td colspan="3">Misinformation on social media has become a critical problem, particularly during a public health pandemic. Most social platforms today rely on users' voluntary reports to determine which news stories to fact-check first. Despite the importance, no prior work has explored the potential biases in such a reporting process. This work proposes a novel methodology to assess how users perceive truth or misinformation in online news stories. By conducting a large-scale survey ( N =15 000), we identify the possible biases in news perceptions and explore how partisan leanings influence the news selection algorithm for fact checking. Our survey reveals several perception biases or inaccuracies in estimating the truth level of stories. The first kind, called the total perception bias (TPB), is the aggregate difference in the ground truth and perceived truth level. The next two are the false-positive bias (FPB) and false-negative bias (FNB), which measures users' gullibility and cynicality of a given claim. We also propose ideological mean perception bias (IMPB), which quantifies a news story's ideological disputability. Collectively, these biases indicate that user perceptions are not correlated with the ground truth of new stories; users believe some stories to be more false and vice versa. This calls for the need to fact-check news stories that exhibit the most considerable perception biases first, which the current voluntary reporting does not offer. Based on these observations, we propose a new framework that can best leverage users' truth perceptions to remove false stories, correct misperceptions of users, or decrease ideological disagreements. We discuss how this new prioritizing scheme can aid platforms to significantly reduce the impact of fake news on user beliefs.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ACCESS.2021.3100245" target="_blank"> MVAN: Multi-View Attention Networks for Fake News Detection on Social Media<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85112635550</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Ni S., Li J., Kao H.-Y.</b></td></tr><tr><td colspan="3">Organisations: <b>National Cheng Kung University</b></td></tr><tr><td colspan="3">Fake news on social media is a widespread and serious problem in today's society. Existing fake news detection methods focus on finding clues from Long text content, such as original news articles and user comments. This paper solves the problem of fake news detection in more realistic scenarios. Only source shot-text tweet and its retweet users are provided without user comments. We develop a novel neural network based model, Multi-View Attention Networks (MVAN) to detect fake news and provide explanations on social media. The MVAN model includes text semantic attention and propagation structure attention, which ensures that our model can capture information and clues both of source tweet content and propagation structure. In addition, the two attention mechanisms in the model can find key clue words in fake news texts and suspicious users in the propagation structure. We conduct experiments on two real-world datasets, and the results demonstrate that MVAN can significantly outperform state-of-the-art methods by 2.5% in accuracy on average, and produce a reasonable explanation.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.7717/PEERJ-CS.624" target="_blank"> Using of n-grams from morphological tags for fake news classification<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85112643670</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Kapusta J., Drlik M., Munk M.</b></td></tr><tr><td colspan="3">Organisations: <b>Constantine the Philosopher University in Nitra, University of Pardubice</b></td></tr><tr><td colspan="3">Research of the techniques for effective fake news detection has become very needed and attractive. These techniques have a background in many research disciplines, including morphological analysis. Several researchers stated that simple content-related n-grams and POS tagging had been proven insufficient for fake news classification. However, they did not realise any empirical research results, which could confirm these statements experimentally in the last decade. Considering this contradiction, the main aim of the paper is to experimentally evaluate the potential of the common use of n-grams and POS tags for the correct classification of fake and true news. The dataset of published fake or real news about the current Covid-19 pandemic was pre-processed using morphological analysis. As a result, n-grams of POS tags were prepared and further analysed. Three techniques based on POS tags were proposed and applied to different groups of n-grams in the pre-processing phase of fake news detection. The n-gram size was examined as the first. Subsequently, the most suitable depth of the decision trees for sufficient generalization was scoped. Finally, the performance measures of models based on the proposed techniques were compared with the standardised reference TF-IDF technique. The performance measures of the model like accuracy, precision, recall and f1-score are considered, together with the 10-fold cross-validation technique. Simultaneously, the question, whether the TF-IDF technique can be improved using POS tags was researched in detail. The results showed that the newly proposed techniques are comparable with the traditional TF-IDF technique. At the same time, it can be stated that the morphological analysis can improve the baseline TF-IDF technique. As a result, the performance measures of the model, precision for fake news and recall for real news, were statistically significantly improved.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-16-1502-3_81" target="_blank"> Fact Check Using Multinomial Naive Bayes<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85112718696</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Pradhan M.A., Shinde A., Dhiman R., Ghorpade S., Jawale S.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Pune</b></td></tr><tr><td colspan="3">An easy access to social media platforms has made information available effortlessly and thus has increased the intricacies to distinguish between true and falsified information. The credibility or reliability on social media platforms is also at stake. It is of utmost necessary to address this as a severe issue and act on it promptly. The extensive spread of counterfeit news has the potential for creating negative impacts on vast audience. Therefore, fake news detection on social media has become a very critical agenda in today’s world. This paper proposes a prototype to detect whether a news is fake or real using the multinomial Naive Bayes algorithm and its various architectures. Furthermore, the proposed prototype is capable of handling the unstructured data as the news can be in the form of images. In addition to this, the use of Django which is a high-level Python framework that allows the development of UI very easily with multiple designing options. As there was a high need of a 24/7 working server, the system has been deployed on Amazon Web Services EC2 Server as it gave less downtime and is highly reliable. Experimentation was done on the synthetic COVID news dataset created by collecting COVID news on social platforms.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-16-1502-3_30" target="_blank"> Automatic Fake News Detector in Social Media Using Machine Learning and Natural Language Processing Approaches<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85112723296</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Srinivas J., Venkata Subba Reddy K., Sunny Deol G.J., VaraPrasada Rao P.</b></td></tr><tr><td colspan="3">Organisations: <b>SR University, Kallam Haranadha Reddy Institute of Technology, Gokaraju Rangaraju Institute of Technology</b></td></tr><tr><td colspan="3">The definition of fake news is a cooked-up story with an objective to fool or to cheat people. The current research aims to detect fake news in social media like Twitter, Watsapp and Facebook by studying the responses of the proposed model on posts acquired from Reddit online news store. Automatic fake news detection is a complex activity as it involves the model to implement natural language processing concepts in-tandem with machine learning approaches. Two feature extraction algorithms, namely CountVectoriser (CV) and term frequency-inverse document frequency (TFIDF), were employed separately for extracting the most relevant features from the dataset. These features were fed to multinomial naive Bayes (MNB), random forest (RF), support vector classifier (SVC) and logistic regression (LR) classifiers for classifying fake news creating a total of eight classification models. A solitary CV-based model was considered as the baseline model for predicting fake news in r/theonion and r/nottheonion datasets. GridsearchCV was also implemented for finding the testing and training scores for the selected parameters. Out of these models, TFIDF with MNB achieved an accuracy of 79.05% and is considered as the best.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.ipm.2021.102712" target="_blank"> Temporally evolving graph neural network for fake news detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85112744798</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Song C., Wu B., Shu K.</b></td></tr><tr><td colspan="3">Organisations: <b>Beijing University of Posts and Telecommunications, Illinois Institute of Technology</b></td></tr><tr><td colspan="3">The proliferation of fake news on social media has the probability to bring an unfavorable impact on public opinion and social development. Many efforts have been paid to develop effective detection and intervention algorithms in recent years. Most of the existing propagation-based fake news detection methods focus on static networks and assume the whole information propagation network structure is accessible before performing learning algorithms. However, in real-world information diffusion networks, new nodes and edges constantly emerge. Therefore, in this paper, we introduce a novel temporal propagation-based fake news detection framework, which could fuse structure, content semantics, and temporal information. In particular, our model can model temporal evolution patterns of real-world news as the graph evolving under the setting of continuous-time dynamic diffusion networks. We conduct extensive experiments on large-scale real-world datasets and the experimental results demonstrate that our proposed model outperforms state-of-the-art fake news detection methods.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICET51757.2021.9450924" target="_blank"> Financial Fake News Detection with Multi fact CNN-LSTM Model<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85112801990</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Zhi X., Xue L., Zhi W., Li Z., Zhao B., Wang Y., Shen Z.</b></td></tr><tr><td colspan="3">Organisations: <b>Shanghai Futures Information Technology Co. Ltd</b></td></tr><tr><td colspan="3">Nowadays, financial news is an indispensable source for investors to conduct research and investment decisions. At the same time, there are many fake financial news flooded into people's daily life. This kind of information may affect public opinion and provide opportunities for some criminals to manipulate the financial market. However, due to the lack of available comparative information, the model based on linguistic features is much less effective in the real world. We believe that multi-source fact comparison and inspection should be integrated into the false news detection model to detect fake news. As the crystallization of collective wisdom, user comments can be of great benefit to this task. News sources are also crucial for detecting. Besides, existing models often ignore one point that financial fake news usually talks about the relevant market, so the market data should be token into consideration. Our proposed multi fact CNNLSTM model integrates all these dimensions mentioned above and performs well. Specially, we use attention mechanism to extract the information from the comments and make a list of authoritative websites to identify the source of news. As for the market dimension, according to the financial products mentioned in the news, we get market price and check whether the statements in the article are correct. Finally, we assign a weight to each dimension and let the model learns by itself.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.procs.2021.05.086" target="_blank"> AraCOVID19-MFH: Arabic COVID-19 Multi-label Fake News & Hate Speech Detection Dataset<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85112862297</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Hadj Ameur M.S., Aliane H.</b></td></tr><tr><td colspan="3">Organisations: <b>Research Centre on Scientific and Technical Information (CERIST)</b></td></tr><tr><td colspan="3">Along with the COVID-19 pandemic, an "infodemic" of false and misleading information has emerged and has complicated the COVID-19 response efforts. Social networking sites such as Facebook and Twitter have contributed largely to the spread of rumors, conspiracy theories, hate, xenophobia, racism, and prejudice. To combat the spread of fake news, researchers around the world have and are still making considerable efforts to build and share COVID-19 related research articles, models, and datasets. This paper releases "AraCOVID19-MFH"1a manually annotated multi-label Arabic COVID-19 fake news and hate speech detection dataset. Our dataset contains 10,828 Arabic tweets annotated with 10 different labels. The labels have been designed to consider some aspects relevant to the fact-checking task, such as the tweet's check worthiness, positivity/negativity, and factuality. To confirm our annotated dataset's practical utility, we used it to train and evaluate several classification models and reported the obtained results. Though the dataset is mainly designed for fake news detection, it can also be used for hate speech detection, opinion/news classification, dialect identification, and many other tasks.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3451215" target="_blank"> Knowledge-aware Multi-modal Adaptive Graph Convolutional Networks for Fake News Detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85112866928</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Qian S., Hu J., Fang Q., Xu C.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Chinese Academy of Sciences, University of Chinese Academy of Sciences</b></td></tr><tr><td colspan="3">In this article, we focus on fake news detection task and aim to automatically identify the fake news from vast amount of social media posts. To date, many approaches have been proposed to detect fake news, which includes traditional learning methods and deep learning-based models. However, there are three existing challenges: (i) How to represent social media posts effectively, since the post content is various and highly complicated; (ii) how to propose a data-driven method to increase the flexibility of the model to deal with the samples in different contexts and news backgrounds; and (iii) how to fully utilize the additional auxiliary information (the background knowledge and multi-modal information) of posts for better representation learning. To tackle the above challenges, we propose a novel Knowledge-aware Multi-modal Adaptive Graph Convolutional Networks (KMAGCN) to capture the semantic representations by jointly modeling the textual information, knowledge concepts, and visual information into a unified framework for fake news detection. We model posts as graphs and use a knowledge-aware multi-modal adaptive graph learning principal for the effective feature learning. Compared with existing methods, the proposed KMAGCN addresses challenges from three aspects: (1) It models posts as graphs to capture the non-consecutive and long-range semantic relations; (2) it proposes a novel adaptive graph convolutional network to handle the variability of graph data; and (3) it leverages textual information, knowledge concepts and visual information jointly for model learning. We have conducted extensive experiments on three public real-world datasets and superior results demonstrate the effectiveness of KMAGCN compared with other state-of-the-art algorithms.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3465481.3470088" target="_blank"> DISSIMILAR: Towards fake news detection using information hiding, signal processing and machine learning<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85113199723</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Megias D., Rosales A., Kuribayashi M., Mazurczyk W.</b></td></tr><tr><td colspan="3">Organisations: <b>Universitat Oberta de Catalunya, Okayama University, Warsaw University of Technology</b></td></tr><tr><td colspan="3">Digital media have changed the classical model of mass media that considers the transmitter of a message and a passive receiver, to a model where users of the digital media can appropriate the contents, recreate, and circulate them. In this context, online social media are a suitable circuit for the distribution of fake news and the spread of disinformation. Particularly, photo and video editing tools and recent advances in artificial intelligence allow non-professionals to easily counterfeit multimedia documents and create deep fakes. To avoid the spread of disinformation, some online social media deploy methods to filter fake content. Although this can be an effective method, its centralized approach gives an enormous power to the manager of these services. Considering the above, this paper outlines the main principles and research approach of the ongoing DISSIMILAR project, which is focused on the detection of fake news on social media platforms using information hiding techniques, in particular, digital watermarking, combined with machine learning approaches.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/TKDE.2021.3103833" target="_blank"> Category-Controlled Encoder-Decoder for Fake News Detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85113338896</td><td>Year: <b>2023</b></td></tr><tr><td colspan="3">Authors: <b>Wu L., Rao Y., Zhao Y., Nazir A., Zhang C.</b></td></tr><tr><td colspan="3">Organisations: <b>Xi'An Jiaotong University, Xi'An Huanyu Satellite Control and Data Application Co. Ltd.</b></td></tr><tr><td colspan="3">The existing data-driven approaches typically capture credibility-indicative representations from relevant articles for fake news detection, such as skeptical and conflicting opinions. However, these methods still have several drawbacks: 1) Due to the difficulty of collecting fake news, the capacity of the existing datasets is relatively small; and 2) there is considerable unverified news that lacks conflicting voices in relevant articles, which makes it difficult for the existing methods to identify their credibility. Especially, the differences between true and fake news are not limited to whether there are conflict features in their relevant articles, but also include more extensive hidden differences at the linguistic level, such as the perspectives of emotional expression (like extreme emotion in fake news), writing style (like the shocking title in clickbait), etc., the existing methods are difficult to fully capture these differences. To capture more general and wide-ranging differences between true and fake news, in this paper, directly from the different categories of news itself, we propose a Category-controlled Encoder-Decoder model (CED) to generate examples with category-differentiated features and extend the dataset capacity to achieve data enhancement effect, thus enhancing fake news detection. Specifically, to make the generated examples enrich more news features, we develop news-guided encoder to guide relevant articles to generate news-semantic context representations. To drive the generated examples to contain more category-differentiated features, we devise category-controlled decoder which relies on pattern-shared unit to respectively capture intra-category shared features within true or fake news, and employs restriction unit to force the two types of shared features to be more different for highlighting inter-category differentiated features. The experimental results on three datasets demonstrate the superiority of CED.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/INCET51464.2021.9456299" target="_blank"> A review of fake news detection methods using machine learning<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85113342034</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Choudhary M., Jha S., Prashant, Saxena D., Singh A.K.</b></td></tr><tr><td colspan="3">Organisations: <b>NIT Kurukshetra</b></td></tr><tr><td colspan="3">The widespread use of social media has had a terrible impact on our society due to the spread of fake news. In particular, the author has seen the idea of the quality of fake news before its origin. Like the internet, publishers used false and misleading information to further their interest. People often get involved in social media as social media provides low cost, quick access, and fast spread of news. It has been seen for many years that fake news harms persons as well as society. So, the challenge of fake news detection arrived. Inappropriate news took place to attract people so the sender can start putting the rumor of news. This had led to a negative impact on people about social media for their news. This led to inconvenience for offline news as well because when people will too much depend on online platforms that will reduce the offline users. This survey deals with a review of existing machine learning algorithms Naïve Bayes, Convolutional Neural Network, LSTM, Neural Network, Support Vector Machine proposed for detecting and reducing fake news from different social media platforms like Facebook, whatsapp, twitter, etc. This review provides a comprehensive detail including data mining perspective, evaluation metrics, and representative datasheets. Further, a comparison of the state-of-the-art is presented and untackled challenges in detecting fake news are highlighted. Research in the field of detecting fake news has been hampered to a great extent by the lack of quantity and quality of existing datasets. Therefore, this review compares the existing approaches to build models and with further improvements to be expected by using the combination of different machine learning techniques.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.patrec.2021.07.020" target="_blank"> Effective fake news detection using graph and summarization techniques<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85113381012</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Kim G., Ko Y.</b></td></tr><tr><td colspan="3">Organisations: <b>Sungkyunkwan University</b></td></tr><tr><td colspan="3">Nowadays, fake news is widely spreading in various media, and this fake information is causing serious damage in many areas. Therefore, there is an increasing need to accurately detect fake news to prevent such damage. In this paper, we propose a novel method that uses graph and summarization techniques for fake news detection. Our proposed method represents the relationship of all sentences in a graph structure to accurately understand the context information of the document. Accordingly, the relationship between sentences in the graph is calculated as a score through the attention mechanism. Then, the summarization technique is used to reflect the sentence subject information in the graph update process. Our proposed method shows better performance than Karimi's and BERT based models by approximately 10.34%p and 3.72%p, respectively.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/CSCI51800.2020.00052" target="_blank"> Shapley based Interpretable Semi-supervised Model for Detecting Similarity Index of Social Media Campaigns<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85113396073</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Framewala A., Patil A., Kazi F.</b></td></tr><tr><td colspan="3">Organisations: <b>Centre of Excellence in Complex and Nonlinear Dynamical Systems</b></td></tr><tr><td colspan="3">Although significant research is done on fake news detection, the definition of a news being fake has always been ambiguous. This problem can be addressed by comparing such campaigns of fake news or harmful content with previously detected similar campaigns on social media. Detecting similar campaigns also helps in structured analysis of social media content useful for various applications including comparison of different marketing campaigns. In this paper authors showcase a novel semi-supervised learning approach for detecting similar campaigns and giving human-like explanations for those predictions. This is done by using a modified version of Artificial Immune System (AIS) for unsupervised detection of similar campaigns. We then use eXtreme Gradient Boosting (XGBoost) model for extracting rules from predictions which are further fed to Shapley Additive exPlanations (SHAP) to generate payoffs of each contributing feature. We demonstrate the approach using three different social media campaigns covering public outrage, marketing and public awareness.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.21817/indjcse/2021/v12i4/211204151" target="_blank"> Fake news detection of social media news in blockchain framework<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85113398856</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Waghmare A.D., Patnaik G.K.</b></td></tr><tr><td colspan="3">Organisations: <b>SSBT’s COET</b></td></tr><tr><td colspan="3">Social media news are most important in today’s worlds, it puts positive or negative influence on social views. There is a wide propagation of fake news on social media so it will be difficult to believe on the news. Fake news has negative impacts on individuals as well as on society. Information spreads rapidly over the social media and so there is a need of mechanism which detects and stops the spreading of fake news. Therefore, detection of fake news is the need of time and also a challenging problem. The goal of this proposed research work is to detect fake news and minimize spreading of the fake news. In the proposed research a machine learning approach is used for detection of fake news with blockchain framework. In first section a supervised machine learning techniques is design to identify the trustiness of specific news while blockchain framework revoke the malicious activity of spreading fake news. A blockchain environment is created with mining, smart contract as well as Proof of Work (PoW) of consensus. The current systematic review broadly focuses on the various methods to detect fake news in social media. After partial implementation of system, performance evaluation has done with traditional blockchain framework. It is found that 10% less time for transaction verification by consensus in P2P environment over the existing systems.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> GPLSI team at CheckThat! 2021: Fine-tuning BETO and RoBERTa<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85113418284</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Sepulveda-Torres R., Saquete E.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Alicante</b></td></tr><tr><td colspan="3">CheckThat! Lab is a challenging lab aimed at tackling the disinformation problem. The GPLSI team from the University of Alicante (Spain) has participated in two tasks of the CheckThat! Lab namely, Task 1 (Check-Worthiness Estimation) and Task 3 (Fake News Detection). We attained second and fifth place in the Spanish-version and English-version of Subtask 1A. Our systems use models based on transfer learning such as RoBERTa and BETO. The best results were achieved by fine-tuning these models. However, our results for Subtask 3A are low compared to the team that achieved the best result. We included some external features in the models for Subtask 1A and 3A, but we could not improve the results. In future work, we will experiment by incorporating other external features into the models with the aim of improving the results of the tasks.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> NITK_NLP at CheckThat! 2021: Ensemble transformer model for fake news classification<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85113427641</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>LekshmiAmmal H.R., Madasamy A.K.</b></td></tr><tr><td colspan="3">Organisations: <b>National Institute of Technology Karnataka</b></td></tr><tr><td colspan="3">Social media has become an inevitable part of our life as we are primarily dependent on them to get most of the news around us. However, the amount of false information propagated through it is much higher than the genuine ones, thus becoming a peril to society. In this paper, we have proposed a model for Fake News Classification as a part of CLEF2021 Checkthat! Lab1 shared task, which had Multi-class Fake News Detection and Topical Domain Classification of News Articles. We have used an ensemble model consisting of pre-trained transformer-based models that helped us achieve 4tℎ and 1st positions on the leaderboard of the two tasks. We achieved an F1-score of 0.4483 against a top score of 0.8376 in one task and a score of 0.8813 in another.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICOEI51242.2021.9453061" target="_blank"> Fake News Detection - A Comparative Study of Advanced Ensemble Approaches<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85113434410</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Ganesh P., Priya L., Nandakumar R.</b></td></tr><tr><td colspan="3">Organisations: <b>Amrita School of Arts and Sciences</b></td></tr><tr><td colspan="3">People have taken to social media as a platform for gathering news for updates on everything such as entertainment, politics, government, sports, education, and technology. Therefore, it is highly necessary to ensure that the information accessible to the public is reliable. But there is a high risk of malicious forces spreading wrong information, making even the savviest news audience at risk. Misinformation can seriously, indeed fatally harm the community. Many machine learning algorithms were proposed for identifying false news. In this paper, we have analyzed the accuracies between the ensemble model (LSVM, Naive Bayes, Decision Tree) using Voting Classifier with Bagging meta-estimator and Boosting (Adaboost and Gradient Boosting) Classifiers. We make a comparison between the two most effective advanced ensemble algorithms bagging and boosting. We base this analysis on two datasets where one is of a smaller size and another is a bigger dataset. Voting Classifier is used for ensembling LSVM, Naive Bayes, and Decision Tree for both the datasets. This ensembled model has been taken as the base estimator of Bagging meta-estimator and is compared with the other classifiers such as Bagging with default base estimator, Adaboost and Gradient Boosting. Our study shows that Bagging meta-estimator with ensemble model as its base estimator shows better performance than Boosting classifiers for both the datasets.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Overview of the CLEF-2021 CheckThat! Lab: Task 3 on fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85113435727</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Shahi G.K., Struss J.M., Mandl T.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Duisburg-Essen, Potsdam University of Applied Sciences, University of Hildesheim</b></td></tr><tr><td colspan="3">We describe the fourth edition of the CheckThat! Lab, part of the 2021 Conference and Labs of the Evaluation Forum (CLEF). The lab evaluates technology supporting three tasks related to factuality, and it covers Arabic, Bulgarian, English, Spanish, and Turkish. Here, we present task 3, which focuses on multi-class fake news detection and topical domain detection of news articles. Overall, there were 88 submissions by 27 teams for Task 3A, and 49 submissions by 20 teams for task 3B (two team from Task 3A and seven teams from Task 3B are excluding from the ranking due to wrong submission file). The best performing system for task 3A achieved a macro F1-score of 0.84 and was ahead of the rest by a rather large margin. The performance of the systems for task 3B was overall higher than for task 3A with the top performing system achieving a macro F1-score of 0.88. In this paper, we describe the process of data collection and the task setup, including the evaluation measures used, and we give a brief overview of the participating systems. Last but not least, we release to the research community all data sets from the lab as well as the evaluation scripts, which should enable further research in automatic classification of news articles with respect to their correctness and topical domain.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Team sigmoid at CheckThat!2021 Task 3a: Multiclass fake news detection with Machine Learning<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85113448539</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Al Mamun Sardar A., Salma S.A., Islam M.S., Hasan M.A., Bhuiyan T.</b></td></tr><tr><td colspan="3">Organisations: <b>Daffodil International</b></td></tr><tr><td colspan="3">Fake news is affecting our lives since the internet has become popular. Particularly, in this era of social media it is very easy to spread and be affected by fake news. In this work we have developed machine learning models which can classify a news claim into four classes. This work has been done under the competition of CheckThat!2021 task-3a. We have conducted our experiment on Check that lab's dataset. Our work has been done only on linguistic features. We have experimented both with traditional Machine Learning algorithms and Deep Learning algorithms. LSTM outperformed other traditional machine learning algorithms and with Adam optimizer LSTM gave a f1-macro score of 26.07%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> CIC at CheckThat! 2021: Fake news detection using machine learning and data augmentation<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85113448631</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Ashraf N., Butt S., Sidorov G., Gelbukh A.</b></td></tr><tr><td colspan="3">Organisations: <b>Instituto Politécnico Nacional</b></td></tr><tr><td colspan="3">Disinformation in the form of fake news, phoney press releases and hoaxes may be misleading, especially when they are not from their original sources and this fake news can cause significant harm to the people. In this paper, we report several machine learning classifiers on the CLEF2021 dataset for the tasks of news claim and topic classification using n-grams. We achieve an F1 score of 38.92% on news claim classification (task 3a) and an F1 score of 78.96% on topic classification (task 3b). In addition, we augmented the dataset for news claim classification and we observed that insertion of alternative words was not beneficial for the fake news classification task.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> NLytics at CheckThat! 2021: Multi-class fake news detection of news articles and domain identification with RoBERTa - A baseline model<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85113449733</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Pritzkau A.</b></td></tr><tr><td colspan="3">Organisations: <b>Fraunhofer Institute for Communication</b></td></tr><tr><td colspan="3">The following system description presents our approach to the detection of fake news in texts. The given task has been framed as a multi-class classification problem. The multi-class classification problem is one in which a target variable such as the given class label is associated with every input chunk. In order to assign class labels to the given documents, we opted for RoBERTa (A Robustly Optimized BERT Pretraining Approach) as a neural network architecture for sequence classification. Starting off with a pre-trained model for language representation we fine-tuned this model on the given classification task with the provided annotated data in supervised training steps.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICOEI51242.2021.9452829" target="_blank"> Battling Fake News: A Survey on Mitigation Techniques and Identification<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85113454857</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Kumar P.J.S., Devi P.R., Sai N.R., Kumar S.S., Benarji T.</b></td></tr><tr><td colspan="3">Organisations: <b>A.N.R. College, Velagapudi Ramakrishna Siddhartha Engineering College, KoneruLakshmaiah Education Foundation, Prasad v Potluri Siddhartha Institute of Technology, Indur Institute of Engineering and Technology</b></td></tr><tr><td colspan="3">Fake news are generally characterized as misdirected news, which are often constructed with a feeling of conviction and tricking people towards accepting a specific incident. Fake news spread widely due to its social associations. The multiplication of fake news via web-based media has opened up a new plethora for performing recognizable testing and regulation on fake news ideals and to alleviate its great influence on the popular hypothesis. Although different existing research works focuses on the distinguishing evidence obtained from fake news that depends on its substance or that abuses customer engagement with news via web-based media, there has been a growing enthusiasm on proactive advocacy methodologies in order to counteract the spread, deception, and its effect on society. This study describes the current topic of fake news and specifically presents the specialist difficulties related to it. This research work discusses about the existing strategies and procedures relevant to both DI and moderation by leveraging significant attention to the critical progress in each strategy along with their points of interest and constraints. Furthermore, the search was regularly limited by the nature of the existing datasets and their particular application settings. To mitigate this problem, this research work completely sort and summarizes the brand highlights obtained from the accessible datasets. Additionally, new exploration headings to further advance workable interdisciplinary agreements are also reported.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> NLP&IR@UNED at CheckThat! 2021: Check-worthiness estimation and fake news detection using transformer models<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85113487959</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Martinez-Rico J.R., Martinez-Romo J., Araujo L.</b></td></tr><tr><td colspan="3">Organisations: <b>Universidad Nacional de Educación a Distancia (UNED), Instituto Mixto de Investigación - Escuela Nacional de Sanidad (IMIENS)</b></td></tr><tr><td colspan="3">This article describes the different approaches used by the NLPIR@UNED team in the CLEF2021 CheckThat! Lab to tackle the tasks 1A-English, 1A-Spanish and 3A-English. The goal of Task 1A in English is to determine which tweets within a set of COVID-19 related tweets are worth checking. Task 1A in Spanish is similar but in this case the tweets are related to political issues in Spain. In both tasks, transformer models have been used to identify check-worthy tweets, obtaining the first place in the task in English and the fourth place in the task in Spanish. Task 3A is focused on determining the veracity of a news article. It is a multi-class classification problem with four possible values: true, partially false, false, and other. For this task we have used two different approaches: a gradient-boosting classifier with TF-IDF and LIWC features, and a transformer model fed with the first tokens of each news article. We got the fourth place out of 25 participants in this task.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Nkovachevich at CheckThat! 2021: BERT fine-tuning approach to fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85113488753</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Kovachevich N.</b></td></tr><tr><td colspan="3">Organisations: <b>Sofia University</b></td></tr><tr><td colspan="3">The success of a text classification approach depends to a large extent on the data that it is trained on. The adaptation of a model with thousands of weights, such as BERT, usually requires large amount of data. CLEF 2021 CheckThat! Lab for fake news detection offers a challenging multi-class task with relatively small data set to train on. The experiments, which include BERT fine-tuning, together with a couple of simpler algorithms, produce average results, and hardly overcome model and data size limitations. Nevertheless, they show a potential to be successful if implemented properly.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> LSACoNet: A Combination of Lexical and Conceptual Features for Analysis of Fake News Spreaders on Twitter Notebook for PAN at CLEF 2020<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85113491271</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Giglou H.B., Razmara J., Sanaei M., Rahgouy M.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Tabriz, Part AI Research Center</b></td></tr><tr><td colspan="3">Fake news detection on social medial has attracted a huge body of research as one of the most important tasks of social analysis in recent years. In this task, given a Twitter feed, the goal is to identify fake/real news authors or spreaders. We assume fake news authors mostly like to play with the semantic aspect of news rather than trying to add specific changes to their styles. However, making a change into the semantic aspect of news can cause unwanted changes in style. We hypothesize, by relying on news content, a combination of semantic and coarse-grained features may lead us to common information about the author’s style while reviewing the conceptual aspect of author documents. In this paper, we propose the LSACoNet representation using a fully connected neural network (FCNN) classifier that combines different levels of document representation to investigate this hypothesis. Experimental results presented in this paper showed that a combination of representations plays an important role in identifying fake/real news spreaders. Finally, we achieved accuracies of 72.5% and 74.5% in the English and Spanish test datasets, respectively, using presented LSACoNet representation and FCNN classifier.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> MUCIC at CheckThat! 2021: FaDo-fake news detection and domain identification using transformers ensembling<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85113505995</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Balouchzahi F., Sidorov G., Shashirekha H.L.</b></td></tr><tr><td colspan="3">Organisations: <b>Instituto Politécnico Nacional, Mangalore University</b></td></tr><tr><td colspan="3">Since the beginning of Covid-19 era in November 2019, the patient growth curve is closely accompanied by the growth of fake news. Therefore, developing tools and models for the detection of fake news from real ones in various domains have become more significant than the earlier days. To address the detection of fake news, in this paper, we, team MUCIC, describe the models submitted to 'Fake News Detection', a shared task organized by CLEF-2021-CheckThat! Lab. This shared task contains two subtasks namely; Fake News Detection of News Articles (Subtask 3A) and Topical Domain Classification of News Articles (Subtask 3B) and both are multi-class text classification tasks. The proposed models have been developed by fine-tuning the three transformer-based language models namely; Roberta, Distilbert, and BERT from HuggingFace using training data and then ensembling them as estimators with majority voting. The proposed models performances evaluated through the evaluation script provided by organizers obtained F1-scores of 0.5309 and 0.8550 for Subtask 3A and Subtask 3B respectively.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> M82B at CheckThat! 2021: Multiclass fake news detection using BiLSTM<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85113515626</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Ashik S.S., Apu A.R., Marjana N.J., Islam M.S., Hasan M.A.</b></td></tr><tr><td colspan="3">Organisations: <b>Daffodil International University</b></td></tr><tr><td colspan="3">The rapid advancement of web technologies enabled to spread of information online faster. This enabled the spreading of both informative and uninformative information among the people. Fake news represents misinformation which is published in the newspapers, blogs, newsfeed, social media. Fake news is expanding very quickly via social media, generated by humans or machines as well as originating the unrest situation in the society, country. Meanwhile, fake news detection using machine learning is becoming a prominent area in the research to identify the credibility of the news instantaneously. To present this work, we used Bidirectional Long Short-Term Memory (BiLSTM) to predict the news is either fake or true. We participated in the fake news classification shared task of CheckThat! 2021 workshop. We obtained the dataset from this event to train and evaluate our model. Finally, we were able to achieve 36% model accuracy and 29.0 F1-macro score with our training data.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Classifier for fake news detection and topical domain of news articles<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85113535975</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>William K.T.</b></td></tr><tr><td colspan="3">Organisations: <b>University Duisburg-Essen</b></td></tr><tr><td colspan="3">Digitization has resulted in a plethora of new methods to read articles or excerpts online using smart-phones or tablets. Nowadays, everything is available online, and dealing with false information has grown increasingly. Online newspapers cannot check the veracity of all social media posts, and in order to combat the spread of fake news, machine learning algorithms might be beneficial in classifying articles based on labels provided by experts. This paper will present relevant algorithms and their outcomes.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> UAICS at CheckThat! 2021: Fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85113560603</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Cusmuliuc C.G., Amarandei M.A., Pelin I., Cociorva V.I., Iftene A.</b></td></tr><tr><td colspan="3">Organisations: <b>“Alexandru Ioan Cuza” University</b></td></tr><tr><td colspan="3">Social media growth in recent years has facilitated an enhancement in human communication. Platforms such as Facebook and Twitter are now ever-present in our lives, influencing how we speak, think and act. The growth of fake news greatly impacts this phenomenon as it lowers one's trust in the content presented. One such example is related to the 2016 U.S. presidential election campaign where fake news was a deciding factor in tipping the balance of power. It is hence of critical importance to develop tools that detect and combat such destructive content. CLEF 2021 CheckThat! Task 3 tries to address the problem of fake news, posing a challenge to develop systems that could detect if the main claim made in an article is true, partially true, false, or other. Our team participated in this task with 5 models, ranking 6th place with an F1-macro of 0.44 and a model based on Gradient Boosting; in this paper we will present our methods, runs and results but also discuss future work.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> University of Regensburg at CheckThat! 2021: Exploring text summarization for fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85113562536</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Hartl P., Kruschwitz U.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Regensburg</b></td></tr><tr><td colspan="3">We present our submission to the CLEF 2021 CheckThat! challenge. More specifically, we took part in Task 3a, Multi-class fake news detection of news articles. The conceptual idea of our work is that (a) transformer-based approaches represent a strong foundation for a broad range of NLP tasks including fake news detection, and that (b) compressing the original input documents into some form of automatically generated summary before classifying them is a promising approach. The official results indicate that this is indeed an interesting direction to explore. They also confirm that oversampling to address the class imbalance was effective to further improve the results. We also note that both abstractive and extractive summarization approaches score way better when we do not apply hypertuning of parameters suggesting that the small scale of the test collection leads to overfitting.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Qword at CheckThat! 2021: An extreme gradient boosting approach for multiclass fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85113582361</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Utsha R.S., Keya M., Hasan M.A., Islam M.S.</b></td></tr><tr><td colspan="3">Organisations: <b>Daffodil International University</b></td></tr><tr><td colspan="3">Fake news basically means fabricating a story without verifiable information, source or quote of the story. CheckThat! 2021 Task-3 has two subtasks, subtask 3a and 3b. We participated in Subtask 3a, which is a multi-class fake news classification problem. The goal was to determine whether the main claim of a news article is true, partially true, false or other. We were provided with a dataset of news articles by the organizers which consists of news articles, their titles and the rating of the article. We took advantage of TF-IDF vectorization and proposed an Extreme Gradient Boosting algorithm for our best classification model. The approaches were very interpretative with a highest classification accuracy of 0.57 and highest f1-macro score of 0.54 on the given dataset. We also tried other classification models and got varying results which are simple Logistic Regression Classifiers, Passive Aggressive Classifiers and Random Forest Classifiers.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> BlackOps at CheckThat! 2021: User profiles analyze of intelligent detection on fake tweets notebook for PAN<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85113582956</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Sohan S.M., Khusbu S.A., Islam M.S., Hasan M.A.</b></td></tr><tr><td colspan="3">Organisations: <b>Daffodil International University</b></td></tr><tr><td colspan="3">An expensive task is fake news detection for recent trends among the concept of misinformation or rumors. In everywhere most of the times information lead or play emergent preface but forthwith misinformation also in everywhere to mislead the peoples mind and activity. Therefore, detecting fake content in any system can be a weapon over fictitious news. In any language cross over the exponential growth of fake news in social sites. Hence, it is the real time process to produce online fake news so that it has been needed to implement an automated technique whenever detect true from false. According to the solution of this approach made a research On English language textual inputs as twitter news from user profiles. At this point, due to accurate analysis for social media we experimented with supervised learning such as Decision tree, Random forest and gradient boosting. In between all the ML classifiers outperformed with 88% detection accuracy that mention the research of detection is more accurate.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-16-3398-0_15" target="_blank"> Fake News Detection Techniques for Social Media<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85113605633</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Saxena A., Saxena P., Reddy H.</b></td></tr><tr><td colspan="3">Organisations: <b>Eindhoven University of Technology, G. L. Bajaj Institute of Technology and Management, _</b></td></tr><tr><td colspan="3">The advent of numerous social networking websites in the twenty-first century has provided an easy outlet for people across the globe through widely available devices such as smartphones. While this has empowered people belonging to different walks of society to post content on topics ranging from current affairs to history, it is not easy to ascertain the content’s veracity. Traditional news media has experts in the domain who have the ability to fact-check the content presented in the news. However, given the enormous amount of social media posts every day, an average human being who is exposed to the content faces difficulty in differentiating false information from real. This has brought researchers’ interest in the automated detection of fake news. In this chapter, we will discuss the features that are used to identify fake news and different categories of fake news detection techniques. We also outline the datasets available for fake news detection and provide the directions for further reading.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-16-3398-0_14" target="_blank"> Misinformation, Fake News and Rumor Detection<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85113697221</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Arora N.</b></td></tr><tr><td colspan="3">Organisations: <b>Jagran Institute of Management</b></td></tr><tr><td colspan="3">Misinformation, fake news and rumors have been an issue of concern for societies and nations. Societies, countries and even organizations experience the negative impact of misinformation, fake news and rumors. These are the forms of information or news that are unverified and could be false. That is why these have immense potential to harm the social system and beliefs. The use of the internet and social media is very common in the dissemination of misinformation. Fake accounts, bots-operated accounts or semi-automated accounts are predominantly used to spread misinformation, fake news and rumors. Some websites are also engaged in the process of creation and aggregation of unverified information. This chapter aims to define different categories of false and unverified information. The impact of misinformation, fake news and rumors and the causes of their dissemination have been explored. This chapter also analyzes the methods, tools and techniques that could be used to detect false information and discourage its dissemination. It is observed that there is a need to create awareness and educate internet users to spot and detect misinformation. Social media platforms and the government authorities are also using algorithms and other technological frameworks to detect and eliminate misinformation, fake news and rumors from the web. The findings of the study might be useful for internet users, academicians, policymakers, entrepreneurs and managers of news and social media industry. The outcomes of the study can be helpful in predicting, explaining and controlling the process of creation and dissemination of misinformation, fake news and rumors.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICAIBD51990.2021.9459078" target="_blank"> SAFS: Social-Article Features-Stacking Model for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85113731987</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Wu X., Wang J.</b></td></tr><tr><td colspan="3">Organisations: <b>Peking University</b></td></tr><tr><td colspan="3">With the rapid development of social media, people can more easily and quickly produce, transmit, receive and share information, but this also provides channels for the widespread dissemination of fake news. Therefore, it is of great practical importance how to properly detect fake news and curb its continued spread. In this paper, an integrated machine learning model for fake news detection, the Social-Article Features-Stacking Model (SAFS), is proposed based on the work of our predecessors, using natural language processing and social network analysis methods. The model achieves good experimental results by multi-feature fusion of textual features and social network features of fake news. From the experimental results on the FakeNewsNet dataset, the SAFS model greatly improves the f1 value of fake news detection by 16.86% compared with the Social-Article Fusion Model (SAF), the original paper model. Finally, the paper explores the effectiveness of different features in detecting fake news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s00521-021-06450-4" target="_blank"> AENeT: an attention-enabled neural architecture for fake news detection using contextual features<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85113802657</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Kaliyar R.K., Goswami A., Jain V., Narang P., Sharma Y.</b></td></tr><tr><td colspan="3">Organisations: <b>Bennett University, BITS</b></td></tr><tr><td colspan="3">In the current era of social media, the popularity of smartphones and social media platforms has increased exponentially. Through these electronic media, fake news has been rising rapidly with the advent of new sources of information, which are highly unreliable. Checking off a particular news article is genuine or fake is not easy for any end user. Search engines like Google are also not capable of telling about the fakeness of any news article due to its restriction with limited query keywords. In this paper, our end goal is to design an efficient deep learning model to detect the degree of fakeness in a news statement. We propose a simple network architecture that combines the use of contextual embedding as word embedding and uses attention mechanisms with relevant metadata available. The efficacy and efficiency of our models are demonstrated on several real-world datasets. Our model achieved 46.36% accuracy on the LIAR dataset, which outperforms the current state of the art by 1.49%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-82153-1_16" target="_blank"> Landscape-Enhanced Graph Attention Network for Rumor Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85113816276</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Jiang J., Liu Q., Yu M., Liu M., Liu C., Huang W., Li G.</b></td></tr><tr><td colspan="3">Organisations: <b>Chinese Academy of Sciences, University of Chinese Academy of Sciences, Deakin University</b></td></tr><tr><td colspan="3">Rumor detection aims to classify the truthfulness of content on social media. Due to the rapid development of web-based social platforms, rumors are disseminated in an ever faster speed. Recently, this problem is tackled as a graph classification problem instead of traditional text classification or time series classification problem, thanks to the natural graph structure of social networks, i.e. content dissemination network in rumor detection. However, we argue that the existing graph-based methods have several defects. They deal with two uni-directional networks separately, which restricts the interaction between nodes. Moreover, there is a gap between training and target representation, since they only learn node-level embedding and simply use average or max pooling to obtain whole graph embedding. Hence, we explore a novel method named L-GAT which solves the above drawbacks. Specifically, we employ a unified graph attention network to aggregate information without splitting information stream. Besides, we enhance the original graph with two virtual global nodes—landscape nodes—to capture global information, and train these global node embedding in an end-to-end style to bridge the gap between training and target. Experiments show that our proposed L-GAT is effective in improving the performance over all the existing rumor detection methods.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Development of software for fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85113862060</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Kaneva O.N., Goncharenko A.I.</b></td></tr><tr><td colspan="3">Organisations: <b>Omsk State Technical University</b></td></tr><tr><td colspan="3">During the research process, a fake news detection approach has been developed. The proposed algorithm includes a FastText-based vectorizer, a clustering algorithm, and a set of fully connected neural networks. The algorithm is developed in Python using machine learning libraries and an API is created with the frameworkFlask. The software package is available on the Internet and is accessible to users.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Automatic Fake News Detection in Political Platforms - A Transformer-based Approach<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85113922653</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Raza S.</b></td></tr><tr><td colspan="3">Organisations: <b>Ryerson University</b></td></tr><tr><td colspan="3">The dynamics and influence of fake news on Twitter during the 2020 US presidential election remains to be clarified. Here, we use a dataset related to 2020 U.S Election that consists of news articles and tweets on those articles. Therefore, it is extremely important to stop the spread of fake news before it reaches a mass level, which is a big challenge. We propose a novel fake news detection framework that can address this challenge. Our proposed framework exploits the information from news articles and social contexts to detect fake news. The proposed model is based on a Transformer architecture, which can learn useful representations from fake news data and predicts the probability of a news as being fake or real. Experimental results on real-world data show that our model can detect fake news with higher accuracy and much earlier, compared to the baselines.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1080/19361610.2021.1963605" target="_blank"> Fake News Detection Using Pos Tagging and Machine Learning<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85114016623</td><td>Year: <b>2023</b></td></tr><tr><td colspan="3">Authors: <b>Kansal A.</b></td></tr><tr><td colspan="3">Organisations: <b>St. Josephs College (Autonomous)</b></td></tr><tr><td colspan="3">In this digital era, one major concern is not knowing what news to believe and not to believe. With the ever-growing progress being made in social media and technology, the problem has become more prominent. This also played a very important role in spreading fake information in this pandemic, creating chaos and worry throughout the world. Through the paper, I propose to understand and analyze the underlying writing style that can help in detecting fake news before it can be published, using a style-based approach in detection. An ensemble machine learning classification model was tried out to detect fake news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/GHCI50508.2021.9514012" target="_blank"> No Rumours Please! A Multi-Indic-Lingual Approach for COVID Fake-Tweet Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85114043526</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Kar D., Bhardwaj M., Samanta S., Azad A.P.</b></td></tr><tr><td colspan="3">Organisations: <b>IIT Kharagpur, IBM Research</b></td></tr><tr><td colspan="3">The sudden widespread menace created by the present global pandemic COVID-19 has had an unprecedented effect on our lives. Man-kind is going through humongous fear and dependence on social media like never before. Fear inevitably leads to panic, speculations, and spread of misinformation. Many governments have taken measures to curb the spread of such misinformation for public well being. Besides global measures, to have effective outreach, systems for demographically local languages have an important role to play in this effort. Towards this, we propose an approach to detect fake news about COVID-19 early on from social media, such as tweets, for multiple Indic-Languages besides English. In addition, we also create an annotated dataset of Hindi and Bengali tweet for fake news detection. We propose a BERT based model augmented with additional relevant features extracted from Twitter to identify fake tweets. To expand our approach to multiple Indic languages, we resort to mBERT based model which is fine tuned over created dataset in Hindi and Bengali. We also propose a zero shot learning approach to alleviate the data scarcity issue for such low resource languages. Through rigorous experiments, we show that our approach reaches around 89% F-Score in fake tweet detection which supercedes the state-of-the-art (SOTA) results. Moreover, we establish the first benchmark for two Indic-Languages, Hindi and Bengali. Using our annotated data, our model achieves about 79% F-Score in Hindi and 81% F-Score for Bengali Tweets. Our zero shot model achieves about 81% F-Score in Hindi and 78% F-Score for Bengali Tweets without any annotated data, which clearly indicates the efficacy of our approach.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.tsc.2021.100934" target="_blank"> Critical thinking predicts reductions in Spanish physicians' stress levels and promotes fake news detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85114152717</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Escola-Gascon A., Gallifa J., Dagnall N.</b></td></tr><tr><td colspan="3">Organisations: <b>Ramon Llull University, Manchester Metropolitan University</b></td></tr><tr><td colspan="3">The prevalence of pseudoscientific beliefs and fake news increased during the coronavirus crisis. Misinformation streams such as these potentially pose risks to people's health. Thus, knowing how these pseudoscientific beliefs and fake news impact the community of internists may be useful for improving primary care services. In this research, analyses of stress levels, effectiveness in detecting fake news, use of critical thinking (CP), and attitudes toward pseudosciences in internists during the COVID-19 crisis were performed. A total of 1129 internists participated. Several multiple regression models were applied using the forward stepwise method to determine the weight of CP and physicians' attitudes toward pseudosciences in predicting reductions in stress levels and facilitating the detection of fake news. The use of critical thinking predicted 46.9% of the reduction in stress levels. Similarly, skeptical attitudes and critical thinking predicted 56.1% of the hits on fake news detection tests. The stress levels of physicians during the coronavirus pandemic were clinically significant. The efficacy of fake news detection increases by 30.7% if the individual was a physician. Study outcomes indicate that the use of critical thinking and skeptical attitudes reduce stress levels and allow better detection of fake news. The importance of how to promote critical and skeptical attitudes in the field of medicine is discussed.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3447548.3467153" target="_blank"> Multimodal Emergent Fake News Detection via Meta Neural Process Networks<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85114172969</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Wang Y., Wang H., Gao J., Ma F., Jha K.</b></td></tr><tr><td colspan="3">Organisations: <b>Purdue University, Pennsylvania State University, University of Virginia</b></td></tr><tr><td colspan="3">Fake news travels at unprecedented speeds, reaches global audiences and puts users and communities at great risk via social media platforms. Deep learning based models show good performance when trained on large amounts of labeled data on events of interest, whereas the performance of models tends to degrade on other events due to domain shift. Therefore, significant challenges are posed for existing detection approaches to detect fake news on emergent events, where large-scale labeled datasets are difficult to obtain. Moreover, adding the knowledge from newly emergent events requires to build a new model from scratch or continue to fine-tune the model, which can be challenging, expensive, and unrealistic for real-world settings. In order to address those challenges, we propose an end-to-end fake news detection framework named MetaFEND, which is able to learn quickly to detect fake news on emergent events with a few verified posts. Specifically, the proposed model integrates meta-learning and neural process methods together to enjoy the benefits of these approaches. In particular, a label embedding module and a hard attention mechanism are proposed to enhance the effectiveness by handling categorical information and trimming irrelevant posts. Extensive experiments are conducted on multimedia datasets collected from Twitter and Weibo. The experimental results show our proposed MetaFEND model can detect fake news on never-seen events effectively and outperform the state-of-the-art methods.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.18178/wcse.2021.02.010" target="_blank"> Comparative study of fake news detection using machine learning and neural network approaches<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85114210336</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Hlaing M.M.M., Kham N.S.M.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Computer Studies</b></td></tr><tr><td colspan="3">In today’s era, fake news related to politic, finance, reputation, health and education gets create and spread like wild fire within the people as the improvement of using social media. Spreading of misinformation is a cause of great concern for human society. Detecting fake news on social media becomes a challenging problem which turns out to be very difficult to manually analyze because more and more online news is increasing on social network. Although a lot of fake news detection researches have shown some significant results and improvements by using different classification algorithms and feature extraction methods, it still has some gaps to meet the important necessities in classifying news. To address this problem, this paper investigates a fake news detection model using machine learning and neural network approaches with frequency-based and word-embedding feature extraction methods. The system performs the experiments upon “ISOT” fake news benchmark dataset. The experimental results show that exploitation of Long Short Term Memory (LSTM) with Glove feature vector achieves better classified results than Feed Forward Neural Network (FFNN), Naïve Bayes (NB) and Support Vector Machine (SVM) in classifying news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/CBMI50038.2021.9461898" target="_blank"> Multimodal Detection of Information Disorder from Social Media<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85114272760</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Armin K., Djordje S., Matthias Z.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Applied Sciences</b></td></tr><tr><td colspan="3">Social media is accompanied by an increasing pro-portion of content that provides fake information or misleading content, known as information disorder. In this paper, we study the problem of multimodal fake news detection on a large-scale multimodal dataset. We propose a multimodal network architecture that enables different levels and types of information fusion. In addition to the textual and visual content of a posting, we further leverage secondary information, i.e. user comments and metadata. We fuse information at multiple levels to account for the specific intrinsic structure of the modalities. Our results show that multimodal analysis is highly effective for the task and all modalities contribute positively when fused properly.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/WIIAT50758.2020.00016" target="_blank"> EnFVe: An ensemble fact verification pipeline<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85114401763</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Kurian J.J., Menezes D.Z.R., Ronanki A., Sharma G., Prasad S.K., Chouhan A., Prabhune A.</b></td></tr><tr><td colspan="3">Organisations: <b>SRH University</b></td></tr><tr><td colspan="3">Recent years have seen exponential growth in the volume of data generated. An undesirable consequence of this rapid expansion is the alarming rise of misinformation that is spreading throughout social networks and publishing platforms. Fact verification is the act of verifying the correctness of a particular statement. Manual fact-checkers find it increasingly difficult to keep up with the rapid proliferation of fake news in the information ecosystem. Fact verification pipelines aim at assisting the fact-checkers. These pipelines involve retrieving potentially relevant documents for a given claim, checking the reliability of the document media sources, evaluating the significance of each document, and verifying the correctness of given claims. However, there are a few limitations to these pipelines. The first limitation is that they treat fact verification as a stance detection or textual entailment task and places less emphasis on pure reasoning as the basis of fact verification. The second limitation is the robustness of the models. The fact verification models do not perform well on real-world data due to the text constructed using a myriad of complex ways. The reason for low accuracy is due to the evaluation and training of models on synthetic data that does not resemble the real-world data. In this paper, we present EnFVe, an end-to-end pipeline that integrates various components of fact verification. EnFVe pipeline improves upon the existing pipelines by integrating: (1) a Data Acquisition module that routinely scrapes data for constructing and updating the ground truth, (2) Preprocessing modules such as Coreference Resolution and Sentence Simplification that improves the robustness of the verification, (3) a Continuous Retrieval Engine module that captures the semantic context of the text, and (4) an Ensemble module that consists of various state-of-the-art fact verification models equipped with hyperparameter optimization. EnFVe achieves an accuracy of (dev/test) 79.26%/73.28%, which is better as compared to the state-of-the-art fact verification pipelines.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/WIIAT50758.2020.00063" target="_blank"> Fake news classification and topic modeling in brazilian portuguese<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85114409383</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Paixao M., Lima R., Espinasse B.</b></td></tr><tr><td colspan="3">Organisations: <b>Universidade Federal Rural de Pernambuco, Aix-Marseille Université</b></td></tr><tr><td colspan="3">All over the world, people receive daily news on many subjects through web-based information sharing platforms such as social networks. However, some of such news are false (fake) with the potential to deceive them. Thus, the automatic detection of false news is a major issue and is gaining careful attention from the scientific community. In this paper, we present experimental analysis using both supervised and unsupervised learning on the Fake.Br corpus, a fake news dataset in Brazilian Portuguese. We propose a classification method for fake news detection based on distinct types of features, and deep learning supervised algorithms. Our best classification model achieved F1 scores up to 96% and was compared with other non-deep learning classifiers. Furthermore, we provide a complementary analysis of the same dataset by performing topic modeling based on both uni-grams and bi-grams.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ISSC52156.2021.9467842" target="_blank"> Fake News Detection on Reddit Utilising CountVectorizer and Term Frequency-Inverse Document Frequency with Logistic Regression, MultinominalNB and Support Vector Machine<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85114422700</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Patel A., Meehan K.</b></td></tr><tr><td colspan="3">Organisations: <b>Letterkenny Institute of Technology</b></td></tr><tr><td colspan="3">The distribution of misleading information or fake news has become a problem for society in recent times. In the world of social media, where anyone can share their opinions, beliefs and make it sound like these are fact, fake news becomes a threat to the reputation of companies and to people. In 2016, the USA Presidential elections gathered more attention from the generation of fake news articles, leading to a huge number of researchers and scientists to explore this Natural Language Processing research area with a sense of urgency and keen interest. However, investigation regarding what people are consuming from social media is in early stages and efforts are in progress to explore how people can separate disinformation from truthful content. The primary challenge in fake news detection is determining how to detect it. Supervised learning methods help us to detect these stories using labelled data to determine if text is real or fake. This research aims to develop and compare supervised learning models using Logistic Regression, MultinominalNB, and Support Vector Machine with CountVectorizer and Term Frequency -Inverse Document Frequency methods on Reddit data. The research concludes that the CountVectorizer and MultinominalNB model achieved highest accuracy on the Reddit dataset.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/WIIAT50758.2020.00129" target="_blank"> Credibility assessment of user generated health information of the bengali language in microblogging sites employing NLP techniques<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85114430154</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Benazir A., Sharmin S.</b></td></tr><tr><td colspan="3">Organisations: <b>Bangladesh University of Engineering and Technology</b></td></tr><tr><td colspan="3">The use of the internet, particularly social networking platforms have been pandemic in recent years for searching, publishing and engaging about health related information, thus making way for the spread of misleading, superfluous or fake health news. Social networks have a powerful influence on individuals in making health decisions. Fake health news spread like a virus because clickbaity content is easier to digest rather than consuming dense scientific, observational material. Bangladesh has also been impacted by such fabricated, sensationalized, evidenceless health news, written in Bangla language on social networks. Although there has been numerous work on tackling fake health news in the English language, to our knowledge, no prior work has been done related to online health information analysis and their authenticity in Bangladesh, making our work a first of its kind. We created a novel dataset of Bangla health news, collected from Twitter. Taking textual features into account, the data was fed to a fake news detection system, which employed state of the art machine learning classifiers and neural network models to predict a label in a fixed category, thus achieving a maximum accuracy of 91% using CNN with fasttext embeddings.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/HORA52670.2021.9461333" target="_blank"> Analysis of the KNN Classifier Distance Metrics for Bulgarian Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85114464585</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Mladenova T., Valova I.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Ruse</b></td></tr><tr><td colspan="3">The problem with fake news and click-bait headlines is not new. Despite that this kind of news has existed for many years now, it was just a few years ago that the focus of the scientific community turned to them. Even though there is quite a lot of research on the topic of detecting fake news in general, there is a limited number of studies on fake news in Cyrillic. This paper focuses on the classification of fake news and click-bait headlines from Bulgarian Facebook Pages. The KNN machine-learning algorithm is chosen and four different distance metrics are tested and analyzed.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.ipm.2021.102723" target="_blank"> Deep contextualized text representation and learning for fake news detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85114515329</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Samadi M., Mousavian M., Momtazi S.</b></td></tr><tr><td colspan="3">Organisations: <b>Amirkabir University of Technology</b></td></tr><tr><td colspan="3">In recent years, due to the widespread use of social media and broadcasting agencies around the world, people are extremely exposed to being affected by false information and fake news, all of which have negative impacts on both collective thoughts and governments’ policies. In recent years, the great success of pre-trained models for embedding contextual information from texts motivates researchers to utilize these embeddings in different natural language processing tasks. However, in a complex task like fake news detection, it is not determined which contextualized embedding can assist the classifier with more valuable features. Due to the lack of a comparative study about utilizing different contextualized pre-trained models besides distinct neural classifiers, we aim to dive into a comparative study about using different classifiers and embedding models. In this paper, we propose three classifiers with different pre-trained models for embedding input news articles. We connect Single-Layer Perceptron (SLP), Multi-Layer Perceptron (MLP), and Convolutional Neural Network (CNN) after the embedding layer which consists of novel pre-trained models such as BERT, RoBERTa, GPT2, and Funnel Transformer in order to benefit from deep contextualized representation provided by those models as well as deep neural classifications. We evaluate our proposed models on three well-known fake news datasets: LIAR (Wang, 2017), ISOT (Ahmed et al., 2017), and COVID-19 Patwa et al. (2020). The results on these three datasets show the superiority of our proposed models for fake news detection compared to the state-of-the-art models. The results show 7% and 0.1% improvements in classification accuracy compared to the proposed model by Goldani et al. (2021) on LIAR and ISOT, respectively. We also achieved 1% improvement compared to the proposed model by Shifath et al. (2021) on the COVID-19 dataset.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.24138/jcomss-2021-0038" target="_blank"> Advances in clickbait and fake news detection using new language-independent strategies<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85114742184</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Coste C.I., Bufnea D.</b></td></tr><tr><td colspan="3">Organisations: <b>Babes-Bolyai University</b></td></tr><tr><td colspan="3">Online publishers rely on different techniques to trap web visitors, clickbait being one such technique. Besides being a bad habit, clickbait is also a strong indicator for fake news spreading. Its presence in online media leads to an overall bad browsing experience for the web consumer. Recently, big players on the Internet scene, such as search engines and social networks, have turned their attention towards this negative phenomenon that is increasingly present in our everyday browsing experience. The research community has also joined in this effort, a broad band of detection techniques being developed. These techniques are usually based on intelligent classifiers, for which feature selection is of great importance. The work presented in this paper brings our own contributions to the field of clickbait detection. We present a new language-independent strategy for clickbait detection that takes into consideration only features that are general enough to be independent of any particular language. The methods presented in this paper could be applied to web content written in different languages. In addition, we present the results of a complex experiment that we performed to evaluate our proposed method and we compare our results with the most relevant results previously obtained in the field.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/CONIT51480.2021.9498436" target="_blank"> A Predominant Advent to Fake News Detection using Machine Learning Algorithm<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85114853541</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Abbad M., Kumar G., Samiullah M., Kumar N.S.</b></td></tr><tr><td colspan="3">Organisations: <b>Galgotias University</b></td></tr><tr><td colspan="3">In Today's era, everyone will have a smartphone and they use their smartphone for various daily needs. One of the most important facts is to read the news over the internet by using different social media applications. There are so many apps and websites as we see on the internet today that will be providing the news with proper authentication factors. But there is one question in everyone's minds that the news that is rolling over the internet is fake or true. Most of the news is always roll over the social media application like Facebook, Twitter, and sometimes on WhatsApp. There are two sides to using social media for news consumption. On the one side, people are attracted to social media because of its low cost, ease of access, and speed at which content is disseminated. On the other hand, it facilitates the spread of fake news, or low-quality news containing deliberately deceptive information. The mass distribution of false information has the potential to be extremely dangerous to individuals and society. As a result, spotting fake news on social media has emerged as a hot new research subject. Fake news monitoring on social media has distinct appearances and features, leaving outdated identification algorithms unreliable or obsolete. First, fake news is intentionally written to lead viewers to accept misleading facts, making it impossible and time-consuming to spot based on news content; as a result, we must have supporting data, such as using social networking interactions on social media, to help in decision-making. Second, as users' social experiences with fake news produce data that is massive, unreliable, shapeless, and noisy, misusing this auxiliary data is motivating in and of itself. We commissioned this survey to assist researchers in better understanding the difficulty of identifying fake news on social media, which is both complex and important. We will also like to discuss related research areas, open topics, and future research ideas for spotting false news on social media. It is very violated towards society to saw such fake news over the internet that is going to happen every day. Our paper will help to detect fake news with the use of python and some machine learning algorithm. It will tell the user that the news that is on the internet is fake or real by using SVM. Our model is working perfectly with good efficiency over the trained dataset.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.websem.2021.100646" target="_blank"> DTN: Deep triple network for topic specific fake news detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85115024582</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Liu J., Wang C., Li C., Li N., Deng J., Pan J.Z.</b></td></tr><tr><td colspan="3">Organisations: <b>Wuhan University, University of Aberdeen, University of Edinburgh</b></td></tr><tr><td colspan="3">Detection of fake news has spurred widespread interests in areas such as healthcare and Internet societies, in order to prevent propagating misleading information for commercial and political purposes. However, efforts to study a general framework for exploiting knowledge, for judging the trustworthiness of given news based on their content, have been limited. Indeed, the existing works rarely consider incorporating knowledge graphs (KGs), which could provide rich structured knowledge for better language understanding. In this work, we propose a deep triple network (DTN) that leverages knowledge graphs to facilitate fake news detection with triple-enhanced explanations. In the DTN, background knowledge graphs, such as open knowledge graphs and extracted graphs from news bases, are applied for both low-level and high-level feature extraction to classify the input news article and provide explanations for the classification. The performance of the proposed method is evaluated by demonstrating abundant convincing comparative experiments. Obtained results show that DTN outperforms conventional fake news detection methods from different aspects, including the provision of factual evidence supporting the decision of fake news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-16-4486-3_26" target="_blank"> A Deep Learning Based Approach for Classification of News as Real or Fake<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85115062402</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Kumari J., Kumari S., Krishna G., Choudhary R.</b></td></tr><tr><td colspan="3">Organisations: <b>Netaji Subhas Institute of Technology, Nalanda College of Engineering</b></td></tr><tr><td colspan="3">In recent past, the growth of both the printed and digital media has greatly facilitated the business and the society. On account of the reach of social media, even the smallest news or event could be spread like wildfire. Often due to this, the news gets amplified and distorted drastically resulting in generation of fake news. This fake news not only misleads the masses but also causes severe impacts in real world. The rapid increase in the area of fake news and its abrasion to judiciary, democracy and trust in the public made the development of a system for detection of fake news vital. Here, in this paper, we have dealt with the proposal of a model in order to detect fake news, by the use of deep learning algorithms to predict whether the given data is real or fake. The experiments were executed using various deep learning algorithms like Convolutional Neural Network (CNN), Long short-term memory (LSTM) and Bidirectional LSTMs (Bi-LSTM). Thereby we compared the results obtained. The model proposed here, has a great accuracy of about 99%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICASSP39728.2021.9414787" target="_blank"> SeRN: Stance extraction and reasoning network for fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85115077878</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Xie J., Liu S., Liu R., Zhang Y., Zhu Y.</b></td></tr><tr><td colspan="3">Organisations: <b>Peking University</b></td></tr><tr><td colspan="3">Fake news brings us panic and misunderstanding against the truth, especially under some unusual circumstances, such as the outbreak of COVID-19. It's crucial to detect fake news on social media early to avoid further propagation. Previous methods manually label the stances implied in post-reply pairs to aid fake news detection, which costs much time and effort. To solve this problem, a novel Stance Extraction and Reasoning Network (SERN) is proposed to extract the stances implied in post-reply pairs implicitly and integrate the stance representations for fake news detection without manually labeling stances, which saves much time and effort. Besides, the adequate utilization of multimodal content in the news is beneficial for complementing information for unimodal representation and jointly improving decision confidence. Thus, a sentence-guided visual attention mechanism is proposed in the text-image fusion module that leverages text-image content for better fake news detection. Encouraging empirical results on Fakeddit and PHEME demonstrate that our method outperforms the state-of-the-art methods.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ACCESS.2021.3112806" target="_blank"> OPCNN-FAKE: Optimized Convolutional Neural Network for Fake News Detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85115150924</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Saleh H., Alharbi A., Alsamhi S.H.</b></td></tr><tr><td colspan="3">Organisations: <b>South Valley University, Taif University, Athlone Institute of Technology, IBB University</b></td></tr><tr><td colspan="3">Recently, there is a rapid and wide increase in fake news, defined as provably incorrect information spread with the goal of fraud. The spread of this type of misinformation is a severe danger to social cohesiveness and well-being since it increases political polarisation and people's distrust of their leaders. Thus, fake news is a phenomenon that is having a significant impact on our social lives, particularly in politics. This paper proposes novel approaches based on Machine Learning (ML) and Deep Learning (DL) for the fake news detection system to address this phenomenon. The main aim of this paper is to find the optimal model that obtains high accuracy performance. Therefore, we propose an optimized Convolutional Neural Network model to detect fake news (OPCNN-FAKE). We compare the performance of the OPCNN-FAKE with Recurrent Neural Network (RNN), Long Short-Term Memory (LSTM), and The six regular ML techniques: Decision Tree (DT), logistic Regression (LR), K Nearest Neighbor (KNN), Random Forest (RF), Support Vector Machine (SVM), and Naive Bayes (NB) using four fake news benchmark datasets. Grid search and hyperopt optimization techniques have been used to optimize the parameters of ML and DL, respectively. In addition, N-gram and Term Frequency - Inverse Document Frequency (TF-IDF) have been used to extract features from the benchmark datasets for regular ML, while Glove word embedding has been used to represent features as a feature matrix for DL models. To evaluate the performance of the OPCNN-FAKE, accuracy, precision, recall, F1-measure were applied to validate the results. The results show that OPCNN-FAKE model has achieved the best performance for each dataset compared with other models. Furthermore, the OPCNN-FAKE has a higher performance of cross-validation results and testing results over the other models, which indicates that the OPCNN-FAKE for fake news detection is significantly better than the other models.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-16-2354-7_43" target="_blank"> Recent Trends of Fake News Detection: A Review<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85115167213</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Gupta A., Anjum A., Gupta S., Katarya R.</b></td></tr><tr><td colspan="3">Organisations: <b>Delhi Technological University</b></td></tr><tr><td colspan="3">In the age of the internet, the rate at which humans consume and produce information is so large that the lines between misinformation and Facts have blurred. A manual censor board is neither equipped nor capable of reviewing news on such a large scale. Humanity has been burdened with fake news. Given the seriousness of the problem, a lot of research is being carried out to understand the characteristics of fake news and thus build an automated fake news detection system. In this paper, we review, critique, and summarize the existing approaches in fake news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-85447-8_53" target="_blank"> Modeling Malicious Behaviors and Fake News Dissemination on Social Networks<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85115183859</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Yoshikawa K., Ichino M., Yoshiura H.</b></td></tr><tr><td colspan="3">Organisations: <b>The University of Electro-Communications</b></td></tr><tr><td colspan="3">As social media has become widely used, fake news has become a serious problem. A representative countermeasure is fake news detection. However, this countermeasure is not sufficient because people using social media tend to ignore facts that contradict their beliefs. To develop effective countermeasures, it is necessary to clarify the influence of fake news and the nature of its dissemination from the perspective of communication. In this paper, we propose two models explaining the dissemination of opinions about fake news: one in which the presence of the ground truth is assumed and one in which it is not assumed. In both models, an attacker disseminates fake news by imitating or hijacking target accounts. In evaluations on real-world social networks, the model in which the ground truth is assumed demonstrates that, contrary to our expectations, account imitation is a more harmful attack than account hijacking. The model in which ground truth is not assumed demonstrates that both account imitation and account hijacking are harmful attacks.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-16-2354-7_29" target="_blank"> A Technique to Detect Fake News Using Machine Learning<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85115184829</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Yadav P., Hasan M.</b></td></tr><tr><td colspan="3">Organisations: <b>Madan Mohan Malaviya University of Technology</b></td></tr><tr><td colspan="3">The impacts of data spread happen at such a quick pace on social networks and so enhanced that that distorted, mistaken data or false data gets an enormous potential to cause certifiable effects. We examine the fake news issue, and the present specialized concerns related to the need for the robustness of automated fake news detection frameworks, and also examine the opportunity that is appropriately developed. In this paper, we have proposed a systematic framework for fake news identification and gives it’s the confusion matrix with a classification report of the accuracy of their perspective model. The proposed approach with comparisons accomplishes classification accuracy 94% and 97% recall. We collect the dataset of real and fake news that is changed from document-based corpus into an event and title-based representation.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ACCESS.2021.3113877" target="_blank"> Context-Aware Deep Markov Random Fields for Fake News Detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85115189785</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Huu Do T., Berneman M., Patro J., Bekoulis G., Deligiannis N.</b></td></tr><tr><td colspan="3">Organisations: <b>Vrije Universiteit Brussel (VUB), imec</b></td></tr><tr><td colspan="3">Fake news is a serious problem, which has received considerable attention from both industry and academic communities. Over the past years, many fake news detection approaches have been introduced, and most of the existing methods rely on either news content or the social context of the news dissemination process on social media platforms. In this work, we propose a generic model that is able to take into account both the news content and the social context for the identification of fake news. Specifically, we explore different aspects of the news content by using both shallow and deep representations. The shallow representations are produced with word2vec and doc2vec models while the deep representations are generated via transformer-based models. These representations are able to jointly or separately address four individual tasks, namely bias detection, clickbait detection, sentiment analysis, and toxicity detection. In addition, we make use of graph convolutional neural networks and mean-field layers in order to exploit the underlying structural information of the news articles. That way, we are able to take into account the inherent correlation between the articles by leveraging their social context information. Experiments on widely-used benchmark datasets indicate the effectiveness of the proposed method.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-16-2877-1_25" target="_blank"> A Research on Fake News Detection Using Machine Learning Algorithm<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85115221695</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Shrivastava S., Singh R., Jain C., Kaushal S.</b></td></tr><tr><td colspan="3">Organisations: <b>Amity University Gurgaon</b></td></tr><tr><td colspan="3">Fake news may have different meaning to different individuals. For the purpose of this paper, we will go by the definition of fake news as those reports that are bogus: The story itself is created, with no relation to realities, sources or statements. In this research on fake news detection through machine learning algorithms, we are implementing two feature selection approaches toward the problem: Bag of words model and TF-IDF vectorization model and are using four classifiers namely, logistic regression classifier, naive Bayes classifier, random forest classifier and passive aggressive classifier for classification purpose. This research is being conducted on two separate datasets, among which for bag of words model along with logistic regression classifier yields average F1 Score of 92.16% and for TF-IDF vectorization, logistic regression classifier yields average F1 Score of 93.47%. Also, passive aggressive classifier works well with high volume of data along with TF-IDF as can be seen by highest increase in F1 Score.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-86475-0_4" target="_blank"> Repurpose Image Identification for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85115269872</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Lee S.J.H., Li T., Hsu W., Lee M.L.</b></td></tr><tr><td colspan="3">Organisations: <b>National University of Singapore</b></td></tr><tr><td colspan="3">The Internet has become the major channel where users gather and disseminate news and information, and has given rise to problems such as fake news and disinformation. This work tackles a class of fake news where visually similar images from past events are purported as visual evidence to exaggerate the severity of a current news event. These images have been repurposed and possess a great affinity to real news, posing a challenge to the fake news detection task. We propose a multi-stage approach that comprises an event type classifier to determine the type of news event, and an image repurpose detector which utilizes a siamese network to detect whether the news is fake and contains a repurposed image. Evaluation on real-world news datasets show that the proposed solution outperforms state-of-the-art methods and is effective in identifying fake news containing repurposed images.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Multi-source multi-class fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85115272467</td><td>Year: <b>2018</b></td></tr><tr><td colspan="3">Authors: <b>Karimi H., Roy P.C., Saba-Sadiya S., Tang J.</b></td></tr><tr><td colspan="3">Organisations: <b>Michigan State University</b></td></tr><tr><td colspan="3">Fake news spreading through media outlets poses a real threat to the trustworthiness of information and detecting fake news has attracted increasing attention in recent years. Fake news is typically written intentionally to mislead readers, which determines that fake news detection merely based on news content is tremendously challenging. Meanwhile, fake news could contain true evidence to mock true news and presents different degrees of fakeness, which further exacerbates the detection difficulty. On the other hand, the spread of fake news produces various types of data from different perspectives. These multiple sources provide rich contextual information about fake news and offer unprecedented opportunities for advanced fake news detection. In this paper, we study fake news detection with different degrees of fakeness by integrating multiple sources. In particular, we introduce approaches to combine information from multiple sources and to discriminate between different degrees of fakeness, and propose a Multi-source Multi-class Fake news Detection framework MMFD, which combines automated feature extraction, multi-source fusion and automated degrees of fakeness detection into a coherent and interpretable model. Experimental results on the real-world data demonstrate the effectiveness of the proposed framework and extensive experiments are further conducted to understand the working of the proposed framework.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.26342/2021-67-19" target="_blank"> Overview of FakeDeS at IberLEF 2021: Fake News Detection in Spanish Shared Task<a></b></td></tr><tr><td>Type: Review</td><td>ID: S_2-s2.0-85115287696</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Gomez-Adorno H., Capetillo C.P., Posadas-Duran J.P., Enguix G.B.</b></td></tr><tr><td colspan="3">Organisations: <b>Universidad Nacional Autónoma de México, Universidad Nacional Autónoma de México, Escuela Superior de Ingeniería Mecánica y Eléctrica</b></td></tr><tr><td colspan="3">This paper presents the overview of FakeDeS 2021, the second edition of this lab under the IberLEF conference. The FakeDeS shared task aims to explore different methodologies and strategies related to fake news detection in Spanish. This year edition brings two main challenges: thematic and language variation. For this purpose, we introduce a new testing corpus containing news related to COVID-19 and news from other Ibero-American countries.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Citius at fakedes 2021: A hybrid strategy for fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85115292378</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Gamallo P.</b></td></tr><tr><td colspan="3">Organisations: <b>Universidade de Santiago de Compostela</b></td></tr><tr><td colspan="3">This article describes several BERT-based supervised classi-fication strategies submitted to Fake News Detection in Spanish Shared Task, where the sources of data are news annotated as fake or real. In our experiments, the systems were trained exclusively with the official datasets provided by the organizers of the shared task, without making use of any other source of information. The best system turned out to be a hybrid strategy that combines sentence similarity with some linguistic heuristics.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Zk15120170770 at fakedes 2021: Fake news detection based on pre-training model<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85115309595</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Zhao K., Zhou S., Li W.</b></td></tr><tr><td colspan="3">Organisations: <b>Yunnan University</b></td></tr><tr><td colspan="3">With the rapid development of Internet technology, the net- work makes the transmission of information no longer limited due to the long distance. All kinds of information can be transmitted conveniently and quickly on the Internet. People can view and send all kinds of in- formation around the world with only a mobile network device. A lot of things happen in the world every day, so this information contains a lot of news information, and people can understand what is happening in the world through news information. However, there is much fake news information mixed in this news information. This fake news will interfere with our cognition and judgment. Therefore, we need more attention to distinguish the authenticity of this news item. This also poses certain challenges to our work tasks. In this paper, we describe the method used for the Fake News Detection in Spanish in IberLEF 2021. We fine-tuned the XLM-Roberta pre-training model based on the data sets provided by the host, Spanish, and obtained good results. The F1 score of our model in Spanish tasks reached 0.7053 and ranking seventh.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Forcenlp at fakedes 2021: Analysis of text features applied to fake news detection in spanish<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85115311457</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Reyes-Magana J., Vega L.E.A.</b></td></tr><tr><td colspan="3">Organisations: <b>Universidad Nacional Autonoma de Mexico, Universidad Autonoma de Yucatan</b></td></tr><tr><td colspan="3">This paper presents our approach to the Task \Fake News Detection", which aims to decide if a news item is fake or real by ana- lyzing its textual representation. The corpus consists of news compiled mainly from Mexican web sources: Established newspaper websites, me- dia companies websites, special websites dedicated to validating fake news, and websites designated by different journalists as sites that reg- ularly publish fake news. Our approach is based mostly on different types of n-grams. For the task we use the classifiers: Logistic Regres- sion, Support Vector Machines and Multinomial Naive-Bayes. Our ap- proach achieved an average F1-score with respect to the other teams in the competition.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Tsia team at fakedes 2021: Fake news detection in spanish using multi-model ensemble learning<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85115313625</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Guan Z.</b></td></tr><tr><td colspan="3">Organisations: <b>Yunnan University</b></td></tr><tr><td colspan="3">Fake news has become a hotly debated topic in journalism. This paper describes our contribution of the TSIA team in the Fake News Detection in Spanish Shared Task of IberLEF 2021. We regard this task as a binary classification task. We mainly propose three model architec- tures based on the pre-trained model BETO and XLM-RoBERTa-Large. We first fine-tuned the Spanish pre-trained model BETO and then we chose the multi-language pre-trained model XLM-RoBERTa-Large to re- place BETO and fine-tune it, including the addition of CNN for feature extraction. Finally, our system achieves best F1-score of 0.6860 by hard voting, which ranks 10th out of 21 teams on the final leaderboard. Our score is only 0.0806 worse than the best score on the leaderboard.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Lcad - Ufes at fakedes 2021: Fake news detection using named entity recognition and part-of-speech sequences<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85115317068</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Spalenza M.A., De Oliveira E., Lima P.M.V., Lusquino-Filho L., Franca F.M.G.</b></td></tr><tr><td colspan="3">Organisations: <b>Federal University of Espirito Santo (UFES), Tercio Pacitti Institute, Federal University of Rio de Janeiro (UFRJ)</b></td></tr><tr><td colspan="3">News is fundamental to share interesting and relevant facts for public knowledge. However, unreliable sources produce fake and biased information, releasing content without proper fact-checking. The biased content attends to a massive disclosure on the internet and sociopolitical tendencies. Consequently, the identification of inaccurate news minimizes the damage to public entities. Therefore, against the misinformation, the fact-checking agencies investigate the trending news. Regarding the investigation, manual checking is slow and expensive. To filter these demands, we propose an automated method using linguistic components, supporting fake content identification. Our approach applies Machine Learning using POSTag+NER sequences. In the interdomain analysis, our method achieves 71% in the F1 measure for fake news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Yeti at fakedes 2021: Fake news detection in spanish with albert<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85115318261</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Luo H.</b></td></tr><tr><td colspan="3">Organisations: <b>Yunnan University</b></td></tr><tr><td colspan="3">This paper explains our participation in the IberLEF2021 shared task 7: Fake News Detection Task. The goal of this task is to analyze a corpus of Spanish News and determine the authenticity of its content. The threat of false information is designed to negatively affect people, by disseminating information that does not match the facts, so that users can accept biased or erroneous information. Therefore, fake news becomes particularly important. For this task, this paper mainly discusses different methods of fake news detection. We chose the ALBERT Model. On this basis we made a simple modification to the upper structure of the ALBERT model. In the end, our system got 63.16 % F1 score in the task. Although our proposal did not reach the best, it provides a new idea for fake news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Bribones tras la esmeralda perdida@fakedes 2021: Fake news detection based on random forests, k-nearest neighbors, and n-grams for a spanish corpora<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85115321459</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Barrie V.L., Perez N., Lara V.M., Neme A.</b></td></tr><tr><td colspan="3">Organisations: <b>Universidad Nacional Autonoma de Mexico, Universidad Autonoma de Yucatan, Universidad Nacional Autonoma de Mexico</b></td></tr><tr><td colspan="3">Fake news constitutes a social problem that affects demo- cratic societies by inuencing and manipulating public opinion. The con- cept of fake news covers a wide range of news that somehow resembles the truth. For example, they might contain explicit false assertions, con- tain some aspects of the truth, or even present the truth in a deformed fashion to disqualify a political figure or a specific group. The obnoxious impact of fake news makes it imperative to develop tools to help pro- fessional journalists, on the one hand, and the public, on the other, to detect news that is fake. In this contribution, we describe a methodology with the aim to tell apart fake from true news in a data set of several hundreds of manually curated journalistic pieces. The proposal is based on a bag-of-words approach and relies on shallow classifiers. We intended to validate the hypothesis that true and fake news can be told apart with simple assumptions. However, as discussed, the hypothesis was rejected, as it was not possible to classify the texts in a subsequent test stage successfully. The corpora used for the classification task is in Spanish, and it was presented as an open challenge in CodaLab.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Gduf_dm at fakedes 2021: Spanish fake news detection with bert and sample memory<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85115324889</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Huang X., Xiong J., Jiang S.</b></td></tr><tr><td colspan="3">Organisations: <b>Guangdong University of Foreign Studies</b></td></tr><tr><td colspan="3">Fake news widely spread on the Internet has had a negative impact on society. This article reports the solution of Spanish fake news detection purposed by our team GDUFS_DM in IberLEF 2021 shared task. Our purpose is to use BERT and Sample Memory with an attention mechanism to detect Spanish fake news. To capture richer semantic information in long news texts, we used BERT to encode the news headline and the news beginning and end part to keep more information instead of using a simple truncation strategy. In addition, we also use a matrix parameter initialized by sample representation (we call it Sample Memory), combine with the attention mechanism, our model can capture the relationship information between samples which strengthens the model's robustness in the inference stage. Our submission result achieved the first place on the leaderboard, which fully reflects the advantages of our model.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Haha at fakedes 2021: A fake news detection method based on tf-idf and ensemble machine learning<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85115337055</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Li K.</b></td></tr><tr><td colspan="3">Organisations: <b>Yunnan University</b></td></tr><tr><td colspan="3">This paper describes our participation in the FakeDeS [5] Task at Iberlef 2021: Fake News Detection in Spanish. Base on this task, we propose the classic TF-IDF feature extraction technology and Stack- ing ensemble learning method base on weak classifiers. It not only an- alyzes the content of the news, but also combines effective information such as publishers and topics to improve the performance of our model. We used five machine learning models, and achieved very competitive results on both the validation set and the test set, and got the second place in the final evaluation phase.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3462203.3475898" target="_blank"> Health misinformation detection in web content: A structural-, content-based, and context-aware approach based on Web2Vec<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85115381075</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Upadhyay R., Pasi G., Viviani M.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Milano-Bicocca</b></td></tr><tr><td colspan="3">In recent years, we have witnessed the proliferation of large amounts of online content generated directly by users with virtually no form of external control, leading to the possible spread of misinformation. The search for effective solutions to this problem is still ongoing, and covers different areas of application, from opinion spam to fake news detection. A more recently investigated scenario, despite the serious risks that incurring disinformation could entail, is that of the online dissemination of health information. Early approaches in this area focused primarily on user-based studies applied to Web page content. More recently, automated approaches have been developed for both Web pages and social media content, particularly with the advent of the COVID-19 pandemic. These approaches are primarily based on handcrafted features extracted from online content in association with Machine Learning. In this scenario, we focus on Web page content, where there is still room for research to study structural-, content- and context-based features to assess the credibility of Web pages. Therefore, this work aims to study the effectiveness of such features in association with a deep learning model, starting from an embedded representation of Web pages that has been recently proposed in the context of phishing Web page detection, i.e., Web2Vec.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-86230-5_62" target="_blank"> Automated Fake News Detection Using Computational Forensic Linguistics<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85115448984</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Moura R., Lopes Cardoso H., Sousa-Silva R.</b></td></tr><tr><td colspan="3">Organisations: <b>Universidade do Porto</b></td></tr><tr><td colspan="3">Fake news is news-like content that has been produced without following journalism principles. Fake news try to mimic the look and feel of real news to intentionally disinform the reader. This phenomenon can have a strong influence on society, thus being potentially a severe problem. To address this phenomenon, systems to detect fake news have been developed, but most of them build upon fact-checking approaches, which are unfit to detect misinformation when a news piece, rather than completely false, is distorted, exaggerated, or even decontextualized. We aim to detect Portuguese fake news by following a forensic linguistics approach. Contrary to previous approaches, we build upon methods of linguistic and stylistic analysis that have been tried and tested in forensic linguists. After collecting corpora from multiple fake news outlets and from a genuine news source, we formulate the task as a text classification problem and demonstrate the effectiveness of the proposed features when training different classifiers for telling fake from genuine news. Furthermore, we perform an ablation study with subsets of features and find that the proposed feature sets are complementary. The highest results reported are very promising, achieving 97% of accuracy and a macro F1-score of 91%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-86979-3_37" target="_blank"> Deep Fake Recognition in Tweets Using Text Augmentation, Word Embeddings and Deep Learning<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85115669366</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Tesfagergish S.G., Damasevicius R., Kapociute-Dzikiene J.</b></td></tr><tr><td colspan="3">Organisations: <b>Kaunas University of Technology, Vytautas Magnus University</b></td></tr><tr><td colspan="3">Spreading of automatically generated clickbaits, fake news, and fake reviews undermines the veracity of the internet as a credible source of information. We investigate the problem of recognizing automatically generated short texts by exploring different Deep Learning models. To improve the classification results, we use text augmentation techniques and classifier hyperparameter optimization. For word embedding and vectorization we use Glove and RoBERTa. We compare the performance of dense neural network, convolutional neural network, gated recurrent network, and hierarchical attention network. The experiments on the TweepFake dataset achieved an 89.7% accuracy.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-16-2937-2_9" target="_blank"> Fake News Detection: Experiments and Approaches Beyond Linguistic Features<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85115675065</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Bhatt S., Goenka N., Kalra S., Sharma Y.</b></td></tr><tr><td colspan="3">Organisations: <b>Birla Institute of Technology and Science</b></td></tr><tr><td colspan="3">Easier access to the Internet and social media has made disseminating information through online sources very easy. Sources like Facebook, Twitter, online news sites and blogs of self-proclaimed journalists have become significant players in providing news content. The sheer amount of information and the speed at which it is generated online makes it beyond the scope of human verification. There is, hence, a pressing need to develop technologies that can assist humans with automatic fact-checking and reliable identification of fake news. This paper summarises the multiple approaches that were undertaken and the experiments that were carried out for the task. Credibility information and metadata associated with the news article have been used for improved results. The experiments also show how modelling justification or evidence can lead to improved results. Additionally, the use of visual features in addition to linguistic features is demonstrated. A detailed comparison of the results showing that our models perform significantly well when compared to robust baselines, and state-of-the-art models are presented.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICoICT52021.2021.9527469" target="_blank"> Fake News Detection with Hybrid CNN-LSTM<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85115686901</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Tan K.L., Poo Lee C., Lim K.M.</b></td></tr><tr><td colspan="3">Organisations: <b>Multimedia University</b></td></tr><tr><td colspan="3">In the past decades, information and communication technology has developed rapidly. Therefore, social media has become the main platform for people to share and spread information to others. Although social media has brought a lot of convenience to people, fake news also spread more rapidly than before. This situation has brought a destructive impact to people. In view of this, we propose a hybrid model of Convolutional Neural Network and Long Short-Term Memory for fake news detection. The Convolutional Neural Network model plays the role of extracting representative high-level sequence features whereas the Long Short-Term Memory model encodes the long-term dependencies of the sequence features. Two regularization techniques are applied to reduce the model complexity and to mitigate the overfitting problem. The empirical results demonstrate that the proposed Convolutional Neural Network-Long Short-Term Memory model yields the highest F1-score on four fake news datasets.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ACCESS.2021.3114093" target="_blank"> Multi-Level Multi-Modal Cross-Attention Network for Fake News Detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85115687139</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Ying L., Yu H., Wang J., Ji Y., Qian S.</b></td></tr><tr><td colspan="3">Organisations: <b>Nanjing University of Information Science and Technology, Hefei University of Technology, China University of Petroleum, Chinese Academy of Sciences</b></td></tr><tr><td colspan="3">With the development of the Mobile Internet, more and more users publish multi-modal posts on social media platforms. Fake news detection has become an increasingly challenging task. Although there are many works using deep schemes to extract and combine textual and visual representation in the post, most existing methods do not sufficiently utilize the complementary multi-modal information containing semantic concepts and entities to complement and enhance each modality. Moreover, these methods do not model and incorporate the rich multi-level semantics of text information to improve fake news detection tasks. In this paper, we propose a novel end-to-end Multi-level Multi-modal Cross-attention Network (MMCN) which exploits the multi-level semantics of textual content and jointly integrates the relationships of duplicate and different modalities (textual and visual modality) of social multimedia posts in a unified framework. Pre-trained BERT and ResNet models are employed to generate high-quality representations for text words and image regions respectively. A multi-modal cross-attention network is then designed to fuse the feature embeddings of the text words and image regions by simultaneously considering data relationships in duplicate and different modalities. Specially, due to different layers of the transformer architecture have different feature representations, we employ a multi-level encoding network to capture the rich multi-level semantics to enhance the presentations of posts. Extensive experiments on the two public datasets (WEIBO and PHEME) demonstrate that compared with the state-of-the-art models, the proposed MMCN has an advantageous performance.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICC42927.2021.9500467" target="_blank"> Evaluating Fake News Detection Models from Explainable Machine Learning Perspectives<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85115697705</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Alharbi R., Vu M.N., Thai M.T.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Florida</b></td></tr><tr><td colspan="3">Many research efforts recently have aimed at understanding the phenomenon of fake news, including recognizing their common features and patterns, leading to several fake news detection models based on machine learning. Yet, the real distinct strength of those models remains uncertain: some perform well only with particular data, but others are more general. Most of the models classified the fake news as a black-box without giving any explanations to users. In this work, therefore, we conduct an exploratory investigation that evaluates and interprets fake new detection models, including looking into which important features that contribute to the models' prediction from the explainable machine learning perspective. This give us some insights on how the detection models work and their trustworthiness.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ACCESS.2021.3113981" target="_blank"> Fake News Detection via Multi-Modal Topic Memory Network<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85115715671</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Ying L., Yu H., Wang J., Ji Y., Qian S.</b></td></tr><tr><td colspan="3">Organisations: <b>Nanjing University of Information Science and Technology, Hefei University of Technology, China University of Petroleum, Chinese Academy of Sciences</b></td></tr><tr><td colspan="3">With the development of the Mobile Internet, more and more people create and release multi-modal posts on social media platforms. Fake news detection has become an increasingly challenging task. Although many current works focus on constructing models extracting abstract features from the content of each post, they neglect the intrinsic semantic architecture such as latent topics, etc. These models only learn patterns in content coupled with certain specific latent topics on the training set to distinguish real and fake posts, which will suffer generalization and discriminating ability decline, especially when posts are associated with rare or new topics. Moreover, most existing works using deep schemes to extract and integrate textual and visual representation in post have not effectively modeled and sufficiently utilized the complementary and noisy multi-modal information containing semantic concepts and entities to complement and enhance each modal. In this paper, to deal with the above problems, we propose a novel end-to-end Multi-modal Topic Memory Network (MTMN), which obtains and combines post representations shared across latent topics together with global features of latent topics while modeling intra-modality and inter-modality information in a unified framework. (1) To tackle real scenarios where newly arriving posts with different topic distribution from the training data, our method incorporates a topic memory module to explicitly characterize final representation as post feature shared across topics and global features of latent topics. These two kinds of features are jointly learned and then combined to generate robust representation. (2) To effectively integrate multi-modality information in posts, we propose a novel blended attention module for multi-modal fusion, which can simultaneously exploit the intra-modality relation within each modal and the inter-modality relation between text words and image regions to complement and enhance each other for high-quality representation. Extensive experiments on two public real-world datasets demonstrate the superior performance of MTMN compared with other state-of-the-art algorithms.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICoICT52021.2021.9527500" target="_blank"> FN-Net: A Deep Convolutional Neural Network for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85115717929</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Tan K.L., Poo Lee C., Lim K.M.</b></td></tr><tr><td colspan="3">Organisations: <b>Multimedia University</b></td></tr><tr><td colspan="3">Information and communication technology has evolved rapidly over the past decades, with a substantial development being the emergence of social media. It is the new norm that people share their information instantly and massively through social media platforms. The downside of this is that fake news also spread more rapidly and diffuse deeper than before. This has caused a devastating impact on people who are misled by fake news. In the interest of mitigating this problem, fake news detection is crucial to help people differentiate the authenticity of the news. In this research, an enhanced convolutional neural network (CNN) model, referred to as Fake News Net (FN-Net) is devised for fake news detection. The FN-Net consists of more pairs of convolution and max pooling layers to better encode the high-level features at different granularities. Besides that, two regularization techniques are incorporated into the FN-Net to address the overfitting problem. The gradient descent process of FN-Net is also accelerated by the Adam optimizer. The empirical studies on four datasets demonstrate that FN-Net outshines the original CNN model.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICSCC51209.2021.9528205" target="_blank"> Analysing and Identifying Crucial Evidences for the prediction of False Information proliferated during COVID-19 Outbreak: A Case Study<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85115725995</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Varshney D., Vishwakarma D.K.</b></td></tr><tr><td colspan="3">Organisations: <b>Delhi Technological University</b></td></tr><tr><td colspan="3">In the current scenario social media platforms are one the efficient way to share opinions and thoughts of an individual. User can freely share their thoughts on an event/ situation. This can be a curse for the society if social media platform is utilized with some bad intention to spread false information and create chaos/ confusion among public which greatly degrades user experience. In the current pandemic many people have their eye on any news article related to corona cure. Malicious users take this as an opportunity to spread fake news in order to create confusion among public or some monetary benefits, the detection of which is of paramount importance. The proposed technique is leverages to learn crucial evidences based on Context Knowledge, Distance Metric and Word Resemblance with respect to news article headline and its content concerning top 10 google search results related to the claim, where considering COVID-19 as one of the special case studies from the application perspective. This paper proposed a novel scheme for the prediction of false information and generated a covidfakenews dataset that further be utilized for the analysis and evaluation of our model. The results reveals that the proposed intelligent strategy gives promising experimental results and quite effective in predicting False information.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-86340-1_30" target="_blank"> Continual Learning for Fake News Detection from Social Media<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85115732558</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Han Y., Karunasekera S., Leckie C.</b></td></tr><tr><td colspan="3">Organisations: <b>The University of Melbourne</b></td></tr><tr><td colspan="3">The prevalence of fake news over social media has a profound impact on justice, public trust and society as a whole. Although significant effort has been applied to mitigate its negative impact, our study shows that existing fake news detection algorithms may perform poorly on new data. In other words, the performance of a model trained on one dataset degrades on another and potentially vastly different dataset. Considering that in practice a deployed fake news detection system is likely to observe unseen data, it is crucial to solve this problem without re-training the model on the entire data from scratch, which would become prohibitively expensive as the data volumes grow. An intuitive solution is to further train the model on the new dataset, but our results show that this direct incremental training approach does not work, as the model only performs well on the latest dataset it is trained on, which is similar to the problem of catastrophic forgetting in the field of continual learning. Instead, in this work, (1) we first demonstrate that with only minor computational overhead, balanced performance can be restored on both existing and new datasets, by utilising Gradient Episodic Memory (GEM) and Elastic Weight Consolidation (EWC)—two techniques from continual learning. (2) We improve the algorithm of GEM so that the drop in model performance on the previous task can be further minimised. Specifically, we investigate different techniques to optimise the sampling process for GEM, as an improvement over random selection as originally designed. (3) We conduct extensive experiments on two datasets with thousands of labelled news items to verify our results.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/B978-0-12-818699-2.00004-4" target="_blank"> A computationally intelligent agent for detecting fake news using generative adversarial networks<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85115768534</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Hiriyannaiah S., Srinivas A.M.D., Shetty G.K., Siddesh G.M., Srinivasa K.G.</b></td></tr><tr><td colspan="3">Organisations: <b>Ramaiah Institute of Technology, NITTTR</b></td></tr><tr><td colspan="3">The explosion of smartphones has led to major changes in the perception of news, including the use of social media to propagate fake news and system-generated content without proper validation. The existing solutions to this problem employ the use of technologies like machine learning. The identification of unverified articles is a classification problem where, given a document, the system classifies it as “fake” or “valid.” This process involves the collection of large amounts of text corpus of both valid and fake news articles. The issue with these existing systems is the validity of the data aggregated from different sources. This can lead to the problem of human bias in labeling the articles collected. As an initial step to reduce this bias, this project proposes a fake news detection framework, which uses a generative modeling technique. In this technique, a generator-discriminator (G-D) setup is employed. The G-D model is extended from the SeqGAN model. The generator generates new data instances, while the discriminator evaluates them for authenticity. When the models train competitively, the generator becomes better at creating synthetic samples and the discriminator gets better at identifying the synthetic samples. Thus, a data set is synthesized by merging the real articles with the articles generated by the generator, which is trained using the G-D setup. This data set is then used to train the agent (classifier) to identify the articles as “fake” or “valid.”.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/COMPSAC51774.2021.00224" target="_blank"> Metamorphic testing of fake news detection software<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85115834947</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Ma Y., Towey D., Chen T.Y., Zhou Z.Q.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Nottingham, Swinburne University of Technology, University of Wollongong</b></td></tr><tr><td colspan="3">Since the popularization of social media, news has entered our lives digitally. While news is spreading broader and faster, fake news is becoming an increasingly popular topic. Fake news detection is therefore important in both social media and research areas. With artificial intelligence technology, software engineers have developed a lot of fake news detection systems. One of the biggest challenges for such systems is that they may face the oracle problem, which means that there may not be a way, or it may take too long time, to confirm the correctness of a specific output. Metamorphic Testing has been applied successfully to alleviate the oracle problem in many different areas, including in artificial intelligence. In this paper, we propose several metamorphic relations for fake news detection and report on experiments using metamorphic testing on fake news detection applications.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Automatic Fake News Detection: Are Models Learning to Reason?<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85115868195</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Hansen C., Hansen C., Lima L.C.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Copenhagen</b></td></tr><tr><td colspan="3">Most fact checking models for automatic fake news detection are based on reasoning: Given a claim with associated evidence, the models aim to estimate the claim veracity based on the supporting or refuting content within the evidence. When these models perform well, it is generally assumed to be due to the models having learned to reason over the evidence with regards to the claim. In this paper, we investigate this assumption of reasoning, by exploring the relationship and importance of both claim and evidence. Surprisingly, we find on political fact checking datasets that most often the highest effectiveness is obtained by utilizing only the evidence, as the impact of including the claim is either negligible or harmful to the effectiveness. This highlights an important problem in what constitutes evidence in existing approaches for automatic fake news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-85251-1_19" target="_blank"> Overview of the CLEF–2021 CheckThat! Lab on Detecting Check-Worthy Claims, Previously Fact-Checked Claims, and Fake News<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85115877178</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Nakov P., Shaar S., Alam F., Da San Martino G., Elsayed T., Haouari F., Hasanain M., Mansour W., Ali Z.S., Barron-Cedeno A., Miguez R., Babulkov N., Nikolov A., Shahi G.K., Struss J.M., Mandl T., Kutlu M., Kartal Y.S., Hamdan B.</b></td></tr><tr><td colspan="3">Organisations: <b>Qatar Computing Research Institute, University of Padova, Qatar University, Università di Bologna, Newtral Media Audiovisual, Sofia University, University of Duisburg-Essen, University of Applied Sciences Potsdam, University of Hildesheim, TOBB University of Economics and Technology, _</b></td></tr><tr><td colspan="3">We describe the fourth edition of the CheckThat! Lab, part of the 2021 Conference and Labs of the Evaluation Forum (CLEF). The lab evaluates technology supporting tasks related to factuality, and covers Arabic, Bulgarian, English, Spanish, and Turkish. Task 1 asks to predict which posts in a Twitter stream are worth fact-checking, focusing on COVID-19 and politics (in all five languages). Task 2 asks to determine whether a claim in a tweet can be verified using a set of previously fact-checked claims (in Arabic and English). Task 3 asks to predict the veracity of a news article and its topical domain (in English). The evaluation is based on mean average precision or precision at rank k for the ranking tasks, and macro-F1 for the classification tasks. This was the most popular CLEF-2021 lab in terms of team registrations: 132 teams. Nearly one-third of them participated: 15, 5, and 25 teams submitted official runs for tasks 1, 2, and 3, respectively.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-87031-7_9" target="_blank"> Evaluating the Role of News Content and Social Media Interactions for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85115884973</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Sotirakou C., Karampela A., Mourlas C.</b></td></tr><tr><td colspan="3">Organisations: <b>National and Kapodistrian University of Athens</b></td></tr><tr><td colspan="3">Societies across the globe suffer from the effects of disinformation campaigns creating an urgent need for a way of tracking falsehoods before they become widely spread. Although building a detection tool for online disinformation campaigns is a challenging task, this paper attempts to approach this problem by examining content-based features related to language use, emotions, and engagement features through explainable machine learning. We propose a model that, except for the textual attributes, harnesses the predictive power of the users’ interactions on the Facebook platform, and forecasts deceptive content in (i) news articles and in (ii) Facebook news-related posts. The findings of the study show that the proposed model is able to predict misleading news stories with a 98% accuracy based on features such as capitals in the main body, headline length, Facebook likes, the total amount of nouns and numbers, lexical diversity, and arousal. In conclusion, the paper provides new insights concerning the false news identifiers crucial for both news publishers and consumers.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.32604/cmc.2021.018901" target="_blank"> Fake News Detection on Social Media: A Temporal-Based Approach<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85115907959</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Jang Y., Park C.-H., Lee D.-G., Seo Y.-S.</b></td></tr><tr><td colspan="3">Organisations: <b>Yeungnam University</b></td></tr><tr><td colspan="3">Following the development of communication techniques and smart devices, the era of Artificial Intelligence (AI) and big data has arrived. The increased connectivity, referred to as hyper-connectivity, has led to the development of smart cities. People in these smart cities can access numerous online contents and are always connected. These developments, however, also lead to a lack of standardization and consistency in the propagation of information throughout communities due to the consumption of information through social media channels. Information cannot often be verified, which can confuse the users. The increasing influence of social media has thus led to the emergence and increasing prevalence of fake news. In this study, we propose a methodology to classify and identify fake news emanating from social channels. We collected content from Twitter to detect fake news and statistically verified that the temporal propagation pattern of quote retweets is effective for the classification of fake news. To verify this, we trained the temporal propagation pattern to a two-phases deep learning model based on convolutional neural networks and long short-term memory. The fake news classifier demonstrates the ability for its early detection. Moreover, it was verified that the temporal propagation pattern was the most influential feature compared to other feature groups discussed in this paper.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.6688/JISE.202109_37(5).0013" target="_blank"> Hyperpartisan news classification with elmo and bias feature<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85115976124</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>HUANG G.K.W., LEE J.C.</b></td></tr><tr><td colspan="3">Organisations: <b>Universiti Malaysia Sarawak</b></td></tr><tr><td colspan="3">Hyperpartisan news is a kind of news riddled with twisted, untruthful, and often extremely one-sided. This kind of news can spread more successfully than the others. One of the obvious traits of hyperpartisan news content is that it can mimic regular news articles. Most are favour fake news detection algorithms, and there is less research conducted for hyperpartisan news. This research aims to perform classification on the hyperpartisan news using ELMo and bias features. ELMo was used to develop a classification model to perform classification on the BuzzFeed Webis News Corpus dataset. The model uses ELMo embedding with bias word score generated from bias lexicon to train a deep learning model using Tensorflow and Keras. We had compared the final result with two proposed baseline models that utilized ELMo from other research. The discussion section further investigated the contribution of ELMo and bias feature in the hyperpartisan task.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3460112.3471974" target="_blank"> A Poster on Learnings from an Attempt to Build an NLP-based Fake News Classification system for Hindi<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85116194045</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Akash B.S., Badam J., Raju K., Chakraborty D.</b></td></tr><tr><td colspan="3">Organisations: <b>Bits Pilani</b></td></tr><tr><td colspan="3">Proliferation of "Fake News"and misinformation is resulting in widespread negative social fallout. Scalable Fake News classification techniques for resource poor languages like Hindi are in early stages because of a lack of datasets and lack of robust NLP libraries for these languages. In this exploratory study we curate a dataset of around 13,000 data points of true news articles, and, articles on fake news authored by media organisations which flag fake news. We then use seven ML classification models on this dataset and present the preliminary results. Our results show that concerted efforts need to be made by the research community towards dataset curation and improving the NLP models for resource poor languages in order to make scalable classification systems.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s13369-021-06223-0" target="_blank"> Detection of Turkish Fake News in Twitter with Machine Learning Algorithms<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85116223274</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Taskin S.G., Kucuksille E.U., Topal K.</b></td></tr><tr><td colspan="3">Organisations: <b>Bandirma Onyedi Eylul University, Suleyman Demirel University, Balikesir University</b></td></tr><tr><td colspan="3">Social media has affected people’s information sources. Since most of the news on social media is not verified by a central authority, it may contain fake news for various reasons such as advertising and propaganda. Considering an average of 500 million tweets were posted daily on Twitter alone in the year of 2020, it is possible to control each share only with smart systems. In this study, we use Natural Language Processing methods to detect fake news for Turkish-language posts on certain topics on Twitter. Furthermore, we examine the follow/follower relations of the users who shared fake-real news on the same subjects through social network analysis methods and visualization tools. Various supervised and unsupervised learning algorithms have been tested with different parameters. The most successful F1 score of fake news detection was obtained with the support vector machines algorithm with 0.9. People who share fake/true news can help in the separation of subgroups in the social network created by people and their followers. The results show that fake news propagation networks may show different characteristics in their own subject based on the follow/follower network.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> A novel filter based multivariate feature Selection technique for text classification<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85116347974</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Palacharla R.K., Vatsavayi V.K.</b></td></tr><tr><td colspan="3">Organisations: <b>Bapatla Engineering College, Andhra University</b></td></tr><tr><td colspan="3">Text classification is a technique of assigning the known class label to the unknown textual documents. This technique assign single label or multiple labels to a specific document based on the content in the document. These techniques are used in various applications such as sentiment analysis, authorship analysis, fake news detection and spam email classification. In the text classification process, the words in the documents are considered as features. The most important words which are having more differentiating power are considered in the representation of a document. Identification of such words or features is a primary step in the classification process. The high dimensionality of data description is a primary issue in text classification. Huge number of features in the analysis not only decreases the performance of classification but also increase the computational time. In this work, a new feature selection technique based on Category specific Feature Distribution without Redundancy Information (CFDRI) is proposed to identify best informative features and eliminating the redundant features. The effectiveness of proposed feature selection technique is compared with existing techniques such as mutual information, information gain, chi square and relative discriminative criterion. The traditional Bag of Words technique is used to designate the documents as vectors. Term frequency and inverse document frequency measure is used to compute the vector value in the document vector representation. Various machine learning algorithms such as Decision Tree, Support Vector Machine, Naïve Bayes, k-Nearest Neighbour, Logistic Regression and Random Forest are used to generate the learned model. Six popular text classification datasets are used in this experiment to train different learning algorithms. The proposed feature selection technique obtained best accuracies for text classification when compared with the popular solutions for text classification.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/IJCNN52387.2021.9533433" target="_blank"> TRANSFAKE: Multi-task Transformer for Multimodal Enhanced Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85116400085</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Jing Q., Yao D., Fan X., Wang B., Tan H., Bi J., Bu X.</b></td></tr><tr><td colspan="3">Organisations: <b>Chinese Academy of Sciences, University of Chinese Academy of Sciences, University of Science and Technology</b></td></tr><tr><td colspan="3">Social media has became a critical manner for people to acquire information in daily life. Despite the great convenience, fake news can be widely spread through social networks, causing various adverse effects on people's lives. Detecting these fake news or misinformations has proved to be a critical task and draws attentions from both governments and individuals. Recently, many methods have been proposed to solve this problem, but most of them rely on the body content of the news, ignoring the social context information such as the comments. We argue that the comments of a specific news contain common judgements of the whole society and could be extremely useful for detecting fake news. In this paper, we propose a new method TRANSFAKE which jointly models the body content and comments of news systemically, and detects fake news with multi-task learning framework. TRANSFAKE model is a Transformer-based model. It takes different modalities as input and employs multiple tasks, i.e. rumor score prediction and event classification, as intermediate tasks for extracting useful hidden relationships across various modalities. These intermediate tasks promote each other and encourage TRANSFAKE making the right decision. Extensive experiments on two standard real-life datasets demonstrate that TRANSFAKE outperforms state-of-the-art methods. It improves the detection accuracy by margins as large as 12.6% and F1 scores as large as 15%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/IJCNN52387.2021.9534254" target="_blank"> Special Symbol Attacks on NLP Systems<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85116455476</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Formento B., Ng S.-K., Foo C.-S.</b></td></tr><tr><td colspan="3">Organisations: <b>AStar, Ids,Nus</b></td></tr><tr><td colspan="3">Adversarial attacks/perturbations are becoming important for NLP research, as it has been shown recently that text-attacking adversaries can degrade an NLP model's performance without the victim's knowledge. This has far-reaching implications, especially when an NLP system is deployed in critical applications such as health or finance. In fact, the robustness of state-of-the-art models such as NLP transformers have increasingly been scrutinised due to their vulnerability against adversarial perturbations such as TextFooler and BERT-Attack. These methods, however, focus on changing words, which at times, ruins the readability and semantics of the sample. This paper introduces Special Symbol Text Attacks 'SSTA', a technique to improve the performance of language adversarial perturbations using special symbols that have downstream task information associated with them even though that should not have been the case. Our tests show that introducing such symbols which are meaningless to a human within a sentence, can perturb the sample in a particular direction. When this technique is used with TextFooler, which is a recent benchmark for the creation of NLP adversaries, through the TextAttack framework, it can improve all main evaluation metrics on three sentiment classification tasks and fake news detection. A simple, novel and symbol-specific adversarial learning technique is then introduced to reduce the influence of such special symbols.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/IJCNN52387.2021.9534362" target="_blank"> Fake News Detection on News-Oriented Heterogeneous Information Networks through Hierarchical Graph Attention<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85116488911</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Ren Y., Zhang J.</b></td></tr><tr><td colspan="3">Organisations: <b>Florida State University</b></td></tr><tr><td colspan="3">The viral spread of fake news has caused great social harm, making fake news detection an urgent task. Current fake news detection methods rely heavily on text information by learning the extracted news content or writing style of internal knowledge. However, deliberate rumors can mask writing style, bypassing language models and invalidating simple text-based models. In fact, news articles and other related components (such as news creators and news topics) can be modeled as a heterogeneous information network (HIN for short). In this paper, we propose a novel fake news detection framework, namely Hierarchical Graph Attention Network (HGAT), which uses a novel hierarchical attention mechanism to perform node representation learning in HIN, and then detects fake news by classifying news article nodes. Experiments on two realworld fake news datasets show that HGAT can outperform text-based models and other network-based models. In addition, the experiments prove the expandability and generalizability of our for graph representation learning and other node classification related applications in heterogeneous graphs.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/IJCNN52387.2021.9534218" target="_blank"> A Multitask Learning Approach for Fake News Detection: Novelty, Emotion, and Sentiment Lend a Helping Hand<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85116508364</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Kumari R., Ashok N., Ekbal A., Ghosal T.</b></td></tr><tr><td colspan="3">Organisations: <b>Indian Institute of Technology, Charles University</b></td></tr><tr><td colspan="3">The recent explosion in false information on social media has led to intensive research on automatic fake news detection models and fact-checkers. Fake news and misinformation, due to its peculiarity and rapid dissemination, have posed many interesting challenges to the Natural Language Processing (NLP) and Machine Learning (ML) community. Admissible literature shows that novel information includes the element of surprise, which is the principal characteristic for the amplification and virality of misinformation. Novel and emotional information attracts immediate attention in the reader. Emotion is the presentation of a certain feeling or sentiment. Sentiment helps an individual to convey his emotion through expression and hence the two are co-related. Thus, Novelty of the news item and thereafter detecting the Emotional state and Sentiment of the reader appear to be three key ingredients, tightly coupled with misinformation. In this paper we propose a deep multitask learning model that jointly performs novelty detection, emotion recognition, sentiment prediction, and misinformation detection. Our proposed model achieves the state-of-the-art(SOTA) performance for fake news detection on three benchmark datasets, viz. ByteDance, Fake News Challenge(FNC), and Covid-Stance with 11.55%, 1.58%, and 21.76% improvement in accuracy, respectively. The proposed approach also shows the efficacy over the single-task framework with an accuracy gain of 11.53, 28.62, and 14.31 percentage points for the above three datasets. The source code is available at https://github.com/Nish-19/Multitask-Fake-News-NES.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.chb.2021.107032" target="_blank"> Using fake news as means of cyber-bullying: The link with compulsive internet use and online moral disengagement<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85116521009</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Maftei A., Holman A.-C., Merlici I.-A.</b></td></tr><tr><td colspan="3">Organisations: <b>“Alexandru Ioan Cuza” University</b></td></tr><tr><td colspan="3">Online moral disengagement and cyberbullying can enhance fake news spreading. We explored the links between these variables and compulsive Internet use in a sample of 509 teenagers and adults aged 11 to 67. We investigated the effect of compulsive Internet use on cyberbullying through fake news creation and/or distribution, both direct and via moral disengagement, and the related differences between adults and teenagers. The indirect effect of compulsive Internet use on cyberbullying through moral disengagement was significant in adolescents, but not in adults. As assumed, teenagers scored significantly higher than adults on all the primary variables. Contrary to our expectations, no significant gender differences emerged, regardless of participants' age, in terms of compulsive Internet use, moral disengagement, nor cyberbullying. The results emphasize the importance of relevant online education programs designed to engage both teenagers and adults in critical thinking that might help in the fake news detection process, especially during the COVID-19 pandemic.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> KAN: Knowledge-aware Attention Network for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85116529165</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Dun Y., Tu K., Chen C., Yuan X., Hou C.</b></td></tr><tr><td colspan="3">Organisations: <b>Nankai University, Tianjin Key Laboratory of Network and Data Security Technology, Tianjin University of Technology</b></td></tr><tr><td colspan="3">The explosive growth of fake news on social media has drawn great concern both from industrial and academic communities. There has been an increasing demand for fake news detection due to its detrimental effects. Generally, news content is condensed and full of knowledge entities. However, existing methods usually focus on the textual contents and social context, and ignore the knowledge-level relationships among news entities. To address this limitation, in this paper, we propose a novel Knowledge-aware Attention Network (KAN) that incorporates external knowledge from knowledge graph for fake news detection. Firstly, we identify entity mentions in news contents and align them with the entities in knowledge graph. Then, the entities and their contexts are used as external knowledge to provide complementary information. Finally, we design News towards Entities (N-E) attention and News towards Entities and Entity Contexts (N-E2C) attention to measure the importances of knowledge. Thus, our proposed model can incorporate both semantic-level and knowledge-level representations of news to detect fake news. Experimental results on three public datasets show that our model outperforms the state-of-the-art methods, and also validate the effectiveness of knowledge attention.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3470482.3479634" target="_blank"> Learning Textual Representations from Multiple Modalities to Detect Fake News through One-Class Learning<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85116565137</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Golo M., Rossi R., Nogueira B., Marcacini R., Caravanti M., Rezende S.</b></td></tr><tr><td colspan="3">Organisations: <b>Institute of Mathematics and Computer Sciences-University of São Paulo (USP), FACOM-Federal University of Mato Grosso Do sul Campo Grande</b></td></tr><tr><td colspan="3">Fake news can rapidly spread through internet users. Approaches proposed in the literature for content classification usually learn models considering textual and contextual features from real and fake news to minimize the spread of disinformation. One of the prominent approaches to detect fake news is One-Class Learning (OCL), as it minimizes the data labeling effort, requiring only the labeling of fake news documents. The performance of these algorithms depends on the structured representation of the documents used in the learning process. Generally, a textual-based unimodal representation is used, such as bag-of-words or representations based on linguistic categories. We propose MVAE-FakeNews, a multimodal representation method to detect fake news in OCL. The proposed approach uses a Multimodal Variational Autoencoder, learns a new representation from the combination of two modalities considered promising for fake news detection: Text embeddings and topic information. In the experiments, we used three datasets considering Portuguese and English languages. Results show that the MVAE-FakeNews obtained a better F1-Score for the class of interest, outperforming another nine methods in ten of twelve evaluated scenarios. MVAE-FakeNews presented a better average ranking and statistical difference from other representation models. The proposed method proved to be promising to represent the texts in the OCL scenario to detect fake news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3470482.3479467" target="_blank"> A Sentiment-Based Multimodal Method to Detect Fake News<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85116586455</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Maia I.M.L., De Souza M.P., Da Silva F.R.M., Freire P.M.S., Goldschmidt R.R.</b></td></tr><tr><td colspan="3">Organisations: <b>Instituto Militar de Engenharia (IME)</b></td></tr><tr><td colspan="3">The dissemination of news through digital media has amplified Fake News proliferation. In the face of this scenario, sentiment-based methods have presented promising results in Fake News detection. Although sentiment-based methods can extract sentiment (i.e., polarity and/or emotion) from either texts or images available in news, the ones applied to Portuguese-written news have considered sentiment exclusively extracted from texts. Thus, this study proposes a multimodal method that, besides the polarity and emotions extracted from texts, also considers sentiment extracted from news' images in order to detect Fake News written in Portuguese. The proposed method showed promising results in experimental data, overcoming the baseline methods in 8 p.p.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICESC51422.2021.9532796" target="_blank"> A Review of Fake News Detection Using Machine Learning Techniques<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85116641082</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Kumar S., Arora B.</b></td></tr><tr><td colspan="3">Organisations: <b>Central University of Jammu</b></td></tr><tr><td colspan="3">With the growing number of users of the internet people share millions of posts, articles and videos. These posts are shred on a number of social media platforms along with twitter, facebook, youtube and other social networking web sites. It is now a well-known fact that many times any misinformation may even lead to conflicts and it also has a significant influence on public opinion. The propagation of fake news stories on social media platforms and on Internet is duping people to an extent, stopping which is the need of the hour. The research area of fake news detection is gaining interest but at the same time it involves a number of challenges due to unavailability of quality resources such as datasets, published literature etc. The existing systems are not that much efficient in the detection of fake news because of the lack of fake news datasets that are comprehensive and at the same time are community-driven datasets. This has become one of the major roadblocks in the research works related to fake news detection. At the same time there are some restrictions on the input and the news category that makes it less varied. The fake news detection system aims to use data repositories such as Buzzfeed, Politifact, CREDBANK, FakeNewsNet and various classification techniques such as Support Vector Machine (SVM), K-Nearest Neighbor (KNN), Decision tree (DT), Logistic Regression (LR), RandomForests etc. to help to achieve maximum accuracy. This review paper provides a detailed review of various fake news detection techniques used by different researchers, the datasets they have worked upon and various evaluation parameters used by them for performance evaluation of their models. We have also discussed the difficulties and challenges faced in fake news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/INISTA52262.2021.9548590" target="_blank"> News identification metric for classification prefiltering<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85116677692</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Cusmuliuc C.-G., Susan S.C., Demetra Chirica B., Iftene A.</b></td></tr><tr><td colspan="3">Organisations: <b>"Alexandru Ioan Cuza"University</b></td></tr><tr><td colspan="3">Growth in social media platforms over the years have facilitated an enhancement in human communication. Platforms such as Facebook and Twitter are most ever-present in our lives and influencing how we speak, think, act and interact. The growth of fake news greatly impacts this phenomenon as it lowers one's trust in the content presented. Dangerous is also the fact that readers can be behaviorally and psychologically profiled in order to be served specially crafted content with the intention of changing one's opinion an action. One such is example is related to the 2016 U.S. presidential election campaign where fake news was a deciding factor in tipping the balance of power and outcome. It is hence of critical importance to develop tools that detect and combat such destructive content. This paper does not focus on the fake news detection problem but on a related problem regarding the prefiltration of the content sent to detection. Considering social media platforms have such diverse content and news is but a fraction of the data handled in the network it would be futile to label every post; not only it would not provide any value to the user, but it would also load the servers in a senseless manner. This work presents and evaluates a metric which is a score, from 0 to 100 of how close a text is to being a news content. The algorithm calculates a relevance score to assess if the content is news as well as uses information about the post and user (how many followers has, how many likes the tweet has and so on).</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/CCET52649.2021.9544276" target="_blank"> It's Time to Confront Fake News and Rumors on Social Media: A Bibliometric Study Based on VOSviewer<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85116705094</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Ding Y., Wang Y., Wang Y.</b></td></tr><tr><td colspan="3">Organisations: <b>Anhui Polytechnic University, Purdue University</b></td></tr><tr><td colspan="3">This paper is aimed to use a quantitative and visual method to evaluate the history, current and future of publications regarding fake news and rumors on social media. VOSviewer was used to identify and summarize the publications from Scopus and WoS from 2010 to 2020. Publication source, publication organization, authors, country, citation of articles, citation of country and organization were recorded and analyzed. Bibliometric maps of authorship, citation, co-citation and network of co-occurrence of keywords were drawn. 6354 articles and 33503 cited references were analyzed. The United States dominates the publications (1615, 25.4%) and citations (5867). University of Chinese Academic of Sciences (85) is the most productive organization. Loftus (26) is the most productive author. Memory Cognition published the most papers about fake news and rumors. The latest keyword 'machine learning' appeared in 2018 in 182 papers. Other relatively new keywords include 'deep learning' 'natural language processing' 'social media platform' 'fake news detection' 'rumors detection' which appeared in 2018 in 98, 66, 63, 58, and 52 papers respectively. As for researchers and practitioners, this paper suggests an analysis of integrated visualization in terms of knowledge and innovation based on the area of fake news and rumors.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICIRCA51532.2021.9544661" target="_blank"> Fake News and Tampered Image Detection in Social Networks Using Machine Learning<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85116867761</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Devi S., Karthik V., Bavatharani S.B.V., Indhumadhi K.</b></td></tr><tr><td colspan="3">Organisations: <b>Coimbatore Institute of Technology</b></td></tr><tr><td colspan="3">Fake News detection is much needed in today's world as it has a large impact in our social as well as personal life but involves some challenges due to the limited resources like datasets, research papers. Nowadays lot of information is being shared over social media and people cannot able to differentiate between which information is fake and which is real. People immediately start sharing the news without confirming its authenticity. This further results in spreading of it. Fake news and rumor are the most popular forms of false and unauthenticated information and should be detected as soon as possible for avoiding their dramatic consequences. In previous research, many fake news detection methods were proposed. In this project the final report is generated by predictions of text classification using SVM, Logistic Regression, Gaussian Naive Bayes and tampered image classification by Error Level Analysis using CNN.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.procs.2021.09.032" target="_blank"> Exploring the impact of data poisoning attacks on machine learning model reliability<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85116881263</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Verde L., Marulli F., Marrone S.</b></td></tr><tr><td colspan="3">Organisations: <b>Università degli Studi della Campania L. Vanvitelli</b></td></tr><tr><td colspan="3">Recent years have seen the widespread adoption of Artificial Intelligence techniques in several domains, including healthcare, justice, assisted driving and Natural Language Processing (NLP) based applications (e.g., the Fake News detection). Those mentioned are just a few examples of some domains that are particularly critical and sensitive to the reliability of the adopted machine learning systems. Therefore, several Artificial Intelligence approaches were adopted as support to realize easy and reliable solutions aimed at improving the early diagnosis, personalized treatment, remote patient monitoring and better decision-making with a consequent reduction of healthcare costs. Recent studies have shown that these techniques are venerable to attacks by adversaries at phases of artificial intelligence. Poisoned data set are the most common attack to the reliability of Artificial Intelligence approaches. Noise, for example, can have a significant impact on the overall performance of a machine learning model. This study discusses the strength of impact of noise on classification algorithms. In detail, the reliability of several machine learning techniques to distinguish correctly pathological and healthy voices by analysing poisoning data was evaluated. Voice samples selected by available database, widely used in research sector, the Saarbruecken Voice Database, were processed and analysed to evaluate the resilience and classification accuracy of these techniques. All analyses are evaluated in terms of accuracy, specificity, sensitivity, F1-score and ROC area.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-88081-1_29" target="_blank"> Adaptive Goal Function of Ant Colony Optimization in Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85116902604</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Probierz B., Kozak J., Stefanski P., Juszczuk P.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Economics in Katowice</b></td></tr><tr><td colspan="3">Currently, there is a very rapid growth of information published on the Internet, both on social media and news sites. However, a serious problem is a disinformation in the form of fake news. Due to the rapid spread of information on the Internet, it is very important to be able to quickly identify true and fake news. The solution to this problem can be an initial analysis of news by its title and quick selection of true or fake news. Additionally, the possibility of balancing precision and recall as the quality of classification measures could allow for better news selection. In this paper, we propose the use of the adaptive goal function of ant colony optimization algorithms in fake news detection. The goal of this solution is to increase recall or precision of the selected class – in this case fake or true news. We use natural language processing (NLP) to describe the title of the news. In addition, a constrained term matrix is used. The choice of titles alone and the restriction of the words analyzed are related to speeding up the initial classification. Eventually, we present an analysis of a real dataset and classification results (detailing recall and precision) of news using the adaptive goal function of the ACDT algorithm.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.3390/app11199292" target="_blank"> Ternion: An autonomous model for fake news detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85116935007</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Islam N., Shaikh A., Asiri Y., Almakdi S., Sulaiman A., Qaiser A., Moazzam V., Babar S.A.</b></td></tr><tr><td colspan="3">Organisations: <b>Iqra University, Najran University, NED University of Engineering and Technology</b></td></tr><tr><td colspan="3">In recent years, the consumption of social media content to keep up with global news and to verify its authenticity has become a considerable challenge. Social media enables us to easily access news anywhere, anytime, but it also gives rise to the spread of fake news, thereby delivering false information. This also has a negative impact on society. Therefore, it is necessary to determine whether or not news spreading over social media is real. This will allow for confusion among social media users to be avoided, and it is important in ensuring positive social development. This paper proposes a novel solution by detecting the authenticity of news through natural language processing techniques. Specifically, this paper proposes a novel scheme comprising three steps, namely, stance detection, author credibility verification, and machine learning-based classification, to verify the authenticity of news. In the last stage of the proposed pipeline, several machine learning techniques are applied, such as decision trees, random forest, logistic regression, and support vector machine (SVM) algorithms. For this study, the fake news dataset was taken from Kaggle. The experimental results show an accuracy of 93.15%, precision of 92.65%, recall of 95.71%, and F1-score of 94.15% for the support vector machine algorithm. The SVM is better than the second best classifier, i.e., logistic regression, by 6.82%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/TKDE.2021.3118815" target="_blank"> A Comprehensive Survey on Graph Anomaly Detection With Deep Learning<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85117120759</td><td>Year: <b>2023</b></td></tr><tr><td colspan="3">Authors: <b>Ma X., Wu J., Xue S., Yang J., Sheng Q.Z., Zhou C., Xiong H., Akoglu L.</b></td></tr><tr><td colspan="3">Organisations: <b>Macquarie University, Academy of Mathematics and Systems Science, State University of New Jersey, Carnegie Mellon University's</b></td></tr><tr><td colspan="3">Anomalies are rare observations (e.g., data records or events) that deviate significantly from the others in the sample. Over the past few decades, research on anomaly mining has received increasing interests due to the implications of these occurrences in a wide range of disciplines - for instance, security, finance, and medicine. For this reason, anomaly detection, which aims to identify these rare observations, has become one of the most vital tasks in the world and has shown its power in preventing detrimental events, such as financial fraud, network intrusions, and social spam. The detection task is typically solved by identifying outlying data points in the feature space, which, inherently, overlooks the relational information in real-world data. At the same time, graphs have been prevalently used to represent the structural/relational information, which raises the graph anomaly detection problem - identifying anomalous graph objects (i.e., nodes, edges and sub-graphs) in a single graph, or anomalous graphs in a set/database of graphs. Conventional anomaly detection techniques cannot tackle this problem well because of the complexity of graph data (e.g., irregular structures, relational dependencies, node/edge types/attributes/directions/multiplicities/weights, large scale, etc.). However, thanks to the advent of deep learning in breaking these limitations, graph anomaly detection with deep learning has received a growing attention recently. In this survey, we aim to provide a systematic and comprehensive review of the contemporary deep learning techniques for graph anomaly detection. Specifically, we provide a taxonomy that follows a task-driven strategy and categorizes existing work according to the anomalous graph objects that they can detect. We especially focus on the challenges in this research area and discuss the key intuitions, technical details as well as relative strengths and weaknesses of various techniques in each category. From the survey results, we highlight 12 future research directions spanning unsolved and emerging problems introduced by graph data, anomaly detection, deep learning and real-world applications. Additionally, to provide a wealth of useful resources for future studies, we have compiled a set of open-source implementations, public datasets, and commonly-used evaluation metrics. With this survey, our goal is to create a 'one-stop-shop' that provides a unified understanding of the problem categories and existing approaches, publicly available hands-on resources, and high-impact open challenges for graph anomaly detection using deep learning.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICEE52715.2021.9544409" target="_blank"> Exploring the impact of machine translation on fake news detection: A case study on Persian tweets about COVID-19<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85117481888</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Saghayan M.H., Bahrani M., Ebrahimi S.F.</b></td></tr><tr><td colspan="3">Organisations: <b>Allameh Tabataba'i University, Sharif University of Technology</b></td></tr><tr><td colspan="3">Fake news detection has become an emerging and critical topic of research in recent years. One of the major complications of fake news detection lies in the fact that news in social networks is multilingual, and therefore developing methods for each and every language in the world is impossible, especially for low resource languages like Persian. In an effort to solve this problem, researchers use machine translation to uniform the data and develop a method for the uniformed data. In this paper, we aim to explore the impacts of machine translation on fake news detection. For this purpose, we extracted and labeled a dataset of Persian Tweets from Twitter on the subject of COVID-19 and developed a method for detecting fake news on the extracted Tweets based on the SVM classifier, then we machine translated the data and applied our proposed method to it. Finally, the result for binary class (only fake and legitimate) fake news detection was 87%, and for multiclass (satire, misinformation, neutral and legitimate) fake news detection was 62%, and our findings demonstrate that machine translation has a 4 % negative impact on binary classification accuracy and a 23% negative impact on multiclass classification.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICAS49788.2021.9551115" target="_blank"> An autonomous semantic learning methodology for fake news recognition<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85117520189</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Wang Y., Xu J.Y.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Calgary</b></td></tr><tr><td colspan="3">A persistent challenge to AI theories and technologies is fake news recognition which demands not only syntactic analyses of language expressions, but also their semantics comprehension. This work presents an autonomous system for fake news recognition based on a novel approach of machine semantic learning. A training-free machine learning algorithm of Differential Sentence Semantic Analyses (DSSA) is designed and implemented for fake news detection. A large set of 876 experiments randomly selected from DataCup' 19 has demonstrated a level of 70.4% accuracy that outperforms the traditional data-driven neural network technologies normally projected at the accuracy level of 55.0%. The DSSA methodology paves a way towards autonomous, training-free, and real-time trustworthy technologies for machine knowledge learning and semantics composition.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ASIANCON51346.2021.9544803" target="_blank"> A Hypergraph Clustering-based Technique for Detecting Fake News from Broadcasting Network<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85117590925</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Muhuri S., Mukhopadhyay D.</b></td></tr><tr><td colspan="3">Organisations: <b>Bennett University</b></td></tr><tr><td colspan="3">In today's digital world, people are aware of social media and consuming scoops or news directly from its news feed. It creates a strenuous situation as the authenticity of the news sources is unknown. Also, it is very difficult to judge whether a published or propagated report is genuine or not. In recent times, fake news or rumors are creating various social issues by deceiving people in several relevant contexts. Existing methods of fake news detection are relied heavily on manual leveling of data, fact-checking from relevant or authenticate sources, and supervised learning techniques. As the supervised learning approach is highly dependent on manual intervention, this manuscript presents an unsupervised approach for detecting any forgery news from online broadcasting network. We have studied inter-user behavior patterns in broadcasting networks based on hypergraph and labeled the news articles for fake news detection. The proposed method would terminate the fake news propagation through social media by eliminating them from broadcasting. The satisfactory inquisitive results of our approach on different real-world data set would inspire the interdisciplinary researchers to probe further in this area.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s13278-021-00799-z" target="_blank"> Social network analysis using deep learning: applications and schemes<a></b></td></tr><tr><td>Type: Review</td><td>ID: S_2-s2.0-85117856181</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Abbas A.M.</b></td></tr><tr><td colspan="3">Organisations: <b>Aligarh Muslim University</b></td></tr><tr><td colspan="3">Online social networks (OSNs) are part of daily life of human beings. Millions of users are connected through online social networks. Due to very large number of users and huge amount of data, social network analysis is a challenging task. The emergence of deep learning techniques has enabled to carry out a rigorous analysis of OSNs. A lot of research is carried out in the area of social network analysis using deep learning techniques from different perspectives. In this paper, we provide an overview of state-of-the-art research for different applications of social network analysis using deep learning techniques. We consider applications such as opinion analysis, sentiment analysis, text classification, recommender systems, structural analysis, anomaly detection, and fake news detection. We compare different schemes on the basis of their focus and features. Further, we point out directions for future work.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.3389/fcomm.2021.661801" target="_blank"> Countering the cognitive, linguistic, and psychological underpinnings behind susceptibility to fake news: A review of current literature with special focus on the role of age and digital literacy<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85117881075</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Gaillard S., Olah Z.A., Venmans S., Burke M.</b></td></tr><tr><td colspan="3">Organisations: <b>University Medical Center Utrecht, Journal of Trial and Error, Utrecht University, Leiden University</b></td></tr><tr><td colspan="3">Fake news poses one of the greatest threats to democracy, journalism, and freedom of expression. In recent cases, fake news' designs are to create confusion and lower trust among the general public - as seen in the 2016 UnitedStates presidential campaign and the Brexit referendum. The spread of information without formal verification increased since the introduction of social media and online news channels. After the popularization of fake news, researchers have tried to evaluate and understand the effects of false information from multiple different perspectives. However, it is evident that to tackle the problem of fake news, interdisciplinary collaboration is needed. This article evaluates the main findings of recent literature from an integrated psychological, linguistic, cognitive, and societal perspective, with a particular focus on digital and age-related aspects of fake news. From a psychosociological standpoint, the article provides a synthesized profile of the fake news believer. This profile generally denotes overconfidence in one's ability to assess falsehoods due to a human need for causal explanations. The fake news believer can be described as well-intentioned and critical, yet driven by a basis of distrust and false foundational knowledge. Within linguistics, manual analytical tools exist to understand the persuasive tactics in fake news. The article takes analytical techniques from both the humanities and the social sciences, such as transitivity analysis, Hugh Rank's language persuasive framework, and others that can be used to analyze the language used in the news. However, in the age of big data perhaps only computational techniques can adequately address the issue at the root. While this proves successful, there are hurdles like the ambiguity of satire and sarcasm, manual labeling of data, and the supple nature of language. Reading comprehension differences between digital versus paper reading seem inconclusive. There are, however, notable behavioral and cognitive differences in reading behavior for the digital medium such as more scanning, less sustained attention, cognitive retreat, and shallower processing. Interestingly, when metacognitive strategies were probed by, for example, having participants independently allocate reading time, a difference in comprehension scores started to emerge. Researchers have also found accounts of differences due to medium preference; and on average older people seem to prefer paper reading. Cognitive retreat, shallow processing, and overconfidence associated with digital reading and the digital medium, in general, might make readers less likely to engage in the cognitive effort fake news detection requires. Considering that there are clear cognitive differences between older generations and younger generations (in terms of decreased processing speed, metacognition, and ability to multitask) differences in how these generations process fake news is plausible. Regrettably, most current research into psychological factors influencing susceptibility to fake news does not take into account age differences. Our meta-analysis showed that 74% of behavioral studies looking at fake news largely ignore age (N= 62), even though voter turnout was far higher among older generations for both the 2016 UnitedStates presidential election and the 2016 UnitedKingdom European Union membership referendum. Many provisional programs set up in the past few years aimed at training digital literacy, reading comprehension, and asking critical questions as virtual skills to detect fake news. These training programs are, however, mostly aimed at younger - digitally native - groups. As a result, these efforts might not be as efficacious as intended and could be improved upon significantly. This article argues that age must become a larger focus in fake news research and efforts in educating people against fake news must expand outside of the universities and isolated areas and include older generations.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> When Does an Individual Accept Misinformation?<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85118135565</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Borukhson D., Lorenz-Spreen P., Ragni M.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Freiburg, Max Planck Institute for Human Development, South Denmark University</b></td></tr><tr><td colspan="3">A new phenomenon is the spread and acceptance of “fake news” on an individual user level, facilitated by social media such as Twitter. So far, state of the art socio–psychological theories and cognitive models focus on explaining how the accuracy of fake news is judged on average, with little consideration of the individual. This paper takes it to a new level: A breadth of core models are comparatively assessed on their predictive accuracy for the individual decision maker, i.e., how well can models predict an individual’s decision before the decision is made. To conduct this analysis, it requires the raw responses of each individual and the implementation and adaption of theories to predict the individual’s response. We used two previously collected large data sets with a total of 3309 participants and searched for, analyzed and refined existing classical and heuristic modeling approaches. The results suggest that classical reasoning, sentiment analysis models and heuristic approaches can best predict the “Accept” or “Reject” response of a person. A hybrid model that combines those models outperformed the prediction of all individual models pointing to an adaptive tool-box.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/AFRICON51333.2021.9570905" target="_blank"> Is it Fake? news disinformation detection on south african news websites<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85118465420</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>De Wet H., Marivate V.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Pretoria</b></td></tr><tr><td colspan="3">Disinformation through fake news is an ongoing problem in our society and has become easily spread through social media. The most cost- and time-effective way to filter these large amounts of data is to use a combination of human and technical interventions to identify it. From a technical perspective, Natural Language Processing (NLP) is widely used in detecting fake news. Social media companies use NLP techniques to identify the fake news and warn their users, but fake news may still slip through undetected. It is especially a problem in more localised contexts (outside the United States of America). How do we adjust fake news detection systems to work better for local contexts such as in South Africa. In this work we investigate fake news detection on South African websites. We curate a dataset of South African fake news and then train detection models. We contrast this with using widely available fake news datasets (from mostly USA website). We also explore making the datasets more diverse by combining them and observe the differences in behaviour in writing between nations' fake news using interpretable machine learning.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ACCESS.2021.3122978" target="_blank"> Using Adversarial Learning and Biterm Topic Model for an Effective Fake News Video Detection System on Heterogeneous Topics and Short Texts<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85118531683</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Choi H., Ko Y.</b></td></tr><tr><td colspan="3">Organisations: <b>Sungkyunkwan University</b></td></tr><tr><td colspan="3">Fake news videos are being actively produced and uploaded on YouTube to attract public attention. In this paper, we propose a topic-agnostic fake news video detection model based on adversarial learning and topic modeling. The proposed model estimates the topic distribution of a video using its title/description and comments by topic modeling and tries to identify the differences in stance by the topic distribution difference between title/description and comments. However, directly applying conventional topic models (e.g. LDA and PLSA) on such short texts may not work well. Therefore, we use BTM (Biterm Topic Model) that is robust even in short texts to estimate topic distribution. Then, it constructs an adversarial neural network to extract topic-agnostic features effectively. The proposed model can effectively detect topic changes for stance analysis and easily shifts among various topics. In this study, it achieves a 3.41%p greater F1-score than previous models used for fake news video detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Orwellian-times at SemEval-2019 task 4: A stylistic and content-based classifier<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85118576533</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Knauth J.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Goettingen</b></td></tr><tr><td colspan="3">While fake news detection received quite a bit of attention in recent years, hyperpartisan news detection is still an underresearched topic. This paper presents our work towards building a classification system for hyperpartisan news detection in the context of the SemEval2019 shared task 4. We experiment with two different approaches - a more stylistic one, and a more content related one - achieving average results.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.3390/s21217083" target="_blank"> Deceptive online content detection using only message characteristics and a machine learning trained expert system<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85118585773</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Liang X.S., Straub J.</b></td></tr><tr><td colspan="3">Organisations: <b>Dallas College—North Lake, North Dakota State University</b></td></tr><tr><td colspan="3">This paper considers the use of a post metadata-based approach to identifying intentionally deceptive online content. It presents the use of an inherently explainable artificial intelligence technique, which utilizes machine learning to train an expert system, for this purpose. It considers the role of three factors (textual context, speaker background, and emotion) in fake news detection analysis and evaluates the efficacy of using key factors, but not the inherently subjective processing of post text itself, to identify deceptive online content. This paper presents initial work on a potential deceptive content detection tool and also, through the networks that it presents for this purpose, considers the interrelationships of factors that can be used to determine whether a post is deceptive content or not and their comparative importance.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.icte.2021.10.003" target="_blank"> Detection of fake news using deep learning CNN–RNN based methods<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85118597607</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Sastrawan I.K., Bayupati I.P.A., Arsa D.M.S.</b></td></tr><tr><td colspan="3">Organisations: <b>Universitas Udayana</b></td></tr><tr><td colspan="3">Fake news is inaccurate information that is intentionally disseminated for a specific purpose. If allowed to spread, fake news can harm the political and social spheres, so several studies are conducted to detect fake news. This study uses a deep learning method with several architectures such as CNN, Bidirectional LSTM, and ResNet, combined with pre-trained word embedding, trained using four different datasets. Each data goes through a data augmentation process using the back-translation method to reduce data imbalances between classes. The results showed that the Bidirectional LSTM architecture outperformed CNN and ResNet on all tested datasets.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Fake news detection on the web: An LSTM-based approach<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85118648305</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Vyas P., Liu J., El-Gayar O.</b></td></tr><tr><td colspan="3">Organisations: <b>Dakota State University</b></td></tr><tr><td colspan="3">The acceptance and popularity of social media platforms for the dispersion and proliferation of news articles have led to the spread of questionable and untrusted information (in part) due to the ease by which misleading content can be created and shared among the communities. While prior research has attempted to automatically classify news articles and tweets as credible and non-credible. In this work, we complement such research by proposing an approach that utilizes the amalgamation of natural language processing (NLP) and deep learning techniques such as Long Short-Term Memory (LSTM). We used publicly available datasets that contain labeled news articles and tweets to validate our model's effectiveness. The results demonstrate that the proposed model works well for both long sequence news articles and short-sequence texts such as tweets.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.14569/IJACSA.2021.0121072" target="_blank"> Comparison of Machine Learning Algorithms for Sentiment Classification on Fake News Detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85118664249</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Mahmud Y., Shaeeali N.S., Mutalib S.</b></td></tr><tr><td colspan="3">Organisations: <b>Universiti Teknologi MARA</b></td></tr><tr><td colspan="3">With the wide usage of World Wide Web (WWW) and social media platforms, fake news could become rampant among the users. They tend to create and share the news without knowing the authenticity of it. This would become the most critical issues among the societies due to the dissemination of false information. In that regard, fake news needs to be detected as early as possible to avoid negative influences on people who may rely on such information while making important decisions. The aim of this paper is to develop an automation of sentiment classifier model that could help individuals, or readers to understand the sentiment of the fake news immediately. The Cross-Industry Standard Process for Data Mining (CRISP-DM) process model has been applied for the research methodology. The dataset on fake news detection were collected from Kaggle website. The dataset was trained, tested, and validated with cross-validation and sampling methods. Then, comparison model performance using four machine learning algorithms which are Naïve Bayes, Logistic Regression, Support Vector Machine and Random Forest was constructed to investigate which algorithms has the most efficiency towards sentiment text classification performance. A comparison between 1000 and 2500 instances from the fake news dataset was analyzed using 200 and 500 tokens. The result showed that Random Forest (RF) achieved the highest accuracy compared to other machine learning algorithms</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3479645.3479666" target="_blank"> Indonesia's Fake News Detection using Transformer Network<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85118840888</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Fawaid J., Awalina A., Krisnabayu R.Y., Yudistira N.</b></td></tr><tr><td colspan="3">Organisations: <b>Brawijaya University</b></td></tr><tr><td colspan="3">Fake news is a problem faced by society in this era. It is not rare for fake news to cause provocation and problems for the people. Indonesia, as a country with the 4th largest population, has a problem in dealing with fake news. More than 30% of the rural and urban population are deceived by this fake news problem. As we have been studying, there is only a little literature on preventing the spread of fake news in Bahasa Indonesia. So, this research is conducted to prevent these problems. The dataset used in this research was obtained from a news portal that identifies fake news, turnbackhoax.id. Using Web Scrapping on this page, we got 1116 data consisting of valid news and fake news. This dataset will be combined with other available datasets. The dataset is then processed by eliminating irrelevant words and dividing the data into training and testing data with a ratio of 80:20. All neural network methods use word embedding with Word2Vec with 50 dimensions. The methods used are CNN, BiLSTM, Hybrid CNN-BiLSTM, and BERT with Transformer Network. This research shows that the BERT method with Transformer Network has the best results with an accuracy of up to 90%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.patter.2021.100369" target="_blank"> Meta-learning for fake news detection surrounding the Syrian war<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85118872669</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Abu Salem F.K., Al Feel R., Elbassuoni S., Ghannam H., Jaber M., Farah M.</b></td></tr><tr><td colspan="3">Organisations: <b>American University of Beirut, Google</b></td></tr><tr><td colspan="3">In this article, we pursue the automatic detection of fake news reporting on the Syrian war using machine learning and meta-learning. The proposed approach is based on a suite of features that include a given article's linguistic style; its level of subjectivity, sensationalism, and sectarianism; the strength of its attribution; and its consistency with other news articles from the same “media camp”. To train our models, we use FA-KES, a fake news dataset about the Syrian war. A suite of basic machine learning models is explored, as well as the model-agnostic meta-learning algorithm (MAML) suitable for few-shot learning, using datasets of a modest size. Feature-importance analysis confirms that the collected features specific to the Syrian war are indeed very important predictors for the output label. The meta-learning model achieves the best performance, improving upon the baseline approaches that are trained exclusively on text features in FA-KES.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Compare to the knowledge: Graph neural fake news detection with external knowledge<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85118918173</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Hu L., Yang T., Shi C., Zhang L., Zhong W., Tang D., Duan N., Zhou M.</b></td></tr><tr><td colspan="3">Organisations: <b>Beijing University of Posts and Telecommunications, Meituan, Sun Yat-Sen University, Microsoft Research Asia</b></td></tr><tr><td colspan="3">Nowadays, fake news detection, which aims to verify whether a news document is trusted or fake, has become urgent and important. Most existing methods rely heavily on linguistic and semantic features from the news content, and fail to effectively exploit external knowledge which could help determine whether the news document is trusted. In this paper, we propose a novel end-to-end graph neural model called CompareNet, which compares the news to the knowledge base (KB) through entities for fake news detection. Considering that fake news detection is correlated with topics, we also incorporate topics to enrich the news representation. Specifically, we first construct a directed heterogeneous document graph for each news incorporating topics and entities. Based on the graph, we develop a heterogeneous graph attention network for learning the topic-enriched news representation as well as the contextual entity representations that encode the semantics of the news content. The contextual entity representations are then compared to the corresponding KB-based entity representations through a carefully designed entity comparison network, to capture the consistency between the news content and KB. Finally, the topic-enriched news representation combining the entity comparison features are fed into a fake news classifier. Experimental results on two benchmark datasets demonstrate that CompareNet significantly outperforms state-of-the-art methods.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/RTEICT52294.2021.9573583" target="_blank"> Study of Fake News Detection using Machine Learning and Deep Learning Classification Methods<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85118935909</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Nath K., Soni P., Anjum, Ahuja A., Katarya R.</b></td></tr><tr><td colspan="3">Organisations: <b>Delhi Technological University</b></td></tr><tr><td colspan="3">False or misleading information, created deliberately to misinform and deceive the reader, is referred to as Fake News. As the most extensively utilized network for disseminating information, social media has become a highly popular platform for individuals to propagate incorrect information. Fake news can be pernicious when it comes to specific individuals and their opinions and perceptions, influencing and misleading their actions. Several initiatives have been taken in the past to reduce the spread of fake news and detect inaccurate information by devoting a significant amount of time and effort. In this paper, we have compared the performance of various Machine Learning and Deep Learning models for Fake News Detection. For our study, we used four datasets. From our experimentation, we realized that Random Forest and Bag of Words on the FARN Dataset outperformed the rest with an accuracy of 98.8%. In addition, we discovered that TF-IDF outperforms other feature extraction methods.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> InfoSurgeon: Cross-media fine-grained information consistency checking for fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85118944710</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Fung Y.R., Reddy R., Ji H., Thomas C., Chang S.-F., McKeown K., Polisetty S., Bansal M., Sil A.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Illinois at Urbana-Champaign, Columbia University, UMass Amherst, University of North Carolina at Chapel Hill, IBM</b></td></tr><tr><td colspan="3">To defend against neural system-generated fake news, an effective mechanism is urgently needed. We contribute a novel benchmark for fake news detection at the knowledge element level, as well as a solution for this task which incorporates cross-media consistency checking to detect the fine-grained knowledge elements making news articles misinformative. Due to training data scarcity, we also formulate a novel data synthesis method by manipulating knowledge elements within the knowledge graph to generate noisy training data with specific, hard to detect, known inconsistencies. Our detection approach outperforms the state-of-the-art (up to 16.8% absolute accuracy gain), and more critically, yields fine-grained explanations.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Cross-lingual evidence improves monolingual fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85118948828</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Dementieva D., Panchenko A.</b></td></tr><tr><td colspan="3">Organisations: <b>Skolkovo Institute of Science and Technology</b></td></tr><tr><td colspan="3">Misleading information spreads on the Internet at an incredible speed, which can lead to irreparable consequences in some cases. Therefore, it is becoming essential to develop fake news detection technologies. While substantial work has been done in this direction, one of the limitations of the current approaches is that these models are focused only on one language and do not use multilingual information. In this work, we propose a new technique based on cross-lingual evidence (CE) that can be used for fake news detection and improve existing approaches. The hypothesis of the usage of cross-lingual evidence as a feature for fake news detection is confirmed, firstly, by manual experiment based on a set of known true and fake news. Besides, we compared our fake news classification system based on the proposed feature with several strong baselines on two multi-domain datasets of general-topic news and one newly fake COVID-19 news dataset showing that combining cross-lingual evidence with strong baselines such as RoBERTa yields significant improvements in fake news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.14569/IJACSA.2021.0120860" target="_blank"> Lightweight Chain For Detection Of Rumors And Fake News In Social Media<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85118970951</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Alsaawy Y., Sen A.A., Alkhodre A., Nadeem A., Bahbouh N.M.</b></td></tr><tr><td colspan="3">Organisations: <b>Islamic University, University of Granada Spain</b></td></tr><tr><td colspan="3">Social media has become one of the most important sources of news in our lives, but the process of validating news and limiting rumors remains an open research issue. Many researchers have suggested using Blockchain to solve this problem, but it has traditionally failed due to the large volume of data and users in such environments. In this paper, we propose to modify the structure of the Blockchain while preserving its main characteristics. We achieve this by integrating customize blockchain with the Text Mining (TM) algorithm to create a modified Light Weight chain (LWC). LWC will speed up the verification process, which is carried out through proof of good history where the nodes will have the weights according to their previous posts. Moreover, the LWC will be compatible with different applications such as verifying the authenticity of news or legal religious ruling (fatwas). In this research, we have implemented a simple model to simulate the proposed LWC for the detection of fake news and preserving the characteristics and features of the traditional Blockchain. The results on experimental data reflect the effectiveness of the proposed algorithm in establishing the chain</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICETCI51973.2021.9574061" target="_blank"> Credibility of Social-Media Content Using Bidirectional Long Short-Term Memory-Recurrent Neural Networks<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85119008330</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Akula S.P., Kamati N.</b></td></tr><tr><td colspan="3">Organisations: <b>St.Peter's Engineering College</b></td></tr><tr><td colspan="3">Fake news is false information that is created, circulated and endorsed similarly as real news. Fake news and the dissemination of fake stories is nothing new to us; it has existed even before the internet was invented. But now due to social media, any person sitting at any corner of the world can create and spread fake news or rumors within minutes, which has the potential to create serious negative implications for society As a consequence, the identification of false news has arisen as a modern study field that is gaining more and more interest every day. In this article, we'll concentrate on the legitimacy of social network news. With the aid of Long ShortTerm Memory (LSTM)-recurrent neural networks, we expect to present a false news identification model. Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN) are two deep neural networks that have been shown to recognizedifferent dynamic trends in textual results. The Dataset used is Fake news Detection Dataset which is publicly available by kaggle, which contains social media news articles that we have used in training our model. As compared to other deep learningstrategies such as Convolutional Neural Networks (CNNs), Gated Recurrent Units (GRU), Unidirectional Long Short-Term Memory-Recurrent neural networks, and other Bi-directional Long Short-Term Memory models, we find that ourproposed Bi-directional LSTM model outperforms in terms of accuracy and performance.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-89654-6_13" target="_blank"> User Response-Based Fake News Detection on Social Media<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85119017899</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Kidu H., Misgna H., Li T., Yang Z.</b></td></tr><tr><td colspan="3">Organisations: <b>Beijing University of Technology</b></td></tr><tr><td colspan="3">Social media has been a major information sharing and communication platform for individuals and organizations on a mass scale. Its ability to engage users to react to information posted on this media in the form of like, share, and comment made it a preferable information sharing platform by many. But the contents posted on social media are not filtered, fact checked or judged by an editorial body like any traditional news platform. Therefore, individuals, institutions and communities who consume news from social media are vulnerable to misinformation by malicious authors. In this work, we are proposing an approach that detects fake news by investigating the reaction of users to a post composed by malicious authors. Using features extracted by bag-of-words model and TF-IDF from text based replies (comments), and visual emotion responses in the form of categorical data, we built models that predicted news as fake or real. We have designed and conducted a series of experiments to evaluate the performance of our approach. The results show the proposed approach outperforms the baseline in all the six models. In particular, our models from random forest, logistic regression, and XGBoost algorithms produce a precision of 0.97, a recall of 0.99 and an F1 of 0.98.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/GUCON50781.2021.9573875" target="_blank"> A Survey on Role of Machine Learning and NLP in Fake News Detection on Social Media<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85119097147</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Agrawal C., Pandey A., Goyal S.</b></td></tr><tr><td colspan="3">Organisations: <b>UIT-RGPV</b></td></tr><tr><td colspan="3">Due to the enormous and exponential advancement in the online social network, the triad of Facebook, Twitter and Whatsapp posed a great challenge in the form of fake news in front of us. In recent years many events like false propaganda of the 'US presidential election', opinion spamming in 'Brexit referendum', and long-tail series of viral rumors after many natural calamities around the world, created a lot of chaos and law and order problem. Simultaneously, this rapid explosion of fake news also attracted the attention of different researchers to investigate the real cause of it and thus to developed some tools and techniques to relieve and discover the Rumors across online media as soon as possible. In this regard, the Machine Learning (ML) algorithms and Natural Language Processing (NLP) algorithms emerged as the remarkably vital and essential tool to detect fake news in the current age. NLP when aided with machine learning produced many remarkable results that were possible just by manual fact-checking or by normal text detection process. We have systematically discussed the role of NLP and machine learning in the fake news detection process, and various detection techniques based on these. Basic terminology of NLP and machine learning too explained in brief. At last, we gave light on the future trends, open issues, challenges, and potential research oriented toward NLP and ML-based approaches.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3459637.3482440" target="_blank"> Integrating Pattern- And Fact-based Fake News Detection via Model Preference Learning<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85119171265</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Sheng Q., Zhang X., Cao J., Zhong L.</b></td></tr><tr><td colspan="3">Organisations: <b>Chinese Academy of Sciences, University of Chinese Academy of Sciences</b></td></tr><tr><td colspan="3">To defend against fake news, researchers have developed various methods based on texts. These methods can be grouped as 1) pattern-based methods, which focus on shared patterns among fake news posts rather than the claim itself; and 2) fact-based methods, which retrieve from external sources to verify the claim's veracity without considering patterns. The two groups of methods, which have different preferences of textual clues, actually play complementary roles in detecting fake news. However, few works consider their integration. In this paper, we study the problem of integrating pattern- and fact-based models into one framework via modeling their preference differences, i.e., making the pattern- and fact-based models focus on respective preferred parts in a post and mitigate interference from non-preferred parts as possible. To this end, we build a Preference-aware Fake News Detection Framework (Pref-FEND), which learns the respective preferences of pattern- and fact-based models for joint detection. We first design a heterogeneous dynamic graph convolutional network to generate the respective preference maps, and then use these maps to guide the joint learning of pattern- and fact-based models for final prediction. Experiments on two real-world datasets show that Pref-FEND effectively captures model preferences and improves the performance of models based on patterns, facts, or both.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3459637.3482139" target="_blank"> MDFEND: Multi-domain Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85119173433</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Nan Q., Cao J., Zhu Y., Wang Y., Li J.</b></td></tr><tr><td colspan="3">Organisations: <b>Chinese Academy of Sciences (CAS), University of Chinese Academy of Sciences</b></td></tr><tr><td colspan="3">Fake news spread widely on social media in various domains, which lead to real-world threats in many aspects like politics, disasters, and finance. Most existing approaches focus on single-domain fake news detection (SFND), which leads to unsatisfying performance when these methods are applied to multi-domain fake news detection. As an emerging field, multi-domain fake news detection (MFND) is increasingly attracting attention. However, data distributions, such as word frequency and propagation patterns, vary from domain to domain, namely domain shift. Facing the challenge of serious domain shift, existing fake news detection techniques perform poorly for multi-domain scenarios. Therefore, it is demanding to design a specialized model for MFND. In this paper, we first design a benchmark of fake news dataset for MFDN with domain label annotated, namely Weibo21, which consists of 4,488 fake news and 4,640 real news from 9 different domains. We further propose an effective Multi-domain Fake News Detection Model (MDFEND) by utilizing domain gate to aggregate multiple representations extracted by a mixture of experts. The experiments show that MDFEND can significantly improve the performance of multi-domain fake news detection. Our dataset and code are available at https://github.com/kennqiang/MDFEND-Weibo21.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Embracing Domain Differences in Fake News: Cross-domain Fake News Detection using Multi-modal Data<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85119193103</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Silva A., Luo L., Karunasekera S., Leckie C.</b></td></tr><tr><td colspan="3">Organisations: <b>The University of Melbourne</b></td></tr><tr><td colspan="3">With the rapid evolution of social media, fake news has become a significant social problem, which cannot be addressed in a timely manner using manual investigation. This has motivated numerous studies on automating fake news detection. Most studies explore supervised training models with different modalities (e.g., text, images, and propagation networks) of news records to identify fake news. However, the performance of such techniques generally drops if news records are coming from different domains (e.g., politics, entertainment), especially for domains that are unseen or rarely-seen during training. As motivation, we empirically show that news records from different domains have significantly different word usage and propagation patterns. Furthermore, due to the sheer volume of unlabelled news records, it is challenging to select news records for manual labelling so that the domain-coverage of the labelled dataset is maximized. Hence, this work: (1) proposes a novel framework that jointly preserves domain-specific and cross-domain knowledge in news records to detect fake news from different domains; and (2) introduces an unsupervised technique to select a set of unlabelled informative news records for manual labelling, which can be ultimately used to train a fake news detection model that performs well for many domains while minimizing the labelling cost. Our experiments show that the integration of the proposed fake news model and the selective annotation approach achieves state-of-the-art performance for cross-domain news datasets, while yielding notable improvements for rarely-appearing domains in news datasets.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3459637.3482212" target="_blank"> Using Topic Modeling and Adversarial Neural Networks for Fake News Video Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85119194238</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Choi H., Ko Y.</b></td></tr><tr><td colspan="3">Organisations: <b>Sungkyunkwan University</b></td></tr><tr><td colspan="3">Fake news videos are being actively produced and uploaded on YouTube to attract public attention. In this paper,we propose a topic-agnostic fake news video detection model based on adversarial learning and topic modeling. The proposed model estimates the topic distribution of a video using its title/description and comments by topic modeling and tries to identify the differences in stance by the topic distribution difference between title/description and comments. Then, it constructs an adversarial neural network to extract topic-agnostic features effectively. The proposed model can effectively detect topic changes for stance analysis and easily shift among various topics. In this study, it achieves an F1-score 2.68% point greater than previous models in fake news video detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/SISY52375.2021.9582484" target="_blank"> Compilation and Validation of a Large Fake News Dataset in Hungarian<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85119292538</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Gencsi M., Bodo Z., Szenkovits A.</b></td></tr><tr><td colspan="3">Organisations: <b>Babeş-Bolyai University</b></td></tr><tr><td colspan="3">Automatically detecting fake news and drawing readers' attention to possible deceptive intentions can be considered rather useful in the online era. While determining the veracity of writings should involve fact-checking the information contained in the article, using lexical and syntactic clues, text complexity measures, etc. one can predict truthfulness with surprisingly high accuracy. To help the scientific community in studying the fake news phenomenon, we compiled a large dataset of 80 547 legitimate and 67 547 fake news articles from trusted and deceptive Hungarian web portals. The dataset is validated by conducting text classification experiments on the news stories, using traditional bag-of-words and more recent neural network models, the best-performing method achieving a 0.98 F1-score.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3474085.3481548" target="_blank"> Improving Fake News Detection by Using an Entity-enhanced Framework to Fuse Diverse Multimodal Clues<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85119338221</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Qi P., Cao J., Sheng Q., Mi X., Li X., Liu H., He Q., Lv Y., Guo C., Yu Y.</b></td></tr><tr><td colspan="3">Organisations: <b>Institute of Computing Technology, University of Chinese Academy of Sciences, Institute of Artifuicial Intelligence, Renmin University of China, Zhengzhou University, Hangzhou ZhongkeRuijian Technology Co.,Ltd.</b></td></tr><tr><td colspan="3">Recently, fake news with text and images have achieved more effective diffusion than text-only fake news, raising a severe issue of multimodal fake news detection. Current studies on this issue have made significant contributions to developing multimodal models, but they are defective in modeling the multimodal content sufficiently. Most of them only preliminarily model the basic semantics of the images as a supplement to the text, which limits their performance on detection. In this paper, we find three valuable text-image correlations in multimodal fake news: entity inconsistency, mutual enhancement, and text complementation. To effectively capture these multimodal clues, we innovatively extract visual entities (such as celebrities and landmarks) to understand the news-related high-level semantics of images, and then model the multimodal entity inconsistency and mutual enhancement with the help of visual entities. Moreover, we extract the embedded text in images as the complementation of the original text. All things considered, we propose a novel entity-enhanced multimodal fusion framework, which simultaneously models three cross-modal correlations to detect diverse multimodal fake news. Extensive experiments demonstrate the superiority of our model compared to the state of the art.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-89363-7_8" target="_blank"> Fake News Detection Using Multiple-View Text Representation<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85119353167</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Ha T., Gao X.</b></td></tr><tr><td colspan="3">Organisations: <b>Victoria University of Wellington</b></td></tr><tr><td colspan="3">Fake news, or false information presented as news, is an increasing risk in today’s society. The practice of automatically detecting fake news is by no means an easy task, since the authors of fake news intend to confuse the readers and make them vulnerable to false information. Traditional methods only consider a limited number of characteristics of fake news, and hence, they face many difficulties in predicting the credibility of the news. This paper proposes WES, an integrated stacking model where the multiple-view text representation from (i) Word-level features, (ii) Emotional features, and (iii) Sentence-level features are used to classify the news article. The proposed system is applied on a real-world dataset, FakeNewsNet, and the experimental results show that the proposed approach achieves significantly better performance than the current state-of-the-art fake news detection method.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s10994-021-06111-6" target="_blank"> A network-based positive and unlabeled learning approach for fake news detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85119356447</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>de Souza M.C., Marcacini R.M., dos Santos B.N., Rezende S.O., Nogueira B.M., Rossi R.G.</b></td></tr><tr><td colspan="3">Organisations: <b>ICMC-USP, FACOM-UFMS</b></td></tr><tr><td colspan="3">Fake news can rapidly spread through internet users and can deceive a large audience. Due to those characteristics, they can have a direct impact on political and economic events. Machine Learning approaches have been used to assist fake news identification. However, since the spectrum of real news is broad, hard to characterize, and expensive to label data due to the high update frequency, One-Class Learning (OCL) and Positive and Unlabeled Learning (PUL) emerge as an interesting approach for content-based fake news detection using a smaller set of labeled data than traditional machine learning techniques. In particular, network-based approaches are adequate for fake news detection since they allow incorporating information from different aspects of a publication to the problem modeling. In this paper, we propose a network-based approach based on Positive and Unlabeled Learning by Label Propagation (PU-LP), a one-class and transductive semi-supervised learning algorithm that performs classification by first identifying potential interest and non-interest documents into unlabeled data and then propagating labels to classify the remaining unlabeled documents. A label propagation approach is then employed to classify the remaining unlabeled documents. We assessed the performance of our proposal considering homogeneous (only documents) and heterogeneous (documents and terms) networks. Our comparative analysis considered four OCL algorithms extensively employed in One-Class text classification (k-Means, k-Nearest Neighbors Density-based, One-Class Support Vector Machine, and Dense Autoencoder), and another traditional PUL algorithm (Rocchio Support Vector Machine). The algorithms were evaluated in three news collections, considering balanced and extremely unbalanced scenarios. We used Bag-of-Words and Doc2Vec models to transform news into structured data. Results indicated that PU-LP approaches are more stable and achieve better results than other PUL and OCL approaches in most scenarios, performing similarly to semi-supervised binary algorithms. Also, the inclusion of terms in the news network activate better results, especially when news are distributed in the feature space considering veracity and subject. News representation using the Doc2Vec achieved better results than the Bag-of-Words model for both algorithms based on vector-space model and document similarity network.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/GCAT52182.2021.9587698" target="_blank"> Microblogs Deception Detection using BERT and Multiscale CNNs<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85119473522</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Raj C., Meel P.</b></td></tr><tr><td colspan="3">Organisations: <b>Delhi Technological University</b></td></tr><tr><td colspan="3">Online news consumption has rapidly increased, and so has the proliferation of false information. People worldwide have mainly become dependent on social media networks to intake news about the happenings around them. Also, the data is profoundly contaminated with wrong information that harms society in uncountable ways. It is of huge importance to be able to identify a false message. The research society is contributing to solving the problem by developing machine learning and deep learning algorithms. With misinformation spreading ubiquitously, various data modalities have emerged that become carriers of such false news. Research trend is advancing towards multi-modal fake news detection to authenticate text, images, and videos on the web. Existing studies have elaborated on the successful use of RNNs and CNNs. Being a new NLP technique, BERT has been used by a limited number of studies, while multiscale CNNs have not been explored yet to apply fake news detection. This research proposes a novel framework using BERT and multiscale CNNs to perform multi-modal fake news classification and achieve results higher than the existing state-of-the-art techniques.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-16-2641-8_10" target="_blank"> Hybrid Ensemble for Fake News Detection: An Attempt<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85119833442</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Singh L.</b></td></tr><tr><td colspan="3">Organisations: <b>Punjab Engineering College</b></td></tr><tr><td colspan="3">Fake news detection has been a challenging problem in the field of machine learning. Researchers have approached it via several techniques using old statistical classification models and modern deep learning. Today, with the growing amount of data, developments in the field of NLP and ML, and an increase in the computation power at disposal, there are infinite permutations and combinations to approach this problem from a different perspective. In this paper, we try different methods to tackle fake news, and try to build, and propose the possibilities of a hybrid ensemble combining the classical machine learning techniques with the modern deep learning approaches.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.3390/math9222988" target="_blank"> Can fake news detection models maintain the performance through time? A longitudinal evaluation of twitter publications<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85119918132</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Guimaraes N., Figueira A., Torgo L.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Porto, Dalhousie University</b></td></tr><tr><td colspan="3">The negative impact of false information on social networks is rapidly growing. Current research on the topic focused on the detection of fake news in a particular context or event (such as elections) or using data from a short period of time. Therefore, an evaluation of the current proposals in a long-term scenario where the topics discussed may change is lacking. In this work, we deviate from current approaches to the problem and instead focus on a longitudinal evaluation using social network publications spanning an 18-month period. We evaluate different combinations of features and supervised models in a long-term scenario where the training and testing data are ordered chronologically, and thus the robustness and stability of the models can be evaluated through time. We experimented with 3 different scenarios where the models are trained with 15-, 30-, and 60-day data periods. The results show that detection models trained with word-embedding features are the ones that perform better and are less likely to be affected by the change of topics (for example, the rise of COVID-19 conspiracy theories). Furthermore, the additional days of training data also increase the performance of the best feature/model combinations, although not very significantly (around 2%). The results presented in this paper build the foundations towards a more pragmatic approach to the evaluation of fake news detection models in social networks.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.neunet.2021.11.006" target="_blank"> ARCNN framework for multimodal infodemic detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85119918428</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Raj C., Meel P.</b></td></tr><tr><td colspan="3">Organisations: <b>Delhi Technological University</b></td></tr><tr><td colspan="3">Fake news and misinformation have adopted various propagation media over time, nowadays spreading predominantly through online social networks. During the ongoing COVID-19 pandemic, false information is affecting human life in many spheres The world needs automated detection technology and efforts are being made to meet this requirement with the use of artificial intelligence. Neural network detection mechanisms are robust and durable and hence are used extensively in fake news detection. Deep learning algorithms demonstrate efficiency when they are provided with a large amount of training data. Given the scarcity of relevant fake news datasets, we built the Coronavirus Infodemic Dataset (CovID), which contains fake news posts and articles related to coronavirus. This paper presents a novel framework, the Allied Recurrent and Convolutional Neural Network (ARCNN), to detect fake news based on two different modalities: text and image. Our approach uses recurrent neural networks (RNNs) and convolutional neural networks (CNNs) and combines both streams to generate a final prediction. We present extensive research on various popular RNN and CNN models and their performance on six coronavirus-specific fake news datasets. To exhaustively analyze performance, we present experimentation performed and results obtained by combining both modalities using early fusion and four types of late fusion techniques. The proposed framework is validated by comparisons with state-of-the-art fake news detection mechanisms, and our models outperform each of them.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ACCESS.2021.3129329" target="_blank"> A Comprehensive Review on Fake News Detection with Deep Learning<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85120045642</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Mridha M.F., Keya A.J., Rahman M.S., Hamid M.A., Monowar M.M.</b></td></tr><tr><td colspan="3">Organisations: <b>Bangladesh University of Business and Technology, King Abdulaziz University</b></td></tr><tr><td colspan="3">A protuberant issue of the present time is that, organizations from different domains are struggling to obtain effective solutions for detecting online-based fake news. It is quite thought-provoking to distinguish fake information on the internet as it is often written to deceive users. Compared with many machine learning techniques, deep learning-based techniques are capable of detecting fake news more accurately. Previous review papers were based on data mining and machine learning techniques, scarcely exploring the deep learning techniques for fake news detection. However, emerging deep learning-based approaches such as Attention, Generative Adversarial Networks, and Bidirectional Encoder Representations for Transformers are absent from previous surveys. This study attempts to investigate advanced and state-of-the-art fake news detection mechanisms pensively. We begin with highlighting the fake news consequences. Then, we proceed with the discussion on the dataset used in previous research and their NLP techniques. A comprehensive overview of deep learning-based techniques has been bestowed to organize representative methods into various categories. The prominent evaluation metrics in fake news detection are also discussed. Nevertheless, we suggest further recommendations to improve fake news detection mechanisms in future research directions.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1108/OIR-10-2020-0441" target="_blank"> Quantitative and qualitative analysis of linking patterns of mainstream and partisan online news media in Central Europe<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85120500826</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Hrckova A., Moro R., Srba I., Bielikova M.</b></td></tr><tr><td colspan="3">Organisations: <b>Kempelen Institute of Intelligent Technologies</b></td></tr><tr><td colspan="3">Purpose: Partisan news media, which often publish extremely biased, one-sided or even false news, are gaining popularity world-wide and represent a major societal issue. Due to a growing number of such media, a need for automatic detection approaches is of high demand. Automatic detection relies on various indicators (e.g. content characteristics) to identify new partisan media candidates and to predict their level of partisanship. The aim of the research is to investigate to a deeper extent whether it would be appropriate to rely on the hyperlinks as possible indicators for better automatic partisan news media detection. Design/methodology/approach: The authors utilized hyperlink network analysis to study the hyperlinks of partisan and mainstream media. The dataset involved the hyperlinks of 18 mainstream media and 15 partisan media in Slovakia and Czech Republic. More than 171 million domain pairs of inbound and outbound hyperlinks of selected online news media were collected with Ahrefs tool, analyzed and visualized with Gephi software. Additionally, 300 articles covering COVID-19 from both types of media were selected for content analysis of hyperlinks to verify the reliability of quantitative analysis and to provide more detailed analysis. Findings: The authors conclude that hyperlinks are reliable indicators of media affinity and linking patterns could contribute to partisan news detection. The authors found out that especially the incoming links with dofollow attribute to news websites are reliable indicators for assessing the type of media, as partisan media rarely receive links with dofollow attribute from mainstream media. The outgoing links are not such reliable indicators as both mainstream and partisan media link to mainstream sources similarly. Originality/value: In contrast to the extensive amount of research aiming at fake news detection within a piece of text or multimedia content (e.g. news articles, social media posts), the authors shift to characterization of the whole news media. In addition, the authors did a geographical shift from more researched US-based media to so far under-researched European context, particularly Central Europe. The results and conclusions can serve as a guide how to derive new features for an automatic detection of possibly partisan news media by means of artificial intelligence (AI). Peer review: The peer review history for this article is available at the following link: https://publons.com/publon/10.1108/OIR-10-2020-0441.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/TIFS.2021.3131026" target="_blank"> Poligraph: Intrusion-Tolerant and Distributed Fake News Detection System<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85120566760</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Shan G., Zhao B., Clavin J.R., Zhang H., Duan S.</b></td></tr><tr><td colspan="3">Organisations: <b>Temple University, Tsinghua University, University of Maryland, Shandong Institute of Blockchain, Tsinghua University</b></td></tr><tr><td colspan="3">We present Poligraph, an intrusion-tolerant and decentralized fake news detection system. Poligraph aims to address architectural, system, technical, and social challenges of building a practical, long-term fake news detection platform. We first conduct a case study for fake news detection at authors' institute, showing that machine learning-based reviews are less accurate but timely, while human reviews, in particular, experts reviews, are more accurate but time-consuming. This justifies the need for combining both approaches. At the core of Poligraph is two-layer consensus allowing seamlessly combining machine learning techniques and human expert determination. We construct the two-layer consensus using Byzantine fault-tolerant (BFT) and asynchronous threshold common coin protocols. We prove the correctness of our system in terms of conventional definitions of security in distributed systems (agreement, total order, and liveness) as well as new review validity (capturing the accuracy of news reviews). We also provide theoretical foundations on parameter selection for our system. We implement Poligraph and evaluate its performance on Amazon EC2 using a variety of news from online publications and social media. We demonstrate Poligraph achieves throughput of more than 5,000 transactions per second and latency as low as 0.05 second. The throughput of Poligraph is only marginally ( {4%} - {7%} ) slower than that of an unreplicated, single-server implementation. In addition, we conduct a real-world case study for the review of fake and real news among both experts and non-experts, which validates the practicality of our approach.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.32604/cmc.2022.021449" target="_blank"> Arabic fake news detection using deep learning<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85120808570</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Fouad K.M., Sabbeh S.F., Medhat W.</b></td></tr><tr><td colspan="3">Organisations: <b>Benha University, University of Jeddah, Nile University</b></td></tr><tr><td colspan="3">Nowadays, an unprecedented number of users interact through social media platforms and generate a massive amount of content due to the explosion of online communication. However, because user-generated content is unregulated, it may contain offensive content such as fake news, insults, and harassment phrases. The identification of fake news and rumors and their dissemination on social media has become a critical requirement. They have adverse effects on users, businesses, enterprises, and even political regimes and governments. State of the art has tackled the English language for news and used feature-based algorithms. This paper proposes a model architecture to detect fake news in the Arabic language by using only textual features.Machine learning and deep learning algorithms were used. The deep learning models are used depending on conventional neural nets (CNN), long short-term memory (LSTM), bidirectional LSTM (BiLSTM), CNN+LSTM, and CNN + BiLSTM. Three datasets were used in the experiments, each containing the textual content of Arabic news articles; one of them is reallife data. The results indicate that the BiLSTM model outperforms the other models regarding accuracy rate when both simple data split and recursive training modes are used in the training process.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-16-6636-0_55" target="_blank"> An Ensemble Method-Based Machine Learning Approach Using Text Mining to Identify Semantic Fake News<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85120875112</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Hossain F., Uddin M.N., Halder R.K.</b></td></tr><tr><td colspan="3">Organisations: <b>Jagannath University</b></td></tr><tr><td colspan="3">Fake news is a frequent problem that is having a massive influence on our social lives, especially in the political arena. Social media provides a forum for people to publicly share their thoughts and feelings, and it has made conversation easier. It also allows people to manipulate the power to spread misleading facts intentionally. Misleading or unreliable information is widely disseminated via prominent social media sites such as Facebook and Twitter in the form of videos, tweets, blogs, and URLs. Anyone can produce and spread fake news content for personal or professional benefit. In these circumstances, detecting and flagging certain material on social media is an emerging task in the recent era. We have proposed an ensemble method-based machine learning approach to identify semantic fake news directly from the text using text mining. Natural Language Processing technique is applied for data preprocessing on LIAR dataset collected from PolitiFact and convert it into a vector form. Univariate Selection, Select Percentile, Select from Model, Linear SVC, Extra Trees Classifier, and Chi-Square feature selection techniques are used to select the effective features directly from the text data. To combine outputs from multiple classifiers, namely Multinomial Naïve Bayes (MNB), Random Forest (RF), K-Nearest Neighbor (KNN), and Gradient Boosting (GB), an ensemble method is constructed. The ensemble method allows producing better prediction compared to a single classifier. Our proposed model obtained an accuracy of 45.48% for multi-class, and an accuracy of 71.8424, AUC-ROC score of 0.6351 better than the previous studies.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.ipm.2021.102740" target="_blank"> What the fake? Probing misinformation detection standing on the shoulder of novelty and emotion<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85120942200</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Kumari R., Ashok N., Ghosal T., Ekbal A.</b></td></tr><tr><td colspan="3">Organisations: <b>Indian Institute of Technology Patna</b></td></tr><tr><td colspan="3">One of the most time-critical challenges for the Natural Language Processing (NLP) community is to combat the spread of fake news and misinformation. Existing approaches for misinformation detection use neural network models, statistical methods, linguistic traits, fact-checking strategies, etc. However, the menace of fake news seems to grow more vigorous with the advent of humongous and unusually creative language models. Relevant literature reveals that one major characteristic of the virality of fake news is the presence of an element of surprise in the story, which attracts immediate attention and invokes strong emotional stimulus in the reader. In this work, we leverage this idea and propose textual novelty detection and emotion prediction as the two tasks relating to automatic misinformation detection. We re-purpose textual entailment for novelty detection and use the models trained on large-scale datasets of entailment and emotion to classify fake information. Our results correlate with the idea as we achieve state-of-the-art (SOTA) performance (7.92%, 1.54%, 17.31% and 8.13% improvement in terms of accuracy) on four large-scale misinformation datasets. We hope that our current probe will motivate the community to explore further research on misinformation detection along this line. The source code is available at the GitHub.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1038/s41598-021-03100-6" target="_blank"> New explainability method for BERT-based model in fake news detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85120977480</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Szczepanski M., Pawlicki M., Kozik R., Choras M.</b></td></tr><tr><td colspan="3">Organisations: <b>ITTI Sp. z o.o., Bydgoszcz University of Science and Technology (PBS)</b></td></tr><tr><td colspan="3">The ubiquity of social media and their deep integration in the contemporary society has granted new ways to interact, exchange information, form groups, or earn money—all on a scale never seen before. Those possibilities paired with the widespread popularity contribute to the level of impact that social media display. Unfortunately, the benefits brought by them come at a cost. Social Media can be employed by various entities to spread disinformation—so called ‘Fake News’, either to make a profit or influence the behaviour of the society. To reduce the impact and spread of Fake News, a diverse array of countermeasures were devised. These include linguistic-based approaches, which often utilise Natural Language Processing (NLP) and Deep Learning (DL). However, as the latest advancements in the Artificial Intelligence (AI) domain show, the model’s high performance is no longer enough. The explainability of the system’s decision is equally crucial in real-life scenarios. Therefore, the objective of this paper is to present a novel explainability approach in BERT-based fake news detectors. This approach does not require extensive changes to the system and can be attached as an extension for operating detectors. For this purposes, two Explainable Artificial Intelligence (xAI) techniques, Local Interpretable Model-Agnostic Explanations (LIME) and Anchors, will be used and evaluated on fake news data, i.e., short pieces of text forming tweets or headlines. This focus of this paper is on the explainability approach for fake news detectors, as the detectors themselves were part of previous works of the authors.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Fake news detection using stacked ensemble of classifiers<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85121121857</td><td>Year: <b>2017</b></td></tr><tr><td colspan="3">Authors: <b>Thorne J., Chen M., Myrianthous G., Pu J., Wang X., Vlachos A.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Sheffield</b></td></tr><tr><td colspan="3">Fake news has become a hotly debated topic in journalism. In this paper, we present our entry to the 2017 Fake News Challenge which models the detection of fake news as a stance classification task that finished in 11th place on the leader board. Our entry is an ensemble system of classifiers developed by students in the context of their coursework. We show how we used the stacking ensemble method for this purpose and obtained improvements in classification accuracy exceeding each of the individual models' performance on the development data. Finally, we discuss aspects of the experimental setup of the challenge.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Semi-automatic annotation proposal for increasing a fake news dataset in Spanish<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85121307195</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Bonet-Jover A.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Alicante</b></td></tr><tr><td colspan="3">The digital era has become an ally of fake news, since it has increased the spread and amount of false information. Fake news is a global problem that causes disorder and generates fear. This phenomenon must be attacked in the same environment in which it is generated: in the digital environment. This paper presents the current state of my doctoral thesis which focuses on the linguistic modelling applied to the automatic detection of fake news through Natural Language Processing (NLP). In order to study the linguistic characteristics of fake news and to create computational models that automate its detection, labelled datasets are needed, but this is a costly task that requires time and expertise. A fake news dataset and an annotation guide were created ad hoc in a previous work to analyse all the parts and elements of a news item. However, after creating and training our system, we realised that the time spent was not proportional to the low annotated data obtained. The need of creating a larger corpus to train and test our hypothesis has led us to think about a way of increasing our corpus without spending so much time. For that purpose, a semi-automatic annotation is proposed for reducing time while increasing speed and quantity of the examples annotated. This proposal, besides allowing us to make progress in our research, may facilitate the creation of datasets, which are essential in NLP research.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-90087-8_17" target="_blank"> Fact Checking: An Automatic End to End Fact Checking System<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85121483440</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Ahmed S., Hinkelmann K., Corradini F.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Camerino, FHNW University of Applied Sciences and Arts Northwestern Switzerland</b></td></tr><tr><td colspan="3">Fact checking is an important topic that needs to be studied scientifically to determine how fake news is spread. Previous work in this area has primarily focused on document- level fact checking. In this paper, however, we will focus on individual statements and the relationship between target statements and the overall news text. In larger context, we will compare statements to known facts, which we will tag within the statement. For dual verification, we will compare our findings to forty mainstream news sources as well as the online encyclopedia (Wikipedia). If a news is detected as fake the existing techniques should block it immediately due to its function, as we cannot replace it. However if a news is detected as fake, we need at least an expert opinion or review before blocking that particular news. This process helps third-party fact-checking organizations to solve the issue; but it is also a time-consuming process. We will attempt to solve the problem of automatically identifying factual claims at the sentence level. Despite its importance, this is a relatively under-studied problem. Existing fake news systems are based on predictive models that simply classify whether a news item is fake or not. Some models use source reliability and network structure so the major challenge in these cases is to train the model. But due to the unavailability of corpora, this is impossible to accomplish. We created a new corpus for social media claims, containing statements that have been fact checked by three reputable sources, and then trained a machine learning model to predict the facts of the news. We presented a fact checking system that takes news as input and then produces an output with an aggregation such as fake, non fake or unclear. To the best of our knowledge it is the only system that has such capabilities.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-90087-8_7" target="_blank"> Fake News Detection Using Ensemble Learning and Machine Learning Algorithms<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85121485745</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Elyassami S., Alseiari S., ALZaabi M., Hashem A., Aljahoori N.</b></td></tr><tr><td colspan="3">Organisations: <b>Abu Dhabi Polytechnic</b></td></tr><tr><td colspan="3">Digital news becomes widely accessible to a large community of users with the advancement of several channels of communication and the progression of technology and thus, contributes to the increase of spreading of fake news. The current study experiments and investigates machine learning models that classify news as either fake or real. Five classifiers were implemented using Random Forest, Support Vector Machine, Gradient Boosting, Logistic Regression, and Naïve Bayes algorithms. Models were trained using merged open-source datasets extracted from online sources covering different domains. Text lemmatization, vectorization, and tokenization were applied to extract useful information from news text and to improve the generalization capabilities and the performance of fake news classification models. The impact of the voting strategy on the performance of ensemble learning models were explored. The performance of the five classifiers was evaluated using the accuracy, the F1-Score, the recall, and the precision. The attained results are promising. The ensemble classifier trained using random forest algorithm and gradient boosting algorithm outperform the other classifiers and thus it might be used effectively against fake news spreading.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-90087-8_8" target="_blank"> Evaluation of Machine Learning Methods for Fake News Detection<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85121495760</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Papakostas D., Stavropoulos G., Katsaros D.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Thessaly</b></td></tr><tr><td colspan="3">In a cyber-connected world, fake information appears to be more enticing or interesting to the audience because of their limited attention spans and the plethora of content choices. Taking this into account, fake news detection/classification is definitely becoming of paramount importance in order to avoid the so-called reality vertigo, preclude misinformation and protect actual reality. This chapter presents a comprehensive performance evaluation of eight machine learning algorithms who perform fake news detection/classification based on regression, support vector machines, neural networks, decision trees and Bayes theorem. In every case, our study reaffirms that performance is governed by the nature of data, nevertheless, it sheds light and draws safe generic conclusions with respect to the dimensionality that each algorithm should have, the kind of training that should be performed beforehand for each one of them, and finally the method for generating vector representations of textual information.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-90087-8_6" target="_blank"> Fake News Detection Using Machine Learning and Natural Language Processing<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85121496278</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Singh M., Patel M., Padiya J.</b></td></tr><tr><td colspan="3">Organisations: <b>Symbiosis International (Deemed University), Nirma University</b></td></tr><tr><td colspan="3">In the present world, online news platform greatly influences our society and culture both in positive and negative ways. Being dependent on social media there is widespread fake news with misleading information leading to the chances where the reputation of the company is threatened. The influence of media has led to heights of depression and mental health issues as they don’t find the real cause of it. This makes it an important issue that needs to be explored, analyzed and resolved to maintain peace and harmony in the world. Herein, this kind of pandemic as well where everything is unpredictable there are many cases where false news are been circulated and due to which the fear and panic have increased in the people. To resolve the issue, the chapter elaborates on developing a system using Machine Learning and Natural Language processing that uses RNN and its techniques like LSTM and Bi-LSTM for the detection of misleading information. The implementation is done for general fake news and purely Covid-19 fake news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-90087-8_11" target="_blank"> Modeling and Solving the Fake News Detection Scheduling Problem<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85121517108</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Aqil S., Lahby M.</b></td></tr><tr><td colspan="3">Organisations: <b>University Hassan II</b></td></tr><tr><td colspan="3">The large amount of information on social networks makes it difficult to distinguish fake news from good news. Society and individuals are often affected by the extent of the dissemination of false information. Currently the fake news detection (FND) is becoming a concern for scientific researchers. In this article, we propose a new approach to modeling the FND document processing process using a flow shop scheduling problem (FSSP). Our approach consists in modeling the FND data processing in the FSSP. In fact, in this model the process is composed of several phases arranged in series forming a FSSP in the flow work. The documents are considered as tasks to be processed available in front of the first machine of the model will be processed by all the machines in the same order. In order, to solve this problem we propose three metaheuristics: the iterated greedy (IG), the genetic (GA) and the artificial bee colony (ABC) algorithms. The goal is to minimize the maximum completion time of the set of documents called the makespan (Cmax ). Various instances are tested by varying the number of documents in front of the queue in the all machines. The simulation results showed that the IG algorithm performs the best compared to other algorithms.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-90087-8_10" target="_blank"> Deep Learning with Self-Attention Mechanism for Fake News Detection<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85121525908</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Cvitanovic I., Babac M.B.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Zagreb</b></td></tr><tr><td colspan="3">Nowadays, fake news is one of major concerns in our society, that is a form of news consisting of deliberate disinformation or hoaxes spread via traditional news media or online social media. Thus, this study aims to explore state-of-the-art methods for detecting fake news in order to design and implement classification models. Four different classification models based on deep learning with self-attention mechanism were trained and evaluated using current datasets that are available for this purpose. Three models explored traditional supervised learning, while the fourth model explored transfer learning by fine-tuning the pre-trained language model for the same task. All four models yield comparable results with the fourth model achieving the best classification accuracy.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-90087-8_20" target="_blank"> Analyzing Deep Learning Optimizers for COVID-19 Fake News Detection<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85121530326</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Chakraborty A., Biswas A.</b></td></tr><tr><td colspan="3">Organisations: <b>Tezpur University, National Institute of Technology Silchar</b></td></tr><tr><td colspan="3">In this time of COVID-19 crisis, the threat posed by the propagation of misinformation leading to mistrust needs to be kept in check. Misinformation related to the vaccines, remedies, false symptoms, etc. are spiraling out of control. We might not be able to directly put a stop to the flow or spread of fake news to a large extent at the moment, but it may be able to identify it as such with the help of Natural Language Processing (NLP) tools and Deep Learning (DL) algorithms. Steps involved in achieving this goal can be narrowed down into collection and analysis of data from various sources, sorting out the articles as covid-relevant and categorizing them as real or fake using DL models. However, DL models use different optimizers in the learning process, which plays an important role in identifying the fake news. This chapter also compares the efficiency of different optimizers in the context of COVID-19 fake news detection using DL models. The newly developed Continuous Coin Betting (CoCoB) Optimizer for DL studied extensively for fake news detection and performed compared with four other widely used optimizers. The comparative analysis shows the CoCoB as well as popularly used Adam optimizers are quite effective in finding optimal classification results for detection of fake news related to COVID-19.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-90087-8_1" target="_blank"> Online Fake News Detection Using Machine Learning Techniques: A Systematic Mapping Study<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85121543572</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Lahby M., Abakarim Y., Aqil S., Yafooz W.M.S.</b></td></tr><tr><td colspan="3">Organisations: <b>University Hassan II, Taibah University</b></td></tr><tr><td colspan="3">This last decade, the amount of data exchanged on the Internet and more specifically on social media networks is growing exponentially. Fake News phenomenon has become a major problem threatening the credibility of these social networks. Machine Learning (ML) techniques represent a promising solution to deal with this issue. For that, several solutions and algorithms using Machine Learning have been proposed in literature in the recent time for detecting fake news generated by different digital media platforms. This chapter aims to conduct a systematic mapping study to analyze and synthesize studies concerning the utilization of machine learning techniques for detecting fake news. Therefore, a total number of 76 relevant papers published on this subject between 1 January 2010 and 30 June 2021 were carefully selected. The selected articles were classified and analyzed according to eight criteria: channel and year of publication, research type, study domain, study platform, study context, study category, feature, and machine learning techniques used to handle categorical data. The results showed that most of the selected papers use both features text/content and linguistic to design machine learning models. Furthermore, SVM technique, and Deep Neural Network (DNN) technique were the most binary classification algorithms used to combat fake news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-90087-8_3" target="_blank"> Fake News Detection in Internet Using Deep Learning: A Review<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85121543743</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Barrutia-Barreto I., Seminario-Cordova R., Chero-Arana B.</b></td></tr><tr><td colspan="3">Organisations: <b>Innova Scientific</b></td></tr><tr><td colspan="3">The main objective of this research was to explore, from a reflexivity approach, the current state of Deep learning techniques for automatic detection of fake news on the Internet, analyzing the most important Deep learning algorithms and studies on their effectiveness in detecting distrustful information. The research methodology employed was bibliographic, documentary and descriptive. The information was collected from several scientific articles provided by indexed journals and web platforms, using keywords such as “fake news”, “Deep learning” and “neural networks” for the compilation. As a result of this research, it was concluded that Deep learning techniques present a better performance than conventional methods and will be of great importance in the future of war against fake news due to their potential in automatic detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-90087-8_19" target="_blank"> Applying Fuzzy Logic and Neural Network in Sentiment Analysis for Fake News Detection: Case of Covid-19<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85121561201</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Mohamed B., Haytam H., Abdelhadi F.</b></td></tr><tr><td colspan="3">Organisations: <b>UAE</b></td></tr><tr><td colspan="3">The pandemic we witnessed starting from December 2019, was accompanied by a significant rise in internet usage, and the social media, in particular, people were asked to stay at home to limit the spreading of the Covid-19 virus, this isolation made fake news a dangerous weapon that can directly harm people’s wellbeing and encourage antagonism and racism. Considering the re-al danger of this misinformation and disinformation, fake news research witnessed a surge of contributions that apply machine learning models, deep learning, and sentiment analysis, but among these models and especially those that use sentiment analysis, we found that there is a lack of the integration of the fuzzy aspect of our language, which may give more details and accuracy to the detection of fake news. In this work, we extend the classification model from our previous work by combining a deep learning algorithm LSTM with fuzzy logic for sentiment-aware classification of fake news. We experiment with a dataset that contains over than 13 K of covid-19 text content al-ready labeled as being real or fake, and we compared the results of our model with the state-of-the-art methods that do not incorporate fuzzy logic and sentiment for fake news classification. and we observed that our approach yields better results.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-90087-8_2" target="_blank"> Using Artificial Intelligence Against the Phenomenon of Fake News: A Systematic Literature Review<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85121562210</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Al-Asadi M.A., Tasdemir S.</b></td></tr><tr><td colspan="3">Organisations: <b>Selçuk University</b></td></tr><tr><td colspan="3">Social networks like Facebook and Twitter have become an important way for people to connect and share their thoughts. The most important feature of social networks is the rapid sharing of information. In this context, users often share fake news without even knowing it. Fake news affects people's daily lives and its consequences can range from mere disturbing to misleading societies or even countries. The aim of this study was to provide a literature review that investigates how artificial intelligence tools are used in detecting fake news on social media and how successful they are in different fields. The study was developed using the methodology presented by Keela (2007), which is a formal methodology in computer science. The results of the study show that artificial intelligence tools such as machine learning and deep learning are widely used to develop systems for detecting fake news in various fields such as politics, sports, business, etc. and that these two tools have proven to be effective in classifying fake news. This study is intended to guide researchers as well as people involved in this field. It is believed that this study will help fill a gap in this field by presenting the main tools used for this purpose and shed light on further research. It is also hoped that this study will be a guide for researchers and individuals interested in the detection of fake news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-90087-8_5" target="_blank"> Fandet Semantic Model: An OWL Ontology for Context-Based Fake News Detection on Social Media<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85121566764</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Bani-Hani A., Majdalawieh M., Adedugbe O., Benkhelifa E.</b></td></tr><tr><td colspan="3">Organisations: <b>Zayed University, Staffordshire University</b></td></tr><tr><td colspan="3">The detection of fake news on social media has become a very active research area. Several approaches and techniques have been proposed and implemented to address the challenge, across diverse technological domains such as NLP (Natural Language Processing) and machine learning. While substantial progress has been made on these, it remains a daunting task due to complexities in its nature. Therefore, it has become pertinent to significantly explore and integrate other technologies to detect fake news on social media. Hence, this research focuses on further exploring and developing native semantic technology solutions for the discourse space. The initial result is a taxonomy classifying socially contextual features for news articles and then Fandet: an OWL ontology for context-based fake news detection by semantically annotating contextual features of news articles and datasets using the ontology. This provides a basis for patterns recognition, analysis, and identification of news articles on social media as either fake or not.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-90087-8_4" target="_blank"> Early Detection of Fake News from Social Media Networks Using Computational Intelligence Approaches<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85121570690</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Ogundokun R.O., Arowolo M.O., Misra S., Oladipo I.D.</b></td></tr><tr><td colspan="3">Organisations: <b>Landmark University Omu-Aran, Covenant University Ota, University of Ilorin</b></td></tr><tr><td colspan="3">In recent years, misinformation which includes false news (FN) has become a worldwide issue owing to its exponential development, mostly on social media (SM). The broad dissemination of misinformation and FN can create harmful societal repercussions. Despite current improvements, spotting fake news remains difficult owing to its intricacy, multiplicity, multi-modality, and fact-scrutiny or annotation expenses. Therefore, there is a necessity for Computational Intelligence Approaches (CIA) that can identify this fake news automatically. This study projected using dimensionality reduction (DR) approach to decrease the dimensionality of the feature vectors before sending them to the classifiers. The study focuses on a computational intelligence-based fake news detection system and a novel approach of employing three CIA for the detection of FN was proposed. The CIA employed for this study are Genetic Algorithm (GA), K-Nearest Neighbor (KNN), and Bagged Ensembled Learning (BEL). The proposed system performance was evaluated utilizing confusion matrix measures like accuracy, sensitivity, specificity, precision, and f-measure. The system was compared with the existing system and it was deduced that the projected system outperformed that of existing systems with an accuracy of 99.28%, sensitivity of 99.28%, precision of 99.99%, and f-measure of 99.63%. In conclusion, it was discovered that GA + KNN performance in terms of accuracy, sensitivity, specificity, precision, and f-measure sur-passed that of the GA + BEL.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Fake news detection related to the COVID-19 in Slovak language using deep learning methods<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85121613972</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Sarnovsky M., Maslej-Kresnakova V., Ivancova K.</b></td></tr><tr><td colspan="3">Organisations: <b>Technical University of Košice</b></td></tr><tr><td colspan="3">One of the biggest problems nowadays in the online environment is the spreading of misinformation. Especially during a global pandemic, the most popular topics of fake news are related to coronavirus. Therefore, automatic detection of such news in the online media or social networks can help with the prevention of misinformation spreading. During the recent years, deep learning models proved to be very efficient in this task. However, the majority of the research focuses on the training of these models using publicly available data collections, mostly containing news articles written in the English language. As the spreading of fake news is a global phenomenon, it is also necessary to explore these approaches on the various local data sources. The work presented in this paper focuses on using the deep learning models for the automatic detection of fake news written in the Slovak language. We collected the data from multiple local online news sources related to the COVID-19 pandemic and used it to train and evaluate the various deep learning models. Thanks to the combination of bidirectional long-short-term memory network with one-dimensional convolutional layers, we achieved an average macro F1 score on an independent test set of 94%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-91305-2_19" target="_blank"> Fake News Detection Using Deep Learning<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85121614679</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Sharma S., Saraswat M., Dubey A.K.</b></td></tr><tr><td colspan="3">Organisations: <b>The NorthCap University, ABES Engineering College</b></td></tr><tr><td colspan="3">Owing to the rapid explosion of social networking portals in the past decade, we spread and consume information via the internet at an expeditious rate. It has caused an alarming proliferation of fake news on social networks. The global nature of social networks has facilitated international blowout of fake news. Fake news has proven to increase political polarization and partisan conflict. Fake news is also found to be more rampant on social media than mainstream media. The evil of fake news is garnering a lot of attention and research effort. In this work, we have tried to handle the spread of fake news via tweets. We have performed fake news classification by employing user characteristics as well as tweet text. Thus, trying to provide a holistic solution for fake news detection. For classifying user characteristics, we have used the XGBoost algorithm which is a collaboration of decision trees utilizing the boosting method. Further to correctly classify the tweet text we used various natural language processing techniques to preprocess the tweets and then applied a sequential neural network and state-of-the-art BERT transformer to classify the tweets. The models have then been evaluated and compared with various baseline models to show that our approach effectively tackles this problem.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Detecting Fake News Spreaders with Behavioural, Lexical and Psycholinguistic Features Notebook for PAN at CLEF 2020<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85121770083</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Bello H.R.M., Heilmann L., Ronan E.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Copenhagen</b></td></tr><tr><td colspan="3">In this paper, we propose a multilingual approach to identifying fake news spreaders on Twitter data, as part of the PAN 2020 competition for author profiling. We manually engineered domain-specific features covering behavioural, lexical and psycholinguistic aspects and evaluated them using traditional machine learning models. The focus of this paper is exploring the problem domain by testing domain-specific features on different types of classifiers first, and evaluating a pure multilingual approach on combined English and Spanish texts second. Out of the methods tested, the Gradient Boosting classifiers performed best. We extended our experiments to a multilingual design using less preprocessing and feature selection, with a comparable result to the monolingual Gradient Boosting models.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Team Buster.ai at CheckThat! 2020: Insights and Recommendations to Improve Fact-Checking<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85121771250</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Bouziane M., Perrin H., Cluzeau A., Mardas J., Sadeq A.</b></td></tr><tr><td colspan="3">Organisations: <b>Buster.AI</b></td></tr><tr><td colspan="3">As part of the CheckThat! 2020 Task 2, we investigated sentence similarity using transformer models. In Task 2, the goal was to effectively rank claims based on their relevancy compared to an input tweet. While setting our baseline on sentence similarity for fact-checking, we gathered insights we felt compelled to share in this paper. We learned how multi-modal data utilization could foster significant uplifts in model performance. We also gained knowledge on which hybrid training and strong sampling worked best for fact-checking applications, and wanted to share our interpretation of the results we got. Finally, we want to explain our recommendations on data augmentations. All of the above allowed us to set our baseline in fact-checking in the CLEF Checkthat! 2020 Task 2 competition.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> A Multi-Aspect Classification Ensemble Approach for Profiling Fake News Spreaders on Twitter Notebook for PAN at CLEF 2020<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85121783896</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Hortenhuemer C., Zangerle E.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Innsbruck</b></td></tr><tr><td colspan="3">In this work, we attempt to differentiate authors of fake news and real news as part of the Profiling Fake News Spreaders on Twitter task at PAN. We propose a set of eight different language features to represent tweets. These representations are subsequently used in an ensemble classification model to identify fake news spreaders on Twitter. The approach is confined to the English language.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> EvolutionTeam at CLEF2020 – CheckThat! lab: Integration of linguistic and sentimental features in a fake news detection approach<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85121787643</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Touahri I., Mazroui A.</b></td></tr><tr><td colspan="3">Organisations: <b>University Mohamed First</b></td></tr><tr><td colspan="3">Misinformation is a growing problem around the web. The spread of such a phenomenon may impact public opinions. Hence fake news detection is indispensable. The first step for fact-checking is the selection of check worthy tweets for a certain topic, then ranking sentences from related web pages according to the carried evidence. Afterward, the claim will be verified according to evident sentences. At CLEF2020 – CheckThat! lab, three tasks run in Arabic, namely check-worthiness on tweets, evidence retrieval, and claim verification that corresponds respectively to task1, task3, and task4. We participated in the three tasks. We integrated manual sentiment features as well as named entities to detect fake news. The integration of sentiment information in the first task caused result degradation since there may be an overlap between check worthy and not check worthy tweets. For the second task, we explored the effect of sentiment presence and we used cosine similarity as a similarity measure between the claim and a specific snippet. The third task is a classification task based on sentiment and linguistic features to compute the overlap and the contradiction between the claim and the detected check worthy sentences. The results of task1 and task3 leave large room for improvement, whereas the results of task 4 are promising since our system reached 0.55 of F1-measure.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-91699-2_1" target="_blank"> A Heterogeneous Network-Based Positive and Unlabeled Learning Approach to Detect Fake News<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85121798783</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>de Souza M.C., Marcacini R.M., Rezende S.O., Nogueira B.M., Rossi R.G.</b></td></tr><tr><td colspan="3">Organisations: <b>University of São Paulo, Federal University of Mato Grosso do Sul</b></td></tr><tr><td colspan="3">The dynamism of fake news evolution and dissemination plays a crucial role in influencing and confirming personal beliefs. To minimize the spread of disinformation approaches proposed in the literature, automatic fake news detection generally learns models through binary supervised algorithms considering textual and contextual information. However, labeling significant amounts of real news to build accurate classifiers is difficult and time-consuming due to their broad spectrum. Positive and unlabeled learning (PUL) can be a good alternative in this scenario. PUL algorithms learn models considering little labeled data of the interest class and use unlabeled data to increase classification performance. This paper proposes a heterogeneous network variant of the PU-LP algorithm, a PUL algorithm based on similarity networks. Our network incorporates different linguistic features to characterize fake news, such as representative terms, emotiveness, pausality, and average sentence size. Also, we considered two representations of the news to compute similarity: term frequency-inverse document frequency, and Doc2Vec, which creates fixed-sized document representations regardless of its length. We evaluated our approach in six datasets written in Portuguese or English, comparing its performance with a binary semi-supervised baseline algorithm, using two well-established label propagation algorithms: LPHN and GNetMine. The results indicate that PU-LP with heterogeneous networks can be competitive to binary semi-supervised learning. Also, linguistic features such as representative terms and pausality improved the classification performance, especially when there is a small amount of labeled news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Detecting Fake News Spreaders on Twitter Using Universal Sentence Encoder Notebook for PAN at CLEF 2020<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85121799999</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Majumder S.B., Das D.</b></td></tr><tr><td colspan="3">Organisations: <b>Jadavpur University</b></td></tr><tr><td colspan="3">In the present attempt, we have developed a framework to detect the fake news spreaders on twitter by utilizing their tweets. Here, we have employed the pre-trained sentence embedding of Google and fed this embedding to a Long Short Term Memory (LSTM) based deep learning framework. Finally, the embedding is passed through an attention layer and predicts whether an author is prone to spread fake news or not. We have built models for two languages – English and Spanish. We have achieved 72% accuracy in this fake news spreader detection task.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Fake news spreader detection using neural tweet aggregation Notebook for PAN at CLEF 2020<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85121835680</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Bakhteev O., Ogaltsov A., Ostroukhov P.</b></td></tr><tr><td colspan="3">Organisations: <b>Antiplagiat, Moscow Institute of Physics and Technology (MIPT)</b></td></tr><tr><td colspan="3">The paper describes the neural networks-based approach for Profiling Fake News Spreaders on Twitter task at PAN 2020. The problem is reduced to the binary classification with a set of tweets of the user as an object to classify and class labels corresponding to users that are likely to spread fake news and ordinary users. To deal with a set of tweets we employ two neural network architectures: either based on recurrent or convolutional neural networks. We try aggregate the whole information obtained from the tweets to decide whether the user can spread fake news or not. We also present an ensemble of models that consists of a neural network and a classification model that works on each tweet separately.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> NLP&IR@UNED at CheckThat! 2020: A Preliminary Approach for Check-Worthiness and Claim Retrieval Tasks using Neural Networks and Graphs<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85121838140</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Martinez-Rico J.R., Araujo L., Martinez-Romo J.</b></td></tr><tr><td colspan="3">Organisations: <b>Universidad Nacional de Educación a Distancia (UNED), Instituto Mixto de Investigación - Escuela Nacional de Sanidad (IMIENS)</b></td></tr><tr><td colspan="3">Check-Worthiness and Claim Retrieval are two of the first tasks to be performed on the Fake News detection pipeline. In this article we present our approach to these tasks presented in the 2020 edition of the CheckThat! Lab. In the task 1, Tweet Check-Worthiness English, we propose a Bi-LSTM model with Glove Twitter embeddings where the number of inputs has been increased with a graph generated from the additional information provided for each tweet. In task 1 Arabic we have followed a similar approach but using a feed forward neural network model with Arabic embeddings. For the task 5, Debate Check-Worthiness, we propose a naive Bi-LSTM model with Glove embeddings. Finally, our approach to the task 2, Claim Retrieval, is based in a feed forward neural network model with features such as cosine similarity over Universal Sentence Encoder embeddings of tweets and claims, and other linguistic features extracted from both elements.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-92185-9_25" target="_blank"> DAFD: Domain Adaptation Framework for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85121844074</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Huang Y., Gao M., Wang J., Shu K.</b></td></tr><tr><td colspan="3">Organisations: <b>Chongqing University, Illinois Institute of Technology</b></td></tr><tr><td colspan="3">Nowadays, social media has become the leading platform for news dissemination and consumption. Due to the convenience of social media platforms, fake news spread at an unprecedented speed, which has brought severe adverse effects to society. In recent years, the method based on deep learning has shown superior performance in fake news detection. However, the training of this kind of model needs a large amount of labeled data. When a new domain of fake news appears, it usually contains only a small amount of labeled data. We proposed a novel Domain Adaptation framework for Fake news Detection named DAFD. It adopts a dual strategy based on domain adaptation and adversarial training, aligns the data distribution of the source domain and target domain during the pre-training process, and generates adversarial examples in the embedding space during the fine-tuning process to increase the generalization and robustness of the model, which can effectively detect fake news in a new domain. Extensive experiments on real datasets show that the proposed DAFD achieves the best performance compared with the state-of-the-art methods for a new domain with a small amount of labeled data.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-91434-9_29" target="_blank"> Fake News Detection Using LDA Topic Modelling and K-Nearest Neighbor Classifier<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85121857939</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Casillo M., Colace F., Santaniello D., Valentino C., Gupta B.B.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Salerno, National Institute of Technology Kurukshetra</b></td></tr><tr><td colspan="3">The spread of the COVID 19 virus has dramatically impacted global society by modifying its lifestyle. Social networks, video streaming tools, virtual collaborative environments have been the primary source of communication through the Internet. This suspension of the “real” has led all activities to be declined through new places and contexts of virtual discussion, increasing new problems, including the most important related to the spread of so-called Fake News. The spread of such news can be devastating: consider what is happening during the critical vaccination phase for COVID 19. In this scenario, systems able to recognize, in a practical way, the truthfulness of news are becoming more and more valuable. This paper aims to present an approach that combines probabilistic and machine learning techniques such as Latent Dirichlet Allocation and K-NN in combination with Context-Awareness techniques to identify the veracity of the news. Adopting Context-Awareness techniques within the proposed system allows a better definition of the operational context Fake News refers to, reducing the problems of semantic polysemy. The first results obtained through standard datasets or using data from real contexts are very interesting and promising.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s11042-021-11782-3" target="_blank"> CB-Fake: A multimodal deep learning framework for automatic fake news detection using capsule neural network and BERT<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85121859108</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Palani B., Elango S., Vignesh Viswanathan K.</b></td></tr><tr><td colspan="3">Organisations: <b>National Institute of Technology, Software Development Engineer Visa Inc</b></td></tr><tr><td colspan="3">The progressive growth of today’s digital world has made news spread exponentially faster on social media platforms like Twitter, Facebook, and Weibo. Unverified news is often disseminated in the form of multimedia content like text, picture, audio, or video. The dissemination of such false news deceives the public and leads to protests and creates troubles for the public and the government. Hence, it is essential to verify the authenticity of the news at an early stage before sharing it with the public. Earlier fake news detection (FND) approaches combined textual and visual features, but the semantic correlations between words were not addressed and many informative visual features were lost. To address this issue, an automated fake news detection system is proposed, which fuses textual and visual features to create a multimodal feature vector with high information content. The proposed work incorporates the bidirectional encoder representations from transformers (BERT) model to extract the textual features, which preserves the semantic relationships between words. Unlike the convolutional neural network (CNN), the proposed capsule neural network (CapsNet) model captures the most informative visual features from an image. These features are combined to obtain a richer data representation that helps to determine whether the news is fake or real. We investigated the performance of our model against different baselines using two publicly accessible datasets, Politifact and Gossipcop. Our proposed model achieves significantly better classification accuracy of 93% and 92% for the Politifact and Gossipcop datasets, respectively, compared to 84.6% and 85.6% for the SpotFake+ model.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-91434-9_33" target="_blank"> Machine Learning Technique for Fake News Detection Using Text-Based Word Vector Representation<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85121860663</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Gaurav A., Gupta B.B., Hsu C.-H., Castiglione A., Chui K.T.</b></td></tr><tr><td colspan="3">Organisations: <b>Ronin Institute, National Institute of Technology Kurukshetra, Asia University, National Chung Cheng University, University of Salerno, Hong Kong Metropolitan University</b></td></tr><tr><td colspan="3">In the modern era, social media has taken off, and more individuals may now utilise it to communicate and learn about current events. Although people get much of their information online, some of the Internet news is questionable and even deceptively presented. It is harder to distinguish fake news from the real news as it is sent about in order to trick readers into believing fabricated information, making it increasingly difficult for detection algorithms to identify fake news based on the material that is shared. As a result, an urgent demand for machine learning (ML), deep learning, and artificial intelligence models that can recognize fake news arises. The linguistic characteristics of the news provide a simple method for detecting false news, which the reader does not need to have any additional knowledge to make use of. We discovered that NLP techniques and text-based word vector representation may successfully predict fabricated news using a machine learning approach. In this paper, on datasets containing false and genuine news, we assessed the performance of six machine learning models. We evaluated model performance using accuracy, precision, recall, and F1-score.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.3390/data7010003" target="_blank"> News monitor: A framework for exploring news in real-time<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85121861678</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Panagiotou N., Saravanou A., Gunopulos D.</b></td></tr><tr><td colspan="3">Organisations: <b>National and Kapodistrian University of Athens</b></td></tr><tr><td colspan="3">News articles generated by online media are a major source of information. In this work, we present News Monitor, a framework that automatically collects news articles from a wide variety of online news portals and performs various analysis tasks. The framework initially identifies fresh news (first stories) and clusters articles about the same incidents. For every story, at first, it extracts all of the corresponding triples and, then, it creates a knowledge base (KB) using open information extraction techniques. This knowledge base is then used to create a summary for the user. News Monitor allows for the users to use it as a search engine, ask their questions in their natural language and receive answers that have been created by the state-of-the-art framework BERT. In addition, News Monitor crawls the Twitter stream using a dynamic set of “trending” keywords in order to retrieve all messages relevant to the news. The framework is distributed, online and performs analysis in real-time. According to the evaluation results, the fake news detection techniques utilized by News Monitor allow for a F-measure of 82% in the rumor identification task and an accuracy of 92% in the stance detection tasks. The major contribution of this work can be summarized as a novel real-time and scalable architecture that combines various effective techniques under a news analysis framework.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Fake News Spreader Detection on Twitter using Character N-Grams Notebook for PAN at CLEF 2020<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85121870337</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Vogel I., Meghana M.</b></td></tr><tr><td colspan="3">Organisations: <b>Fraunhofer Institute for Secure Information Technology SIT</b></td></tr><tr><td colspan="3">The authors of fake news often use facts from verified news sources and mix them with misinformation to create confusion and provoke unrest among the readers. The spread of fake news can thereby have serious implications on our society. They can sway political elections, push down the stock price or crush reputations of corporations or public figures. Several websites have taken on the mission of checking rumors and allegations, but are often not fast enough to check the content of all the news being disseminated. Especially social media websites have offered an easy platform for the fast propagation of information. Towards limiting fake news from being propagated among social media users, the task of this year’s PAN 2020 challenge lays the focus on the fake news spreaders. The aim of the task is to determine whether it is possible to discriminate authors that have shared fake news in the past from those that have never done it. In this notebook, we describe our profiling system for the fake news detection task on Twitter. For this, we conduct different feature extraction techniques and learning experiments from a multilingual perspective, namely English and Spanish. Our final submitted systems use character n-grams as features in combination with a linear SVM for English and Logistic Regression for the Spanish language. Our submitted models achieve an overall accuracy of 73% and 79% on the English and Spanish official test set, respectively. Our experiments show that it is difficult to differentiate solidly fake news spreaders on Twitter from users who share credible information leaving room for further investigations. Our model ranked 3rd out of 72 competitors.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-16-8531-6_12" target="_blank"> SOMPS-Net: Attention Based Social Graph Framework for Early Detection of Fake Health News<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85121908291</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Dhanasekaran P., Sankar S., Srinivasan H., Vijayaraghavan V., Sree S.S., Devi I.S.G.</b></td></tr><tr><td colspan="3">Organisations: <b>SSN College of Engineering, Solarillion Foundation, Anna University</b></td></tr><tr><td colspan="3">Fake news is fabricated information that is presented as genuine, with intention to deceive the reader. Recently, the magnitude of people relying on social media for news consumption has increased significantly. Owing to this rapid increase, the adverse effects of misinformation affect a wider audience. On account of the increased vulnerability of people to such deceptive fake news, a reliable technique to detect misinformation at its early stages is imperative. Hence, the authors propose a novel graph-based framework SOcial graph with Multi-head attention and Publisher information and news Statistics Network (SOMPS-Net) (https://github.com/PrasannaKumaran/SOMPS-Net-Social-graph-framework-for-fake-health-news-detection ) comprising of two components – Social Interaction Graph (SIG) and Publisher and News Statistics (PNS). The posited model is experimented on the HealthStory dataset and generalizes across diverse medical topics including Cancer, Alzheimer’s, Obstetrics, and Nutrition. SOMPS-Net significantly outperformed other state-of-the-art graph-based models experimented on HealthStory by 17.1%. Further, experiments on early detection demonstrated that SOMPS-Net predicted fake news articles with 79% certainty within just 8 h of its broadcast. Thus the contributions of this work lay down the foundation for capturing fake health news across multiple medical topics at its early stages.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.neucom.2021.12.037" target="_blank"> A heuristic-driven uncertainty based ensemble framework for fake news detection in tweets and news articles<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85121908340</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Das S.D., Basak A., Dutta S.</b></td></tr><tr><td colspan="3">Organisations: <b>Razorthink Inc, IIT Madras</b></td></tr><tr><td colspan="3">The significance of social media has increased manifold in the past few decades as it helps people from even the most remote corners of the world to stay connected. With the advent of technology, digital media has become more relevant and widely used than ever before and along with this, there has been a resurgence in the circulation of fake news and tweets that demand immediate attention. In this paper, we describe a novel Fake News Detection system that automatically identifies whether a news item is “real” or “fake”, as an extension of our work in the CONSTRAINT COVID-19 Fake News Detection in English challenge. We have used an ensemble model consisting of pre-trained models followed by a statistical feature fusion network, along with a novel heuristic algorithm by incorporating various attributes present in news items or tweets like source, username handles, URL domains and authors as statistical feature. Our proposed framework have also quantified reliable predictive uncertainty along with proper class output confidence level for the classification task. We have evaluated our results on the COVID-19 Fake News dataset and FakeNewsNet dataset to show the effectiveness of the proposed algorithm on detecting fake news in short news content as well as in news articles. We obtained a best F1-score of 0.9892 on the COVID-19 dataset, and an F1-score of 0.9156 on the FakeNewsNet dataset.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-90888-1_43" target="_blank"> HACK: A Hierarchical Model for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85121913651</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Li Y., Ji K., Ma K., Chen Z., Wu J., Li Y., Xu G.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Jinan, Beijing Jiaotong University, University of Technology Sydney</b></td></tr><tr><td colspan="3">Online social media sites have become the most powerful platform to share news nowadays. However, all kinds of unauthenticated news that are released online without strict limits may lead to the spread of fake news, which has become a synonym for social and political threats. The existing solutions to the fake news issue are mostly trying to construct a social graph network by integrating the news content and social context of the news, which may be restricted when lacking social context information. In this paper, we propose a model for text only, regardless of contextual information, and named it HACK (HierArchical deteCtion for faKe news), which can construct high-level combined features of spatial capsule vectors from low-level character features and phrase features by fusing a pre-trained language model and convolution network. The experimental results on real-life data show that the classification accuracy is significantly improved by our method comparing with the state-of-the-art methods.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.13053/CyS-25-4-4089" target="_blank"> Covid-19 Fake News Detection: A Survey<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85122125887</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Shushkevich E., Cardiff J., Alexandrov M.</b></td></tr><tr><td colspan="3">Organisations: <b>Technological University Dublin, Russian Presidential Academy of National Economy and Public Administration, Autonomous University of Barcelona</b></td></tr><tr><td colspan="3">The increase of fake news in social media, especially about Covid-19, poses a real threat to the mental and physical health of people. It is an important task to detect such news and to stop it spreading. In this article, we describe the main approaches for fake news about Covid-19 detection, including Classical Machine Learning models, models based on Neural Networks and models, which were created based on the other approaches and preprocessing steps. We analyze the results of the challenge "Constraint@AAAI2021 - COVID19 Fake News Detection", the main goal of which was the binary classification of news collected from social media for fake and real news. We analyze the best approaches, which were proposed by researchers during the challenge. In addition, we describe datasets of fake news related to Covid-19, which could be useful for the detection and classification of such news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.3390/app12010453" target="_blank"> MUFFLE: Multi-Modal Fake News Influence Estimator on Twitter<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85122207398</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Wu C.-L., Hsieh H.-P., Jiang J., Yang Y.-C., Shei C., Chen Y.-W.</b></td></tr><tr><td colspan="3">Organisations: <b>National Cheng Kung University, Swansea University, Academia Sinica</b></td></tr><tr><td colspan="3">To alleviate the impact of fake news on our society, predicting the popularity of fake news posts on social media is a crucial problem worthy of study. However, most related studies on fake news emphasize detection only. In this paper, we focus on the issue of fake news influence prediction, i.e., inferring how popular a fake news post might become on social platforms. To achieve our goal, we propose a comprehensive framework, MUFFLE, which captures multi-modal dynamics by encoding the representation of news-related social networks, user characteristics, and content in text. The attention mechanism developed in the model can provide explainability for social or psychological analysis. To examine the effectiveness of MUFFLE, we conducted extensive experiments on real-world datasets. The experimental results show that our proposed method outperforms both state-of-the-art methods of popularity prediction and machine-based baselines in top-k NDCG and hit rate. Through the experiments, we also analyze the feature importance for predicting fake news influence via the explainability provided by MUFFLE.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1142/S012918312250084X" target="_blank"> Intelligent gravitational search random forest algorithm for fake news detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85122250574</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Natarajan R., Mehbodniya A., Rane K.P., Jindal S., Hasan M.F., Vives L., Bhatt A.</b></td></tr><tr><td colspan="3">Organisations: <b>Jaya Institute of Technology, Kuwait College of Science and Technology, Kce Society's College of Engineering and Information Technology, Shaheed Bhagat Singh State University, Kerbala University, Peruvian University of Applied Sciences, College of Engineering Pune</b></td></tr><tr><td colspan="3">Online social media has made the process of disseminating news so quick that people have shifted their way of accessing news from traditional journalism and press to online social media sources. The rapid rotation of news on social media makes it challenging to evaluate its reliability. Fake news not only erodes public trust but also subverts their opinions. An intelligent automated system is required to detect fake news as there is a tenuous difference between fake and real news. This paper proposes an intelligent gravitational search random forest (IGSRF) algorithm to be employed to detect fake news. The IGSRF algorithm amalgamates the Intelligent Gravitational Search Algorithm (IGSA) and the Random Forest (RF) algorithm. The IGSA is an improved intelligent variant of the classical gravitational search algorithm (GSA) that adds information about the best and worst gravitational mass agents in order to retain the exploitation ability of agents at later iterations and thus avoid the trapping of the classical GSA in local optimum. In the proposed IGSRF algorithm, all the intelligent mass agents determine the solution by generating decision trees (DT) with a random subset of attributes following the hypothesis of random forest. The mass agents generate the collection of solutions from solution space using random proportional rules. The comprehensive prediction to decide the class of news (fake or real) is determined by all the agents following the attributes of random forest. The performance of the proposed algorithm is determined for the FakeNewsNet dataset, which has sub-categories of BuzzFeed and PolitiFact news categories. To analyze the effectiveness of the proposed algorithm, the results are also evaluated with decision tree and random forest algorithms. The proposed IGSRF algorithm has attained superlative results compared to the DT, RF and state-of-the-art techniques.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1155/2021/9076211" target="_blank"> HMBI: A New Hybrid Deep Model Based on Behavior Information for Fake News Detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85122270199</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Xing J., Wang S., Zhang X., Ding Y.</b></td></tr><tr><td colspan="3">Organisations: <b>Chinese Academy of Sciences, University of Chinese Academy of Sciences, Coordination Center of China Xinjiang Branch</b></td></tr><tr><td colspan="3">Fake news can cause widespread and tremendous political and social influence in the real world. The intentional misleading of fake news makes the automatic detection of fake news an important and challenging problem, which has not been well understood at present. Meanwhile, fake news can contain true evidence imitating the true news and present different degrees of falsity, which further aggravates the difficulty of detection. On the other hand, the fake news speaker himself provides rich social behavior information, which provides unprecedented opportunities for advanced fake news detection. In this study, we propose a new hybrid deep model based on behavior information (HMBI), which uses the social behavior information of the speaker to detect fake news more accurately. Specifically, we model news content and social behavior information simultaneously to detect the degrees of falsity of news. The experimental analysis on real-world data shows that the detection accuracy of HMBI is increased by 10.41% on average, which is the highest of the existing model. The detection accuracy of fake news exceeds 50% for the first time.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3485768.3485774" target="_blank"> Fake News Detection Using Machine Learning<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85122302375</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Villagracia Octaviano M.</b></td></tr><tr><td colspan="3">Organisations: <b>National University</b></td></tr><tr><td colspan="3">Fake news has been an issue in every generateon. As the technology evolves, the problem of detecting accurate data for the unreliable news evolves with it and its resolution becomes more significant. This paper explores various feature sets, wherein two new features are introduced to develop an automated fake news detector on news articles. Experiment obtained 96.60% on using XGBoost that has been noted to be comparable to existing works.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-89698-0_67" target="_blank"> Fake News Detection Based on Dual Graph Attention Networks<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85122362001</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Yan X., Guo Y., Wang G., Kuang Y., Li Y., Zheng Z.</b></td></tr><tr><td colspan="3">Organisations: <b>Xi’an University of Posts and Telecommunications</b></td></tr><tr><td colspan="3">Social media, with the characteristics of fast spread and easy access, has become a main channel for people to obtain news. However, in this situation, fake news spread faster and farther, which has a negative impact on national politics, economy and culture. Therefore, how to automatically detect fake news from numerous news has become significantly important. Most of the current detection algorithms mainly explore and extract features from text characteristics of news, obtaining less effective, because the fake news on social media does not exist independently. More auxiliary information is needed to enhance the accuracy of detection. In this paper, a new fake news detection model Dual Graph Attention Networks (DGAT) is proposed, which utilize three entities (news, publishers and users), existing in social media platforms, and their relationships to construct heterogeneous information networks. DGAT model consists of two layers of graph attention networks. The node level attention network is responsible for learning the different weights of the same-type neighbor nodes. The type level attention network is responsible for learning the different weights of different types. The experimental results show that DGAT model outperforms all baseline models in terms of accuracy, precision, recall and F1 value on FakeNewsNet datasets.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Words are the Window to the Soul: Language-based User Representations for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85122371775</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Del Tredici M., Fernandez R.</b></td></tr><tr><td colspan="3">Organisations: <b>Amazon, University of Amsterdam</b></td></tr><tr><td colspan="3">Cognitive and social traits of individuals are reflected in language use. Moreover, individuals who are prone to spread fake news online often share common traits. Building on these ideas, we introduce a model that creates representations of individuals on social media based only on the language they produce, and use them to detect fake news. We show that language-based user representations are beneficial for this task. We also present an extended analysis of the language of fake news spreaders, showing that its main features are mostly domain independent and consistent across two English datasets. Finally, we exploit the relation between language use and connections in the social graph to assess the presence of the Echo Chamber effect in our data.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-36778-7_44" target="_blank"> Fake News Identification Based on Sentiment and Frequency Analysis<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85122486663</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Kapusta J., Benko L., Munk M.</b></td></tr><tr><td colspan="3">Organisations: <b>Constantine the Philosopher University in Nitra, Pedagogical University of Cracow</b></td></tr><tr><td colspan="3">The advent of social networks has changed how can be the thinking of the population influenced. Although the spreading of false information or false messages for personal or political benefit is certainly nothing new, current trends such as social media enable every individual to create false information easier than ever with the spread compared to the leading news portals. Fake news detection has recently attracted growing interest from the general public and researchers. The paper aims to compare basic text characteristics of fake and real news article types. We analysed two datasets that contained a total of 28 870 articles. The results were validated using the third data set consisting of 402 articles. The most important finding is the statistically significant difference in the news sentiment where it has been shown that fake news articles have a more negative sentiment. Also, an interesting result was the difference of average words per sentence. Finding statistically significant differences in individual text characteristics is a piece of important information for the future fake news classifier in terms of selecting the appropriate attributes for classification.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.jbusres.2021.11.032" target="_blank"> Understanding patterns of COVID infodemic: A systematic and pragmatic approach to curb fake news<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85122506867</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Gupta A., Jiang W., Li H., Farnoush A.</b></td></tr><tr><td colspan="3">Organisations: <b>Auburn University, University of New Mexico, Auburn University</b></td></tr><tr><td colspan="3">Amid the flood of fake news on Coronavirus disease of 2019 (COVID-19), now referred to as COVID-19 infodemic, it is critical to understand the nature and characteristics of COVID-19 infodemic since it not only results in altered individual perception and behavior shift such as irrational preventative actions but also presents imminent threat to the public safety and health. In this study, we build on First Amendment theory, integrate text and network analytics and deploy a three-pronged approach to develop a deeper understanding of COVID-19 infodemic. The first prong uses Latent Direchlet Allocation (LDA) to identify topics and key themes that emerge in COVID-19 fake and real news. The second prong compares and contrasts different emotions in fake and real news. The third prong uses network analytics to understand various network-oriented characteristics embedded in the COVID-19 real and fake news such as page rank algorithms, betweenness centrality, eccentricity and closeness centrality. This study carries important implications for building next generation trustworthy technology by providing strong guidance for the design and development of fake news detection and recommendation systems for coping with COVID-19 infodemic. Additionally, based on our findings, we provide actionable system focused guidelines for dealing with immediate and long-term threats from COVID-19 infodemic.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.ipm.2021.102739" target="_blank"> Users’ ability to perceive misinformation: An information quality assessment approach<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85122508041</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Zrnec A., Pozenel M., Lavbic D.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Ljubljana</b></td></tr><tr><td colspan="3">Digital information exchange enables quick creation and sharing of information and thus changes existing habits. Social media is becoming the main source of news for end-users replacing traditional media. This also enables the proliferation of fake news, which misinforms readers and is used to serve the interests of the creators. As a result, automated fake news detection systems are attracting attention. However, automatic fake news detection presents a major challenge; content evaluation is increasingly becoming the responsibility of the end-user. Thus, in the present study we used information quality (IQ) as an instrument to investigate how users can detect fake news. Specifically, we examined how users perceive fake news in the form of shorter paragraphs on individual IQ dimensions. We also investigated which user characteristics might affect fake news detection. We performed an empirical study with 1123 users, who evaluated randomly generated stories with statements of various level of correctness by individual IQ dimensions. The results reveal that IQ can be used as a tool for fake news detection. Our findings show that (1) domain knowledge has a positive impact on fake news detection; (2) education in combination with domain knowledge improves fake news detection; and (3) personality trait conscientiousness contributes significantly to fake news detection in all dimensions.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-93247-3_46" target="_blank"> Fake News Detection of COVID-19 Using Machine Learning Techniques<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85122528297</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Ghosh P., Raihan M., Hassan M.M., Zaman S., Akter L., Awal M.A.</b></td></tr><tr><td colspan="3">Organisations: <b>North Western University, Khulna University of Engineering and Technology, Khulna University</b></td></tr><tr><td colspan="3">Covid-19 or Coronavirus is the most popular common term in recent time. The SARS-CoV-2 virus caused a pandemic of respiratory disturbance which is named as COVID-19. The coronavirus is outspread through drop liquids as well as virus bits which are released into the air by an infected person’s breathing, coughing or sneezing. This pandemic has become a great death threat to the people, even the children too. It’s quite unexpected that some corrupted individuals spread false or fake news to disrupt the social balance. Due to the news misguidance, numerous people have been misled for taking proper care. For this issue, we have analyzed some machine learning techniques, among them, an ensemble method Random forest has gained 90% with the best exactitude. The other models Naive Bayes got 85%, as well as another ensemble method created by Naive Bayes with Support Vector Machine (SVM), gained the exactitude as 88%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-91244-4_26" target="_blank"> Fake News Detection Using Artificial Neural Network Algorithm<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85122542202</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Isha Priyavamtha U.J., Vishnu Vardhan Reddy G., Devisri P., Manek A.S.</b></td></tr><tr><td colspan="3">Organisations: <b>RV Institute of Technology and Management</b></td></tr><tr><td colspan="3">As technology is increasing rapidly, nowadays most people prefer social media over newspapers for the news. There are chances of spreading fake news widely on social media because of circulation of news can be done by anyone. The fake news can show adverse effects on economic as well as political issues. It can spread hatred among the community which can cause serious problems to peace in society. Hence, it is important to detect fake news. The developed model using Artificial Neural Network is a solution for the problem of fake news detection and filtered to avoid wide spread. The proposed model detects fake news that includes three main phases ‘preprocessing, feature extraction and classification’. Initially input is preprocessed to extract features using clustering algorithms. Subsequently, the model is developed to detect fake news. The Neural Networks and Linear Support Vector Clustering algorithms resulted in 99.90% and 97.5% accuracy respectively. Finally, analysis is carried out for validating the betterment of the presented model in terms of different measures.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.14569/IJACSA.2021.0121219" target="_blank"> An Empirical Study on Fake News Detection System using Deep and Machine Learning Ensemble Techniques<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85122569284</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Divya T.V., Banik D.B.G.</b></td></tr><tr><td colspan="3">Organisations: <b>KoneruLakshmaiah Education Foundation Aziz Nagar</b></td></tr><tr><td colspan="3">With the revolution that happened in electronic gadgets in the past few years, information sharing has evolved into a new era that can spread the news globally in a fraction of minutes, either through yellow media or through satellite communication without any proper authentication. At the same time, all of us are aware that with the increase of different social media platforms, many organizations try to grab people's attention by creating fake news about celebrities, politicians (or) politics, branded products, and others. There are three ways to generate fake news: tampering with an image using advanced morphing tools; this is generally a popular technique while posting phony information about the celebrities (or) cybercrimes related to women. The second one deals with the reposting of the old happenings with new fake content injected into it. For example, in generally few social media platforms either to increase their TRP ratings or to expand their subscribers, they create old news that happened somewhere years ago as latest one with new fake content like by changing the date, time, locations, and other important information and tries to make them viral across the globe. The third one deals with the image/video real happened at an event or place, but media try to change the content with a false claim instead of the original one that occurred. A few decades back, researchers started working on fake news detection topics with the help of textual data. In the recent era, few researchers worked on images and text data using traditional and ensemble deep and machine learning algorithms, but they either suffer from overfitting problems due to insufficient data or unable to extract the complex semantic relations between documents. The proposed system designs a transfer learning environment where Neural Style Transfer Learning takes care of the size and quality of the datasets. It also enhances the auto-encoders by customizing the hidden layers to handle complex problems in the real world.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-93709-6_31" target="_blank"> Amharic Fake News Detection on Social Media Using Feature Fusion<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85122572231</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Worku M.H., Woldeyohannis M.M.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Gondar, Addis Ababa University</b></td></tr><tr><td colspan="3">These days, many people use social media as a source of information and medium of communication due to its easy to access, fast to disseminate and low-cost platform. However, it also enables the wide propagation of fake news which causes economic, political, and social crises to the society. As a result, many researchers have been working towards detecting fake news. Most of the researches concerned on linguistic analysis of news content to identify its credibility, however fake news is also written intentionally to mislead users by mimicking true news. Beside this, Amharic is one of the under-resourced language that suffer from the benefits of fake news detection. To overcome the problem of fake news using content feature and under-resourced language, this study uses a feature fusion of linguistic and social context feature of the publisher information to detect Amharic fake news. For this, a total of 4,590 instance has been collected from different Facebook pages in different domain. Each article have been annotated by professional journalists and linguist for the purposes of doing experiments. The experimental result of feature fusion-based experiment shows at least 94.13% and at most 98.7% with a high relative error reduction over the content-based approaches. The result obtained from the experiment shows that, it is promising to detect fake news using fusion feature. We are now working towards incorporating intentionally edited pictures to the news content as part of the fake news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-16-4807-6_25" target="_blank"> Fake News Detection Exploiting TF-IDF Vectorization with Ensemble Learning Models<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85122576711</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Mondal S.K., Wang J., Sahoo J.P., Mondal K., Rahman M.M.</b></td></tr><tr><td colspan="3">Organisations: <b>Macau University of Science and Technology, Siksha ‘O’ Anusandhan (Deemed to be University), North Western University, University of Tasmania</b></td></tr><tr><td colspan="3">Nowadays, fake news is one of the utmost problems in society. Aspect such as, this paper presents a basic concepts and principles in the field of fake news detection. The idea and principles of detection explores the types of detection methods. Besides, based on machine learning and linguistics, an empirical analysis of fake news detection is explored. In fine, we elaborate the challenges of fake news detection along with a couple of machine learning and ensemble learning techniques exploiting the Count and TF-IDF vectorization methods.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s13042-021-01503-5" target="_blank"> Augmentation and heterogeneous graph neural network for AAAI2021-COVID-19 fake news detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85122680931</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Karnyoto A.S., Sun C., Liu B., Wang X.</b></td></tr><tr><td colspan="3">Organisations: <b>School of Computer Science and Technology</b></td></tr><tr><td colspan="3">Misinformation has become a frightening specter of society, especially fake news that concerning Covid-19. It massively spreads on the Internet, and then induces misunderstandings of information to the national and global communities during the pandemic. Detecting massive misinformation on the Internet is crucial and challenging because humans have struggled against this phenomenon for a long time. Our research concerns detecting fake news related to covid-19 using augmentation [random deletion (RD), random insertion (RI), random swap (RS), synonym replacement (SR)] and several graph neural network [graph convolutional network (GCN), graph attention network (GAT), and GraphSAGE (SAmple and aggreGatE)] model. We constructed nodes and edges in the graph, word-word node, and word-document node to graph neural network. Then, we tested those models in different amounts of sample training data to obtain accuracy for each model and compared them. For our fake news detection task, we found training accuracy steadily increasing for GCN, GAT, and SAGE models from the beginning to the end of the epochs. This result proved that the performance of GNN, whether GCN, GAT, or SAGE gained an entirely insignificant difference precision result.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3493700.3493736" target="_blank"> Aletheia: A Fake News Detection System for Hindi<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85122688286</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Badam J., Bonagiri A., Raju K., Chakraborty D.</b></td></tr><tr><td colspan="3">Organisations: <b>Birla Institute Of Technology And Science</b></td></tr><tr><td colspan="3">"Fake News"and Misinformation can have far-reaching negative social impacts. Scalable fake news classification techniques for resource-poor languages such as Hindi are in their infancy due to the lack of data sets and lack of robust NLP libraries in these languages. We present Aletheia, a Fake News classification system for Hindi. We curate a dataset of approximately 13,000 news articles by media organizations that flag authentic and fake news. We present preliminary results using several Machine Learning models on this dataset. We also developed a system accessible over the web (http://responsible-tech.bits-hyderabad.ac.in/aletheia/demo/) using which users can test if a given piece of news is fake or authentic. We also use the website to collect crowd-sourced labelled news data and present additional information on the dataset and the models to the users.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.32604/cmc.2022.023628" target="_blank"> Fake News Classification Using a Fuzzy Convolutional Recurrent Neural Network<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85122754740</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Dixit D.K., Bhagat A., Dangi D.</b></td></tr><tr><td colspan="3">Organisations: <b>Maulana Azad National Institute of Technology (MANIT)</b></td></tr><tr><td colspan="3">In recent years, social media platforms have gained immense popularity. As a result, there has been a tremendous increase in content on social media platforms. This content can be related to an individual's sentiments, thoughts, stories, advertisements, and news, among many other content types. With the recent increase in online content, the importance of identifying fake and real news has increased. Although, there is a lot of work present to detect fake news, a study on Fuzzy CRNN was not explored into this direction. In this work, a system is designed to classify fake and real news using fuzzy logic. The initial feature extraction process is done using a convolutional recurrent neural network (CRNN). After the extraction of features, word indexing is done with high dimensionality. Then, based on the indexing measures, the ranking process identifies whether news is fake or real. The fuzzy CRNN model is trained to yield outstanding results with 99.99 ± 0.01% accuracy. This work utilizes three different datasets (LIAR, LIAR-PLUS, and ISOT) to find the most accurate model.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1108/JSIT-11-2020-0257" target="_blank"> Examination of fake news from a viral perspective: an interplay of emotions, resonance, and sentiments<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85122818055</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Nanath K., Kaitheri S., Malik S., Mustafa S.</b></td></tr><tr><td colspan="3">Organisations: <b>Middlesex University – Dubai Campus</b></td></tr><tr><td colspan="3">Purpose: The purpose of this paper is to examine the factors that significantly affect the prediction of fake news from the virality theory perspective. The paper looks at a mix of emotion-driven content, sentimental resonance, topic modeling and linguistic features of news articles to predict the probability of fake news. Design/methodology/approach: A data set of over 12,000 articles was chosen to develop a model for fake news detection. Machine learning algorithms and natural language processing techniques were used to handle big data with efficiency. Lexicon-based emotion analysis provided eight kinds of emotions used in the article text. The cluster of topics was extracted using topic modeling (five topics), while sentiment analysis provided the resonance between the title and the text. Linguistic features were added to the coding outcomes to develop a logistic regression predictive model for testing the significant variables. Other machine learning algorithms were also executed and compared. Findings: The results revealed that positive emotions in a text lower the probability of news being fake. It was also found that sensational content like illegal activities and crime-related content were associated with fake news. The news title and the text exhibiting similar sentiments were found to be having lower chances of being fake. News titles with more words and content with fewer words were found to impact fake news detection significantly. Practical implications: Several systems and social media platforms today are trying to implement fake news detection methods to filter the content. This research provides exciting parameters from a viral theory perspective that could help develop automated fake news detectors. Originality/value: While several studies have explored fake news detection, this study uses a new perspective on viral theory. It also introduces new parameters like sentimental resonance that could help predict fake news. This study deals with an extensive data set and uses advanced natural language processing to automate the coding techniques in developing the prediction model.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s00607-021-01013-w" target="_blank"> MANIFESTO: a huMAN-centric explaInable approach for FakE news spreaders deTectiOn<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85122918256</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Lampridis O., Karanatsiou D., Vakali A.</b></td></tr><tr><td colspan="3">Organisations: <b>Aristotle University of Thessaloniki</b></td></tr><tr><td colspan="3">Fake news spreading is strongly connected with the human involvement as individuals tend to fall, adopt and circulate misinformation stories. Until recently, the role of human characteristics in fake news diffusion, in order to deeply understand and fight misinformation patterns, has not been explored to the full extent. This paper suggests a human-centric approach on detecting fake news spreading behavior by building an explainable fake-news-spreader classifier based on psychological and behavioral cues of individuals. Our model achieves promising classification results while offering explanations of human motives and features behind fake news spreading behavior. Moreover, to the best of our knowledge, this is the first study that aims at providing a fully explainable setup that evaluates fake news spreading based on users credibility applied to public discussions aiming to a comprehensive way to combat fake news through human involvement.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.26615/issn.2603-2821.2021_029" target="_blank"> Toward Discourse-Aware Models for Multilingual Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85122967975</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Vargas F., Pardo T.A.S., Benevenuto F.</b></td></tr><tr><td colspan="3">Organisations: <b>University of São Paulo, Federal University of Minas Gerais</b></td></tr><tr><td colspan="3">Statements that are intentionally misstated (or manipulated) are of considerable interest to researchers, government, security, and financial systems. According to deception literature, there are reliable cues for detecting deception and the belief that liars give off cues that may indicate their deception is near-universal. Therefore, given that deceiving actions require advanced cognitive development that honesty simply does not require, as well as people’s cognitive mechanisms have promising guidance for deception detection, in this Ph.D. ongoing research, we propose to examine discourse structure patterns in multilingual deceptive news corpora using the Rhetorical Structure Theory framework. Considering that our work is the first to exploit multilingual discourse-aware strategies for fake news detection, the research community currently lacks multilingual deceptive annotated corpora. Accordingly, this paper describes the current progress in this thesis, including (i) the construction of the first multilingual deceptive corpus, which was annotated by specialists according to the Rhetorical Structure Theory framework, and (ii) the introduction of two new proposed rhetorical relations: INTERJECTION and IMPERATIVE, which we assume to be relevant for the fake news detection task.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3366030.3366116" target="_blank"> Content based fake news detection using N-gram models<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85123042758</td><td>Year: <b>2019</b></td></tr><tr><td colspan="3">Authors: <b>Wynne H.E., Wint Z.Z.</b></td></tr><tr><td colspan="3">Organisations: <b>Mandalay Technological University</b></td></tr><tr><td colspan="3">Fake news is very popular these days because of the increasing popularity of social media. Detecting fake news is considered as one of the most dangerous types of deception because it is created with dishonest intention to misdirect the public. Many researchers proposed fake news detection systems considering many approaches; content, social-context, and propagation. When the news is detected fake or real, there is a limitation in the accuracy and understandability of language. In this paper, we propose the fake news detection system that considers the content of the online news articles. We investigate two machine learning algorithms with the use of word n-grams and character n-grams analysis. Experiments yield better results using character n-grams with Term-Frequency-Inverted Document Frequency (TF-IDF) and Gradient Boosting Classifier achieves an accuracy of 96%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3469877.3490614" target="_blank"> Inter-modality Discordance for Multimodal Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85123049802</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Singhal S., Dhawan M., Shah R.R., Kumaraguru P.</b></td></tr><tr><td colspan="3">Organisations: <b>IIIT Delhi, IIIT Hyderabad</b></td></tr><tr><td colspan="3">The paradigm shift in the consumption of news via online platforms has cultivated the growth of digital journalism. Contrary to traditional media, lowering entry barriers and enabling everyone to be part of content creation have disabled the concept of centralized gatekeeping in digital journalism. This in turn has triggered the production of fake news. Current studies have made a significant effort towards multimodal fake news detection with less emphasis on exploring the discordance between the different multimedia present in a news article. We hypothesize that fabrication of either modality will lead to dissonance between the modalities, and resulting in misrepresented, misinterpreted and misleading news. In this paper, we inspect the authenticity of news coming from online media outlets by exploiting relationship (discordance) between the textual and multiple visual cues. We develop an inter-modality discordance based fake news detection framework to achieve the goal. The modal-specific discriminative features are learned, employing the cross-entropy loss and a modified version of contrastive loss that explores the inter-modality discordance. To the best of our knowledge, this is the first work that leverages information from different components of the news article (i.e., headline, body, and multiple images) for multimodal fake news detection. We conduct extensive experiments on the real-world datasets to show that our approach outperforms the state-of-the-art by an average F1-score of 6.3%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.23919/MIPRO52101.2021.9596928" target="_blank"> Fake News Detection by Using Doc2Vec Representation Model and Various Classification Algorithms<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85123057030</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Janakieva D., Mirceva G., Gievska S.</b></td></tr><tr><td colspan="3">Organisations: <b>Ss. Cyril and Methodius University in Skopje</b></td></tr><tr><td colspan="3">Dissemination of fake news and disinformation on social media platforms pose a serious threat to society. Distinguishing between fake and truthful information is not an easy task for humans as well and automatic detection of fake news has received considerable attention in recent years. In this paper, we focus on the task of automatic detection of fake news using several machine learning algorithms. The impact of various linguistic features and preprocessing techniques on the performance of the classifiers has been evaluated using a dataset containing 17324 news entries. The experimental results are encouraging, with the most successful models obtaining accuracy of 99.97%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.3390/app12031093" target="_blank"> FMFN: Fine-Grained Multimodal Fusion Networks for Fake News Detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85123077150</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Wang J., Mao H., Li H.</b></td></tr><tr><td colspan="3">Organisations: <b>East China Normal University</b></td></tr><tr><td colspan="3">As one of the most popular social media platforms, microblogs are ideal places for news propagation. In microblogs, tweets with both text and images are more likely to attract attention than text-only tweets. This advantage is exploited by fake news producers to publish fake news, which has a devasting impact on individuals and society. Thus, multimodal fake news detection has attracted the attention of many researchers. For news with text and image, multimodal fake news detection utilizes both text and image information to determine the authenticity of news. Most of the existing methods for multimodal fake news detection obtain a joint representation by simply concatenating a vector representation of the text and a visual representation of the image, which ignores the dependencies between them. Although there are a small number of approaches that use the attention mechanism to fuse them, they are not fine-grained enough in feature fusion. The reason is that, for a given image, there are multiple visual features and certain correlations between these features. They do not use multiple feature vectors representing different visual features to fuse with textual features, and ignore the correlations, resulting in inadequate fusion of textual features and visual features. In this paper, we propose a novel fine-grained multimodal fusion network (FMFN) to fully fuse textual features and visual features for fake news detection. Scaled dot-product attention is utilized to fuse word embeddings of words in the text and multiple feature vectors representing different features of the image, which not only considers the correlations between different visual features but also better captures the dependencies between textual features and visual features. We conduct extensive experiments on a public Weibo dataset. Our approach achieves competitive results compared with other methods for fusing visual representation and text representation, which demonstrates that the joint representation learned by the FMFN (which fuses multiple visual features and multiple textual features) is better than the joint representation obtained by fusing a visual representation and a text representation in determining fake news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s10796-021-10240-7" target="_blank"> Digital Resilience Through Training Protocols: Learning To Identify Fake News On Social Media<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85123098139</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Soetekouw L., Angelopoulos S.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Amsterdam, Durham University Business School</b></td></tr><tr><td colspan="3">We explore whether training protocols can enhance the ability of social media users to detect fake news, by conducting an online experiment (N = 417) to analyse the effect of such a training protocol, while considering the role of scepticism, age, and level of education. Our findings show a significant relationship between the training protocol and the ability of social media users to detect fake news, suggesting that the protocol can play a positive role in training social media users to recognize fake news. Moreover, we find a direct positive relationship between age and level of education on the one hand and ability to detect fake news on the other, which has implications for future research. We demonstrate the potential of training protocols in countering the effects of fake news, as a scalable solution that empowers users and addresses concerns about the time-consuming nature of fact-checking.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.patrec.2022.01.007" target="_blank"> Effective fake news video detection using domain knowledge and multimodal data fusion on youtube<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85123184241</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Choi H., Ko Y.</b></td></tr><tr><td colspan="3">Organisations: <b>Sungkyunkwan University 2066</b></td></tr><tr><td colspan="3">In the digital age, numerous videos are being actively produced and uploaded online. Simultaneously, fake news videos to attract public attention are also on the rise. Therefore, intensive research is being conducted to detect them. Validating video content is critical for all users as the public is exposed to various fake news videos. This study proposes ways to detect fake news videos effectively using domain knowledge and multimodal data fusion. We use domain knowledge to perform learning by reflecting the potential meaning of comments, helping us detecting fake news videos. We also use the linear combination to efficiently adjust the encoding rate for each characteristic of the video and effectively detect fake news videos. In particular, the domain knowledge improves the model performance by approximately 3% for all test datasets. Consequently, we achieve an F1-score of 0.93, which is higher than those of other comparison models in all the test datasets.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ISCC53001.2021.9631256" target="_blank"> Multi-Modal fake news Detection on Social Media with Dual Attention Fusion Networks<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85123217353</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Yang H., Wang Y., Zhu H., Ma C., Huang W., Sun D., Zhao X.</b></td></tr><tr><td colspan="3">Organisations: <b>Chinese Academy of Sciences, University of Chinese Academy of Sciences, York Univeristy</b></td></tr><tr><td colspan="3">Most of the existed fake news detection works on social media driven-fake news mainly focused on text. However, more and more social media platforms like Twitter, facebook, etc, allow users to create multi-modal contents, including text, image and video. Hence, it is obvious that only investigating text contents is insufficient to achieve solid detection. In this paper, we study the fake news on social media platforms composed of multimodal contents (text and images), and propose Dual Attention Fusion Networks for fake news detection on social media. We explore three modalities, (text modality, image modality and image attributes modality), and further propose a Dual Attention Fusion Networks (DAFN) model for this task. First, our proposed model extracts text modality and image modality, respectively. We then pass combinations of image attributes modality and text modality through BERT to extract text features. Finally, we reconstruct features of three modalities and fuse them into a feature vector for prediction. Our method is verified on realworld datasets consisting of collected social media platforms. Experiments show that the our method achieves promising results on real world datasets. outperforming all baseline models.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/CITSM52892.2021.9589004" target="_blank"> Systematic Literature Review on Methods used in Classification and Fake News Detection in Indonesian<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85123247159</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Rohman M.A., Khairani D., Hulliyah K., Arini, Riswandi P., Lakoni I.</b></td></tr><tr><td colspan="3">Organisations: <b>Informatics UIN Syarif Hidayatullah, Informatics UIN Syarif Hidayatullah, Accounting Universitas Prof.Dr.Hazairin</b></td></tr><tr><td colspan="3">Currently, around 150 million Indonesians are online on social media, and around 70.7% of fake news was received in the form of text or writing. Recent studies of fake news text detection classification have resulted in data sets and methods that allow them to explore and understand fake news detection and clasifications. So many techniques, algorithms, methods, and published data on the classification of fake news texts' classification are complex and different, making it difficult to get a comprehensive picture of the status of research on the classification of fake news. The literature search study based on Systematic Literature Review aims to identify and analyze trends, topics, datasets, and methods and answer research questions in classifying fake news text detection in Bahasa between 2017 and 2021. By exploring the literature, this research uses the SLR-based method to address the gap in the works on fake news and text classification in Indonesian that has received a little empirical investigation. Based on the data search, thirty related studies were obtained, which were further analyzed. However, there are still few studies that have a good ranking and reputation. Nineteen methods or algorithms are applied to classify fake news, and there are two methods or algorithms that are most often used namely Naïve Bayes and Term Frequency-Inverse Document Frequency.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-92708-0_6" target="_blank"> Preventing Fake News Propagation in Social Networks Using a Context Trust-Based Security Model<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85123294403</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Voloch N., Gudes E., Gal-Oz N.</b></td></tr><tr><td colspan="3">Organisations: <b>Ben-Gurion University of the Negev, Sapir Academic College</b></td></tr><tr><td colspan="3">Online Social Networks (OSN) security issues have been extensively researched in the past decade. Information is posted and shared by individuals and organizations in social networks in huge quantities. One of the most important non-resolved topics is the Fake News propagation problem. Fake news propagates because of several reasons, one of which is non-trustworthy users. These users, some with malicious intentions, and some with low social media awareness, are the ones actually spreading misleading information. As this occurs, other users, that are valid reliable users, are exposed to false information. In our previous research we have devised a comprehensive Trust-based model that can handle this problem from the user Trust aspect. The model involves Access Control for the direct circle of friends and Flow Control for the friends’ networks. In this paper we use this model as a basis for the purpose of prevention of Fake News. We add context awareness and user profiling by analyzing the user’s activity in the network (posts, shares, etc.), and then use Machine Learning to detect these problematic users by analyzing data items that are fake or misleading. This addition creates a much more accurate picture of OSN users and their data and helps revealing the sources of the Fake News propagation and can prevent it. These aspects of the model create a strong reliable OSN data infrastructure.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/SCC53864.2021.00027" target="_blank"> Ensemble Learning-based Fake News and Disinformation Detection System<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85123299265</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Hasimi L., Poniszewska-Maranda A.</b></td></tr><tr><td colspan="3">Organisations: <b>Lodz University of Technology</b></td></tr><tr><td colspan="3">In the age of the Internet, access to information is no longer a concern, the credibility, however, is the new era challenge. Information reaches people in an unfiltered format and therefore raises questions about the authenticity, validity, and credibility. This paper focuses on increasing the reliability of the news, concentrating on static analysis of written text intending to detect possible disingenuous information. To achieve this goal, intelligent solutions were engaged, designed to detect patterns of fake articles that can hint at the lack of knowledge or outright maliciously. The architecture, of the proposed fake news detection system is a composite solution of different classification algorithms, with a final network output obtained through the use of the ensemble learning methods, respectively the comparison of three voting systems. The baseline model allowed a satisfactory accuracy of 99% for the given dataset.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICSET53708.2021.9612540" target="_blank"> Fake News Detection using Naive Bayes<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85123347814</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Yuslee N.S., Abdullah N.A.S.</b></td></tr><tr><td colspan="3">Organisations: <b>Universiti Teknologi Mara</b></td></tr><tr><td colspan="3">The issue of fake news arises every year. Moreover, the enhancement and evolution of technologies enable the news to be manipulated by irresponsible people. However, it is not deniable that somehow this technology impacts our daily life. Nowadays, people get the latest news through the social media platforms as it is free, easy to access, and fast. However, not all the news on social media is reliable, and some fake news are spread to mislead the readers. Fake news can disseminate information to confuse people to believe things that are not true. In Natural Language Processing, text processing such as regular expression, removing the stop words and lemmatization are done before the data is being transformed into N-grams using TF-IDF and Count Vectorizer. Therefore, this paper aimed to review the fake news detection using the Naive Bayes algorithms. Results shows that Naive Bayes with n-gram gives a slight increase in the accuracy of TF-IDF and Count Vectorizer. It proves that TF-IDF Vectorizer can detect fake news better as it has higher precision of 94 % whereas Count Vectorizer can detect both fake news and real news in quite a balance.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICRITO51393.2021.9596438" target="_blank"> Fake News Detection Using Intelligent Techniques<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85123361362</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Vora A., Shekokar N.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Mumbai</b></td></tr><tr><td colspan="3">Nowadays fake news spreads very easily through internet and social media. People tend to easily believe in that fake information and start discussing about it. The more we hear about fake news, the more it becomes easier to believe on it. The main aim of fake news is to earn money through advertising revenue by web trafficking or discrediting a public figure, company,etc. Fake news is one of the biggest issues of this modern era especially in the world of social media. Lot of authors have contributed in detection of fake news using various machine learning algorithms but some gaps were found during analysis which are improved in our proposed model. Our approach detects fake news using intelligent techniques such as SVM, Naive Bayes and Logistic Regression. Their performance is analysed using parameters such as F1 score, recall, precision.support, accuracy.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.jjimei.2020.100007" target="_blank"> Fake news detection: A hybrid CNN-RNN based deep learning approach<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85123365765</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Nasir J.A., Khan O.S., Varlamis I.</b></td></tr><tr><td colspan="3">Organisations: <b>National University of Ireland Galway, International Islamic University Islamabad, Harokopio University of Athens</b></td></tr><tr><td colspan="3">The explosion of social media allowed individuals to spread information without cost, with little investigation and fewer filters than before. This amplified the old problem of fake news, which became a major concern nowadays due to the negative impact it brings to the communities. In order to tackle the rise and spreading of fake news, automatic detection techniques have been researched building on artificial intelligence and machine learning. The recent achievements of deep learning techniques in complex natural language processing tasks, make them a promising solution for fake news detection too. This work proposes a novel hybrid deep learning model that combines convolutional and recurrent neural networks for fake news classification. The model was successfully validated on two fake news datasets (ISO and FA-KES), achieving detection results that are significantly better than other non-hybrid baseline methods. Further experiments on the generalization of the proposed model across different datasets, had promising results.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICRITO51393.2021.9596286" target="_blank"> Pursuit for Authentic News using Machine Learning Models<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85123386030</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Pradhan R., Tiwary P., Agarwal P., Sharma D.K.</b></td></tr><tr><td colspan="3">Organisations: <b>GLA University</b></td></tr><tr><td colspan="3">Fake news spreads like a wildfire and this is a big issue in this era. The Online world contains lots of fake news from various sources and channels by political parties, influential peoples, and bots. People are not good for easily able to distinguish fake news from real one. This will negatively impact people's lives, society, and the world. To maintain stability from the harm done by fake news, we will tackle the topic of fake news detection. we are investigating the effectiveness of machine learning technologies and also introducing a deep learning model for fake news detection with better accuracy. We are using Natural language processing with the above technologies for our purpose. In investigating the effectiveness of machine learning technologies, we had applied various classification algorithms on our data processed by NLP to obtain their accuracy for the problem. Then using new emerging technologies like deep learning, we are proposing solutions with better accuracy. In the machine learning technologies for fake news detection, we have found that AdaBoost classifier, Gradient boosting classifier, and Logistic regression are better in terms of accuracy than other classifiers like decision tree, KNeighbors classifier, Random Forest classifier, and MultinomialNB. But These technologies are more prone to error when a different category of data comes. Deep learning technology used here is the Long short-term memory deep learning model which gave us an accuracy of more than 0.993 and the Bi-directional LSTM model with accuracy near 0.99 taking more time in training than the LSTM model. Through this research, we conclude that machine learning technologies perform worse than deep learning technologies. And proposed LSTM model is better than the Bi-directional LSTM model for fake news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.5267/j.ijdns.2022.1.003" target="_blank"> A combined deep learning model based on the ideal distance weighting method for fake news detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85123409798</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Gonwirat S., Choompol A., Wichapa N.</b></td></tr><tr><td colspan="3">Organisations: <b>Kalasin University</b></td></tr><tr><td colspan="3">Fake news has become a major problem affecting people, society, the economy and national security. This work proposes a combined deep learning model based on the ideal distance weighting method for fake news detection. The proposed model was validated on the ISOT and COVID-19 fake news datasets. Firstly, the ISOT and COVID-19 fake news datasets were collected. Secondly, the training-based models were used to provide accuracy values. After that, these values were transformed into criteria weights using the new ideal distance weighting method. Finally, the prediction value of the proposed model is calculated by the criteria weights. The results show that the proposed method is effective to distinguish the fake news datasets.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3485127" target="_blank"> A Review on Fact Extraction and Verification<a></b></td></tr><tr><td>Type: Review</td><td>ID: S_2-s2.0-85123412279</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Bekoulis G., Papagiannopoulou C., Deligiannis N.</b></td></tr><tr><td colspan="3">Organisations: <b>Vrije Universiteit Brussel, Imec</b></td></tr><tr><td colspan="3">We study the fact-checking problem, which aims to identify the veracity of a given claim. Specifically, we focus on the task of Fact Extraction and VERification (FEVER) and its accompanied dataset. The task consists of the subtasks of retrieving the relevant documents (and sentences) from Wikipedia and validating whether the information in the documents supports or refutes a given claim. This task is essential and can be the building block of applications such as fake news detection and medical claim verification. In this article, we aim at a better understanding of the challenges of the task by presenting the literature in a structured and comprehensive way. We describe the proposed methods by analyzing the technical perspectives of the different approaches and discussing the performance results on the FEVER dataset, which is the most well-studied and formally structured dataset on the fact extraction and verification task. We also conduct the largest experimental study to date on identifying beneficial loss functions for the sentence retrieval component. Our analysis indicates that sampling negative sentences is important for improving the performance and decreasing the computational complexity. Finally, we describe open issues and future challenges, and we motivate future research in the task.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-16-5529-6_8" target="_blank"> Improving Text Classifiers Through Controlled Text Generation Using Transformer Wasserstein Autoencoder<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85123416607</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Harikrishnan C., Dhanya N.M.</b></td></tr><tr><td colspan="3">Organisations: <b>Amrita Vishwa Vidyapeetham</b></td></tr><tr><td colspan="3">Training good classifiers on imbalanced dataset has always been a challenge, especially if the classifier has to work with textual data. Natural language is one such area where there are abundant imbalanced datasets such as spam filtering, fake news detection, and toxic comment classification. Techniques for generating synthetic data like synthetic minority over-sampling technique fail to train effective classifiers. This paper proposes a technique for generating controlled text using the transformer-based Wasserstein autoencoder which helps in improving the classifiers. The paper compares the results with classifiers trained on data generated by other synthetic data generators. Furthermore, the potential issues of the proposed model for training classifiers are discussed.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1080/0145935X.2021.2024758" target="_blank"> Literacy Concepts as an Intervention Strategy for Improving Fake News Knowledge, Detection Skills, and Curtailing the Tendency to Share Fake News in Nigeria<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85123421830</td><td>Year: <b>2023</b></td></tr><tr><td colspan="3">Authors: <b>Apuke O.D., Omar B., Asude Tunca E.</b></td></tr><tr><td colspan="3">Organisations: <b>Universiti Sains Malaysia, Taraba State University, European University of Lefke</b></td></tr><tr><td colspan="3">This study examined the role of literacy concepts (information, news, media, and digital literacies), as an intervention strategy, in improving fake news knowledge, detection skills, and curtailing the tendency to share fake news among social media users. In doing so, this study used the inoculation theory and message interpretation process (MIP) theory to provide a useful explanation for literacy concept intervention. An experiment was carried out to test the effects of literacy intervention on the treatment group which were later compared with the results deduced from the control group who did not receive any intervention. It was found that participants in the experimental group demonstrated a higher knowledge of fake news, better ability to detect fake news and shared more accurate news articles, as compared to their counterparts who were in the control group. Implications for research and practice were discussed.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.32604/iasc.2022.022720" target="_blank"> Social Networks Fake Account and Fake News Identification with Reliable Deep Learning<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85123423259</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Kanagavalli N., Baghavathi Priya S.</b></td></tr><tr><td colspan="3">Organisations: <b>Rajalakshmi Institute of Technology, Rajalakshmi Engineering College</b></td></tr><tr><td colspan="3">Recent developments of the World Wide Web (WWW) and social networking (Twitter, Instagram, etc.) paves way for data sharing which has never been observed in the human history before. A major security issue in this network is the creation of fake accounts. In addition, the automatic classification of the text article as true or fake is also a crucial process. The ineffectiveness of humans in distinguishing the true and false information exposes the fake news as a risk to credibility, democracy, logical truth, and journalism in government sectors. Besides, the automatic fake news or rumors from the social networking sites is a major research area in the field of social media analytics. With this motivation, this paper develops a new reliable deep learning (DL) based fake account and fake news detection (RDL-FAFND) model for the social networking sites. The goal of the RDL-FAFND model is to resolve the major problems involved in the social media platforms namely fake accounts, fake news/rumor identification. The presented RDL-FAFND model detects the fake account by the use of a parameter tuned deep stacked Auto encoder (DSAE) using the krill herd (KH) optimization algorithm for detecting the fake social networking accounts. Besides, the presented RDL-FAFND model involves an ensemble of the machine learning (ML) models with different linguistic features (EML-LF) for categorizing the text as true or fake. An extensive set of experiments have been carried out for highlighting the superior performance of the RDL-FAFND model. A detailed comparative results analysis has stated that the presented RDL-FAFND model is considerably better than the existing methods.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-87954-9_15" target="_blank"> FakeTouch: Machine Learning Based Framework for Detecting Fake News<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85123453223</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Siddikk A.B., Lia R.J., Muntasir M.F., Rahman S.S.M.M., Arman M.S., Jahan M.R.</b></td></tr><tr><td colspan="3">Organisations: <b>Daffodil International University, nFuture Research Lab</b></td></tr><tr><td colspan="3">Fake news is any content or information that is false and often generated to mislead its readers in believing something which is not true. Fake news has become one of major threats that can harm someone’s reputation. It often circulates wrong or made up information about various products, events, people or entity. The deliberate making of such news is escalating drastically these days. Fake news deceives us in taking wrong decisions. Therefore, Fake News Detection has attained immense deal of interest from researchers all over the world. In this chapter, a machine learning approach has been proposed named FakeTouch starting with Natural Language Processing based concept by applying text processing, cleaning and extraction techniques. This approach aim to arrange the information to be “obeyed” into each classification model for training and tuning parameters for every model to bring out the optimized and best prediction to find out the Fake news. To evaluate the proposed framework, three use cases with three different datasets has been developed during this study. The proposed framework will also help to understand what amount of data is responsible for detecting fake news, trying to stage the linguistic differences between fake and true articles providing a visualization of the results using different visualization tools. This chapter also presents a comprehensive performance evaluation to compare different well known machine learning classifiers like Support Vector Machine, Naïve Bayes Method, Decision Tree Classifier, Random Forest, Logistic Regression as well as to develop an ensemble method (Bagging & Boosting) like XGBClassifier, Bagging Classifier of different combinations of classification models to identify which will give the best optimal results for three part of datasets. As a result, it has been found that with an appropriate set of features extracted from the texts and the headlines, XGB classifier can effectively classify fake news with very high detection rate. This framework also provides a strong baseline of an intelligent anti-fake news detector.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/GCCE53005.2021.9621803" target="_blank"> Propagation-Based Fake News Detection Using Graph Neural Networks with Transformer<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85123473564</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Matsumoto H., Yoshida S., Muneyasu M.</b></td></tr><tr><td colspan="3">Organisations: <b>Kansai University</b></td></tr><tr><td colspan="3">The spread of fake news has become a worldwide problem, affecting public trust. Recent studies have reported that fake news and real news spread differently on social media. Thus, propagation-based detection methods, which construct graphs with users as nodes and news sharing chains as edges and simultaneously learn propagation patterns and users' preferences using Graph Neural Networks (GNNs), have attracted much attention. However, for extracting users' preferences from the graph, it is a challenge to learn the relationship between unconnected nodes. In this paper, we propose a method for fake news detection using Graph Transformer Network (GTN), which can learn efficient node representations while identifying useful connections between nodes in the original graph. The effectiveness of the proposed method is confirmed by comparison experiments using the real-world dataset composed of Twitter data.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s10844-021-00678-1" target="_blank"> Fake news detection based on statement conflict<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85123477512</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Zhang D., Xu J., Zadorozhny V., Grant J.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Pittsburgh, University of Maryland</b></td></tr><tr><td colspan="3">The detection of fake news has become essential in recent years. This paper presents a new technique that is highly effective in identifying fake news articles. We assume a scenario where the relationship between a news article and a statement has already been classified as either agreeing or disagreeing with the statement, being uncertain about it, or being unrelated to it. Using this information, we focus on selecting the news articles that are most likely to be fake. We propose two models: the first one uses only the agree and disagree classifications; the second uses a subjective opinions based model that can also handle the uncertain cases. Our experiments on a real-world dataset (the Fake News Challenge 1 dataset) and a simulated dataset validate that both proposed models achieve state-of-the-art performance. Furthermore, we show which model to use in different scenarios to get the best performance.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-16-6407-6_48" target="_blank"> Boosting Approach for Multiclass Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85123601791</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Kareddula R., Singh P.</b></td></tr><tr><td colspan="3">Organisations: <b>National Institute of Technology Raipur</b></td></tr><tr><td colspan="3">In the modern era of information, data integrity is of utmost priority. With the rapid development in the field of Artificial Intelligence, one who has credible data owns the key to build a reliable future. But with the breakneck development of communication over social media the reliability of data is no more guaranteed. “Fake News” is data that doesn’t have any real-world significance (or) a fact which has been modified by some middleman over the chain of communication. Spreading of such fake news affects humanity in various unacceptable perspectives. As a solution, in this paper, a machine learning approach is proposed to verify the trustworthiness of news. Instead of just classifying the data as true or fake, various degrees of truth and falsehood are also explored. The proposed methodology has been applied to “Liar, Liar Pants on Fire”, a benchmark data set for fake news detection. The proposed approach with 41.1% accuracy, outperforms the baseline approaches.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.patter.2021.100394" target="_blank"> Meta-learning for fake news detection surrounding the Syrian war: An interview with co-author Roaa Al Feel<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85123690472</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Al Feel R.</b></td></tr><tr><td colspan="3">Organisations: <b>American University of Beirut</b></td></tr><tr><td colspan="3">Roaa Al Feel, an early-career researcher, discusses her passion for using data science for social good. She uses data to reflect living conditions of society, and in the paper published with Patterns in November, the team explores machine learning techniques for the detection of fake news around the Syrian war, demonstrating the efficacy of meta-learning techniques when tackling datasets of a modest size.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/AICT52784.2021.9620228" target="_blank"> Dataset for Arabic Fake News<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85123752436</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Assaf R., Saheb M.</b></td></tr><tr><td colspan="3">Organisations: <b>Palestine Polytechnic University</b></td></tr><tr><td colspan="3">the adaptation of social media platforms allows the fast spread of misinformation, which can mislead the public. This dissemination of information and usage of the internet enables users to create and share massive amounts of information, some of which are unreliable. Fake news has become an important social issue for researchers to tackle. Few English fake news datasets were published and numerous machine learning approaches were proposed for news reliability classification. However, up to now, there is a limited reliable Arabic dataset for fake news detection. This paper is a data paper in which we present a new dataset of Arabic fake news. The data was collected from various sources including PalKashif. The articles and news segments were labeled by two experts. The dataset contains about 500 news segments and the inter-annotator agreement measured using Cohen's Kappa is 0.807. The dataset will be published for public use on Github 1.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICSES52305.2021.9633857" target="_blank"> Content Based Offline Fake News Detection using Classification Technique<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85123785997</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Gupta M., Kumar R., Pradhan G., Kumawat D.</b></td></tr><tr><td colspan="3">Organisations: <b>Chandigarh University</b></td></tr><tr><td colspan="3">The phrase post-reality coined with the aid of using the dictionary of Oxford word in the Year 2016. The adjective name, referring to the describing conditions of which goal information have little impact on reframing public opinion instead of being attractive to non-public emotions and beliefs. This ends in incorrect information and social problems. Therefore, it's far essential to take the time to locate this information and save you them from spreading. In this paper, astrategyis used for device mastering, particularly surveyed reading, to reap fake information. Specifically, this work used a database of non-fiction tales to educate the device mastering version, the use of the Scikit-study which is a library in Python. Records were extracted by us from the database the use of textual content illustration fashions together with a bag of words, the term frequency Inverse document frequency, and the bi diagram frequency. After which we tested strategies of type, particularly the feasible type and the linear department of the name and content material, searching at whether it changed into a typical/no-click on feed, in a fake / real sequence. The end result of our take a look at is that line segregation works high-quality with the TF-IDF version withinside the content material segmentation process. The Bi-gram frequency version furnished an awful lot of decrease accuracy of theme separation as compared to the term bag of words and TF-IDF.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/MysuruCon52639.2021.9641517" target="_blank"> Characterization, Classification and Detection of Fake News in Online Social Media Networks<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85123850854</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Jose X., Madhu Kumar S.D., Chandran P.</b></td></tr><tr><td colspan="3">Organisations: <b>National Institute of Technology Calicut</b></td></tr><tr><td colspan="3">Due to its increasing popularity, low cost, and easy-to-access nature, Online Social Media (OSM) networks have evolved as a powerful platform for people to access, consume, and share news. However, this has led to the large-scale distribution of fake news, i.e., deliberate, false, or misleading information. Fake news is a pressing dilemma, as it has serious negative implications for individual users and for society as a whole. The news contents in the OSM networks are distributed rapidly, so the identification systems should predict news items as soon as possible to avoid spreading false news. Therefore, it is extremely crucial and technically challenging to detect fake news in social media networks. In this paper, we have discussed different characteristics and types of fake news and also propose an effective solution to detect fake news in OSM networks. The stance detection model and the fabricated content classifier are the main two components of the solution. The stance detection model achieved an accuracy of 90.37% with Logistic Regression, and the fabricated content classifier achieved an accuracy of 93.46% with Bi-directional LSTM.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s41060-021-00302-z" target="_blank"> Fake news detection based on news content and social contexts: a transformer-based approach<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85123859491</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Raza S., Ding C.</b></td></tr><tr><td colspan="3">Organisations: <b>Ryerson University</b></td></tr><tr><td colspan="3">Fake news is a real problem in today’s world, and it has become more extensive and harder to identify. A major challenge in fake news detection is to detect it in the early phase. Another challenge in fake news detection is the unavailability or the shortage of labelled data for training the detection models. We propose a novel fake news detection framework that can address these challenges. Our proposed framework exploits the information from the news articles and the social contexts to detect fake news. The proposed model is based on a Transformer architecture, which has two parts: the encoder part to learn useful representations from the fake news data and the decoder part that predicts the future behaviour based on past observations. We also incorporate many features from the news content and social contexts into our model to help us classify the news better. In addition, we propose an effective labelling technique to address the label shortage problem. Experimental results on real-world data show that our model can detect fake news with higher accuracy within a few minutes after it propagates (early detection) than the baselines.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Claim Detection in Biomedical Twitter Posts<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85123918032</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Wuhrl A., Klinger R.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Stuttgart</b></td></tr><tr><td colspan="3">Social media contains unfiltered and unique information, which is potentially of great value, but, in the case of misinformation, can also do great harm. With regards to biomedical topics, false information can be particularly dangerous. Methods of automatic fact-checking and fake news detection address this problem, but have not been applied to the biomedical domain in social media yet. We aim to fill this research gap and annotate a corpus of 1200 tweets for implicit and explicit biomedical claims (the latter also with span annotations for the claim phrase). With this corpus, which we sample to be related to COVID-19, measles, cystic fibrosis, and depression, we develop baseline models which detect tweets that contain a claim automatically. Our anal-yses reveal that biomedical tweets are densely populated with claims (45 % in a corpus sampled to contain 1200 tweets focused on the domains mentioned above). Baseline classification experiments with embedding-based classifiers and BERT-based transfer learning demonstrate that the detection is challenging, however, shows acceptable performance for the identification of explicit expressions of claims. Implicit claim tweets are more challenging to detect.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICTAI52525.2021.00168" target="_blank"> Fake News Detection by Using Common Latent Semantics Matching Method<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85123925838</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Zeng Z., Ye L., Liu R., Cui Z., Wu M., Sha Y.</b></td></tr><tr><td colspan="3">Organisations: <b>Huazhong Agricultural University</b></td></tr><tr><td colspan="3">As news has become an important way to obtain in-formation, the spread of fake news has caused serious social problems, such as misleading readers and damaging the authority of the government. Therefore, fake news detection has become an important field in social network research. One challenge of fake news detection is how to explore the common latent semantics, which are universally implied in fake news. However, the existing methods are not enough for mining this kind of semantic information. Therefore, we proposed a fake news detection framework named Common Latent Semantics Matching Model (CLSMM), which improves the performance of fake news detection by utilizing common latent semantics in fake news. First, we use BERT model to extract common latent semantics of fake news and use summary generation model to extract distinct latent semantics among each piece of news. Second, we rank the semantic credibility score according to the matching degree of the two kinds of latent semantics mentioned above. Finally, these semantic credibility scores are injected into a fake news classifier to improve the detection performance. Experiments are based on two large scale real-world social media datasets, namely Liar and BuzzFeed. The experimental results show that our model can outperform the accuracy of the state-of-the-art methods by 2.7% and 17.26% on Liar and BuzzFeed, respectively.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Multimodal Fusion with Co-Attention Networks for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85123950101</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Wu Y., Zhan P., Zhang Y., Wang L., Xu Z.</b></td></tr><tr><td colspan="3">Organisations: <b>Chinese Academy of Sciences, University of Chinese Academy of Sciences</b></td></tr><tr><td colspan="3">Fake news with textual and visual contents has a better story-telling ability than text-only contents, and can be spread quickly with social media. People can be easily deceived by such fake news, and traditional expert identification is labor-intensive. Therefore, automatic detection of multimodal fake news has become a new hot-spot issue. A shortcoming of existing approaches is their inability to fuse multi-modality features effectively. They simply concatenate unimodal features without considering inter-modality relations. Inspired by the way people read news with image and text, we propose a novel Multimodal Co-Attention Networks (MCAN) to better fuse textual and visual features for fake news detection. Extensive experiments conducted on two real-world datasets demonstrate that MCAN can learn inter-dependencies among multimodal features and outperforms state-of-the-art methods.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICTAI52525.2021.00141" target="_blank"> Analysis of COVID-19 Misinformation in Social Media using Transfer Learning<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85123952910</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Dhankar A., Samuel H., Farruque N., Zaiane O., Hassan F., Bolduc F.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Alberta, University of Alberta</b></td></tr><tr><td colspan="3">Most major events are often accompanied by misinformation on online Social Networking platforms. Due to its nature, the COVID-19 pandemic was bound to lead to an explosion of information online, much of it false or misleading. This information explosion, termed "infodemic"by the World Health Organization (WHO), has revealed the need for automatic fake news detection to help with the exponentially growing flow of unverified information. The objective of this study is to explore combinations of different supervised classification models trained on different general and domain-specific embeddings, and compare the effects of the iterations on the results. We also analyze the results to determine whether the differences in weighted F1-score performance metrics are statistically significant. Ultimately, we demonstrate that concatenation of general and context-specific embeddings improves performance. Our research shows promise for health misinformation detection and formulation of effective public health responses.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/AICT52120.2021.9628907" target="_blank"> Fake News Detection in the Framework of Decision-Making System through Graph Neural Network<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85123979656</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Pilkevych I., Fedorchuk D., Naumchak O., Romanchuk M.</b></td></tr><tr><td colspan="3">Organisations: <b>Korolyov Zhytomyr Military Institute</b></td></tr><tr><td colspan="3">The rapid growth of the number of fake news has become a serious threat to the credibility of the governments of many countries. The extensive use of social platforms contributes to the creation and dissemination of fake news. This is actualize the task of fake news detection. Much research has already focused on this. Modern methods of detecting fake news rely heavily on textual information, examining the extracted news content or writing style based on internal knowledge. However, intentional rumors can mask the style of writing, bypassing languages and text patterns. In order to combat the spread of fake news, methods of automatic detection based on artificial intelligence and machine learning were studied. In a world where millions of articles are deleted and published every minute, this cannot be done effectively manually. The solution may be to develop a system to provide reliable automated assessment systems or to assess the reliability of different publishers and news contexts using deep learning techniques, namely graph neural networks with an inductive structure.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/BESC53957.2021.9635201" target="_blank"> An Exploration of Machine and Deep Learning Models for Fake News Detection in Social Media<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85124005272</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Tian Y., Gu J., Jia Y., Sinnott R.O.</b></td></tr><tr><td colspan="3">Organisations: <b>The University of Melbourne</b></td></tr><tr><td colspan="3">Due to the popularity of online media and especially social media, accessing news online through social media platforms has become the preferred way for people to obtain their news. However, it is now widely recognized that there is an increasing amount of fake news on the Internet. Fake news can be very similar to real news, so it is often difficult for readers to distinguish the truth/veracity of the news they read. Machine learning and deep learning models can help in this regard. In this paper, we compare and analyse the performance of four machine learning models (Logistic regression, Random Forest, Support Vector Machines (SVM), Naïve Bayes) and three deep learning models (Recurrent Neural Network (RNN), Long Short-Term Memory (LSTM) and BERT) on data sets comprising both true and fake news. We explore different methods for extracting language features from the news and evaluate the performance of the model using accuracy as an evaluation indicator. We identified that the BERT model reached an accuracy of 86.76 and was most effective.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICSCT53883.2021.9642565" target="_blank"> Fake News Detection Based on Deep Learning<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85124018981</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Keya A.J., Afridi S., Maria A.S., Pinki S.S., Ghosh J., Mridha M.F.</b></td></tr><tr><td colspan="3">Organisations: <b>Bangladesh University of Business and Technology</b></td></tr><tr><td colspan="3">Fake news is invalid and misleading information that is conveyed as accurate news. Fake news detection has become indispensable in modern society because of the extreme propagation of false news on social platforms and news portals. Several studies have been released that use fake news on social platforms instead of news content for decision-making. Therefore, this paper introduces an automated model for detecting fake news relying on Deep Learning (DL) and Natural Language Processing (NLP) for a low-resource language like Bangla, utilizing news content and headline features. We propose an ensemble approach of Convolutional Neural Network (CNN) and Gated Recurrent Unit (GRU) with a pre-Trained GloVe embedding method that achieved an accuracy of 98.71% on the test data. For comparison, the combination of Long short-Term memory (LSTM) and CNN with Globe is trained using the same dataset and parameters. We also experimented on a benchmark dataset containing English news with our suggested model and achieved an accuracy of 98.94%. Our model's performance is evaluated using diverse evaluation metrics, including accuracy, recall, precision, fl-score, etc.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3492324.3494157" target="_blank"> Linking User Accounts across Social Media Platforms<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85124042569</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Sinnott R., Wang Z.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Melbourne</b></td></tr><tr><td colspan="3">To improve social media analysis across diverse platforms, an effective method to evaluate the possibility that different accounts belong to the same users is required. This might be used to support fake news detection or other nefarious activities. In this paper, we present an approach to calculate the probability that different social media accounts on diverse social media platforms belong to the same user. We consider various platform aspects related to user accounts that can be used for user matching including the selected username, the avatar or profile picture, the content of platform posts and related metadata such as the writing style, account binding and use of hyperlinks across platforms. The experimental results showed that the approach is able to distinguish whether the same person has different platform accounts with an F1-score of up to 0.937.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-88817-6_15" target="_blank"> Combining Conceptual Graphs and Sentiment Analysis for Fake News Detection<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85124047113</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Cuenca W., Gonzalez-Fernandez C., Fernandez-Isabel A., Martin de Diego I., Martin A.G.</b></td></tr><tr><td colspan="3">Organisations: <b>Universidad Rey Juan Carlos</b></td></tr><tr><td colspan="3">Misinformationhas always existed in our society. In these days, the emergence of technological development and the appearance of social networks, pseudo-newspapers and blogs, has aggravated this problem by facilitating the rapid spread of fake news. This fact eases the use of misinformation as a vector of attack on huge communities, which may even compromises the security of a country. This leads to the development of systems that detect the appearance of this type of news and mitigate their influence. This article presents a first prototype of a knowledge-based system for the detection of fake news using reliable information sources. This framework makes use of text mining and sentiment analysis techniques to build conceptual graphs that represent the extracted knowledge. It can be estimated if a text provides misinformation combining similarity matrices gathered from them. Preliminary experiments confirm the potential of the proposal.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.14569/IJACSA.2022.0130118" target="_blank"> Automatic Fake News Detection based on Deep Learning, FastText and News Title<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85124070292</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Taher Y., Moussaoui A., Moussaoui F.</b></td></tr><tr><td colspan="3">Organisations: <b>Center of Guidance and Planning, Moulay Ismail University</b></td></tr><tr><td colspan="3">As a range of daily phenomena, Fake News is quickly becoming a longstanding issue affecting individuals, public and private sectors. This major challenge of the connected and modern world can cause many severe and real damages such as manipulating public opinion, damaging reputations, contributing to the loss in stock market value and representing many risks to the global health. With the fast spreading of online misinformation, checking manually Fake News becomes ineffective solution (not obvious, difficult and takes a long time). The improvement of Deep Learning Networks (DLN) can support with high degree of accuracy and efficiency the classical processes of Fake News spotting. One of the keys improvement strategies are optimizing the Word Embedding Layer (WEL) and finding relevant Fake News predicting features. In this context, and based on six DLN architectures, FastText process as WEL and Inverted Pyramid as News Articles Pattern (IPP), the present paper focuses on the assessment of the first news article feature that is hypothesized as affecting the performances of fake news predicting: News Title. By assessing the impact that the Embedding Vector Size (EVS), Window Size (WS) and Minimum Frequency of Words (MFW) in News Titles corpus can have on DLN, the experiments carried out in this paper showed that the News Title feature and FastText process can have a significant improvement on DLN fake news detection with accuracy rates exceeding 98%</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/RIVF51545.2021.9642125" target="_blank"> Multimodal Fusion with BERT and Attention Mechanism for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85124100792</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Duc Tuan N.M., Quang Nhat Minh P.</b></td></tr><tr><td colspan="3">Organisations: <b>Toyo University, Aimesoft JSC</b></td></tr><tr><td colspan="3">Fake news detection is an important task for in- creasing the reliability of the information on the internet since fake news is spreading fast on social media and has a negative effect on our society. In this paper, we present a novel method for detecting fake news by fusing multi-modal features derived from textual and visual data. Specifically, we proposed a scaled dot- product attention mechanism to capture the relationship between text features extracted by a pre-trained BERT model and visual features extracted by a pre-trained VGG-19 model. Experimental results showed that our method improved against the current state-of-the-art method on a public Twitter dataset by 3.1% accuracy.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ISCSIC54682.2021.00027" target="_blank"> Active Learning for Text Classification and Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85124148818</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Sahan M., Smidl V., Marik R.</b></td></tr><tr><td colspan="3">Organisations: <b>CTU in Prague</b></td></tr><tr><td colspan="3">Supervised classification of texts relies on the availability of reliable class labels for the training data. However, the process of collecting data labels can be complex and costly. A standard procedure is to add labels sequentially by querying an annotator until reaching satisfactory performance. Active learning is a process of selecting unlabeled data records for which the knowledge of the label would bring the highest discriminability of the dataset. In this paper, we provide a comparative study of various active learning strategies for different embeddings of the text on various datasets. We focus on Bayesian active learning methods that are used due to their ability to represent the uncertainty of the classification procedure. We compare three types of uncertainty representation: i) SGLD, ii) Dropout, and iii) deep ensembles. The latter two methods in cold-and warm-start versions. The texts were embedded using Fast Text, LASER, and RoBERTa encoding techniques. The methods are tested on two types of datasets, text categorization (Kaggle News Category and Twitter Sentiment140 dataset) and fake news detection (Kaggle Fake News and Fake News Detection datasets). We show that the conventional dropout Monte Carlo approach provides good results for the majority of the tasks. The ensemble methods provide more accurate representation of uncertainty that allows to keep the pace of learning of a complicated problem for the growing number of requests, outperforming the dropout in the long run. However, for the majority of the datasets the active strategy using Dropout MC and Deep Ensembles achieved almost perfect performance even for a very low number of requests. The best results were obtained for the most recent embeddings RoBERTa</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-16-8885-0_4" target="_blank"> Fake News Detection Based on a Bi-directional LSTM with CNN<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85124149505</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Ji Y.</b></td></tr><tr><td colspan="3">Organisations: <b>University of California</b></td></tr><tr><td colspan="3">The misleading information brought by fake news has troubled our society for a long time. Recently, the increasing spreading rate of fake news has more severe consequences than ever in the past. Many types of neural networks have been applied to solve fake news detection and other natural language problems during these years. Nevertheless, due to the limitation of each structure, a hybrid neural network would often achieve a preferable accuracy. In this paper, a novel deep neural network is proposed for the fake news detection problem based on Convolutional Neural Network and Bi-directional Long Short Term Memory network. Sequential information will be captured by using Bi-LSTM and hidden features will be captured at a detailed level using CNN. The model will be tested on large-scale datasets, which demonstrated better performance than conventional neural networks.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3461614" target="_blank"> Enriching Conventional Ensemble Learner with Deep Contextual Semantics to Detect Fake News in Urdu<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85124261357</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Saeed R., Afzal H., Abbas H., Fatima M.</b></td></tr><tr><td colspan="3">Organisations: <b>National University of Sciences and Technology (NUST)</b></td></tr><tr><td colspan="3">Increased connectivity has contributed greatly in facilitating rapid access to information and reliable communication. However, the uncontrolled information dissemination has also resulted in the spread of fake news. Fake news might be spread by a group of people or organizations to serve ulterior motives such as political or financial gains or to damage a country's public image. Given the importance of timely detection of fake news, the research area has intrigued researchers from all over the world. Most of the work for detecting fake news focuses on the English language. However, automated detection of fake news is important irrespective of the language used for spreading false information. Recognizing the importance of boosting research on fake news detection for low resource languages, this work proposes a novel semantically enriched technique to effectively detect fake news in Urdu-a low resource language. A model based on deep contextual semantics learned from the convolutional neural network is proposed. The features learned from the convolutional neural network are combined with other n-gram-based features and are fed to a conventional majority voting ensemble classifier fitted with three base learners: Adaptive Boosting, Gradient Boosting, and Multi-Layer Perceptron. Experiments are performed with different models, and results show that enriching the traditional ensemble learner with deep contextual semantics along with other standard features shows the best results and outperforms the state-of-The-Art Urdu fake news detection model.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3472619" target="_blank"> A Transformer-Based Approach to Multilingual Fake News Detection in Low-Resource Languages<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85124270042</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>De A., Bandyopadhyay D., Gain B., Ekbal A.</b></td></tr><tr><td colspan="3">Organisations: <b>Indian Institute of Technology Hyderabad, Indian Institute of Technology Patna</b></td></tr><tr><td colspan="3">Fake news classification is one of the most interesting problems that has attracted huge attention to the researchers of artificial intelligence, natural language processing, and machine learning (ML). Most of the current works on fake news detection are in the English language, and hence this has limited its widespread usability, especially outside the English literate population. Although there has been a growth in multilingual web content, fake news classification in low-resource languages is still a challenge due to the non-Availability of an annotated corpus and tools. This article proposes an effective neural model based on the multilingual Bidirectional Encoder Representations from Transformer (BERT) for domain-Agnostic multilingual fake news classification. Large varieties of experiments, including language-specific and domain-specific settings, are conducted. The proposed model achieves high accuracy in domain-specific and domain-Agnostic experiments, and it also outperforms the current state-of-The-Art models. We perform experiments on zero-shot settings to assess the effectiveness of language-Agnostic feature transfer across different languages, showing encouraging results. Cross-domain transfer experiments are also performed to assess language-independent feature transfer of the model. We also offer a multilingual multidomain fake news detection dataset of five languages and seven different domains that could be useful for the research and development in resource-scarce scenarios.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3505588" target="_blank"> Introduction to Special Issue on Misinformation, Fake News and Rumor Detection in Low-Resource Languages<a></b></td></tr><tr><td>Type: Review</td><td>ID: S_2-s2.0-85124271505</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Kumar A., Esposito C., Karras D.A.</b></td></tr><tr><td colspan="3">Organisations: <b>-</b></td></tr><tr><td colspan="3">-</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3472620" target="_blank"> Persian Fake News Detection: Neural Representation and Classification at Word and Text Levels<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85124299339</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Samadi M., Mousavian M., Momtazi S.</b></td></tr><tr><td colspan="3">Organisations: <b>Amirkabir University of Technology</b></td></tr><tr><td colspan="3">Nowadays, broadcasting news on social media and websites has grown at a swifter pace, which has had negative impacts on both the general public and governments; hence, this has urged us to build a fake news detection system. Contextualized word embeddings have achieved great success in recent years due to their power to embed both syntactic and semantic features of textual contents. In this article, we aim to address the problem of the lack of fake news datasets in Persian by introducing a new dataset crawled from different news agencies, and propose two deep models based on the Bidirectional Encoder Representations from Transformers model (BERT), which is a deep contextualized pre-Trained model for extracting valuable features. In our proposed models, we benefit from two different settings of BERT, namely pool-based representation, which provides a representation for the whole document, and sequence representation, which provides a representation for each token of the document. In the former one, we connect a Single Layer Perceptron (SLP) to the BERT to use the embedding directly for detecting fake news. The latter one uses Convolutional Neural Network (CNN) after the BERT's embedding layer to extract extra features based on the collocation of words in a corpus. Furthermore, we present the TAJ dataset, which is a new Persian fake news dataset crawled from news agencies' websites. We evaluate our proposed models on the newly provided TAJ dataset as well as the two different Persian rumor datasets as baselines. The results indicate the effectiveness of using deep contextualized embedding approaches for the fake news detection task. We also show that both BERT-SLP and BERT-CNN models achieve superior performance to the previous baselines and traditional machine learning models, with 15.58% and 17.1% improvement compared to the reported results by Zamani et al. [30], and 11.29% and 11.18% improvement compared to the reported results by Jahanbakhsh-Nagadeh et al. [9].</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3447650" target="_blank"> Fake News Classification: A Quantitative Research Description<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85124315738</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Jain R., Jain D.K., Dharana, Sharma N.</b></td></tr><tr><td colspan="3">Organisations: <b>Bharati Vidyapeeth's College of Engineering, Chongqing University of Posts and Telecommunications</b></td></tr><tr><td colspan="3">Social media can render content circulating to reach millions with a knack to influence people, despite the questionable authencity of the facts. Internet sources are the most convenient and easy approach to obtain any information these days. Fake news has become the topic of interest for academicians and the rest of society. This kind of propaganda has the power to influence the general perception, offering political groups the ability to control the results of democratic affairs such as elections. Automatic identification of fake news has emerged as one of the significant problems due to the high risks involved. It is challenging in a way because of the complexity levels of accurately interpreting the data. An extensive search has already been performed on English language news data. Our work presents a comparative analysis of fake news classifiers on the low resource Bengali language ĝ€ban fake news' dataset from Kaggle. The analysis presented compares deep learning techniques such as LSTM (Long short-Term Memory) and BiLSTM (Bi-directional Long short-Term Memory) and machine learning methods like Naive Bayes, Passive Aggressive Classifier (PAC), and Random Forest. The comparison has been drawn based on classification metrics such as accuracy, precision, recall, and F1 score. The deep learning method BiLSTM shows 55.92% accuracy while Random Forest, in contrast, has outperformed all the other methods with an accuracy of 62.37%. The work presented in this paper sets a basis for researchers to select the optimum classifiers for their approach towards fake news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.datak.2022.101985" target="_blank"> FaNDS: Fake News Detection System using energy flow<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85124320464</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Xu J., Zadorozhny V., Zhang D., Grant J.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Pittsburgh, University of Maryland</b></td></tr><tr><td colspan="3">Recently, the term “fake news” has been broadly and extensively utilized for disinformation, misinformation, hoaxes, propaganda, satire, rumors, click-bait, and junk news. It has become a serious problem around the world. We present a new system, FaNDS, that detects fake news efficiently. The system is based on several concepts used in some previous works but in a different context. There are two main concepts: an Inconsistency Graph and Energy Flow. The Inconsistency Graph contains news items as nodes and inconsistent opinions between them for edges. Energy Flow assigns each node an initial energy and then some energy is propagated along the edges until the energy distribution on all nodes converges. To illustrate FaNDS we use the original data from the Fake News Challenge (FNC-1). First, the data has to be reconstructed in order to generate the Inconsistency Graph. The graph contains various subgraphs with well-defined shapes that represent different types of connections between the news items. Then the Energy Flow method is applied. The nodes with high energy are the candidates for being fake news. In our experiments, all these were indeed fake news as we checked each using several reliable web sites. We compared FaNDS to several other fake news detection methods and found it to be more sensitive in discovering fake news items.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3503162.3505240" target="_blank"> UrduFake@FIRE2021: Shared Track on Fake News Identification in Urdu<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85124364536</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Amjad M., Butt S., Sidorov G., Gelbukh A., Amjad H.I., Zhila A.</b></td></tr><tr><td colspan="3">Organisations: <b>Instituto Politecnico Nacional, Moscow Institute of Physics and Technology, Ronin Institute for Independent Scholarship</b></td></tr><tr><td colspan="3">This study reports the second shared task named as UrduFake@Fire2021 on identifying fake news detection in Urdu language. This is a binary classification problem in which the task is to classify a given news article into two classes: (i) real news, or (ii) fake news. In this shared task, 34 teams from 7 different countries (China, Egypt, Israel, India, Mexico, Pakistan, and UAE)registered to participate in the shared task, 18 teams submitted their experimental results and 11 teams submitted their technical reports. The proposed systems were based on various count-based features and used different classifiers as well as neural network architectures. The stochastic gradient descent (SGD) algorithm outperformed other classifiers and achieved 0.679 F-score.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.4018/978-1-7998-2543-2.ch004" target="_blank"> 'Fake News' in the context of information literacy: A Canadian case study<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85124370336</td><td>Year: <b>2020</b></td></tr><tr><td colspan="3">Authors: <b>Delellis N.S., Rubin V.L.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Western Ontario</b></td></tr><tr><td colspan="3">This chapter describes a study that interviewed 18participants (8professors, 6 librarians, and 4 department chairs) about their perceptions of 'fake news' in the context of their educational roles in information literacy (IL) within a large Canadian university. Qualitative analysis of the interviews reveals a substantial overlap in these educators ' perceptions of skills associated with IL and 'fake news ' detection. Librarians ' IL role seems to be undervalued. Better communication among integral IL educator groups is recommended. Most study participants emphasized the need for incorporating segments dedicated to detecting 'fake news' in IL curricula. Pro-active IL campaigns to prevent, detect, and deter the spread of various 'fakes' in digital media and specialized mis-/disinformation awareness courses are among best practices that support critical thinking and information evaluation within the societal context. Two other interventions, complementary to IL as per Rubin 's Disinformation and Misinformation Triangle, are suggested - detection automation technology and media regulation.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Overview of the Shared Task on Fake News Detection in Urdu at FIRE 2021<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85124373581</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Amjad M., Butt S., Sidorov G., Gelbukh A., Zhila A., Amjad H.I.</b></td></tr><tr><td colspan="3">Organisations: <b>Center for Computing Research (CIC), Ronin Institute for Independent Scholarship, Moscow Institute of Physics and Technology</b></td></tr><tr><td colspan="3">Automatic detection of fake news is a highly important task in the contemporary world. This study reports the 2nd shared task called UrduFake@FIRE2021 on identifying fake news detection in Urdu language. The goal of the shared task is to motivate the community to come up with efficient methods for solving this vital problem, particularly for the Urdu language. The task is posed as a binary classification problem to label a given news article as a real or a fake news article. The organizers provide a dataset comprising news in five domains: (i) Health, (ii) Sports, (iii) Showbiz, (iv) Technology, and (v) Business, split into training and testing sets. The training set contains 1300 annotated news articles —750 real news, 550 fake news, while the testing set contains 300 news articles —200 real, 100 fake news. 34 teams from 7 different countries (China, Egypt, Israel, India, Mexico, Pakistan, and UAE) registered for participation in the UrduFake@FIRE2021 shared task. Out of those, 18 teams submitted their experimental results and 11 of those submitted their technical reports, which is substantially higher compared to the UrduFake shared task in 2020 when only 6 teams submitted their technical reports. The technical reports submitted by the participants demonstrated different data representation techniques ranging from count-based BoW features to word vector embeddings as well as the use of numerous machine learning algorithms ranging from traditional SVM to various neural network architectures including Transformers such as BERT and RoBERTa. In this year’s competition, the best performing system obtained an F1-macro score of 0.679, which is lower than the past year’s best result of 0.907 F1-macro. Admittedly, while training sets from the past and the current years overlap to a large extent, the testing set provided this year is completely different.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3487351.3490960" target="_blank"> Fake news and COVID-19 vaccination: A comparative study<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85124387144</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Jouyandeh F., Sadeghi S., Rahmatikargar B., Zadeh P.M.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Windsor</b></td></tr><tr><td colspan="3">COVID-19 pandemic has changed almost every aspect of people's lives around the world. Along with non-pharmaceutical interventions such as physical distancing, vaccination is one of the proposed solutions to control the spread of this pandemic. However, so much fake information is spread on social media websites about the vaccination. In this paper, we study the problem of fake news detection on Twitter network. After collecting a dataset and pre-processing, a set of features are extracted from the tweets. This includes the tweet's length and its keywords, number of followers, sentiment, and readability scores. In the next phase, six well-known classifiers are executed on this data, and the best result with the highest accuracy is chosen for the community detection process to study and track the evolution of fake news campaigns. For the analysis, we considered multiple criteria such as the number of communities, their sizes, leaders, and topics. The results of this research can help decision-makers to understand the underlying and formation of fake news campaigns.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3487351.3488346" target="_blank"> MMCoVaR: Multimodal COVID-19 vaccine focused data repository for fake news detection and a baseline architecture for classification<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85124405047</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Chen M., Chu X., Subbalakshmi K.P.</b></td></tr><tr><td colspan="3">Organisations: <b>Stevens Institute of Technology</b></td></tr><tr><td colspan="3">The outbreak of COVID-19 has resulted in an "infodemic"that has encouraged the propagation of misinformation about COVID-19 and cure methods which, in turn, could negatively affect the adoption of recommended public health measures in the larger population. In this paper, we provide a new multimodal (consisting of images, text and temporal information) labeled dataset containing news articles and tweets on the COVID-19 vaccine. We collected 2,593 news articles from 80 publishers for one year between Feb 16th 2020 to May 8th 2021 and 24184 Twitter posts (collected between April 17th 2021 to May 8th 2021). We combine ratings from two news media ranking sites: Medias Bias Chart and Media Bias/Fact Check (MBFC) to classify the news dataset into two levels of credibility: reliable and unreliable. The combination of two filters allows for higher precision of labeling. We also propose a stance detection mechanism to annotate tweets into three levels of credibility: reliable, unreliable and inconclusive. We provide several statistics as well as other analytics like, publisher distribution, publication date distribution, topic analysis, etc. We also provide a novel architecture that classifies the news data into misinformation or truth to provide a baseline performance for this dataset. We find that the proposed architecture has an F-Score of 0.919 and accuracy of 0.882 for fake news detection. Furthermore, we provide benchmark performance for misinformation detection on tweet dataset. This new multimodal dataset can be used in research on COVID-19 vaccine, including misinformation detection, influence of fake COVID-19 vaccine information, etc.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3487351.3490965" target="_blank"> SCATE: Shared cross attention transformer encoders for multimodal fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85124406944</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Sachan T., Pinnaparaju N., Gupta M., Varma V.</b></td></tr><tr><td colspan="3">Organisations: <b>IIIT Hyderabad</b></td></tr><tr><td colspan="3">Social media platforms have democratized the publication process resulting into easy and viral propagation of information. Oftentimes this misinformation is accompanied by misleading or doctored images that quickly circulate across the internet and reach many unsuspecting users. Several manual as well as automated efforts have been undertaken in the past to solve this critical problem. While manual efforts cannot keep up with the rate at which this content is churned out, many automated approaches only leverage concatenation (of the image and text representations) thereby failing to build effective crossmodal embeddings. Architectures like this fail in many cases because the text or image doesn't need to be false for the corresponding text, image pair to be misinformation. While some recent work attempts to use attention techniques to compute a crossmodal representation using pretrained text and image embeddings, we show a more effective approach towards utilizing such pretrained embeddings to build richer representations that can be classified better. This involves several challenges like how to handle text variations on Twitter and Weibo, how to encode the image information and how to leverage the text and image encodings together effectively. Our architecture, SCATE (Shared Cross Attention Transformer Encoders), leverages deep convolutional neural networks and transformer-based methods to encode image and text information utilizing crossmodal attention and shared layers for the two modalities. Our experiments with three popular benchmark datasets (Twitter, WeiboA and WeiboB) show that our proposed methods outperform the state-of-the-art methods by approximately three percentage points on all three datasets.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.3390/app12031743" target="_blank"> Efficient Fake News Detection Mechanism Using Enhanced Deep Learning Model<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85124491751</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Ahmad T., Faisal M.S., Rizwan A., Khan P.W., Alkanhel R., Muthanna A.</b></td></tr><tr><td colspan="3">Organisations: <b>COMSATS University Islamabad, Jeju National University, Princess Nourah bint Abdulrahman University, The Bonch-Bruevich Saint-Petersburg State University of Telecommunications, Peoples’ Friendship University of Russia (RUDN University)</b></td></tr><tr><td colspan="3">The spreading of accidental or malicious misinformation on social media, specifically in critical situations, such as real-world emergencies, can have negative consequences for society. This facilitates the spread of rumors on social media. On social media, users share and exchange the latest information with many readers, including a large volume of new information every second. However, updated news sharing on social media is not always true.In this study, we focus on the challenges of numerous breaking-news rumors propagating on social media networks rather than long-lasting rumors. We propose new social-based and content-based features to detect rumors on social media networks. Furthermore, our findings show that our proposed features are more helpful in classifying rumors compared with state-of-the-art baseline features. Moreover, we apply bidirectional LSTM-RNN on text for rumor prediction. This model is simple but effective for rumor detection. The majority of early rumor detection research focuses on long-running rumors and assumes that rumors are always false. In contrast, our experiments on rumor detection are conducted on real-world scenario data set. The results of the experiments demonstrate that our proposed features and different machine learning models perform best when compared to the state-of-the-art baseline features and classifier in terms of precision, recall, and F1 measures.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/IDSTA53674.2021.9660811" target="_blank"> Detecting Arabic Fake News Using Machine Learning<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85124504151</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Khalil A., Jarrah M., Jararweh Y., Aldwairi M.</b></td></tr><tr><td colspan="3">Organisations: <b>Jordan University of Science and Technology, Zayed University</b></td></tr><tr><td colspan="3">The rise of fake news has been the subject of several research studies in the last decade. This is due to the increasing number of Internet users and the simplicity in posting news over platforms and websites. Hence, researchers have been developing machine learning (ML) models to detect fake contents and warn readers. However, there is a limited number of Arabic fake news datasets in terms of articles and news sources. This paper aims at introducing the first large Arabic fake news corpus which consists of 606912 articles collected from 134 Arabic online news sources. An Arabic fact-check platform is used to annotate news sources as credible, not-credible, and undecided. Moreover, different ML algorithms are used for the detection task. Experiments show that deep learning models perform better than traditional ML models. Models training showed underfitting and overfitting problems which indicate that the corpus is noisy and challenging.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.neucom.2022.01.096" target="_blank"> Knowledge graph informed fake news classification via heterogeneous representation ensembles<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85124506470</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Koloski B., Skrlj B., Stepisnik Perdih T., Pollak S., Robnik-Sikonja M.</b></td></tr><tr><td colspan="3">Organisations: <b>Jožef Stefan Int. Postgraduate School, Jožef Stefan Institute, University of Ljubljana</b></td></tr><tr><td colspan="3">Increasing amounts of freely available data both in textual and relational form offers exploration of richer document representations, potentially improving the model performance and robustness. An emerging problem in the modern era is fake news detection—many easily available pieces of information are not necessarily factually correct, and can lead to wrong conclusions or are used for manipulation. In this work we explore how different document representations, ranging from simple symbolic bag-of-words, to contextual, neural language model-based ones can be used for efficient fake news identification. One of the key contributions is a set of novel document representation learning methods based solely on knowledge graphs, i.e., extensive collections of (grounded) subject-predicate-object triplets. We demonstrate that knowledge graph-based representations already achieve competitive performance to conventionally accepted representation learners. Furthermore, when combined with existing, contextual representations, knowledge graph-based document representations can achieve state-of-the-art performance. To our knowledge this is the first larger-scale evaluation of how knowledge graph-based representations can be systematically incorporated into the process of fake news classification.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICITR54349.2021.9657257" target="_blank"> Ontology Based Fake News Detection for Sinhala Language<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85124539831</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Bandara O., Jayarathne D., Shashinika D., Ranathunga L.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Moratuwa</b></td></tr><tr><td colspan="3">With the current trend in extensive use of internet technologies, people are accustomed to a life of being online. Similar phenomena apply for news awareness as well where social media has become one of the main sources of information of these tech-savvy people. Even though it gives easy access to information, there is a problem with the trustworthiness and authenticity of the news posted on social media. As such, fake news detection in social media platforms has become an active research area. Despite that, for the Sinhala language, there are only a few attempts carried out to detect fake news. With this background, this research project has come up with a novel idea of ontology-based fake news detection for news published using Sinhala language. We believe that content-based fake news identification is the most appropriate method to assess the truthiness of a news article and our system was able to give promising results in detecting fake news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s13204-021-02330-4" target="_blank"> Hybrid deep learning model for automatic fake news detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85124568496</td><td>Year: <b>2023</b></td></tr><tr><td colspan="3">Authors: <b>Hanshal O.A., Ucan O.N., Sanjalawe Y.K.</b></td></tr><tr><td colspan="3">Organisations: <b>İstanbul Altınbaş Üniversitesi</b></td></tr><tr><td colspan="3">With the fast advancement in digital news, fake news has already caused grave threats to the public’s actual judgment and credibility, in specific, with the wide use of social networking platforms, which provide a rich environment for the generation and dissemination of fake news. To cope with these challenges, several techniques were proposed to detect fake news, but still, there is an urgent need to propose an improved detection technique that provides a high level of detection performance in an automatic manner. Therefore, this article proposes a hybrid-improved deep learning model for automatic fake news detection. The proposed model adopts automatic data augmentation method, called Auxiliary Classifier Generative Adversarial Networks, to artificially synthesize new fake news samples, and then, hybridize the Convolutional Neural Network with the Recurrent Neural Networks to detect the fake news efficiently. The proposed model shows superior results against the state-of-the-art models as it provides 93.87% accuracy, 10.39% recall, 93.12% precision in detecting the fake news using Buzzfeed, FakeNewsNet and FakeNewsChallenges datasets.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.techsoc.2022.101930" target="_blank"> People lie, actions Don't! Modeling infodemic proliferation predictors among social media users<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85124591704</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Raj C., Meel P.</b></td></tr><tr><td colspan="3">Organisations: <b>Delhi Technological University</b></td></tr><tr><td colspan="3">Social media is interactive, and interaction brings misinformation. With the growing amount of user-generated data, fake news on online platforms has become much more frequent since the arrival of social networks. Now and then, an event occurs and becomes the topic of discussion, generating and propagating false information. Existing literature studying fake news elaborates primarily on fake news classification models. Approaches exploring fake news characteristics to distinguish it from real news are minimal. Not much research has focused on statistical testing and generating new factor discoveries. This study assumes fifteen hypotheses to identify factors exhibiting a relationship with fake news. We perform the experiments on two real-world COVID-19 datasets using qualitative and quantitative testing methods. We determine the impact of conditional effects among sentiment, gender, and media usage. This study concludes that sentiment polarity and gender can significantly identify fake news. Dependence on the presence of visual media is, however, inconclusive. Additionally, Twitter-specific user engagement factors like followers count, friends count, favorite count, and retweet count significantly differ in fake and real news. Though, the contribution of status count is currently disputed. This study identifies practical factors to be conjunctly utilized in developing fake news detection algorithms.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/CEC45853.2021.9504723" target="_blank"> Mitigating Attacks on Fake News Detection Systems using Genetic-Based Adversarial Training<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85124621054</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Smith M., Brown B., Dozier G., King M.</b></td></tr><tr><td colspan="3">Organisations: <b>Auburn University, School of Computing</b></td></tr><tr><td colspan="3">The study of adversarial effects on AI systems is not a new concept, but much of the research has been devoted to deep learning. In this paper we explore the effects of adversarial examples on 4 machine learning classifiers and measure the effectiveness of adversarial training. Additionally, we present a novel method for selecting adversarial training examples that lead to a more robust machine learning system. Our results suggest that adversarial examples can significantly hinder the classification performance and that adversarial training is an effective defensive counter-measure.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICCICT50803.2021.9510134" target="_blank"> A Hybrid Method for Fake News Detection using Cosine Similarity Scores<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85124700780</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Mhatre S., Masurkar A.</b></td></tr><tr><td colspan="3">Organisations: <b>Vidyalankar Institute of Technology</b></td></tr><tr><td colspan="3">In this work, we propose a novel hybrid method for fake news detection. Two approaches have been used to assess the authenticity of the news using web-scrapped data. In the first approach the data is the pre-processed using NLP techniques like extraction of raw text, the removal of special-characters, white-spaces, and stop words. This is followed by lemmatization which groups words with similar meanings. After Lemmatization we apply, Term Frequency - Inverse Document Frequency (TF-IDF) Vectorization to form a corpus which is further used to train the models. We propose the use of cosine similarity score, obtained after performing topic modelling along with the corpus to improve the classification accuracies. The classifiers are KNN, Decision Tree, Naive Bayes, Logistic Regression, Passive-aggressive Classifier, and SVM to determine the news is reliable or unreliable. More focus has been given to improve the classification accuracies of the passive aggressive classifier which is the most widely used classifier in fake news detection. In the second approach, we use ensemble learning technique called as stacking along with cosine similarity score to train another model which gives the result as reliable or unreliable. It is observed that the second approach shows good improvement in the accuracy of fake news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1088/1742-6596/2161/1/012027" target="_blank"> Fake News Detection from Online media using Machine learning Classifiers<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85124705668</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Pandey S., Prabhakaran S., Reddy N.V.S., Acharya D.</b></td></tr><tr><td colspan="3">Organisations: <b>MAHE</b></td></tr><tr><td colspan="3">With the advancement in technology, the consumption of news has shifted from Print media to social media. The convenience and accessibility are major factors that have contributed to this shift in consumption of the news. However, this change has bought upon a new challenge in the form of “Fake news” being spread with not much supervision available on the net. In this paper, this challenge has been addressed through a Machine learning concept. The algorithms such as K-Nearest Neighbor, Support Vector Machine, Decision Tree, Naïve Bayes and Logistic regression Classifiers to identify the fake news from real ones in a given dataset and also have increased the efficiency of these algorithms by pre-processing the data to handle the imbalanced data more appropriately. Additionally, comparison of the working of these classifiers is presented along with the results. The model proposed has achieved an accuracy of 89.98% for KNN, 90.46% for Logistic Regression, 86.89% for Naïve Bayes, 73.33% for Decision Tree and 89.33% for SVM in our experiment.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s13369-021-06449-y" target="_blank"> Arabic Fake News Detection Based on Textual Analysis<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85124753230</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Himdi H., Weir G., Assiri F., Al-Barhamtoshy H.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Strathclyde, University of Jeddah, King Abdulaziz University</b></td></tr><tr><td colspan="3">Over the years, social media has had a considerable impact on the way we share information and send messages. With this comes the problem of the rapid distribution of fake news which can have negative impacts on both individuals and society. Given the potential negative influence, detecting unmonitored ‘fake news’ has become a critical issue in mainstream media. While there are recent studies that built machine learning models that detect fake news in several languages, lack of studies in detecting fake news in the Arabic language is scare. Hence, in this paper, we study the issue of fake news detection in the Arabic language based on textual analysis. In an attempt to address the challenges of authenticating news, we introduce a supervised machine learning model that classifies Arabic news articles based on their context’s credibility. We also introduce the first dataset of Arabic fake news articles composed through crowdsourcing. Subsequently, to extract textual features from the articles, we create a unique approach of forming Arabic lexical wordlists and design an Arabic Natural Language Processing tool to perform textual features extraction. The findings of this study promises great results and outperformed human performance in the same task.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.3390/math10040569" target="_blank"> MisRoBÆRTa: Transformers versus Misinformation<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85124767694</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Truica C.-O., Apostol E.-S.</b></td></tr><tr><td colspan="3">Organisations: <b>Uppsala University, University Politehnica of Bucharest</b></td></tr><tr><td colspan="3">Misinformation is considered a threat to our democratic values and principles. The spread of such content on social media polarizes society and undermines public discourse by distorting public perceptions and generating social unrest while lacking the rigor of traditional journalism. Transformers and transfer learning proved to be state-of-the-art methods for multiple well-known natural language processing tasks. In this paper, we propose MisRoBÆRTa, a novel transformer-based deep neural ensemble architecture for misinformation detection. MisRoBÆRTa takes advantage of two state-of-the art transformers, i.e., BART and RoBERTa, to improve the performance of discriminating between real news and different types of fake news. We also benchmarked and evaluated the performances of multiple transformers on the task of misinformation detection. For training and testing, we used a large real-world news articles dataset (i.e., 100,000 records) labeled with 10 classes, thus addressing two shortcomings in the current research: (1) increasing the size of the dataset from small to large, and (2) moving the focus of fake news detection from binary classification to multi-class classification. For this dataset, we manually verified the content of the news articles to ensure that they were correctly labeled. The experimental results show that the accuracy of transformers on the misinformation detection problem was significantly influenced by the method employed to learn the context, dataset size, and vocabulary dimension. We observe empirically that the best accuracy performance among the classification models that use only one transformer is obtained by BART, while DistilRoBERTa obtains the best accuracy in the least amount of time required for fine-tuning and training. However, the proposed MisRoBÆRTa outperforms the other transformer models in the task of misinformation detection. To arrive at this conclusion, we performed ample ablation and sensitivity testing with MisRoBÆRTa on two datasets.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.knosys.2022.108378" target="_blank"> A quantitative argumentation-based Automated eXplainable Decision System for fake news detection on social media<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85124876446</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Chi H., Liao B.</b></td></tr><tr><td colspan="3">Organisations: <b>Zhejiang University</b></td></tr><tr><td colspan="3">Social media is flooded with rumors, which make fake news detection a pressing problem. Many black-box approaches have been proposed to automatically predict the veracity of claims. These methods are lack of interpretability. Thus, we propose a Quantitative Argumentation-based Automated eXplainable Decision-making System (QA-AXDS) to tackle this problem and provide users with explanations about the results. The system is fully data-driven in its processes, which allows our models to make greater use of data and be more automatic and scalable than other quantitative framework models. In terms of interpretability, the system can automatically acquire human-level knowledge, and interact with users in the form of dialog trees through explanatory models, thus helping them understand the internal reasoning process of the system. The experimental results show that our system has better transparency and interpretability than other approaches based on the pure machine learning methods, and performs competitively in accuracy among others. In addition, the explanation model provides a way to improve the algorithms when some problems are identified by checking the explanations.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.3390/math10040585" target="_blank"> TB-BCG: Topic-Based BART Counterfeit Generator for Fake News Detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85124987452</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Karnyoto A.S., Sun C., Liu B., Wang X.</b></td></tr><tr><td colspan="3">Organisations: <b>People’s Daily Online, School of Computer Science and Technology</b></td></tr><tr><td colspan="3">Fake news has been spreading intentionally and misleading society to believe unconfirmed information; this phenomenon makes it challenging to identify fake news based on shared content. Fake news circulation is not only a current issue, but it has been disseminated for centuries. Dealing with fake news is a challenging task because it spreads massively. Therefore, automatic fake news detection is urgently needed. We introduced TB-BCG, Topic-Based BART Counterfeit Generator, to increase detection accuracy using deep learning. This approach plays an essential role in selecting impacted data rows and adding more training data. Our research implemented Latent Dirichlet Allocation (Topic-based), Bidirectional and Auto-Regressive Transformers (BART), and Cosine Document Similarity as the main tools involved in Constraint @ AAAI2021-COVID19 Fake News Detection dataset shared task. This paper sets forth this simple yet powerful idea by selecting a dataset based on topic and sorting based on distinctive data, generating counterfeit training data using BART, and comparing counterfeit-generated text toward source text using cosine similarity. If the comparison value between counterfeit-generated text and source text is more than 95%, then add that counterfeit-generated text into the dataset. In order to prove the resistance of precision and the robustness in various numbers of data training, we used 30%, 50%, 80%, and 100% from the total dataset and trained it using simple Long Short-Term Memory (LSTM) and Convolutional Neural Network (CNN). Compared to baseline, our method improved the testing performance for both LSTM and CNN, and yields are only slightly different.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.jocs.2022.101576" target="_blank"> Technical solution to counter potential crime: Text analysis to detect fake news and disinformation<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85125017121</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Kozik R., Choras M., Wozniak M., Kula S.</b></td></tr><tr><td colspan="3">Organisations: <b>Bydgoszcz University of Science and Technology, Kazimierz Wielki University, Wrocław University of Science and Technology</b></td></tr><tr><td colspan="3">Fake news detection is a challenging and complex task. Yet, several approaches to deal with this problem have already been proposed. The majority of solutions employ the NLP-based approach, where various architectures of a deep artificial neural network are proposed. However, as the experiments show, different NLP-based solutions have great performance in a single domain, but transferring them to another one is tedious. Therefore, in this paper, we propose a hybrid approach to dealing with this problem. Instead of retraining one big model on different types of data, we bundle several smaller models using meta-learning techniques. This paper is an extension of our previous research presented in Kula et al. (2021).</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/AIMV53313.2021.9670914" target="_blank"> Chatbot User Interface for Customer Relationship Management using NLP models<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85125018575</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Doshi J.</b></td></tr><tr><td colspan="3">Organisations: <b>New York University</b></td></tr><tr><td colspan="3">NLP is the most researched field. Speech-totext conversions, fake-news detection, and text summarization are the hot topics of NLP. ChatBot User Interface(UI) using NLP, allows machines to understand customers better. The aim was to use different NLP and machine learning techniques and to add ChatBot UI to guide customers or clients through the CRM software and help them whenever they get stuck. Different approaches, libraries, and algorithms like 'RASA', python's 'Chatterbot', 'Cosine similarity', and Google's embedder were used to train the model and then later compared to see which gave the best results. After that, during the deployment other 2 approaches were tried, one was fetching questions from the database and then training the model, the other was to maintain a local text document and train the model from that. The advantages and disadvantages of each approach, plus challenges and better methods for deployment is also discussed.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.4018/IJWLTT.287096" target="_blank"> Detecting Fake News Over Job Posts via Bi-Directional Long Short-Term Memory (BIDLSTM)<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85125019589</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Divya T.V., Banik B.G.</b></td></tr><tr><td colspan="3">Organisations: <b>Koneru Lakshmaiah Education Foundation (Deemed)</b></td></tr><tr><td colspan="3">Detection of fake news on job advertisements has grabbed the attention of many researchers over the past decade. Various forms of classifiers such as support vector machine (SVM), XGBoost classifier, and random forest classifier (RF) methods are greatly utilized for fake and real news detection about job advertisement posts in social media. There exhibits the slight or elusive variance among fake and the real news, which are obtained through topics and word embeddings, that affect system accuracy. Initially, pre-processing steps for job post data like stop word removal, tokenization, and lemmatizing words are done utilizing wordnet. The oversampling procedure is accomplished for data balancing. Subsequently, the new columns are generated representing each possible attribute value existence from original data by suggesting one-hot encoding. The dataset insignificant features removal is accomplished, which is exploited for fake news detection. As a final point, bi-directional long short-term memory classifier (Bi-LSTM) is greatly utilized for learning word representations in lower-dimensional vector space and learning significant words word embedding or terms revealed through the word embedding algorithm. The fake news detection is greatly achieved along with real news on job posts from online social media which is achieved by Bi-LSTM classifier, thereby evaluating corresponding performance. The performance level metrics such as precision, recall, F1-score, and accuracy are assessed for effectiveness by fraudulency based on job posts. The outcome infers the effectiveness and prominence of features for detecting false news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICSC53193.2021.9673192" target="_blank"> ImageFake: An Ensemble Convolution Models Driven Approach for Image Based Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85125037756</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Choudhary A., Arora A.</b></td></tr><tr><td colspan="3">Organisations: <b>Jaypee Institute of Information Technology</b></td></tr><tr><td colspan="3">Social media usage has shot up over the past decade which gives us many wonderful opportunities to showcase ourselves, our skills, and field of competences. In short, the facial nature of social media raised opportunities to create and promote one's own brand to gain influence in the market. Besides exploiting these social media content uplifted the negative impacts of spreading false information as well. As a consequence, falsehood detection in terms of information gain diverted researchers' attention and the same issue has been addressed in this work. We present an ImageFake ensemble model which makes use of abundant pre-trained CNN models to discover the usage of multimedia features for image-based fake news detection and classification. The pre-trained models used for fake news detection and classification are VGG-16, VGG-19, Inception v3, SqueezeNet, and ResNet-101, and finally the bagging ensemble model is used for selecting the best of the bunch. MediaEval 2015, a Twitter dataset is used for the experiment and to validate multimedia feature usage. The performance of pre-trained CNN models on the particular visual domain is performed and compared and out of all best-considered models in terms of accuracy and execution time is ResNet-101 which is able to achieve 96% training accuracy. The ensemble model is able to get training and validation accuracy 97% and 66% respectively.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s11042-022-12290-8" target="_blank"> An effective strategy for multi-modal fake news detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85125044014</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Peng X., Xintong B.</b></td></tr><tr><td colspan="3">Organisations: <b>Beijing University of Posts and Telecommunications</b></td></tr><tr><td colspan="3">News plays an indispensable role in the development of human society. With the emergence of new media, fake news including multi-modal content such as text and images has greater social harm. Therefore how to identify multi-modal fake news has been a challenge. The traditional methods of multi-modal fake news detection are to simply fuse the different modality information, such as concatenation and element-wise product, without considering the different impacts of the different modalities, which leads to the low accuracy of fake news detection. To address this issue, we design a new multi-modal attention adversarial fusion method built on the pre-training language model BERT, which consists of two important components: the attention mechanism and the adversarial mechanism. The attention mechanism is used to capture the differences in different modalities. The adversarial mechanism is to capture the correlation between different modalities. Experiments on a fake news Chinese public dataset indicate that our proposed new method achieves 5% higher in terms of F1.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/AI-CSP52968.2021.9671174" target="_blank"> Arabic Fake News and Spam Handling: Methods, Resources and Opportunities<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85125078830</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Rahab H., Zitouni A., Djoudi M.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Khenchela, University of Constantine 2, University of Poitiers</b></td></tr><tr><td colspan="3">Fake news detection and elimination is an emergent challenge with the growth development in social media and especially by the user-generated content UGC. Works in handling such content are more and more important worldwide, however, those interested in the Arabic language are still very limited when compared to the use of this language on the web. In this paper, we give the main used methods in last years to handle Arabic spam content and fake news in social media. Our findings are twice, the first is that Twitter is the most investigated platform in this area, and the second is the dominance of Arabic dialectal content by spammers. We recommend more works in handling Arabic dialects, also the orientation to other social media platforms such as Facebook, which are the most used in some Arab regions.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/UPCON52273.2021.9667614" target="_blank"> Fake News Detection Using BERT-VGG19 Multimodal Variational Autoencoder<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85125083797</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Jaiswal R., Singh U.P., Singh K.P.</b></td></tr><tr><td colspan="3">Organisations: <b>Mlo Lab</b></td></tr><tr><td colspan="3">In this era of readily accessible Internet, there has been a monumental shift in the way information is created, processed and disseminated to the netizens. Moreover, social media has played a very vital role where users can not only interact with one another and share information but also have the capability to influence the thought process of others through their content. One of the major drawbacks of these platforms remains the absence of credibility in the information being circulated and this inherent vulnerability is exploited by many to circulate fake news over these platforms. This falsehood not only jeopardises the credibility of information and the platform itself but is also a growing technological mess simply because fake news spreads much more rapidly and has the capacity to even cause unrest, discontent and misery among the masses. We propose a BERT and VGG19 based multi-modal variational autoencoder for fake news detection. Our proposed model combines the information present in text and image modality to obtain better discriminatory power. The model takes both text and image data of fake news and extract textual feature and visual feature of the News and process both the feature simultaneously into variational autoencoder so the purposed model is call as multi-model variational autoencoder. Specifically, Bert and VGG19 embeddings are obtained for text and image modalities respectively after which the two embeddings are concatenated and passed through a multi-modal variational autoencoder for obtaining the shared latent representation. The shared latent representation so obtained is then fed to a binary classifier that outputs a probability that the input is fake. Our proposed model gives state of the art results on MediaEval2015 data set (with a 0.924 f-score) and remains competitive with state of the art approaches on Weibo dataset (0.656 f-score).</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/IBSSC53889.2021.9673448" target="_blank"> Effective Fake News Classifier and its Applications to COVID-19<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85125110620</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Garg R., Jeevaraj S.</b></td></tr><tr><td colspan="3">Organisations: <b>ABV-IIITM</b></td></tr><tr><td colspan="3">With the spread of the COVID-19 over the globe, it has conducted a large amount of misinformation and fake news on social networking sites. In this situation, when true and accurate information is necessary for public safety and health, fake news related to COVID-19 has spread rapidly, even quicker than the truth. Rational confusion can be caused by this fake news and put people's lives in danger during times like the COVID-19 pandemic. We used the COVID-19 Fake News dataset to conduct a study to compare the effect of various machine learning-related approaches. We looked at different traditional machine learning models and deep learning language models for detecting fake news and compared their results in multiple ways. We discovered that LSTM and similar neural network models are the most effective at detecting fake news, especially with large datasets. We are confident that our benchmark study will assist the research community and various news blogs/sites to choose the best fake news detection algorithm.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/UEMCON53757.2021.9666642" target="_blank"> The Relation of Online Behavioral Response to Fake News Exposure and Detection Accuracy<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85125179372</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Caramancion K.M.</b></td></tr><tr><td colspan="3">Organisations: <b>State University of New York</b></td></tr><tr><td colspan="3">Using a Fake News test consisting of mixed legitimate and misleading news headlines, this study investigated and explored how the behavioral responses of users (N=153) to false headlines are associated with their ability to detect content legitimacy. The behavioral responses were (a) report the content, (b) engage in debate/discussion, or (c) simply ignore it. The results revealed that the subjects who engaged in a discussion have higher detection accuracy than the mere reporters. The participants who simply ignored the deceptive content performed the poorest while those who performed both reporting and discussion registered with the highest accuracy. The intended target audience of this paper are information scientists, digital forensic professionals, communication experts, policymakers, and other scholars possibly seeking references on this subject.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/BIBM52615.2021.9669662" target="_blank"> COVID-19 Fake News Detection via Graph Neural Networks in Social Media<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85125181769</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Yang Y.</b></td></tr><tr><td colspan="3">Organisations: <b>Huazhong Agricultural University</b></td></tr><tr><td colspan="3">Recently it is convenient for people to seek out and consume news from social media, but misinformation including fake news and low-quality information also spreads which may have extremely negative impacts on individuals and society especially in the pandemics e.g., Covid-19. Previous fake news detectors view articles or tweets as i.i. d data and ignore the relation between them. In this paper we propose a novel fake news detection framework by exploring the similarity relation between tweets and mapping this problem into a semi-supervised classification task on a graph. We evaluate our proposed framework on a real-world social media dataset and the experimental results demonstrate the effectiveness of our proposed method comparing to different baselines.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/UEMCON53757.2021.9666618" target="_blank"> BERT Model for Fake News Detection Based on Social Bot Activities in the COVID-19 Pandemic<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85125186097</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Heidari M., Uzuner O., Jones J.H., Zad S., Hajibabaee P., Malekzadeh M., Hekmatiathar S.</b></td></tr><tr><td colspan="3">Organisations: <b>George Mason University, Florida International University, University of Massachusetts at Lowell, Cornell University</b></td></tr><tr><td colspan="3">In the global pandemic, social media platforms are the primary source of information exchange. Social bots are one of the main sources of misinformation in the COVID-19 pandemic but do social bots spread the fake and real news with the same ratio as human accounts on social media platforms? Can bot detection improve fake news detection on social media platforms? Who presents more fake news in the COVID-19 pandemic, Human or social bots? This work provides preliminary research results based on limited data to answer these questions, but it opens a new perspective on fake news detection and bot detection on online platforms. We use Bidirectional Encoder Representations from Transformers(BERT) to create a new model for fake news detection. We use the transfer learning model to detect bot accounts in the COVID-19 data set. Then apply new features to improve the new fake news detection model in the COVID-19 data set.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/SMART52563.2021.9676333" target="_blank"> Multi Class Fake News Detection using LSTM Approach<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85125193312</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Majumdar B., Rafiuzzamanbhuiyan M., Hasan M.A., Islam M.S., Noori S.R.H.</b></td></tr><tr><td colspan="3">Organisations: <b>Daffodil International University</b></td></tr><tr><td colspan="3">Nowadays the spread of fake news or information is having a detrimental effect on society. Due to the widespread spread of fake news, we sometimes believe a lot of fake news is true. As a result, we face issues and deprive ourselves of a lot of good and realistic news. To protect people's lives from these various problems, we need to work to automatically detect fake news. Fake news detection is very complex task. In this paper we present our approach to address multi class fake news detection using Deep Learning. We used a Long Short Term Memory (LSTM) model for multi class fake news detection using data provided by the task organizers. Our best performing model on the training data achieved an accuracy of 0.98. Our trained model gave an accurate response to the detection of fake news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-16-5689-7_47" target="_blank"> Fake News Classification Using Vectorized Semantic and Syntactical Analysis<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85125258282</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Kumar S., Dhingra P., Jaiswal P., Bharti R.</b></td></tr><tr><td colspan="3">Organisations: <b>Delhi Technological University</b></td></tr><tr><td colspan="3">The sudden growth in wireless communication, computing, and insightful device management has led to the rapid spread of the Internet all over the globe. Internet applications and services can be accessed by people at any given time. This rapid growth has made the quality of living better by saving our efforts and time. However, the spread of the Internet has also increased its misuse in online platforms. One example is the extensive spread of fake news over the globe in social, political, and economic contexts. Fake news is news that is deliberately made to deceive the readers. Fake agendas are distributed as real information as news to the readers. Detection of fake news is a bold task for the already present content analysis of traditional models. Lately, feature extraction in neural network models has gotten an edge over the traditional models in detecting fake news. However, there is still a lot of research scope in the field of fake news detection. In this paper, fake news detection is done on news articles that are spread over the Internet. We built up a model which precisely decides if a news article is fake or real using vectorized semantic and syntactical analysis. The codes and results are available at https://github.com/pushkarrrr/Fake-News-Detection/blob/master/fakenews.ipynb.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/BigData52589.2021.9671970" target="_blank"> Transforming Fake News: Robust Generalisable News Classification Using Transformers<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85125295678</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Blackledge C., Atapour-Abarghouei A.</b></td></tr><tr><td colspan="3">Organisations: <b>Newcastle University, Durham University</b></td></tr><tr><td colspan="3">As online news has become increasingly popular and fake news increasingly prevalent, the ability to audit the veracity of online news content has become more important than ever. Such a task represents a binary classification challenge, for which transformers have achieved state-of-the-art results. Using the publicly available ISOT and Combined Corpus datasets, this study explores transformers' abilities to identify fake news, with particular attention given to investigating generalisation to unseen datasets with varying styles, topics and class distributions. Moreover, we explore the idea that opinion-based news articles cannot be classified as real or fake due to their subjective nature and often sensationalised language, and propose a novel two-step classification pipeline to remove such articles from both model training and the final deployed inference system. Experiments over the ISOT and Combined Corpus datasets show that transformers achieve an increase in F scores of up to 4.9% for out of distribution generalisation compared to baseline approaches, with a further increase of 10.1% following the implementation of our two-step classification pipeline. To the best of our knowledge, this study is the first to investigate generalisation of transformers in this context.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/iSAI-NLP54397.2021.9678187" target="_blank"> LimeSoda: Dataset for Fake News Detection in Healthcare Domain<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85125297093</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Payoungkhamdee P., Sinthunyathum A., Songphum P., Kawidam W., Loha-Udom W., Sutantayawalee V., Porkaew P., Boonkwan P.</b></td></tr><tr><td colspan="3">Organisations: <b>Backyard Co. Ltd, Nectec</b></td></tr><tr><td colspan="3">In this paper, we present our Thai fake news dataset in the healthcare domain, LIMESODA, with the construction guideline. Each document in the dataset is classified as fact, fake, or undefined. Moreover, we also provide token-level annotations for validating classifier decisions. Five high-level annotation tags1 are 1) misleading headline 2) imposter 3) fabrication 4) false connection and 5) misleading content. We curate and manually annotated 7,191 documents with these tags. We evaluate our dataset with two deep learning approaches; RNN and Transformer baselines and analyzed token-level contributions to understand model behaviors. For the RNN model, we use the attention weights as token-level contributions. For Transformer models, we use the integrated gradient method at the embedding layers. We finally compared these token-level contributions with human annotations. Although our baseline models yield promising performances, we found that tokens that support model decisions are quite different from human annotation.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.3390/medicina58020311" target="_blank"> A Comprehensive Review of the Technological Solutions to Analyse the Effects of Pandemic Outbreak on Human Lives<a></b></td></tr><tr><td>Type: Review</td><td>ID: S_2-s2.0-85125303328</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Shah I., Doshi C., Patel M., Tanwar S., Hong W.-C., Sharma R.</b></td></tr><tr><td colspan="3">Organisations: <b>Nirma University, Asia Eastern University of Science and Technology, University of Petroleum and Energy Studies</b></td></tr><tr><td colspan="3">A coronavirus outbreak caused by a novel virus known as SARS-CoV-2 originated towards the latter half of 2019. COVID-19’s abrupt emergence and unchecked global expansion highlight the inability of the current healthcare services to respond to public health emergencies promptly. This paper reviews the different aspects of human life comprehensively affected by COVID-19. It then discusses various tools and technologies from the leading domains and their integration into people’s lives to overcome issues resulting from pandemics. This paper further focuses on providing a detailed review of existing and probable Artificial Intelligence (AI), Internet of Things (IoT), Augmented Reality (AR), Virtual Reality (VR), and Blockchain-based solutions. The COVID-19 pandemic brings several challenges from the viewpoint of the nation’s healthcare, security, privacy, and economy. AI offers different predictive services and intelligent strategies for detecting coronavirus signs, promoting drug development, remote healthcare, classifying fake news detection, and security attacks. The incorporation of AI in the COVID-19 outbreak brings robust and reliable solutions to enhance the healthcare systems, increases user’s life expectancy, and boosts the nation’s economy. Furthermore, AR/VR helps in distance learning, factory automation, and setting up an environment of work from home. Blockchain helps in protecting consumer’s privacy, and securing the medical supply chain operations. IoT is helpful in remote patient monitoring, distant sanitising via drones, managing social distancing (using IoT cameras), and many more in combating the pandemic. This study covers an up-to-date analysis on the use of blockchain technology, AI, AR/VR, and IoT for combating COVID-19 pandemic considering various applications. These technologies provide new emerging initiatives and use cases to deal with the COVID-19 pandemic. Finally, we discuss challenges and potential research paths that will promote further research into future pandemic outbreaks.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICTAI53825.2021.9673378" target="_blank"> Fake News Detection using Machine Learning and Natural Language Processing<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85125326375</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Kumar V., Kumar A., Singh A.K., Pachauri A.</b></td></tr><tr><td colspan="3">Organisations: <b>Galgotias College of Engineering and Technology, Accentures Solutions Pvt. Ltd, Pure Software Pvt. Ltd, Apeejay International School</b></td></tr><tr><td colspan="3">everyone depends on numerous online resources for news in today's world, where the internet is used as a medium. As the use of social media sites such as Facebook, Twitter, and others has grown, news has spread quickly between a large number of users in a tiny snap of time. The dissemination of false news has the implications, from swaying voting results in favour of some parties to creating skewed opinions. Furthermore, spammers use enticing news stories to generate revenue from click-bait ads. Our goal in this paper is to use AI, and ML principles to implement binary classification of different news contents available on social media sites. Our goal is to give the user the ability to identify news as fake or actual, as well as to verify the legitimacy of the website that published the news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICDMW53433.2021.00110" target="_blank"> Cross-lingual COVID-19 Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85125328498</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Du J., Dou Y., Xia C., Yu P.S., Cui L., Ma J.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Illinois at Chicago, Pennsylvania State University, Hong Kong Baptist University</b></td></tr><tr><td colspan="3">The COVID-19 pandemic poses a great threat to global public health. Meanwhile, there is massive misinformation associated with the pandemic which advocates unfounded or unscientific claims. Even major social media and news outlets have made an extra effort in debunking COVID-19 misinformation, most of the fact-checking information is in English, whereas some unmoderated COVID-19 misinformation is still circulating in other languages, threatening the health of less-informed people in immigrant communities and developing countries. In this paper, we make the first attempt to detect COVID-19 misinformation in a low-resource language (Chinese) only using the fact-checked news in a high-resource language (English). We start by curating a Chinese realfake news dataset according to existing fact-checking information. Then, we propose a deep learning framework named CrossFake to jointly encode the cross-lingual news body texts and capture the news content as much as possible. Empirical results on our dataset demonstrate the effectiveness of CorssFake under the cross-lingual setting and it also outperforms several monolingual and cross-lingual fake news detectors. The dataset is available at https://github.com/YingtongDou/CrossFake.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICDMW53433.2021.00039" target="_blank"> Legitimacy: An Ensemble Learning Model for Credibility Based Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85125330596</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Ramkissoon A.N., Goodridge W.</b></td></tr><tr><td colspan="3">Organisations: <b>The University of the West Indies at St Augustine</b></td></tr><tr><td colspan="3">The unadulterated spread of fake news, especially via social media platforms, can have serious deleterious effects on our data driven society. Fake news can be classified using a variety of methods. Predicting and detecting fake news has proven to be challenging even for machine learning algorithms. This research presents, Legitimacy a unique ensemble machine learning model to accomplish the task of Credibility Based Fake News Detection. The Legitimacy ensemble combines the learning potential of a Two Class Boosted Decision Tree and a Two Class Neural Network. The ensemble technique follows a pseudo mixture-of-experts methodology. For the gating model, an instance of Logistic Regression is implemented. This study validates Legitimacy using a standard dataset with features relating to the credibility of news publishers to predict fake news. These features are analysed using the ensemble algorithm. The results of these experiments are examined using four evaluation methodologies. The analysis reveals positive performance with the use of the ensemble ML method. Based upon our selected dataset, the Legitimacy ensemble model has proven to be most appropriate for the purpose of Credibility Based Fake News Detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ACIT53391.2021.9677453" target="_blank"> Comparing traditional machine learning methods for covid-19 fake news<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85125338248</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Almatarneh S., Gamallo P., ALshargabi B., AL-Khassawneh Y., Alzubi R.</b></td></tr><tr><td colspan="3">Organisations: <b>Zarqa University, Universidade de Santiago de Compostela, Middle East University, King Faisal University</b></td></tr><tr><td colspan="3">This article describes some supervised classification techniques for COVID-19 fake news detection in English, where the sources of data are annotated posts from various social media platforms such as Twitter, Facebook, or Instagram. The main objective is to examine the performance of traditional machine learning techniques of COVID-19 fake news detection. In this situation, models trained with Support Vector Machine and Na¨ıve Bayes algorithms outperformed all other strategies.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICTAI53825.2021.9673252" target="_blank"> A Study on Artificial Intelligence Techniques for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85125346610</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Narang P., Sharma U.</b></td></tr><tr><td colspan="3">Organisations: <b>Amity Institute of Information Technology Amity University</b></td></tr><tr><td colspan="3">In recent years, there is an explosive growth of fake news on social media platform. Purpose behind spreading fake news is to create deception. This dissemination of fake news is becoming increasingly dangerous. This paper presents a comprehensive survey of fake news detection methods along with the identification of available data sets. We discuss the various artificial intelligence methods along with their comparative study. Finally, this review identifies the research challenges and potential directions for detection of fake news over social media.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/BigData52589.2021.9671592" target="_blank"> Multi-Source Domain Adaptation with Weak Supervision for Early Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85125348054</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Li Y., Lee K., Kordzadeh N., Faber B., Fiddes C., Chen E., Shu K.</b></td></tr><tr><td colspan="3">Organisations: <b>Worcester Polytechnic Institute, Illinois Institute of Technology</b></td></tr><tr><td colspan="3">Recently, the massive and diverse fake news from politics to entertainment and health has amplified the social distrust problem and has become a big challenge for the society and research community. The existing fake news detection methods are mostly designed for either a specific domain or require huge labeled data from various domains. If there is not enough labeled data in a certain domain, existing models may not work well for detecting fake news from that domain. To overcome these limitations we propose a novel framework based on multisource domain adaptation and weak supervision for early fake news detection. The framework transfers sufficient labeled source domains' knowledge into a target/new domain with limited or even no labeled data by the multi-source domain adaptation, and applies researchers' prior knowledge about fake news to the target domain by the weak supervision. The weak supervision assigns the weak labels to the unlabeled samples in the target domain through known heuristic rules. Our experimental results show that our approach outperforms 7 state-of-the-art methods in three real-world datasets. In particular, our model achieves, on average, 5.2% higher accuracy than the best baseline. Our model with a more advanced encoder can further boost the performance by 3.7%. The code is available at this clickable link.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/BigData52589.2021.9671722" target="_blank"> A Study of Cantonese Covid-19 Fake News Detection on Social Media<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85125352473</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Wang Z., Zhao M., Song Y., Chen Y., Lan L.</b></td></tr><tr><td colspan="3">Organisations: <b>Hong Kong Baptist University, Nanjing University</b></td></tr><tr><td colspan="3">With the prevalence of social media, fake news has become one of the greatest challenges in journalism, which has weakened public trust in news outlets and authorities. During the COVID-19 epidemic, the widely circulated pandemic-related fake news on social media misleads or threatens the public. Recent works have investigated fake news detection on social platforms in English and Mandarin, though Cantonese fake news has been understudied. To pave the way for Cantonese COVID-19 fake news detection, we first presented an annotated COVID-19 related Cantonese fake news dataset collected from a popular local discussion forum in Hong Kong. Then, we explored the dataset by applying topic modeling to identify the topics that contain the most significant amount of fake news. Moreover, we evaluated both traditional machine learning algorithms and deep learning algorithms for Cantonese fake news detection. Our empirical results show that deep learning based methods perform slightly better than traditional machine learning methods on TF-IDF features.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.24507/icicel.16.03.289" target="_blank"> INDOBERT FOR INDONESIAN FAKE NEWS DETECTION<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85125402921</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Isa S.M., Nico G., Permana M.</b></td></tr><tr><td colspan="3">Organisations: <b>Bina Nusantara University</b></td></tr><tr><td colspan="3">Fake news has been known as a deceptive information. In the digital era, especially in COVID-19 pandemic outbreak, fake news is used to mislead society for certain purposes. Social media such as Facebook, Twitter and WhatsApp are used as a platform to spread false news. To identify fake news, we have to manually verify the news with legitimate sources. However, this takes some effort and time rather than using fake news detection systems. A good fake news detection system is needed to reduce the spread of misleading information and those side effects of it. Most of the recent research in English fake news detection systems has already used deep learning models especially transformer models. However, research in Indonesian fake news detection systems is still using old machine learning approaches. In this study, we proposed IndoBERT, an Indonesian Bidirectional Encoder Representations from Transformers (BERT) based transformer model that focuses on the context and attention of the input sentences. For the experiment, we fine-tuned the proposed model with the dataset that was collected from turnbackhoax.id and adjusted hyperparameter to get the best result. Afterwards, we evaluated our model and achieved 94.66% score on precision, recall, and F1-score.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.4018/IJSWIS.295553" target="_blank"> Mc-DNN: Fake News Detection Using MultiChannel Deep Neural Networks<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85125479948</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Tembhurne J.V., Diwan T., Moin Almin Md.</b></td></tr><tr><td colspan="3">Organisations: <b>Indian Institute of Information Technology, Tezpur University, Zaloni Technologies India Pvt. Ltd.</b></td></tr><tr><td colspan="3">With the advancement of technology, social media has become a major source of digital news due to its global exposure. This has led to an increase in spreading fake news and misinformation online. Humans cannot differentiate fake news from real news because they can be easily influenced. A lot of research work has been conducted for detecting fake news using artificial intelligence and machine learning. A large number of deep learning models and their architectural variants have been investigated, and many websites are utilizing these models directly or indirectly to detect fake news. However, state-of-the-arts demonstrate the limited accuracy in distinguishing fake news from the original news. The authors propose a multi-channel deep learning model, namely Mc-DNN, leveraging and processing the news headlines and news articles along different channels for differentiating fake or real news. They achieve the highest accuracy of 99.23% on ISOT Fake News Dataset and 94.68% on Fake News Data for Mc-DNN. Thus, they highly recommend the use of Mc-DNN for fake news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/IKT54664.2021.9685211" target="_blank"> A New Method Based on Deep Learning and Time Stabilization of the Propagation Path for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85125615290</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Torgheh F., Masoumi B., Keyvanpour M.R.</b></td></tr><tr><td colspan="3">Organisations: <b>Islamic Azad University, Alzahra University</b></td></tr><tr><td colspan="3">The increasing use of social media and people's interest in obtaining information through social media has made several challenges. One of the most important challenges in this context is the propagation of incorrect information, making problems in various areas. Fake news is a class of incorrect information propagating in the media due to different reasons, and handling them should be discussed from various aspects. In this paper, it is tried to present a method for detecting fake news based on their propagation path using deep networks and evaluate the capability of these networks in this context. To this end, an algorithm is presented for stabilizing the propagation path and the proposed model is implemented on this algorithm.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/iCORE54267.2021.00046" target="_blank"> Fake News Detection on English News Article's Title<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85125726688</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Castillo J.M., Fadera K.D.F., Ladao A.A.A., Go J.G., Tamayo M.B., Octaviano M.V.</b></td></tr><tr><td colspan="3">Organisations: <b>National University</b></td></tr><tr><td colspan="3">A power of an online user can start on a single click. It is now easier to spread news on cyberspace. This can be done on social media or any other websites online. But not everything online is real. Fake news emerges with a malicious intent that might harm and cause trouble. Primarily online wherein it is easy to publish and spread false information in seconds. This paper presents the development of a fake news detection on English news article's title using Machine learning algorithm as fake news continuously spread worldwide. With the use of ensembling method, Naïve Bayes achieved 54%. Similarly, ensembling technique is applied to another algorithm, XGBoost that garnered 80%. Furthermore, SVM was also added on feature combinations that are also explored to further understand which feature combination can give a better performance. Findings of the study shows that the ensemble learning techniques can be used to identify the accuracy of fake news in title alone.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s00521-022-07057-z" target="_blank"> ZoKa: a fake news detection method using edge-weighted graph attention network with transfer models<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85125746903</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Inan E.</b></td></tr><tr><td colspan="3">Organisations: <b>The University of Manchester</b></td></tr><tr><td colspan="3">Recent advances in social networks enable users to communicate and share their ideas. While social networks are beneficial to our society, it can lead to exponential disinformation growth. The extensive spread of such unreliable information and fake news can lead an adverse impact on the public opinion and cause uncertain outcomes of public events. Despite the recent progress in identifying fake news, it is still a time-consuming, complex, and diverse task. To address these challenges, we first generate a user friendship and retweet propagation graph to filter the potential fake users by leveraging Graph Attention Network. The underlying user graph is built by the functional connectivity matrices and the node features including both the user–user connections regarding their activities on the Twitter social network. Also, we generate a content graph including comments, profile descriptions of potential fake users along with their shared news contents. Then, we employ a novel fake news detection method on the generated content graph based on the Edge-weighted Graph Attention Network) using pre-trained encoders. The results from the experiments conducted on two real-world datasets show that our method achieves remarkable results when compared to the existing approaches in terms of Accuracy and F1 scores.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/SSCI50451.2021.9659944" target="_blank"> Fake News Detection: An Application of Quantum K-Nearest Neighbors<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85125803490</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Tian Z., Baskiyar S.</b></td></tr><tr><td colspan="3">Organisations: <b>Auburn University</b></td></tr><tr><td colspan="3">Social media has been a popular source for receiving news or information in daily life due to its rapid dissemination and ease of access. However, this trend causes a series of critical issues. The most critical issue, fake news, is a quickly growing threat. Fake news has the capability to compromise the democracy and credibility of information. Compared to other malicious threats, fake news is harder to detect due to being created to intentionally deceive target audiences. Various studies have been conducted and suggested that machine learning can be effectively utilized in detecting fake news. However, with the increasing amount of data, traditional machine learning algorithms will face challenges in ingesting and processing the data at scale. Thus, we propose a fake news detection system that incorporates both a quantum k-nearest neighbors (QKNN) machine learning model and Genetic and Evolutionary Feature Selection (GEFeS). With our proposed system, the highest accuracy achieved in this research is 87.12%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/SSCI50451.2021.9659866" target="_blank"> Adversarial UFP/UFN Attack Evolution<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85125803919</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Brown B., Smith M., Parker S., Leslie J., Seals C., Dozier G., King M.</b></td></tr><tr><td colspan="3">Organisations: <b>Auburn University, Florida Institute of Technology</b></td></tr><tr><td colspan="3">In this paper, we explore the effects of using evolutionary computation in an effort to increase the effectiveness of universal false positive and universal false negative attacks. These attacks are focused on machine learning based fake news detection systems. For this task, we use a steady-state genetic algorithm to evolve a set of adversarial samples. Our results suggest that using a steady-state genetic algorithm to evolve adversarial samples yields a noticeable increase in misclassification rates and exposes potential vulnerabilities in the evaluated machine learning algorithms.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICRAMI52622.2021.9585909" target="_blank"> An Arabic Corpus for Covid-19 related Fake News<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85125965680</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Mohdeb D., Laifa M., Naidja M.</b></td></tr><tr><td colspan="3">Organisations: <b>Mohamed El Bachir El Ibrahimi University</b></td></tr><tr><td colspan="3">In 2020, we have witnessed a universal health crisis that affected the lives of many people around the world. Covid-19 outbreak has been accompanied with an unprecedented wave of misinformation shared on the web and social media leading to confusion and inappropriate public reactions. In this paper, we investigate the fake news spread in Arabic content during the pandemic crisis. We have collected a dataset for the aim of detecting fake news that are related to the coronavirus subject. The dataset includes Arabic fake and true news extracted from reliable sources. To the best of our knowledge, it is the first fake news dataset on Covid-19 Arabic misinformation. The collected data have been explored then exploited for fake news detection task using the classification baseline methods. Results indicated comparable high performance of baseline models with a relative superiority of SVM classifier.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.3390/electronics11060846" target="_blank"> A Feature-Based Approach for Sentiment Quantification Using Machine Learning<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85126018527</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Ayyub K., Nisar M.W., Munir E.U., Iqbal S., Alarfaj F.K., Almusallam N.</b></td></tr><tr><td colspan="3">Organisations: <b>COMSATS University Islamabad, Al Ain University, Imam Mohammad Ibn Saud Islamic University (IMSIU)</b></td></tr><tr><td colspan="3">Sentiment analysis has been one of the most active research areas in the past decade due to its vast applications. Sentiment quantification, a new research problem in this field, extends sentiment analysis from individual documents to an aggregated collection of documents. Sentiment analysis has been widely researched, but sentiment quantification has drawn less attention despite offering a greater potential to enhance current business intelligence systems. In this research, to perform sentiment quantification, a framework based on feature engineering is proposed to exploit diverse feature sets such as sentiment, content, and part of speech, as well as deep features including word2vec and GloVe. Different machine learning algorithms, including conventional, ensemble learners, and deep learning approaches, have been investigated on standard datasets of SemEval2016, SemEval2017, STS-Gold, and Sanders. The empirical-based results reveal the effectiveness of the proposed feature sets in the process of sentiment quantification when applied to machine learning algorithms. The results also reveal that the ensemble-based algorithm AdaBoost outperforms other conventional machine learning algorithms using a combination of proposed feature sets. The deep learning algorithm RNN, on the other hand, shows optimal results using word embedding-based features. This research has the potential to help diverse applications of sentiment quantification, including polling, trend analysis, automatic summarization, and rumor or fake news detection.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s11042-022-12764-9" target="_blank"> Fake news detection and classification using hybrid BiLSTM and self-attention model<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85126036093</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Mohapatra A., Thota N., Prakasam P.</b></td></tr><tr><td colspan="3">Organisations: <b>School of Electronics Engineering</b></td></tr><tr><td colspan="3">Living in the twenty-first century, from shopping to reading news articles everything has changed, everything has become online. Anyone can access most of everything with a single touch from a cell phone. Internet is the new normal, everyone is very much attached to it. Reading news online is something very common among people of all age groups, thousands of articles are being published on various online media portals online every hour. These articles are not necessarily genuine always, sometimes false information is written knowingly and sometimes knowingly. It is very much needed to keep these articles away from the users. Many kinds of research have been conducted using traditional mathematical models and sequential neural networks to detect this fraud news online. In most of these studies, the news is being analysed in a unidirectional way. Therefore, a need of changing current mechanisms is required to increases the accuracy of false news detection. In this paper, we propose a Bi-LSTM based (Bidirectional long short term memory) deep learning approach by adding self-attention on top of it. This helps in developing a higher clarity, which is the most challenging part of the deep learning paradigm. The classification result demonstrated that the proposed hybrid deep learning model outperforms existing models with an accuracy score of 98.65%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICCCNT51525.2021.9580035" target="_blank"> Bangla Fake News Detection Based On Multichannel Combined CNN-LSTM<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85126183354</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>George M.Z.H., Hossain N., Bhuiyan M.R., Masum A.K.M., Abujar S.</b></td></tr><tr><td colspan="3">Organisations: <b>Daffodil International University, Independent University</b></td></tr><tr><td colspan="3">There have recently been many cases of unverified or misleading information circulating quickly over bogus web networks and news portals. This false news creates big damage to society and misleads people. For Example, in 2019 there was a rumor that the Padma Bridge of Bangladesh needed 100,000 human heads for sacrifice. This rumor turns into a deadly position and this misleading information takes the lives of innocent people. There is a lot of work in English but a few works in Bangla. In this study, we are going to identify the fake news from the unconsidered news source to provide the newsreader with natural news or real news. The paper is based on the combination of convolutional neural network (CNN) and long short term memory (LSTM) where CNN is used for deep feature extraction and LSTM is used for detection using the extracted feature. The first thing we did to deploy this piece of work was data collection. We compiled a data set from websites and attempted to deploy it using the methodology of deep learning which contains about 50k of news. With the proposed model of Multichannel combined CNN-LSTM architecture, our model gained an accuracy of 75.05% which is a good sign for detecting fake news in Bangla.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICCCNT51525.2021.9579543" target="_blank"> FAKE NEWS PREDICTION ON COVID DATASET USING MACHINE LEARNING<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85126202136</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Rajalakshmi C., Subika T., Vaishali K., Shana J.</b></td></tr><tr><td colspan="3">Organisations: <b>Coimbatore Institute of Technology</b></td></tr><tr><td colspan="3">Fake news is false information, nowadays these are big challenges in all types of media, especially social media. In this covid-19 pandemic situation, people are facing more problems and struggling every day. One among those problems, is fake news or false information about covid. To tackle this, we have made an attempt and created a dataset with 4200 records from social media. We analyze the outbreak of covid information and visualize them using charts and graphs and predict the fake news using three classifier machine learning models. They are passive aggressive classifiers, Naïve Bayes classifiers and Support Vector Machines.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICCCNT51525.2021.9579777" target="_blank"> Fake and Authentic News Detection Using Social Data Strivings<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85126202409</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Anjum A., Keya M., Masum A.K.M., Noori S.R.H.</b></td></tr><tr><td colspan="3">Organisations: <b>Daffodil International University</b></td></tr><tr><td colspan="3">Fake news is a piece of contrived records that mirrors a news association's substance in structure however not in hierarchical interaction or purpose. Fake news is spreading in our society day by day. Web-based media stages permit nearly everybody to distribute their musings or offer stories with the world. The difficulty is, a great many people don't check the wellspring of the material that they see online before they share it, which can prompt phony word getting out rapidly or in any event, circulating around the web. For this reason, we wanted to work with the detection of fake news. Bangla fake news observation is not as easy as English. The features of the Bangla language are comparatively different from other languages. We use machine learning approaches like Random Forest, Decision Tree, Naive Bayes, Support Vector Machine, K-Nearest Neighbors classifier for detecting Bangla fake news. We have got the best accuracy for the Random Forest Classifier. Finally, our proposed model can recognize fake report successfully.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICIEVICIVPR52578.2021.9564138" target="_blank"> Bengali Fake News Detection Using Machine Learning and Effectiveness of Sentiment as a Feature<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85126205970</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Tohabar M.Y., Nasrah N., Samir A.M.</b></td></tr><tr><td colspan="3">Organisations: <b>Shahjalal University of Science and Technology</b></td></tr><tr><td colspan="3">Fake news is one of the rising global crises. It often aims to damage the reputation of a person or entity or make money through advertising revenue. Sometimes it can become influential and can spread exceedingly fast. That is why more and more research is running in this particular sector. Bengali-speaking people are also not immune to this problem. But research on Bengali fake news is rare. Keeping this in mind, this paper experiments with machine learning (ML) techniques to detect fake news. We also incorporate sentiment as a feature to check the effect in the process. We got an highest accuracy score of 73.20% using support vector machine (SVM). Also, we show that sentiment analysis has no good prospect as a feature to detect fake news. Contribution-Expanding the research dimension of fake news detection in Bengali language and assessing the relevance of sentiment analysis in this context.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-16-7657-4_5" target="_blank"> COVID-19 Fake News Detection Using GloVe and Bi-LSTM<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85126220892</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Kulkarni C., Monika P., Shruthi S., Deepak Bharadwaj M.S., Uday D.</b></td></tr><tr><td colspan="3">Organisations: <b>Dayananda Sagar College of Engineering (DSCE)</b></td></tr><tr><td colspan="3">Fake news detection is a key use case of Natural Language Processing and Machine Learning. With the advancement of technology, electronic content has become more significant and extensively used than ever before, resulting in a revival in the spurious news as well as tweets that seek quick attention. It is critical to achieve early detection and identification of misinformation in social media. In these difficult times of COVID-19 where the whole world is fighting a global pandemic, it is very important to provide people with genuine news and updates about the prevailing situation. The Twitter is flooded with tweets about COVID-19 and related news, but not all the information is factual and full of veracity. To classify this issue, a Deep Learning model is being proposed to classify misinformation about COVID-19 and related news. Pre-trained state-of-the-art GloVe model was used in the proposed method for converting tokens into vectors. Deep Learning models like RNN, LSTM, and Bi-LSTM were tested to obtain better results after preprocessing the data using basic NLP preprocessing techniques. Bi-LSTM model got a training accuracy as high as 99%. All the results are tabulated and cogently laid out in the latter section.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/SPIN52536.2021.9565958" target="_blank"> Deep Ensemble Approach for COVID-19 Fake News Detection from Social Media<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85126225066</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Priya A., Kumar A.</b></td></tr><tr><td colspan="3">Organisations: <b>Central University of Punjab, Department of Computer Science and Technology,Government Engineering College, Siksha 'O' Anusandhan (Deemed to be University)</b></td></tr><tr><td colspan="3">Social media networks such as Facebook and Twitter are overwhelmed with COVID-19-related posts during the outbreak. People have also posted several fake news among the massive COVID-19-related social media posts. Fake news has the potential to create public fear, weaken government credibility, and pose a serious threat to social order. This paper provides a deep ensemble-based method for detecting COVID-19 fake news. An ensemble classifier is made up of three different classifiers: Support Vector Machine, Dense Neural Network, and Convolutional Neural Network. The extensive experiments with the proposed ensemble model and eight different conventional machine learning classifiers are carried out using the character and word n-gram TF-IDF features. The results of the experiments show that character n-gram features outperform word n-gram features. The proposed deep ensemble classifier performed better, with a weighted Fl -score of 0.97 in contrast to numerous conventional machine learning classifiers and deep learning classifiers.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/MIPR51284.2021.00048" target="_blank"> Socially Aware Multimodal Deep Neural Networks for Fake News Classification<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85126233888</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Rezayi S., Soleymani S., Arabnia H.R., Li S.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Georgia</b></td></tr><tr><td colspan="3">The importance of fake news detection and classification on Online Social Networks (OSN) has recently increased and drawn attention. Training machine learning models for this task requires different types of attributes or modalities for the target OSN. Existing methods mainly rely on social media text, which carries rich semantic information and can roughly explain the discrepancy between normal and multiple fake news types. However, the structural characteristics of OSNs are overlooked. This paper aims to exploit such structural characteristics and further boost the fake news classification performance on OSN. Using deep neural networks, we build a novel multimodal classifier that incorporates relaying features, textual features, and network feature concatenated with each other in a late fusion manner. Experimental results on benchmark datasets demonstrate that our socially aware architecture outperforms existing models on fake news classification.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-96040-7_11" target="_blank"> Fake News Detection Using Ethereum Blockchain<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85126235390</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Upadhyay A., Baranwal G.</b></td></tr><tr><td colspan="3">Organisations: <b>Banaras Hindu University</b></td></tr><tr><td colspan="3">The progression of technology, Internet availability, and rapid adoption of social media unintentionally paved the way for the viral spread of fake news and hoaxes. Around the world, people are using fake news for their profit either by presenting information in the wrong manner for gaining more viewers or by manipulating the publics’ opinion for influencing their behavior in major events of society, for example, elections or view towards someone’s part in an unfortunate event. In this paper, we present a blockchain-based platform where one can get the news contents authenticated by anonymous individuals around the globe independently as genuine or fake. It gives people a secure and anonymous channel for verifying content’s reliability and further limiting the reckless sharing and spreading of news content by people. Inherited properties of blockchain by the platform, i.e., immutability and traceability, combat the spread of fake news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICCCNT51525.2021.9580073" target="_blank"> Machine Learning Methods to identify Hindi Fake News within social-media<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85126239712</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Sharma D.K., Garg S.</b></td></tr><tr><td colspan="3">Organisations: <b>GLA University</b></td></tr><tr><td colspan="3">Over the last decades, Fake news has exploded online. Fabricated stories go viral on digital media. The rise in the use of digital media has accelerated the pace of fake news. It affects the offline public and also threatens human safety. It is critical to check the veracity of news over social media platforms to mitigate its grave impacts. Finding accurate information within this ocean of data is where fake news detection comes into the picture. Most of the existing work is based on the English language. A little work is done using resource scare language for fake news identification. This paper presents an Indian dataset for Hindi Language using Devanagari lipi. Indian Hindi news is collected using the Parsehub scrapping tool. We performed several experiments by using an existing machine learning algorithm and achieved satisfactory results. The outcome reflects the effectiveness of our proposed dataset.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-96040-7_53" target="_blank"> Performances of Different Approaches for Fake News Classification: An Analytical Study<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85126256037</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Abdullah-Al-Kafi M., Tasnova I.J., Wadud Islam M., Banshal S.K.</b></td></tr><tr><td colspan="3">Organisations: <b>Daffodil International University</b></td></tr><tr><td colspan="3">The penetration of social and online platforms has opened a new substantial domain of Fake news dissemination in the current time. Also, this dynamic form of data opens up new dimensions for researchers to detect Fake news from the ocean of data. Therefore, Fake news detection has attracted both academia and industry indifferently as research or analytical domain in the concurrent time. Due to data availability, the classification tasks have been tested in different sets and types of data. Detecting Fake news evolves as an actual potential domain to explore with more efficient algorithms and parameter-based modified algorithms. In this work, an analytical sketch has been drawn to compare the performances of different classifiers depending on accuracy and time. Seven classifiers of four different types have been implemented and tested namely, Multilayer Perceptron, Sequential Minimal Optimization, Logistic Regression, Decision Tree, J48, Random Forest and Naïve Bayes Classifier. The analytical evaluation process has been designed with three experimental setups, 10-fold cross-validation, 70% split and 80% split. The separate setups show distinctive outcomes across the algorithms. Naïve-Bayes classifier model shows its prominence along with the Random Forest classifier. However, the and Decision Tree-based classifiers perform differently from earlier knowledge. Furthermore, this paper identifies a different aspect of using testing-training splitting in classifier tasks.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ACCESS51619.2021.9563292" target="_blank"> Fake News Detection Using Natural Language Processing and Logistic Regression<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85126260463</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Shete A., Soni H., Sajnani Z., Shete A.</b></td></tr><tr><td colspan="3">Organisations: <b>Thadomal Shahani Engineering College, University of Washington</b></td></tr><tr><td colspan="3">Newspapers and radios are the things of the past, the current generation depends on the internet, specifically social media platforms to stay up to date with the global news. The ease of access, affordability and widespread audience has made these platforms a perfect choice to reach the world. While this has sped up and streamlined news consumption, it is not without drawbacks. The major issue is the proliferation of false/fake news which can have serious repercussions in sensitive matters. Understanding the difference and authenticity of the news is becoming complicated everyday. Social media platforms and online newsletters are responsible for the spread of fake news. However, this problem can be tackled using machine learning techniques and give verifiable news. The paper identifies counterfeit news using Logistic Regression. This model successfully labels a said article as “fake” or “real” with up to 80% accuracy. The paper ends with a review of the model's feasibility and how it would be useful as an impactful mining method as well as proposes the scope of future improvements in the model which will help achieve greater accuracy in the prediction results.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ACCESS.2022.3157724" target="_blank"> Are You a Cyborg, Bot or Human?-A Survey on Detecting Fake News Spreaders<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85126335497</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Shahid W., Li Y., Staples D., Amin G., Hakak S., Ghorbani A.</b></td></tr><tr><td colspan="3">Organisations: <b>University of New Brunswick</b></td></tr><tr><td colspan="3">One of the major components of Societal Digitalization is Online social networks (OSNs). OSNs can expose people to different popular trends in various aspects of life and alter people's beliefs, behaviors, and decisions and communication. Social bots and malicious users are the significant sources for spreading misinformation on social media and can pose serious cyber threats in society. The degree of similarity of user profiles of a cyber bot and a malicious user spreading fake news is so great that it is very difficult to differentiate both based on their attributes. Over the years, researchers have attempted to find a way to mitigate this problem. However, the detection of fake news spreaders across OSNs remains a challenge. In this paper, we have provided a comprehensive survey of the state of art methods for detecting malicious users and bots based on different features proposed in our novel taxonomy. We have also aimed to avert the crucial problem of fake news detection by discussing several key challenges and potential future research areas to help researchers who are new to this field.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-16-7610-9_45" target="_blank"> Detecting Fake News Using Machine Learning<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85126359019</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Patel R.H., Patel R., Patel S., Patel N.</b></td></tr><tr><td colspan="3">Organisations: <b>Chandubhai S. Patel Institute of Technology (CSPIT)</b></td></tr><tr><td colspan="3">The evolution of information and communication in this digital era has increased the number of Internet accessible people. Internet has changed the way information is consumed, and as its consequence, the fake news market has boomed up. Fake news is one of the major concerns regarding the spread of Internet connectivity because fake news has the potential to make high political damages to countries. “Fake news” gained popularity during US electoral campaign. Fake news detection works with application on natural language processing for clarifying and cleaning up the news, and then, the model uses term frequency-inverse domain frequency for further processing. Aim of this paper is computational approach automatically detects fake news and also gives accuracy of the model.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.eswa.2022.116635" target="_blank"> DSS: A hybrid deep model for fake news detection using propagation tree and stance network<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85126362362</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Davoudi M., Moosavi M.R., Sadreddini M.H.</b></td></tr><tr><td colspan="3">Organisations: <b>Shiraz University</b></td></tr><tr><td colspan="3">Nowadays, online social media play a significant role in news broadcasts due to their convenience, speed, and accessibility. Social media platforms leverage the rapid production of a large volume of information and cause the propagation of untrustworthy and fake news. Since fake news is engineered to deceive a wide range of readers deliberately, it is not easy to detect them merely based on the news content. Hence, more information, such as the social context, is needed. Moreover, to limit the impact of fake news on society, it is essential to detect them as early as possible. In this paper, we have developed an automated system “DSS” for the early detection of fake news wherein we leverage the propagation tree and the stance network simultaneously and dynamically. Our proposed model comprises three major components: Dynamic analysis, Static analysis, and Structural analysis. During dynamic analysis, a recurrent neural network is used to encode the evolution pattern of the propagation tree and the stance network over time. The static analysis uses a fully connected network to precisely represent the overall characteristics of the propagation tree and the stance network at the end of a detection deadline. The node2vec algorithm is used during structural analysis as a graph embedding model to encode the structure of the propagation tree and the stance network. Finally, the outputs of these components are aggregated to determine the veracity of the news articles. Our proposed model is evaluated on the FakeNewsNet repository, comprising two recent well-known datasets in the field, namely PolitiFact and GossipCop. Our results show encouraging performance, outperforming the state-of-the-art methods by 8.2% on the PolitiFact and 3% on the GossipCop datasets. Early detection of fake news is the merit of the proposed model. The DSS model provides outstanding accuracy in the early stages of spreading, as well as the later stages.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-16-7182-1_8" target="_blank"> Machine Learning Based Fake News Detection on Covid-19 Tweets Data<a></b></td></tr><tr><td>Type: Boch</td><td>ID: S_2-s2.0-85126370450</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Mehta V., Mishra R.K.</b></td></tr><tr><td colspan="3">Organisations: <b>Dubai International Academic City</b></td></tr><tr><td colspan="3">The importance of social media has seen a huge growth in last few years as it lets folks from any part of the world remain in contact. Due to COVID-19 epidemic, social media is used extensively and has turned to be more pertinent than the past years. Alongside, fake news dissemination has revived and also dissemination of tweets has taken the attention. For the present study, we used various machine learning models to detect the fake news on COVID-19 related tweets. Due to millions of active social media users, identifying the fake news has become a crucial task. The models we applied are Gradient Boosting Classifier (GBC), Logistic Regression (LR), Random Forest Classifier (RFC), Decision Tree Classification (DT). All these models detect if the tweet relating to COVID-19 is “Fake News” or “Not a Fake News”. Hence we conclude that Logistic Regression is best among all other models.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/i-PACT52855.2021.9696762" target="_blank"> Fake News Detection of Live Media using Speech to Text Conversion<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85126428010</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Dixit Y., Sanjay A., Kaarthik E., Shridevi S.</b></td></tr><tr><td colspan="3">Organisations: <b>Vellore Institute of Technology</b></td></tr><tr><td colspan="3">A made-up tale with the goal to deceive or mislead is characterized as fake news. After translating the live media stream audio into text, detecting false news using Machine Learning techniques are used to solve the problem. The aim of this work is to create a model that can detect false news by identifying the most optimal parameter that can yield the greatest accuracy. Additional investigation on how different hyper parameters affect the performance of the model and summed up the details for future work. The work emphasizes various kinds of classifiers as well as Speech Recognition techniques which could be used. It gives an understanding of which classifier is better suited for Real time Fake News Detection. Two different kinds of Speech Recognition techniques have been identified and have been incorporated. These act as the input for the Machine Learning Model. This is then followed by Data pre-processing, and passed onto various classifiers which would then identify whether the news retrieved is fake or not.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s40747-021-00552-1" target="_blank"> IFND: a benchmark dataset for fake news detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85126430233</td><td>Year: <b>2023</b></td></tr><tr><td colspan="3">Authors: <b>Sharma D.K., Garg S.</b></td></tr><tr><td colspan="3">Organisations: <b>GLA University</b></td></tr><tr><td colspan="3">Spotting fake news is a critical problem nowadays. Social media are responsible for propagating fake news. Fake news propagated over digital platforms generates confusion as well as induce biased perspectives in people. Detection of misinformation over the digital platform is essential to mitigate its adverse impact. Many approaches have been implemented in recent years. Despite the productive work, fake news identification poses many challenges due to the lack of a comprehensive publicly available benchmark dataset. There is no large-scale dataset that consists of Indian news only. So, this paper presents IFND (Indian fake news dataset) dataset. The dataset consists of both text and images. The majority of the content in the dataset is about events from the year 2013 to the year 2021. Dataset content is scrapped using the Parsehub tool. To increase the size of the fake news in the dataset, an intelligent augmentation algorithm is used. An intelligent augmentation algorithm generates meaningful fake news statements. The latent Dirichlet allocation (LDA) technique is employed for topic modelling to assign the categories to news statements. Various machine learning and deep-learning classifiers are implemented on text and image modality to observe the proposed IFND dataset's performance. A multi-modal approach is also proposed, which considers both textual and visual features for fake news detection. The proposed IFND dataset achieved satisfactory results. This study affirms that the accessibility of such a huge dataset can actuate research in this laborious exploration issue and lead to better prediction models.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICCICA52458.2021.9697269" target="_blank"> Fake News Detection Using XLNet Fine-Tuning Model<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85126440633</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Kumar J A., Esther Trueman T., Cambria E.</b></td></tr><tr><td colspan="3">Organisations: <b>Anna University, Nanyang Technological University</b></td></tr><tr><td colspan="3">In recent years, the traditional way of getting news from a Television, news paper, or national newscast is gone. Today, online social media provides the fastest news content for people. This, however, brings about the problem of fake news. In fact, fake news detection is one of the challenging tasks in natural language processing to differentiate between real (or true) and fake (or false) news content. In this paper, we propose an XLNet fine-tuning model to predict fake news in a multi-class and binary class problem. Our results show that the proposed XLNet model comparatively achieves a better result than the existing state-of-the-art models.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICBASE53849.2021.00049" target="_blank"> A Discriminative Graph Neural Network for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85126460229</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Cao H., Deng J., Dong G., Yuan D.</b></td></tr><tr><td colspan="3">Organisations: <b>Huazhong University of Science and Technology, University of Massachusetts-Amherst, University of Wisconsin-Madison, YK Pao School</b></td></tr><tr><td colspan="3">Fake news detection aims to distinguish disinformation from social media. The existing fake News detection model, namely Factual News Graph (FANG), is a novel social context representation and learning framework for fake news detection. Focusing on representation learning, this inductive model is superior to conventional contextual models for its efficiency, scalability, and robustness. However, we find that the framework does not take inner/inter variants into consideration. Specifically, this method treats each news item as an independent individual and ignores the latent relationship among them, which may inevitably limit the accuracy. In order to improve the discriminative power, we propose a new model called Discriminative-FANG, which enhances the discriminative power of the model on fake news detection. By means of adding a discriminative regularization term, our model finds deep feature centers of every class and minimizes the distances between all the features and their class centers simultaneously. Thus, it leads to better learning inter-class dispersion as well as intra-class compactness. Moreover, experiments are carried out on several popular Fake News Detection datasets, which verify the better performance of our model than other popular baselines by a large margin.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICCICA52458.2021.9697244" target="_blank"> A multinomial technique for detecting fake news using the Naive Bayes Classifier<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85126461539</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Yerlekar A., Mungale N., Wazalwar S.</b></td></tr><tr><td colspan="3">Organisations: <b>Rajiv Gandhi College of Engineering and Research, G.H. Raisoni College of Engineering</b></td></tr><tr><td colspan="3">Faux news and hoaxes are there for the reason that before the advent of the internet. The broadly common definition of internet fake news is: "fictitious articles intentionally fancied to lie to readers". Social media and information stores submit fake information to increase the target market or as part of battle. This exposition analyses the prevalence of pretend news in light-weight of the advances in verbal exchange created capacity by the emergence of social networking web sites. We tend to apply device mastering techniques to classify the datasets. The Fake news detection may be utilized by users to sight a piece of writing containing fake and dishonorable info. This paper indicates an easy technique for faux news detection using naive Bayes classifier. We have a tendency to use honest and punctiliously decided on alternatives of the name and publish to appropriately determine fake posts. On the test set, we achieved a type accuracy of 80% approximately, which is a decent result given the version's relative simplicity.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1002/asi.24642" target="_blank"> Making sense of the black-boxes: Toward interpretable text classification using deep learning models<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85126470430</td><td>Year: <b>2023</b></td></tr><tr><td colspan="3">Authors: <b>Tao J., Zhou L., Hickey K.</b></td></tr><tr><td colspan="3">Organisations: <b>Fairfield University, The University of North Carolina at Charlotte, Worcester Polytechnic Institute</b></td></tr><tr><td colspan="3">Text classification is a common task in data science. Despite the superior performances of deep learning based models in various text classification tasks, their black-box nature poses significant challenges for wide adoption. The knowledge-to-action framework emphasizes several principles concerning the application and use of knowledge, such as ease-of-use, customization, and feedback. With the guidance of the above principles and the properties of interpretable machine learning, we identify the design requirements for and propose an interpretable deep learning (IDeL) based framework for text classification models. IDeL comprises three main components: feature penetration, instance aggregation, and feature perturbation. We evaluate our implementation of the framework with two distinct case studies: fake news detection and social question categorization. The experiment results provide evidence for the efficacy of IDeL components in enhancing the interpretability of text classification models. Moreover, the findings are generalizable across binary and multi-label, multi-class classification problems. The proposed IDeL framework introduce a unique iField perspective for building trusted models in data science by improving the transparency and access to advanced black-box models.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ISCON52037.2021.9702379" target="_blank"> Fake Content Identification Using Pre-Trained Glove-Embedding<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85126472181</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Shrivastava P., Sharma D.K.</b></td></tr><tr><td colspan="3">Organisations: <b>GLA University</b></td></tr><tr><td colspan="3">Fake news is misleading content presented as real news. It is intentionally written to deceive the reader. Fake news is created to fulfill personal motives including political motives. Fake content creates a large amount of revenue for malicious entities. It is required to reduce the propagation of fake news to reduce its severe impact. In existing studies, the useful approach employs lexico-syntactic features for fake news detection. Existing methods used a small training dataset. To solve this problem, this study applied pre-trained word embedding on the Gossip-cop dataset. Glove embedding is combined with deep learning classifiers for final prediction. Glove embedding generated vector representation of words based on their co-occurrence with other words. It transforms the words into high dimensional space. Dataset is collected by scrapping Gossipcop fact-checking websites. The total number of fake news samples is 4,947 while the total true news is 16,694. The proposed model improves the accuracy of the dataset in comparison to existing state of art methods.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ISCON52037.2021.9702434" target="_blank"> A Novel Hybrid Approach for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85126482554</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Somkunwar R.K., Shikalgar F., Kapdi R., Maral S., Paithankar A., Gupta A.K.</b></td></tr><tr><td colspan="3">Organisations: <b>Dr. D. Y. Patil Institute of Technology, CDAC</b></td></tr><tr><td colspan="3">This Fake news is false and misleading information presented as news. It is frequently done to harm a person's or company's reputation, or to profit from advertising revenue. As we all know, the spread of false news has become a major problem in today's world of communication. It is disseminated with the goal of misleading people. This has resulted in a number of unpleasant situations in various countries. Because of its global influence, false news has become a topic of discussion among journalists and the general public. The rise of social media as a medium has a problem with the creation and spread of false information. This threatens not only the platform where the news content is published but also the Internet as a source of communication for the whole story. This paper provides a proactive strategy for predicting fake news on the internet based on a stance detection model implemented with LSTM + GloVe classifier. The simplest way to deal with this problem is to compare how well-respected sources feel about such statements, rather than studying the facts. We believe that our hybrid classifier-based system has a higher level of reliability. The results and discussion section provides evidence for our claims and establishes the objectives.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ACCESS.2022.3159651" target="_blank"> A Taxonomy of Fake News Classification Techniques: Survey and Implementation Aspects<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85126536992</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Rohera D., Shethna H., Patel K., Thakker U., Tanwar S., Gupta R., Hong W.-C., Sharma R.</b></td></tr><tr><td colspan="3">Organisations: <b>Nirma University, Asia Eastern University of Science and Technology, University of Petroleum and Energy Studies</b></td></tr><tr><td colspan="3">In the present era, social media platforms such as Facebook, WhatsApp, Twitter, and Telegram are significant sources of information distribution, and people believe it without knowing their origin and genuineness. Social media has fascinated people worldwide in spreading fake news due to its easy availability, cost-effectiveness, and ease of information sharing. Fake news can be generated to mislead the community for personal or commercial gains. It can also be used for other personal benefits such as defaming eminent personalities, amendment of government policies, etc. Thus, to mitigate the awful consequences of fake news, several research types have been conducted for its detection with high accuracy to prevent its fatal outcome. Motivated by the aforementioned concerns, we present a comprehensive survey of the existing fake news identification techniques in this paper. Then, we select Machine Learning (ML) models such as Long-Short Term Memory (LSTM), Passive Aggressive Algorithm, Random Forest (RF), and Naive Bayes (NB) and train them to detect fake news articles on the self-aggregated dataset. Later, we implemented these models by hyper tuning various parameters such as smoothing, drop out factor, and batch size, which has shown promising results in accuracy and other evaluation metrics such as F1-score, recall, precision, and Area under the ROC Curve (AUC) score. The model is trained on 6335 news articles, with LSTM showing the highest accuracy of 92.34% in predicting fake news and NB were showing the highest recall. Based on these results, we propose a hybrid fake news detection technique using NB and LSTM. At last, challenges and open issues along with future research directions are discussed to facilitate the research in this domain further.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.3390/info13030137" target="_blank"> An Explainable Fake News Detector Based on Named Entity Recognition and Stance Classification Applied to COVID-19<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85126568633</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>De Magistris G., Napoli C., Russo S., Roma P., Starczewski J.T.</b></td></tr><tr><td colspan="3">Organisations: <b>Sapienza University of Rome, Sapienza Univesity of Rome, Czestochowa University of Technology</b></td></tr><tr><td colspan="3">Over the last few years, the phenomenon of fake news has become an important issue, especially during the worldwide COVID-19 pandemic, and also a serious risk for the public health. Due to the huge amount of information that is produced by the social media such as Facebook and Twitter it is becoming difficult to check the produced contents manually. This study proposes an automatic fake news detection system that supports or disproves the dubious claims while returning a set of documents from verified sources. The system is composed of multiple modules and it makes use of different techniques from machine learning, deep learning and natural language processing. Such techniques are used for the selection of relevant documents, to find among those, the ones that are similar to the tested claim and their stances. The proposed system will be used to check medical news and, in particular, the trustworthiness of posts related to the COVID-19 pandemic, vaccine and cure.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/SEEDA-CECNSM53056.2021.9566243" target="_blank"> Predicting Fake News using GloVe and BERT Embeddings<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85126578604</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Kishwar A., Zafar A.</b></td></tr><tr><td colspan="3">Organisations: <b>Riphah International University</b></td></tr><tr><td colspan="3">The growth of fake news in multiple fields such as in the political or health sector has become a great concern as it possess huge impact on the reader's mind. Identifying the fake news or differentiating between fake and authentic news is quite challenging. The focus of this research is to identify fake news by applying different artificial intelligence techniques along with different embeddings and to assess the performance of all the applied models. The performance of these models and the embeddings is compared based on precision, accuracy, F1-score and recall. For machine learning techniques SVM, KNN, Naive Bayes, Logistic Regression and Decision Trees are used, while for deep learning techniques CNN and LSTM are used with GloVe and BERT embeddings. Multiple experiments using these techniques are performed on the LIAR and Fake-or-Real dataset. Naïve Bayes has shown the best results from machine learning techniques on both datasets. While in deep learning techniques, LSTM with GloVe has shown the best results on the LIAR dataset and CNN with BERT has shown the best performance on the Fake-or-Real dataset. Overall GloVe word embeddings performed well on the LIAR dataset while BERT sentence embeddings have shown good performance on the Fake-or-Real dataset.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.jjimei.2021.100052" target="_blank"> Combating the menace: A survey on characterization and detection of fake news from a data science perspective<a></b></td></tr><tr><td>Type: Review</td><td>ID: S_2-s2.0-85126612930</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Ansar W., Goswami S.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Calcutta, University of Calcutta</b></td></tr><tr><td colspan="3">Journalism has always remained a vital constituent of our society and journalists play a key role in making people aware of the happenings and developments in society. This spread of information enables shaping the ideologies, orientations and thoughts of individuals as well as the society. Contrary to this, the spread of misinformation or fake news leads to detrimental consequences. With the advent of social media, the menace of fake news has become grievous due to the unrestrained propagation of information and difficulty to track several accounts operated by humans or bots. This menace can be mitigated through data science approaches by combining artificial intelligence with statistics and domain-based knowledge. In this paper, a survey of works aimed at characterization, feature extraction and subsequent detection of fake news has been conducted from a data science perspective. Along with it, an analysis of the 8 renowned fake news detection repositories has been presented. Furthermore, through a case study on tweets related to COVID-19 pandemic, the factors behind the spread of misinformation during critical times, distinguishing between factual and emotional tweets and viable approaches to restrain fake news has been enunciated.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.jjimei.2021.100051" target="_blank"> Optimization and improvement of fake news detection using deep learning approaches for societal benefit<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85126614132</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Chauhan T., Palivela H.</b></td></tr><tr><td colspan="3">Organisations: <b>PICT, eClerx Services limited</b></td></tr><tr><td colspan="3">Fake news is a topic that has been discussed for quite some time. Prior to the internet era, it was mostly distributed through yellow journalism, with a focus on sensational news such as crime, rumours, accidents, and amusing news. To rescue the life of people from these fake news propagation, detection of fake news at an early stage becomes the most crucial step. People unknowingly propagate fake news and become a part of fake news propagation. While the original fake news propagators are the one with their aim to target innocent people for spreading the fake news. To stop this series of events, fake news detection and its pattern of propagation becomes very essential to society and the government. Various techniques exist to detect fake news in social media, among which neural networks have shown effective results. For this research, a deep learning based approach has been used to differentiate false news from the original ones. A LSTM neural network has been used to build the proposed model. Besides the neural network, a gloVe word embedding has been used for vector representation of textual words. Also, for feature extraction or vectorization, tokenization technique has been used. N-grams concept is used to enhance the proposed model. The comparative analysis of multiple fake news detection techniques is analysed. The results of proposed model have been evaluated using accuracy metrics. The model outperformed by achieving 99.88% of accuracy.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s10844-021-00646-9" target="_blank"> A comprehensive Benchmark for fake news detection<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85126769368</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Galli A., Masciari E., Moscato V., Sperli G.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Naples</b></td></tr><tr><td colspan="3">Nowadays, really huge volumes of fake news are continuously posted by malicious users with fraudulent goals thus leading to very negative social effects on individuals and society and causing continuous threats to democracy, justice, and public trust. This is particularly relevant in social media platforms (e.g., Facebook, Twitter, Snapchat), due to their intrinsic uncontrolled publishing mechanisms. This problem has significantly driven the effort of both academia and industries for developing more accurate fake news detection strategies: early detection of fake news is crucial. Unfortunately, the availability of information about news propagation is limited. In this paper, we provided a benchmark framework in order to analyze and discuss the most widely used and promising machine/deep learning techniques for fake news detection, also exploiting different features combinations w.r.t. the ones proposed in the literature. Experiments conducted on well-known and widely used real-world datasets show advantages and drawbacks in terms of accuracy and efficiency for the considered approaches, even in the case of limited content information.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s11042-022-12772-9" target="_blank"> Fake news detection system based on modified bi-directional long short term memory<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85126806421</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Agrawal C., Pandey A., Goyal S.</b></td></tr><tr><td colspan="3">Organisations: <b>University Institute of Technology Rajiv Gandhi Proudyogiki Vishwavidyalay (UIT - RGPV)</b></td></tr><tr><td colspan="3">The use of social media has increased tremendously during the past few decades and is considered one of the major sources of news. Social media don’t have the authority to verify the authenticity of the news and because of this, it is considered as a significant reason behind the spread of fake news. Many existing methods have been applied to detect fake news in social media and all those have the drawbacks of lower efficiency and overfitting problem. In this research, structural features with the Modified Bi-directional Long Short Term Memory (MBi-LSTM) method are proposed to improve the efficiency of Fake news detection. The attention layer is introduced in the Bi-LSTM to update the weight value of the input features and Term Frequency – Inverse Document Frequency (TF-IDF), based on the scalar factor. This weight value is updated in the input gate weight value of the Bi-LSTM that helps to find the relevant feature to store in cell. The proper weight in the Bi-LSTM model stores the features related to reliable information in long-term that helps to improves the classification performance. The structural, user, content, and temporal features were extracted from the Twitter data and applied to the MBi-LSTM method. 33 features were extracted for structural, user, content, and temporal features for the classification. The PolitiFact dataset is collected and used for testing the efficiency of the proposed MBi-LSTM method. Additionally, the CREDBANK dataset is also applied to test the effectiveness of the proposed MBi-LSTM method in the case of a large dataset. The experimental result shows that the proposed MBi-LSTM method has an accuracy of 91% and the Bi-LSTM method has an accuracy of 86.69% in PolitiFact’s dataset.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICMEAS52683.2021.9692374" target="_blank"> Fake News Detection in News Articles and Social Media Posts<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85126847221</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Aji M.M., Ohikere F.A., Kofo-Alada S., Nwodo T.A., Aiyelabegan F.A., Thomas S.</b></td></tr><tr><td colspan="3">Organisations: <b>Nile University of Nigeria</b></td></tr><tr><td colspan="3">With the introduction of the World Wide Web and the growing usage of social media platforms (such as Twitter and Facebook), information transmission leads to hoax information that has not been seen in history. With the emergence of social media such as Facebook, Twitter, Instagram, YouTube, WhatsApp and so on print media have decreased the function of print media such as television, radio, news channels and electronic media. In this transition the development of social media platforms has played a major influence. Social media reach is significantly larger than any other medium, e.g. every family has a single TV/radio/newspaper, but currently every member has access to technological gadgets. More rapidly, the sharing of information through social media has multiplied. Customers create more information and share more than ever, some of which are untruthful, by now using social media platforms. A task is to categorize a written article automatically as deceptive. Even a specialist in a certain area has to research various elements before evaluating whether the material is legitimate. This paper proposes a technique to identify counterfeit news articles by using Naïve Bayes classifier.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1016/j.matpr.2021.11.334" target="_blank"> Analysis of fake news detection using machine learning technique<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85126856287</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Seetharaman R., Tharun M., Sreeja Mole S.S., Anandan K.</b></td></tr><tr><td colspan="3">Organisations: <b>Anna University, Christu Jyothi Institute of Technology and Science, TUV SUD South Asia Pvt Ltd</b></td></tr><tr><td colspan="3">The advent of the World Wide Web and the fast reception of web-based media stages (like Facebook and Twitter) prepared for data scattering that has never been seen in mankind's set of experiences. With the current utilization of web-based media stages, buyers are making and sharing more data than any time in recent memory, some of which are misdirecting with no significance to the real world. Mechanized arrangement of a book article as falsehood or misinformation is a difficult errand. Indeed, even a specialist in a specific space needs to investigate numerous viewpoints prior to giving a decision on the honesty of an article. In this work, we propose to utilize an AI group approach for the computerized characterization of news stories. Our investigation investigates distinctive literary properties that can be utilized to separate phony substance from genuine. By utilizing those properties, we train a blend of various AI calculations utilizing different outfit strategies and assess their presentation on genuine world datasets. Trial assessment affirms the predominant presentation of our proposed gathering student approach in contrast with singular students.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICAC3N53548.2021.9725519" target="_blank"> Fake News Detection using Hybrid of Deep Neural Network and Stacked LSTM<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85126912562</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Narayan U., Kumar A., Kumar K.</b></td></tr><tr><td colspan="3">Organisations: <b>Dr. B R Ambedkar National Institute of Technology Jalandhar</b></td></tr><tr><td colspan="3">Fake News is one of the major concerns for the world and it could cause many problems like misleading people, the potential to influence people's opinions, etc. Hence distinguishing fake news is very crucial. Fake news can be detected using artificial intelligence methodologies using a title, body of the news, and other attributes such as credibility of the authors, location, media such as images, audio, and video, etc. In this paper, a hybrid of deep neural networks and stacked LSTM (Long Short-Term Memory) is used to detect fake news. We used Glove 300d as a word embedding layer and implemented the concept of stacked LSTM. The model has been applied to two different datasets. The results are compared with previous models and have found with good performance in comparison to the selected previously existing models.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/SCSET55041.2022.00019" target="_blank"> A CNN-RNN Based Fake News Detection Model Using Deep Learning<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85126951190</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Abbas Q., Zeshan M.U., Asif M.</b></td></tr><tr><td colspan="3">Organisations: <b>Tianjin University</b></td></tr><tr><td colspan="3">False news has become widespread in the last decade in political, economic, and social dimensions. This has been aided by the deep entrenchment of social media networking in these dimensions. Facebook and Twitter have been known to influence the behavior of people significantly. People rely on news/information posted on their favorite social media sites to make purchase decisions. Also, news posted on mainstream and social media platforms has a significant impact on a particular country's economic stability and social tranquility. Therefore, there is a need to develop a deceptive system that evaluates the news to avoid the repercussions resulting from the rapid dispersion of fake news on social media platforms and other online platforms. To achieve this, the proposed system uses the preprocessing stage results to assign specific vectors to words. Each vector assigned to a word represents an intrinsic characteristic of the word. The resulting word vectors are then applied to RNN models before proceeding to the LSTM model. The output of the LSTM is used to determine whether the news article/piece is fake or otherwise.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICAC3N53548.2021.9725560" target="_blank"> Detecting Fake News using Machine Learning Algorithms<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85126960622</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Chaturvedi S., Saxena A., Gupta A., Alam F.</b></td></tr><tr><td colspan="3">Organisations: <b>Galgotias University</b></td></tr><tr><td colspan="3">The problem of fake news has become one of the most complicated issues facing society. Nowadays, via social media, false information will spread easily. In this respect, fake news needs to be identified as soon as possible to prevent adverse effects on individuals who may rely on such knowledge when making important decisions (e.g., presidential elections). In this post, we present a groundbreaking approach that utilises machine learning methods for fake news detection. Our studies show that the proposed approach uses the passive aggressive algorithm for correct result classification, such an algorithm remains passive and when there is a miscalculation, it becomes active, updating and adjusting. The aim is to make changes that correct the error, making very little changes to the outcomes and enables us to achieve promising outcomes. As per the studies and test performed the accuracy of this solution is about 96%.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICAC3N53548.2021.9725484" target="_blank"> Fake News Detection: Needs for Individuals and Businesses in the time of Covid-19 and its Future Applications<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85126965789</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Jha S., Gupta S.N., Gupta V., Tiwari P.</b></td></tr><tr><td colspan="3">Organisations: <b>Greater Noida Institute of Technology</b></td></tr><tr><td colspan="3">Today social media plays a very important role in everyone life through which we create online communities to share every kind of information. No one can be one sure about the news they are receiving is true or not? In India, WhatsApp has limited that a person cannot forward a text to more than 5 people at once [1]. This was done to curb the rise of false information. In this paper a machine learning models is create to segregate false and real news. A performance comparison for all the model has been performed in the terms of accuracy. The present article also explores the application of the fake news detector in the real world application.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.15849/IJASCA.220328.04" target="_blank"> Empirical Evaluation of Machine Learning Classification Algorithms for Detecting COVID-19 Fake News<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85126999805</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Alsaidi H., Etaiwi W.</b></td></tr><tr><td colspan="3">Organisations: <b>Princess Sumaya University for Technology</b></td></tr><tr><td colspan="3">Humans have been fighting the Covid19 pandemic since it started, not just to protect their wellbeing but also to counteract the news and rumors that have been spreading about it. Rumors and false allegations can be almost as dangerous as the virus, as they affect people's mental health and increase their stress levels. To address this problem, several machine learning techniques could be used to detect fake news. In this paper, four different machine learning algorithms are compared according to their ability to detect fake news, including Naive Bayes, Decision Tree, Support Vector Machines, and Logistic Regression. A dataset of annotated news is used in the experiments. The experimental results show that Naïve Bayes outperforms other algorithms in terms of accuracy, precision, recall, and F1 score.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="_" target="_blank"> Stance Detection in German News Articles<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85127050638</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Mascarell L., Ruzsics T., Schneebeli C., Schlattner P., Campanella L., Klingler S., Kadar C.</b></td></tr><tr><td colspan="3">Organisations: <b>ETH Zurich, Neue Zürcher Zeitung</b></td></tr><tr><td colspan="3">The widespread use of the Internet and the rapid dissemination of information poses the challenge of identifying the veracity of its content. Stance detection, which is the task of predicting the position of a text in regard to a specific target (e.g. claim or debate question), has been used to determine the veracity of information in tasks such as rumor classification and fake news detection (Küçük and Can, 2020). While most of the work and available datasets for stance detection address short texts snippets extracted from textual dialogues, social media platforms, or news headlines with a strong focus on the English language, there is a lack of resources targeting long texts in other languages. Our contribution in this paper is twofold. First, we present a German dataset of debate questions and news articles that is manually annotated for stance and emotion detection. Second, we leverage the dataset to tackle the supervised task of classifying the stance of a news article with regards to a debate question and provide baseline models as a reference for future work on stance detection in German news articles.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/SYNASC54541.2021.00051" target="_blank"> A Novel Method for COVID-19 Pandemic Information Fake News Detection Based on the Arithmetic Optimization Algorithm<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85127061662</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Zivkovic M., Petrovic A., Bacanin N., Strumberger I., Stoean C., Zivkovic T.</b></td></tr><tr><td colspan="3">Organisations: <b>Singidunum University, University of Craiova, University of Belgrade</b></td></tr><tr><td colspan="3">The problem of fake news on the Internet is not new. However, in the case of a global pandemic, this kind of misinformation can be dangerous, confusing, and costly in terms of the loss of human lives. The ongoing COVID-19 pandemic has unfortunately shown the significant and remarkable spread of fake news, concerning the disease itself, vaccination, number of deaths, and so on. It is necessary to develop an effective algorithm that will be able to detect COVID-19 misinformation and help scientists to easily separate fake from true news. The research presented in this paper proposes an arithmetic optimization algorithm (AOA)-based approach that can improve the classification results by reducing the number of features and achieve high accuracy. The AOA has been utilized as a wrapper feature selection. The obtained simulation results were subject to a comparative analysis with both world-class classifiers and other nature-inspired evolutionary approaches. The results of the simulation indicate better performance of the proposed approach with AOA over other algorithms and demonstrate that it obtains superior accuracy.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-3-030-98305-5_6" target="_blank"> FakeRecogna: A New Brazilian Corpus for Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85127101959</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Garcia G.L., Afonso L.C.S., Papa J.P.</b></td></tr><tr><td colspan="3">Organisations: <b>São Paulo State University</b></td></tr><tr><td colspan="3">Fake news has become a research topic of great importance in Natural Language Processing due to its negative impact on our society. Although its pertinence, there are few datasets available in Brazilian Portuguese and mostly comprise few samples. Therefore, this paper proposes creating a new fake news dataset named FakeRecogna that contains a greater number of samples, more up-to-date news, and covering a few of the most important categories. We perform a toy evaluation over the created dataset using traditional classifiers such as Naive Bayes, Optimum-Path Forest, and Support Vector Machines. A Convolutional Neural Network is also evaluated in the context of fake news detection in the proposed dataset.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1111/exsy.13008" target="_blank"> Deep transfer learning for COVID-19 fake news detection in Persian<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85127413653</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Ghayoomi M., Mousavian M.</b></td></tr><tr><td colspan="3">Organisations: <b>Institute for Humanities and Cultural Studies, Amirkabir University of Technology</b></td></tr><tr><td colspan="3">The spread of fake news on social media has increased dramatically in recent years. Hence, fake news detection systems have received researchers' attention globally. During the COVID-19 outbreak in 2019 and the worldwide epidemic, the importance of this issue becomes more apparent. Due to the importance of the issue, a large number of researchers have begun to collect English datasets and to study COVID-19 fake news detection. However, there are a large number of low-resource languages, including Persian, that cannot develop accurate tools for automatic COVID-19 fake news detection due to the lack of annotated data for the task. In this article, we aim to develop a corpus for Persian in the domain of COVID-19 where the fake news is annotated and to provide a model for detecting Persian COVID-19 fake news. With the impressive advancement of multilingual pre-trained language models, the idea of cross-lingual transfer learning can be proposed to improve the generalization of models trained with low-resource language datasets. Accordingly, we use the state-of-the-art deep cross-lingual contextualized language model, XLM-RoBERTa, and the parallel convolutional neural networks to detect Persian COVID-19 fake news. Moreover, we use the idea of knowledge transferring across-domains to improve the results by using both the English COVID-19 dataset and the general domain Persian fake news dataset. The combination of both cross-lingual and cross-domain transfer learning has outperformed the models and it has beaten the baseline by 2.39% significantly.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/CISAI54367.2021.00148" target="_blank"> A Discriminative Deep Neural Network for Text Classification<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85127443323</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Gao J., Li X., Huang Z.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Ottawa, Wake Forest University</b></td></tr><tr><td colspan="3">Text classification plays an important role in natural language processing. It has been widely applied to sentiment analysis, stance detection and fake news detection. Although previous work on text classification has made great progress in recent years, these methods do not consider discriminative. And the ignoration degrades the performance of text classification. Hence, this paper proposes a novel CNN-based method, which incorporates the power of discriminative by adding an extra regularization term. We conduct experiments on three datasets, and the results demonstrate that our model is superior to other popular text classification methods.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICCKE54056.2021.9721509" target="_blank"> The Process of Multi-Class Fake News Dataset Generation<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85127464454</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Rezaei S., Kahani M., Behkamal B.</b></td></tr><tr><td colspan="3">Organisations: <b>Ferdowsi University</b></td></tr><tr><td colspan="3">Nowadays, news plays a significant role in everyday life. Due to the increasing usage of social media and the dissemination of news by people who have access to social media, there is a problem that the validation of the news may be questioned, and people may publish fake news for their benefit. Automatic fake news detection is a complex issue. It is necessary to have up-to-date and reliable data to build an efficient model for detection. However, there are very few such datasets available for researchers. In this paper, we proposed a new fake news dataset extracted from three famous and reliable fact-checking websites. Because of the different labels used in each site, an algorithm was developed to integrated these 37 labels into five unified labels. Some experiments were conducted to show the usability and validity of the dataset.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICCKE54056.2021.9721441" target="_blank"> A Novel Method for Fake News Detection Based on Propagation Tree<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85127502388</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Davoudi M., Moosavi M.R., Sadreddini M.H.</b></td></tr><tr><td colspan="3">Organisations: <b>Shiraz University</b></td></tr><tr><td colspan="3">Nowadays, online social media platforms are playing an increasingly important role in news broadcasting. Social media platforms may quickly produce massive amounts of misleading information, altering public opinion and allowing malicious groups to manipulate public events like elections.In this paper, we offer a new methodology for detecting fake news that is based on studying the propagation tree over time. To this aim, we continuously extract related features from the constructed propagation trees. A type of recurrent neural network (LSTM) is utilized to capture the temporal dynamics of extracted features and detect the model of development of the propagation tree over time in order to estimate the validity of a news article.The FakeNewsNet repository is utilized to test our proposed model, which comprises two recent well-known datasets in the field, PolitiFact and GossipCop. On the PolitiFact and GossipCop datasets, our results indicate promising results, surpassing state-of-the-art approaches by 2.3% and 1.2%, respectively.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3510249.3510301" target="_blank"> Fake News Detection on Social Media: Case Study of 2019 Novel Coronavirus<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85127515136</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Kowirat R., Boongasame L.</b></td></tr><tr><td colspan="3">Organisations: <b>King Mongkut's Institute of Technology Ladkrabang</b></td></tr><tr><td colspan="3">Fake news is news that is created with the intent to deceive and mislead readers. It is a problem that occurs in every era because it creates misunderstandings for people through a variety of media channels such as newspapers, radio, or television. Nowadays, fake news has become a big problem. When social media has become another channel to increase the spread of fake news and came to play a big role during the epidemic like COVID-19. Fake news creates panic and creates false knowledge of how to protect yourself from COVID-19. Therefore, the objective of this research is to create a method that can detect fake news on social media. It focuses only on news related to COVID-19. In addition, the information was extracted directly from social media such as Twitter. Moreover, this research applying machine learning processes to classify real and fake news. From the experimental results, the accuracy was measured at 99.92% with the Decision Tree model.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/Confluence52989.2022.9734129" target="_blank"> Classifying Fake News Detection Using SVM, Naive Bayes and LSTM<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85127572227</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Jain P., Sharma S., Monica, Aggarwal P.K.</b></td></tr><tr><td colspan="3">Organisations: <b>Kiet Group Of Institutions, Abes Engineering College</b></td></tr><tr><td colspan="3">Web-primarily based media is a stage to state one's perspectives and viewpoints unreservedly and has made correspondence simpler than it became previously. This moreover opens up a risk for people to get out counterfeit phrase intentionally. The trustworthy entry to an collection of statistics sources on the net likewise brings the issue of people being provided to counterfeit facts and doubtlessly accepting such information. This makes it considerable for us to understand furthermore, banner such substance through on-line media. With the modem-day tempo of information created via online media, it's far hard to split between certifiable information and fabrications without knowing the wellspring of the news. In this paper, we propose various techniques to verify that the collected news is fake or not. For this, the approach named Natural Language Processing (NLP) is used. Various other methodologies like text classification, classification modeling is also used, and analysis of results has been done. Data from various sources was collected and to verify that the news is correct or not various techniques like SVM, Naive Bayes LSTM are used.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1145/3517214" target="_blank"> FANG: Leveraging Social Context for Fake News Detection Using Graph Representation<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85127572465</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Nguyen V.-H., Kan M.-Y., Sugiyama K., Nakov P.</b></td></tr><tr><td colspan="3">Organisations: <b>National University of Singapore, Kyoto University, Qatar Computing Research Institute</b></td></tr><tr><td colspan="3">We propose Factual News Graph (FANG), a novel graphical social context representation and learning framework for fake news detection. Unlike previous contextual models that have targeted performance, our focus is on representation learning. Compared to transductive models, FANG is scalable in training as it does not have to maintain the social entities involved in the propagation of other news and is efficient at inference time, without the need to reprocess the entire graph. Our experimental results show that FANG is better at capturing the social context into a high-fidelity representation, compared to recent graphical and nongraphical models. In particular, FANG yields significant improvements for the task of fake news detection and is robust in the case of limited training data. We further demonstrate that the representations learned by FANG generalize to related tasks, such as predicting the factuality of reporting of a news medium.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/Confluence52989.2022.9734144" target="_blank"> COVID-19 Fake News Detection System<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85127573878</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Malhotra R., Mahur A., Achint</b></td></tr><tr><td colspan="3">Organisations: <b>Delhi Technological University</b></td></tr><tr><td colspan="3">This article deals with the problem of the rapidly increasing COVID-19 infodemic in the world. Thus, there is a need for an effective framework of detecting fake information or misleading news related to COVID-19 virus/disease. To resolve this, we have used a dataset obtained from ConstraintAI'21. The dataset consists of 10,700 tweets and online posts of fake and real news concerning COVID-19. Machine Learning (ML) algorithms compared in this paper to classify the given news or tweet into real or fake are Logistic Regression (LR), K-Nearest Neighbor (KNN), Linear Support Vector Machine (LSVM), Random Forest Classifier (RFC), Decision Tree (DT), Naive Bayes (NB) and Stochastic Gradient Descent (SGD) algorithm. Two feature extraction techniques were used count vectorization and TF-IDF. Deep Learning (DL) algorithms implemented using Adam optimizer are Recurrent Neural Network (RNN), Long Short-Term Memory (LSTM), and Gated Recurrent Unit (GRU). The best testing accuracy was achieved with the LSVM model using TF-IDF feature extraction method followed by Stochastic Gradient Descent classifier with TF-IDF feature extraction technique. LR, DT, and RFC performed better with the Count vectorization feature extraction technique, whereas LSVM, KNN, NB and SGD had better accuracy with TF-IDF feature extraction technique. The LSTM model performed slightly better among the DL algorithms.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/Confluence52989.2022.9734180" target="_blank"> Fake News Detection: GA-Transformer And IG-Transformer Based Approach<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85127587033</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Ranjan V., Agrawal P.</b></td></tr><tr><td colspan="3">Organisations: <b>Maulana Azad National Institute Of Technology</b></td></tr><tr><td colspan="3">A significant part of the information available on the internet is fake news which is generated to influence the decision of individuals politically and socially. Detecting fake news from social media has become a very important problem. It can be done either manually or by using Deep Learning. In this work, we focus on detecting fake news with Transformer models of Deep Learning. We analyze the performance of Transformer models like BERT, XLNet, RoBERTa, and Longformer. We also propose two novel approaches by combining Information Gain and Genetic Algorithm with all these models for further improving their results. The models based on our proposed approaches show better results than the previous models. Among all the models, Longformer and RoBERTa using Genetic Algorithm give the best result when 80% unique keywords are used. The micro average F1-score of both methods is 0.62. Our proposed approaches also reduce the training text dimension due to which computing time for training the models reduce too.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.3390/info13030151" target="_blank"> Automatic Fake News Detection for Romanian Online News<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85127603482</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Buzea M.C., Trausan-Matu S., Rebedea T.</b></td></tr><tr><td colspan="3">Organisations: <b>University Politehnica of Bucharest, Research Institute for Artificial Intelligence “Mihai Draganescu” of the Romanian Academy</b></td></tr><tr><td colspan="3">This paper proposes a supervised machine learning system to detect fake news in online sources published in Romanian. Additionally, this work presents a comparison of the obtained results by using recurrent neural networks based on long short-term memory and gated recurrent unit cells, a convolutional neural network, and a Bidirectional Encoder Representations from Transformers (BERT) model, namely RoBERT, a pre-trained Romanian BERT model. The deep learning architectures are compared with the results achieved by two classical classification algorithms: Naïve Bayes and Support Vector Machine. The proposed approach is based on a Romanian news corpus containing 25,841 true news items and 13,064 fake news items. The best result is over 98.20%, achieved by the convolutional neural network, which outperforms the standard classification methods and the BERT models. Moreover, based on irony detection and sentiment analysis systems, additional details are revealed about the irony phenomenon and sentiment analysis field which are used to tackle fake news challenges.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICONAT53423.2022.9725937" target="_blank"> A Proposed Bi-LSTM Method to Fake News Detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85127611553</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Islam T., Hosen M.D.A., Mony A., Hasan M.D.T., Jahan I., Kundu A.</b></td></tr><tr><td colspan="3">Organisations: <b>Daffodil International University</b></td></tr><tr><td colspan="3">Recent years have seen an explosion in social media usage, allowing people to connect with others. Since the appearance of platforms such as Facebook and Twitter, such platforms influence how we speak, think, and behave. This problem negatively undermines confidence in content because of the existence of fake news. For instance, false news was a determining factor in influencing the outcome of the U.S. presidential election and other sites. Because this information is so harmful, it is essential to make sure we have the necessary tools to detect and resist it. We applied Bidirectional Long Short-Term Memory (Bi-LSTM) to determine if the news is false or real in order to showcase this study. A number of foreign websites and newspapers were used for data collection. After creating running the model, the work achieved 84% model accuracy and 62.0 F1-macro scores with training data.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICONAT53423.2022.9725933" target="_blank"> Blockchains to curb Fake News in an Online World<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85127615818</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Wahane A., Patil B.</b></td></tr><tr><td colspan="3">Organisations: <b>MIT World Peace University</b></td></tr><tr><td colspan="3">Fake news has become a significant problem in today's online world. Misinformation is easily propagated through online social media platforms. It is essential to curb the spread of fake news. Blockchain has provided a framework for tamperproof and traceable data, and can therefore be used for developing a news platform. Applying blockchain technology to news tracing has formed the groundwork for supressing the spread of fake news. However, the scale of online platforms and the characteristics of blockchain add several new challenges that hinder the real world deployment of such solutions. This study reviews various blockchain based methods that combat the spread of fake news on online platforms and discusses the challenges faced in realizing such solutions.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ICCSS53909.2021.9721975" target="_blank"> Veracity: A Fake News Detection Architecture for MANET Messaging<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85127693425</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Ramkissoon A.N., Goodridge W.</b></td></tr><tr><td colspan="3">Organisations: <b>The University of the West Indies at St Augustine</b></td></tr><tr><td colspan="3">Mobile Ad Hoc Network Messaging has become an integral part of today's social communication landscape. They are used in a variety of applications. One major problem that these networks face is the spread of fake news. This problem can have serious deleterious effects on our social data driven society. Detecting fake news has proven to be challenging even for modern day algorithms. This research presents, Veracity, a unique computational social system to accomplish the task of Fake News Detection in MANET Messaging. The Veracity architecture attempts to model social behaviour and human reactions to news spread over a MANET. Veracity introduces five new algorithms namely, VerifyNews, CompareText, PredictCred, CredScore and EyeTruth for the capture, computation and analysis of the credibility and content data features. The Veracity architecture works in a fully distributed and infrastructureless environment. This study validates Veracity using a generated dataset with features relating to the credibility of news publishers and the content of the message to predict fake news. These features are analysed using a machine learning prediction model. The results of these experiments are analysed using four evaluation methodologies. The analysis reveals positive performance with the use of the fake news detection architecture.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s11042-022-12668-8" target="_blank"> Evaluating the effectiveness of publishers’ features in fake news detection on social media<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85127750071</td><td>Year: <b>2023</b></td></tr><tr><td colspan="3">Authors: <b>Jarrahi A., Safari L.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Zanjan</b></td></tr><tr><td colspan="3">With the expansion of the Internet and attractive social media infrastructures, people prefer to follow the news through these media. Despite the many advantages of these media in the news field, the lack of control and verification mechanism has led to the spread of fake news as one of the most critical threats to democracy, economy, journalism, health, and freedom of expression. So, designing and using efficient automated methods to detect fake news on social media has become a significant challenge. One of the most relevant entities in determining the authenticity of a news statement on social media is its publishers. This paper examines the publishers’ features in detecting fake news on social media, including Credibility, Influence, Sociality, Validity, and Lifetime. In this regard, we propose an algorithm, namely CreditRank, for evaluating publishers’ credibility on social networks. We also suggest a high accurate multi-modal framework, namely FR-Detect, for fake news detection using user-related and content-related features. Furthermore, a sentence-level convolutional neural network is provided to properly combine publishers’ features with latent textual content features. Experimental results show that the publishers’ features can improve the performance of content-based models by up to 16% and 31% in accuracy and F1, respectively. Also, the behavior of publishers in different news domains has been statistically studied and analyzed.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/ACCESS.2022.3165226" target="_blank"> Conspiracy or Not? A Deep Learning Approach to Spot It on Twitter<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85127753035</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Galende B.A., Hernandez-Penaloza G., Uribe S., Garcia F.A.</b></td></tr><tr><td colspan="3">Organisations: <b>Universidad Politécnica de Madrid</b></td></tr><tr><td colspan="3">Sentiment analysis is an active topic in Natural Language Processing (NLP). It has attracted a significant interest of research community due to the wide range of applications, including social-media, fake news spotting and interactive applications. In this paper, we present a novel approach for semi-automatic background creation and conspiracy classification. For this purpose, a complete framework including novel recurrent models is proposed. The BORJIS: Best algorithm foR Joint conspiracy and sarcasm detection has been tested on twitter-crawled data and It is composed by: (a) the crawler and labelling module, (b) the features vector extraction and (c) the conspiracy classifier. BORJIS was compared with up-to-date techniques and it showed a significant improvement (≥ 10% accuracy) when applied to diverse datasets.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/s42979-021-00775-6" target="_blank"> Thai Fake News Detection Based on Information Retrieval, Natural Language Processing and Machine Learning<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85127830832</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Meesad P.</b></td></tr><tr><td colspan="3">Organisations: <b>King Mongkut’s University of Technology North Bangkok</b></td></tr><tr><td colspan="3">Fake news is a big problem in every society. Fake news must be detected and its sharing should be stopped before it causes further damage to the country. Spotting fake news is challenging because of its dynamics. In this research, we propose a framework for robust Thai fake news detection. The framework comprises three main modules, including information retrieval, natural language processing, and machine learning. This research has two phases: the data collection phase and the machine learning model building phase. In the data collection phase, we obtained data from Thai online news websites using web-crawler information retrieval, and we analyzed the data using natural language processing techniques to extract good features from web data. For comparison, we selected some well-known classification Machine Learning models, including Naïve Bayesian, Logistic Regression, K-Nearest Neighbor, Multilayer Perceptron, Support Vector Machine, Decision Tree, Random Forest, Rule-Based Classifier, and Long Short-Term Memory. The comparison study on the test set showed that Long Short-Term Memory was the best model, and we deployed an automatic online fake news detection web application.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1007/978-981-16-9423-3_31" target="_blank"> Fake News Detection Based on Attention Mechanism and Convolutional Neural Network<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85127865651</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Wang F., Zhang H., Cheng R., Xu P.W.R.</b></td></tr><tr><td colspan="3">Organisations: <b>Xinjiang Normal University</b></td></tr><tr><td colspan="3">The rapid development of social media has made Internet news flood all aspects of our lives, and also facilitated the spread of fake news, so it is important to detect fake news to reduce social impact. In this paper, we propose a fake news detection method based on the combination of attention mechanism and convolutional neural network, which obtains the internal relationship of sentences by self-attention mechanism, and then uses convolutional neural network to process the extracted features for classification. In order to verify the effectiveness of the model, this model is experimented on three different public datasets, and good detection results are achieved under ten-fold cross-validation.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/CDMA54072.2022.00021" target="_blank"> A comparative analysis of Graph Neural Networks and commonly used machine learning algorithms on fake news detection<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85127881783</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Mahmud F.B., Rayhan M.M.S., Shuvo M.H., Sadia I., Morol M.K.</b></td></tr><tr><td colspan="3">Organisations: <b>American International University-Bangladesh (AIUB)</b></td></tr><tr><td colspan="3">Fake news on social media is increasingly regarded as one of the most concerning issues. Low cost, simple accessibility via social platforms, and a plethora of low-budget online news sources are some of the factors that contribute to the spread of false news. Most of the existing fake news detection algorithms are solely focused on the news content only but engaged users' prior posts or social activities provide a wealth of information about their views on news and have significant ability to improve fake news identification. Graph Neural Networks are a form of deep learning approach that conducts prediction on graph-described data. Social media platforms are followed graph structure in their representation, Graph Neural Network are special types of neural networks that could be usually applied to graphs, making it much easier to execute edge, node and graph-level prediction. Therefore, in this paper, we present a comparative analysis among some commonly used machine learning algorithms and Graph Neural Networks for detecting the spread of false news on social media platforms. In this study, we take the UPFD dataset and implement several existing machine learning algorithms on text data only. Besides this, we create different GNN layers for fusing graph-structured news propagation data and the text data as the node feature in our GNN models. GNNs provide the best solutions to the dilemma of identifying false news in our research.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1109/CSDE53843.2021.9718487" target="_blank"> A Performance Comparison of Fake News Detection Approaches<a></b></td></tr><tr><td>Type: Conf</td><td>ID: S_2-s2.0-85127900545</td><td>Year: <b>2021</b></td></tr><tr><td colspan="3">Authors: <b>Zhu H., Sinnott R.O.</b></td></tr><tr><td colspan="3">Organisations: <b>The University of Melbourne</b></td></tr><tr><td colspan="3">Fake news occurs when a news article is intentionally released and subsequently shown to be false. This can negatively impact on an individual's or indeed society's comprehension of topics and shape public opinion on major events, e.g. elections. With the ubiquity of social media and fake news websites, people are increasingly exposed to fake news. In this article, we explore and compare the performance of fake news detection approaches using both machine and deep learning methods. Specifically we explore Logistic Regression, Support Vector Machines (SVM), Recurrent Neural Networks (RNN), Long Short Term Memory (LSTM) and Bidirectional Encoder Representations from Transformers (BERT) and compare the results with human crowds ability to distinguish real vs fake news. We utilise over 8.5m records from FakeNewsCorpus and 23k records from FakeNewsNet. The results shown that BERT achieved the best overall accuracy at 82.5%. Groups of individual assessors achieved an accuracy of 79%, whilst individuals varied significantly between 60-80% in their ability to distinguish real vs fake news.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.1155/2022/1575365" target="_blank"> Analyzing Machine Learning Enabled Fake News Detection Techniques for Diversified Datasets<a></b></td></tr><tr><td>Type: Review</td><td>ID: S_2-s2.0-85128212354</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Mishra S., Shukla P., Agarwal R.</b></td></tr><tr><td colspan="3">Organisations: <b>LNCT, DoCSEUIT-RGPV</b></td></tr><tr><td colspan="3">Fake news, or fabric which appeared to be untrue with point of deceiving the open, has developed in ubiquity in current a long time. Spreading this kind of data undermines societal cohesiveness and well by cultivating political division and doubt in government. Since of the sheer volume of news being disseminated through social media, human confirmation has ended up incomprehensible, driving to the improvement and arrangement of robotized strategies for the recognizable proof of wrong news. Fake news publishers use a variety of stylistic techniques to boost the popularity of their works, one of which is to arouse the readers' emotions. Due to this, text analytics' sentiment analysis, which determines the polarity and intensity of feelings conveyed in a text, is now being utilized in false news detection methods, as either the system's foundation or as a supplementary component. This assessment analyzes the full explanation of false news identification. The study also emphasizes characteristics, features, taxonomy, different sorts of data in the news, categories of false news, and detection approaches for spotting fake news. This research recognized fake news using the probabilistic latent semantic analysis approach. In particular, the research describes the fundamental theory of the related work to provide a deep comparative analysis of various literature works that has contributed to this topic. Besides this, a comparison of different machine learning and deep learning techniques is done to assess the performance for fake news detection. For this purpose, three datasets have been used.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.3233/JIFS-219251" target="_blank"> Fake News detection using n-grams for PAN@CLEF competition<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85128228359</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Damian S., Calvo H., Gelbukh A.</b></td></tr><tr><td colspan="3">Organisations: <b>Instituto Politécnico Nacional</b></td></tr><tr><td colspan="3">The paper presents a classifier for fake news spreaders detection in social media. Detecting fake news spreaders is an important task because this kind of disinformation aims to change the reader's opinion about a relevant topic for the society. This work presents a classifier that can compete with the ones that are found in the state-of-the-art. In addition, this work applies Explainable Artificial Intelligence (XIA) methods in order to understand the corpora used and how the model estimates results. The work focuses on the corpora developed by members of the PAN@CLEF 2020 competition. The score obtained surpasses the state-of-the-art with a mean accuracy score of 0.7825. The solution uses XIA methods for the feature selection process, since they present more stability to the selection than most of traditional feature selection methods. Also, this work concludes that the detection done by the solution approach is generally based on the topic of the text.</td></tr><tr><td colspan="3" style="background:#CCCCCC"><b><a href="http://doi.org/10.3233/JIFS-219266" target="_blank"> Anbar: Collection and analysis of a large scale Urdu language Twitter corpus<a></b></td></tr><tr><td>Type: Article</td><td>ID: S_2-s2.0-85128243024</td><td>Year: <b>2022</b></td></tr><tr><td colspan="3">Authors: <b>Tahir B., Mehmood M.A.</b></td></tr><tr><td colspan="3">Organisations: <b>University of Engineering and Technology</b></td></tr><tr><td colspan="3">The confluence of high performance computing algorithms and large scale high-quality data has led to the availability of cutting edge tools in computational linguistics. However, these state-of-the-art tools are available only for the major languages of the world. The preparation of large scale high-quality corpora for low-resource language such as Urdu is a challenging task as it requires huge computational and human resources. In this paper, we build and analyze a large scale Urdu language Twitter corpus Anbar. For this purpose, we collect 106.9 million Urdu tweets posted by 1.69 million users during one year (September 2018-August 2019). Our corpus consists of tweets with a rich vocabulary of 3.8 million unique tokens along with 58K hashtags and 62K URLs. Moreover, it contains 75.9 million (71.0%) retweets and 847K geotagged tweets. Furthermore, we examine Anbar using a variety of metrics like temporal frequency of tweets, vocabulary size, geo-location, user characteristics, and entities distribution. To the best of our knowledge, this is the largest repository of Urdu language tweets for the NLP research community which can be used for Natural Language Understanding (NLU), social analytics, and fake news detection.</td></tr></tbody></table></body></html>